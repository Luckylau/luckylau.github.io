<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Openstack 负载均衡LoadBalancerv2]]></title>
      <url>%2F2017%2F03%2F07%2FOpenstack%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1LoadBalancerv2%2F</url>
      <content type="text"><![CDATA[​ 最近研究了一下Openstack负载均衡，yum源和源码级别的安装都尝试成功了。网上有很多文章都是LoadBalancerv1，这个已经被放弃了。所以写一下自己是如何使用LoadBalancerv2。当然在介绍之前还是从负载均衡基础知识开始吧。 负载均衡的概念？负载均衡有哪些重要厂商？负载均衡部署模式？LoadBalancerv2初体验？参考：https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html http://www.cnblogs.com/sammyliu/p/4656176.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python yield 使用浅析]]></title>
      <url>%2F2017%2F03%2F06%2FPython-yield-%E4%BD%BF%E7%94%A8%E6%B5%85%E6%9E%90%2F</url>
      <content type="text"><![CDATA[yield的概念？1.简单的斐波那契數列第一版： 12345678def fab(max): n, a, b = 0, 0, 1 while n &lt; max: print b a, b = b, a + b n = n + 1if __name__ == '__main__': fab(5) 缺点：直接在 fab 函数中用 print 打印数字会导致该函数可复用性较差，因为 fab 函数返回 None，其他函数无法获得该函数生成的数列。 2.简单的斐波那契數列第二版： 1234567891011def fab(max): n, a, b = 0, 0, 1 L = [] while n &lt; max: L.append(b) a, b = b, a + b n = n + 1 return Lif __name__ == '__main__': for n in fab(5): print n 缺点：该函数在运行中占用的内存会随着参数 max 的增大而增大，如果要控制内存占用，最好不要用 List。 3.简单的斐波那契數列第三版： 根据range与xrange的思想设计： 123456789101112131415161718class Fab(object): def __init__(self,max): self.max=max self.n,self.a,self.b=0,0,1 def __iter__(self): return self def next(self): if self.n&lt;self.max: r=self.b self.a, self.b = self.b, self.a + self.b self.n=self.n+1 return r raise StopIterationif __name__ == '__main__': for n in Fab(5): print n 缺点：代码远远没有第一版的 fab 函数来得简洁。 如果我们想要保持第一版 fab 函数的简洁性，同时又要获得 iterable 的效果，yield 就派上用场了。 123456789def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': for n in fab(5): print n ​ yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator，调用 fab(5) 不会执行 fab 函数，而是返回一个 iterable 对象！在 for 循环执行时，每次循环都会执行 fab 函数内部的代码，执行到 yield b 时，fab 函数就返回一个迭代值，下次迭代时，代码从 yield b 的下一条语句继续执行，而函数的本地变量看起来和上次中断执行前是完全一样的，于是函数继续执行，直到再次遇到 yield。 12345678910111213def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': f=fab(5) print (f.next()) print (f.next()) print (f.next()) print (f.next()) print (f.next()) 一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。比如在读取文件时候很好使用的。 123456789def read_file(fpath): BLOCK_SIZE = 1024 with open(fpath, 'rb') as f: while True: block = f.read(BLOCK_SIZE) if block: yield block else: return yield的源码分析？在解释生成器之前，需要讲解一下Python虚拟机的调用原理。 1234567891011121314151617181920212223242526272829303132333435typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* code segment */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* points after the last local */ /* Next free slot in f_valuestack. Frame creation sets to f_valuestack. Frame evaluation usually NULLs it, but a frame that yields sets it to the current stack top. */ PyObject **f_stacktop; PyObject *f_trace; /* Trace function */ /* If an exception is raised in this frame, the next there are used to * record the exception info (if any) originally in the thread state. See * comments before set_exc_info() -- it's not obvious. * Invariant: if _type is NULL, then so are _value and _traceback. * Desired invariant: all three are NULL, or all three are non-NULL. That * one isn't currently true, but "should be". */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; PyThreadState *f_tstate; int f_lasti; /* Last instruction if called */ /* Call PyFrame_GetLineNumber() instead of reading this field directly. As of 2.3 f_lineno is only valid when tracing is active (i.e. when f_trace is set). At other times we use PyCode_Addr2Line to calculate the line from the current bytecode index. */ int f_lineno; /* Current line number */ int f_iblock; /* index in f_blockstack */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */&#125; PyFrameObject; 生成器的源码在Objects/genobject.c 12345678910111213141516PyObject *PyGen_New(PyFrameObject *f)&#123; PyGenObject *gen = PyObject_GC_New(PyGenObject, &amp;PyGen_Type); # 创建生成器对象 if (gen == NULL) &#123; Py_DECREF(f); return NULL; &#125; gen-&gt;gi_frame = f; # 赋予代码块 Py_INCREF(f-&gt;f_code); # 引用计数+1 gen-&gt;gi_code = (PyObject *)(f-&gt;f_code); gen-&gt;gi_running = 0; # 0表示为执行，也就是生成器的初始状态 gen-&gt;gi_weakreflist = NULL; _PyObject_GC_TRACK(gen); # GC跟踪 return (PyObject *)gen;&#125; send与next 123456789101112static PyObject *gen_iternext(PyGenObject *gen)&#123; return gen_send_ex(gen, NULL, 0);&#125;static PyObject *gen_send(PyGenObject *gen, PyObject *arg)&#123; return gen_send_ex(gen, arg, 0);&#125; 从上面的代码中可以看到，send和next都是调用的同一函数gen_send_ex，区别在于是否带有参数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static PyObject *gen_send_ex(PyGenObject *gen, PyObject *arg, int exc)&#123; PyThreadState *tstate = PyThreadState_GET(); PyFrameObject *f = gen-&gt;gi_frame; PyObject *result; if (gen-&gt;gi_running) &#123; # 判断生成器是否已经运行 PyErr_SetString(PyExc_ValueError, "generator already executing"); return NULL; &#125; if (f==NULL || f-&gt;f_stacktop == NULL) &#123; # 如果代码块为空或调用栈为空，则抛出StopIteration异常 /* Only set exception if called from send() */ if (arg &amp;&amp; !exc) PyErr_SetNone(PyExc_StopIteration); return NULL; &#125; if (f-&gt;f_lasti == -1) &#123; # f_lasti=1 代表首次执行 if (arg &amp;&amp; arg != Py_None) &#123; # 首次执行不允许带有参数 PyErr_SetString(PyExc_TypeError, "can't send non-None value to a " "just-started generator"); return NULL; &#125; &#125; else &#123; /* Push arg onto the frame's value stack */ result = arg ? arg : Py_None; Py_INCREF(result); # 该参数引用计数+1 *(f-&gt;f_stacktop++) = result; # 参数压栈 &#125; /* Generators always return to their most recent caller, not * necessarily their creator. */ f-&gt;f_tstate = tstate; Py_XINCREF(tstate-&gt;frame); assert(f-&gt;f_back == NULL); f-&gt;f_back = tstate-&gt;frame; gen-&gt;gi_running = 1; # 修改生成器执行状态 result = PyEval_EvalFrameEx(f, exc); # 执行字节码 gen-&gt;gi_running = 0; # 恢复为未执行状态 /* Don't keep the reference to f_back any longer than necessary. It * may keep a chain of frames alive or it could create a reference * cycle. */ assert(f-&gt;f_back == tstate-&gt;frame); Py_CLEAR(f-&gt;f_back); /* Clear the borrowed reference to the thread state */ f-&gt;f_tstate = NULL; /* If the generator just returned (as opposed to yielding), signal * that the generator is exhausted. */ if (result == Py_None &amp;&amp; f-&gt;f_stacktop == NULL) &#123; Py_DECREF(result); result = NULL; /* Set exception if not called by gen_iternext() */ if (arg) PyErr_SetNone(PyExc_StopIteration); &#125; if (!result || f-&gt;f_stacktop == NULL) &#123; /* generator can't be rerun, so release the frame */ Py_DECREF(f); gen-&gt;gi_frame = NULL; &#125; return result;&#125; 参考：http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/ http://www.cnblogs.com/coder2012/p/4990834.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的eventlet使用与理解]]></title>
      <url>%2F2017%2F03%2F06%2FPython%E7%9A%84eventlet%E4%BD%BF%E7%94%A8%E4%B8%8E%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Eventlet eventlet在openstack，还有ryu控制器中使用频率很高，有必要总结一下用法。 什么是协程？​ 说到Coroutine，我们必须提到两个更远的东西。在操作系统（os）级别，有进程（process）和线程（thread）两个（仅从我们常见的讲）实际的“东西”（不说概念是因为这两个家伙的确不仅仅是概念，而是实际存在的，os的代码管理的资源）。这两个东西都是用来模拟“并行”的，写操作系统的程序员通过用一定的策略给不同的进程和线程分配CPU计算资源，来让用户“以为”几个不同的事情在“同时”进行“。在单CPU上，是os代码强制把一个进程或者线程挂起，换成另外一个来计算，所以，实际上是串行的，只是“概念上的并行”。在现在的多核的cpu上，线程可能是“真正并行的”。 ​ Coroutine，翻译成”协程“，初始碰到的人马上就会跟上面两个概念联系起来。直接先说区别，Coroutine是编译器级的，Process和Thread是操作系统级的。Coroutine的实现，通常是对某个语言做相应的提议，然后通过后成编译器标准，然后编译器厂商来实现该机制。Process和Thread看起来也在语言层次，但是内生原理却是操作系统先有这个东西，然后通过一定的API暴露给用户使用，两者在这里有不同。Process和Thread是os通过调度算法，保存当前的上下文，然后从上次暂停的地方再次开始计算，重新开始的地方不可预期，每次CPU计算的指令数量和代码跑过的CPU时间是相关的，跑到os分配的cpu时间到达后就会被os强制挂起。Coroutine是编译器的魔术，通过插入相关的代码使得代码段能够实现分段式的执行，重新开始的地方是yield关键字指定的，一次一定会跑到一个yield对应的地方。 总之，对于Coroutine，是编译器帮助做了很多的事情，来让代码不是一次性的跑到底，而不是操作系统强制的挂起。代码每次跑多少，是可预期的。但是，Process和Thread，在这个层面上完全不同，这两个东西是操作系统管理的。 python-eventlet又是什么?官方网站对eventlet的描述是： ​ Eventlet is built around the concept of green threads (i.e. coroutines, we use the terms interchangeably) that are launched to do network-related work. Green threads differ from normal threads in two main ways: ​ Green threads are so cheap they are nearly free. You do not have to conserve green threads like you would normal threads. In general, there will be at least one green thread per network connection.Green threads cooperatively yield to each other instead of preemptively being scheduled. The major advantage from this behavior is that shared data structures don’t need locks, because only if a yield is explicitly called can​ another green thread have access to the data structure. It is also possible to inspect primitives such as queues to see if they have any pending data. ​ 大概意思是Eventlet是以绿色线程（协同线程）的概念建立起来的网络库，绿色线程和普通线程的区别是：1.绿色线程的开销小 2.绿色线程共享数据，无需锁，同一时刻只有一个线程能访问数据，通过类似队列的去查找等待的数据。 ​ eventlet是一个用来处理和网络相关的python库函数，而且可以通过协程来实现并发，在eventlet里，把“协程”叫做 greenthread(绿色线程)。所谓并发，就是开启了多个greenthread，并且对这些greenthread进行管理，以实现非阻塞式的 I/O。比如说用eventlet可以很方便的写一个性能很好的web服务器，或者是一个效率很高的网页爬虫，这都归功于eventlet的“绿色线程”，以及对“绿色线程”的管理机制。更让人不可思议的是，eventlet为了实现“绿色线程”，竟然对python的和网络相关的几个标准库函数进行了改写，并且可以以补丁（patch）的方式导入到程序中，因为python的库函数只支持普通的线程，而不支持协程，eventlet称之为“绿化”。​ 它通过greenlet提供的协程功能，让开发者可以不用将以往的多线程等并发程序的开发方式转变成异步状态机模型，就能直接使用select/epoll/kqueue等操作系统提供的支持高并发IO接口，并且能尽可能地发挥它们在并发上的优势。 eventlet的结构如下图所示,eventlet实现的”并发” 更准确的讲, 是 IO多路复用。 python-eventlet API?Greenthread Spawn (spawn，孵化的意思，即如何产生greenthread) 主要有3个函数可以创建绿色线程： 1)eventlet.spawn(func, args, *kwargs)： ​ 创建一个绿色线程去运行func这个函数，后面的参数是传递给这个函数的参数。返回值是一个eventlet.GreenThread对象，这个对象可以用来接受func函数运行的返回值。在绿色线程池还没有满的情况下，这个绿色线程一被创建就立刻被执行。其实，用这种方法去创建线程也是可以理解的，线程被创建出来，肯定是有一定的任务要去执行，这里直接把函数当作参数传递进去，去执行一定的任务，就好像标准库中的线程用run()方法去执行任务一样。 2)eventlet.spawn_n(func, args, *kwargs)： 这个函数和spawn()类似，不同的就是它没有返回值，因而更加高效，这种特性，使它也有存在的价值。 3)eventlet.spawn_after(seconds, func, args, *kwargs)： 这个函数和spawn()基本上一样，都有一样的返回值，不同的是它可以限定在什么时候执行这个绿色线程，即在seconds秒之后，启动这个绿色线程。 Greenthread Control 1）eventlet.sleep(seconds=0) 悬挂当前的绿色线程，以允许其它的绿色线程执行 2）class eventlet.GreenPool ​ 这是一个类，在这个类中用set集合来容纳所创建的绿色线程，并且可以指定容纳线程的最大数量（默认是1000个），它的内部是用Semaphore和Event这两个类来对池进行控制的，这样就构成了线程池。其中，有几个比较重要的方法： ​ free() ​ imap(function, *iterables) ​ resize(new_size) ​ running() ​ spawn(function, args, *kwargs) ​ spawn_n(function, args, *kwargs) ​ starmap(function, iterable) ​ waitall() ​ waiting() 3）class eventlet.GreenPile 这也是一个类，而且是一个很有用的类，在它内部维护了一个GreenPool对象和一个Queue对象。这个GreenPool对象可以是从外部传递进来的，也可以是在类内部创建的，GreenPool对象主要是用来创建绿色线程的，即在GreenPile内部调用了GreenPool.spawn()方法。而Queue对象则是用来保存spawn()方法的返回值的，即Queue中保存的是GreenThread对象。并且它还实现了next()方法，也就意味着GreenPile对象具有了迭代器的性质。所以如果我们要对绿色线程的返回值进行操作的话，用这个类是再好不过的了。 next()Wait for the next result, suspending the current greenthread until it is available. Raises StopIteration when there are no more results. spawn(func, args, *kw)Runs func in its own green thread, with the result available by iterating over the GreenPile object 4）class eventlet.Queue ​ 基类是LightQueue，它实现了大部分的队列的常用方法。它是用collections做为实现队列的基本数据结构的。而且这个LightQueue的实现，不单单实现了存取操作，在本质上它实现了一个生产者和消费者问题，定义了两个set()类型的成员变量putters和getters，前者用来存放在队列满时，被阻塞的绿色线程，后者用来存放当队列空时，被阻塞的绿色线程。类中的putting()和getting()方法就是分别得到被阻塞的绿色线程的数量。Queue继承了LightQueue，并且又增加了它自己的两个方法：task_done()和join()。task_done()是被消费者的绿色线程所调用的，表示在这个项上的所有工作都做完了，join()是阻塞，直到队列中所有的任务都完成。LifoQueue和PriorityQueue是存放数据的两种不同的方式。 5）class eventlet.Timeout This class is a way to add timeouts to anything. It raises exception in the current greenthread after timeout seconds. When exception is omitted or None, the Timeout instance itself is raised. Patching Functions 这里就是之前所说的“绿化”，经过eventlet“绿化”过的模块都在eventlet.green中，导入他们主要有两种方法： 1) eventlet.import_patched(modulename, additional_modules, *kw_additional_modules) 1234567from eventlet.green import socketfrom eventlet.green import SocketServerBaseHTTPServer = eventlet.import_patched('BaseHTTPServer', ('socket', socket), ('SocketServer', SocketServer))BaseHTTPServer = eventlet.import_patched('BaseHTTPServer', socket=socket, SocketServer=SocketServer) 2）eventlet.monkey_patch(all=True, os=False, select=False, socket=False, thread=False, time=False) 12import eventleteventlet.monkey_patch(socket=True, select=True) Network Convenience Functions（和网络相关的函数） eventlet.connect(addr, family=, bind=None) 主要执行了以下几个步骤：新建了一个TCP类型的socket，绑定本地的ip和端口，和远程的地址进行连接 123456def connect(addr, family=socket.AF_INET, bind=None): sock = socket.socket(family, socket.SOCK_STREAM) if bind is not None: sock.bind(bind) sock.connect(addr) return sock eventlet.listen(addr, family=, backlog=50) 和connect()类似，只是把connect()换成了listen()，backlog指定了最大的连接数量 1234567def listen(addr, family=socket.AF_INET, backlog=50): sock = socket.socket(family, socket.SOCK_STREAM) if sys.platform[:3]=="win": sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #这段不知道具体是做什么的 sock.bind(addr) sock.listen(backlog) return sock eventlet.wrap_ssl(sock, a, *kw) 给socket加上ssl(安全套接层)，对数据进行加密 eventlet.serve(sock, handle, concurrency=1000) 这个函数直接创建了一个socket服务器，在它内部创建了一个GreenPool对象，默认的最大绿色线程数是1000，然后是一个循环来接受连接 123456789101112def serve(sock, handle, concurrency=1000): pool = greenpool.GreenPool(concurrency) server_gt = greenthread.getcurrent() while True: try: conn, addr = sock.accept() gt = pool.spawn(handle, conn, addr) gt.link(_stop_checker, server_gt, conn) conn, addr, gt = None, None, None except StopServe: return eventlet 中的wsgi？流程描述： 服务器开一个socket等待客户端连接；请求来了，服务器会读出传来的数据，然后根据HTTP协议做一些初步的封装，接着就可以调用事先注册的应用程序了，并将请求的数据塞进去；等响应处理完毕了再把数据通过socket发出去。 123456789101112131415161718192021222324server参数介绍：def server(sock, # Server socket, must be already bound to a port and listening(IP和端口并开启监听). site, # WSGI application function(事件处理函数，发送start_response响应头然后返回响应内容) log=None, # File-like object that logs should be written to.If not specified, sys.stderr is used.(日志处理，默认为sys.stderr用来重定向标准错误信息的) environ=None, # Additional parameters that go into the environ dictionary of every request(每次请求的参数，写入一个字典中) max_size=None, #Maximum number of client connections opened at any time by this server.(默认为1024) max_http_version=DEFAULT_MAX_HTTP_VERSION, # Set to "HTTP/1.0" to make the server pretend it only supports HTTP 1.0. # This can help with applications or clients that don't behave properly using HTTP 1.1.(HTTP协议版本,默认为HTTP/1.1) protocol=HttpProtocol, # Protocol class.（协议类，默认为HttpProtocol） server_event=None, # Used to collect the Server object(搜集服务器对象信息) minimum_chunk_size=None, # Minimum size in bytes for http chunks. This can be used to improve performance of applications which yield many small strings, though # using it technically violates the WSGI spec. This can be overridden on a per request basis by setting environ['eventlet.minimum_write_chunk_size']. # 设置最小的Chunk大小，可以通过设置environ['eventlet.minimum_write_chunk_size']来覆盖.Chunk表示服务器发送给客户端的分块传输编码（Chunked transfer encoding） log_x_forwarded_for=True, # If True (the default), logs the contents of the x-forwarded-for header in addition to the actual client ip address in the 'client_ip' field of the log line. # 默认为True,记录客户端IP日志,X-Forwarded-For(XFF)是用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段。 custom_pool=None, # A custom GreenPool instance which is used to spawn client green threads.If this is supplied, max_size is ignored.(协程池，如果启用则可以忽略前面的max_size参数) keepalive=True, # If set to False, disables keepalives on the server; all connections will be closed after serving one request.（控制客户端连接数是否保持alive） log_output=True, # A Boolean indicating if the server will log data or not.(确定服务端是否输出日志) log_format=DEFAULT_LOG_FORMAT, # A python format string that is used as the template to generate log lines.(日志输出格式) url_length_limit=MAX_REQUEST_LINE, # A maximum allowed length of the request url. If exceeded, 414 error is returned.（最大的url长度限制，默认为8192） debug=True, # True if the server should send exception tracebacks to the clients on 500 errors.If False, the server will respond with empty bodies.(是否发送调式信息给客户端) socket_timeout=None, # Timeout for client connections' socket operations. Default None means wait forever.(Socket超时时间设置，单位是秒) capitalize_response_headers=True) # Normalize response headers' names to Foo-Bar(是否标准化相应头) Client端： 12345678#客户端代码：import eventletc=eventlet.connect(('127.0.0.1', 6000))while True: data=raw_input('Enter data:') c.sendall(data) rc=c.recv(1024) print rc Server端： 123456789101112#服务端代码：import eventletdef handle(client): while True: c = client.recv(1024) print c client.sendall(c)server = eventlet.listen(('127.0.0.1', 6000))pool = eventlet.GreenPool(10000)while True: new_sock, address = server.accept() pool.spawn_n(handle, new_sock) python-eventlet 的Demo?官方上引以为傲的“网页爬虫”，用到了绿色线程池和imap()函数 123456789101112131415urls = [ "http://www.google.com/intl/en_ALL/images/logo.gif", "http://python.org/images/python-logo.gif", "http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif",]import eventletfrom eventlet.green import urllib2def fetch(url): return urllib2.urlopen(url).read()pool = eventlet.GreenPool()for body in pool.imap(fetch, urls): print("got body", len(body)) 源码级别的分析？eventlet主要依赖另外2个python package: greenletpython-epoll (或其他类似的异步IO库, 如poll/select等) 主要做了3个工作: 封装greenlet封装epoll改写python标准库中相关的module, 以便支持epoll 什么是epoll？ epoll是linux实现的一个基于事件的异步IO库, 在之前类似的异步IO库poll上改进而来。 下面两个例子会演示如何用epoll将阻塞的IO操作用epoll改写为异步非阻塞： blocking IO import socket 12345678910111213141516171819202122EOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)try: while True: connectiontoclient, address = serversocket.accept() request = b'' while EOL1 not in request and EOL2 not in request: request += connectiontoclient.recv(1024) print('-'*40 + '\n' + request.decode()[:-2]) connectiontoclient.send(response) connectiontoclient.close()finally: serversocket.close() ​ 需要注意的是程序会在connectiontoclient, address = serversocket.accept()这一行block住, 直到获取到新的连接, 程序才会继续往下运行.同时, 这个程序同一个时间内只能处理一个连接, 如果有很多用户同时访问8080端口, 必须要按先后 顺序依次处理这些连接, 前面一个连接成功返回后, 才会处理后面的连接. non-blocking IO by using epoll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import socket, selectEOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)serversocket.setblocking(0)epoll = select.epoll()epoll.register(serversocket.fileno(), select.EPOLLIN)try: connections = &#123;&#125;; requests = &#123;&#125;; responses = &#123;&#125; while True: events = epoll.poll(1) for fileno, event in events: if fileno == serversocket.fileno(): connection, address = serversocket.accept() connection.setblocking(0) epoll.register(connection.fileno(), select.EPOLLIN) connections[connection.fileno()] = connection requests[connection.fileno()] = b'' responses[connection.fileno()] = response elif event &amp; select.EPOLLIN: requests[fileno] += connections[fileno].recv(1024) if EOL1 in requests[fileno] or EOL2 in requests[fileno]: epoll.modify(fileno, select.EPOLLOUT) print('-'*40 + '\n' + requests[fileno].decode()[:-2]) elif event &amp; select.EPOLLOUT: byteswritten = connections[fileno].send(responses[fileno]) responses[fileno] = responses[fileno][byteswritten:] if len(responses[fileno]) == 0: epoll.modify(fileno, 0) connections[fileno].shutdown(socket.SHUT_RDWR) elif event &amp; select.EPOLLHUP: epoll.unregister(fileno) connections[fileno].close() del connections[fileno]finally: epoll.unregister(serversocket.fileno()) epoll.close() serversocket.close() 可以看到, 例子中首先使用serversocket.setblocking(0)将socket设为异步的模式,然后 用select.epoll()新建了一个epoll, 接着用epoll.register(serversocket.fileno(),select.EPOLLIN)将该socket上的IO输入事件(select.EPOLLIN)注册到epoll里.这样做了以后, 就可以将 上面例子中会在socket.accept()这步阻塞的MainLoop改写为基于异步IO事件的epoll循环了.events = epoll.poll(1) ​ 简单的说, 如果有很多用户同时连接到8080端口, 这个程序会同时accept()所有的socket连接, 然后通过这行代码将发生IO事件socket放到events中, 并在后面循环中处理. 没有发生IO事件的 socket不会在loop中做处理. 这样使用epoll就实现了一个简单的并发web服务器. 注意, 这里提到的并发, 和我们通常所理解线程/进程的并发并不太一样, 更准确的说, 是 IO多路复用 . 什么是greenlet？ greentlet是python中实现我们所谓的”Coroutine(协程)”的一个基础库. 12345678910111213141516from greenlet import greenletdef test1(): print 12 gr2.switch() print 34def test2(): print 56 gr1.switch() print 78 gr1 = greenlet(test1) gr2 = greenlet(test2) gr1.switch()#输出125634 ​ 程序先分别为两个函数定义了2个greenlet: gr1和gr2.gr1.switch()显式切换到gr1上执行, gr1中输出”12”后gr2.switch()显式切换到gr2上执行输出56, 又gr1.switch()显式切换到gr1上, 输出34. test1()执行结束,gr1 die. 于是 test2()里的78不会输出.可以发现greenlet仅仅是实现了一个最简单的”coroutine”, 而eventlet中的greenthread是在 greenlet的基础上封装了一些更high-level的功能, 比如greenlet的调度等. 什么是eventlet.green？ 从epoll的运行机制可以看出, 要使用异步IO, 必须要将相关IO操作改写成non-blocking的方式. 但是我们用eventlet.spawn()的函数,并没有针对epoll做任何改写, 那eventlet是怎么实现 异步IO的呢?这也是eventlet这个package最凶残的地方, 它自己重写了python标准库中IO相关的操作, 将它们 改写成支持epoll的模式, 放在eventlet.green中.比如说, socket.accept()被改成了这样 123456789101112def accept(self): if self.act_non_blocking: return self.fd.accept() fd = self.fd while True: res = socket_accept(fd) if res is not None: client, addr = res set_nonblocking(client) return type(self)(client), addr trampoline(fd, read=True, timeout=self.gettimeout(), timeout_exc=socket.timeout("timed out")) ​ 然后在eventlet.spawn()的时候, 通过 一些高阶魔法和”huge hack”, 将这些改写过得模块”patch”到spawn出的greenthread上, 从而 实现epoll的IO多路复用, 相当凶残.其中的hub和greenthread分别对应eventlet.hubs.hub和eventlet.greenthread, 本质都是 一个greenlet的实例.hub中封装前面提到的epoll, epoll的事件循环是由hub.run()这个方法里实现.每当用户调用 eventlet.spawn(), 就会在当前python线程的pool里产生一个新的greenthread. 由于greenthread 里的IO相关的python标准库被改写成non-blocking的模式(参考上面的socket.accept()).每当greenthread里做IO相关的操作时, 最终都会返回到hub中的epoll循环, 然后根据epoll中的 IO事件, 调用响应的函数. 具体如下面所示.greenthread.sleep(), 实际上也是将CPU控制权交给hub,然后由hub调度下一个需要运行的 greenthread. 123456789101112131415161718192021222324252627282930313233def wait(self, seconds=None): readers = self.listeners[READ] writers = self.listeners[WRITE] if not readers and not writers: if seconds: sleep(seconds) return try: presult = self.poll.poll(int(seconds * self.WAIT_MULTIPLIER)) except select.error, e: if get_errno(e) == errno.EINTR: return raise SYSTEM_EXCEPTIONS = self.SYSTEM_EXCEPTIONS for fileno, event in presult: try: if event &amp; READ_MASK: readers.get(fileno, noop).cb(fileno) if event &amp; WRITE_MASK: writers.get(fileno, noop).cb(fileno) if event &amp; select.POLLNVAL: self.remove_descriptor(fileno) continue if event &amp; EXC_MASK: readers.get(fileno, noop).cb(fileno) writers.get(fileno, noop).cb(fileno) except SYSTEM_EXCEPTIONS: raise except: self.squelch_exception(fileno, sys.exc_info()) clear_sys_exc_info() 参考:http://blog.csdn.net/xiangmin2587/article/details/8182775 http://blog.csdn.net/qq910894904/article/details/41699541 http://www.cnblogs.com/wonderKK/p/4062591.html http://eventlet.net/doc/ http://eventlet.net/doc/modules/wsgi.html http://www.xuebuyuan.com/1379840.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java框架之SpringBoot]]></title>
      <url>%2F2017%2F03%2F03%2Fjava%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBoot%2F</url>
      <content type="text"><![CDATA[SpringBoot非常受欢迎，在github我也用SpringBoot封装neutron-api，地址为： https://github.com/Luckylau/SpringBoot-NeutronApi 总觉得应该普及一下基本知识。 什么是SpringBoot？​ Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式，Boot致力于在蓬勃发展的快速应用开发领域（rapid application development）成为领导者。 ​ Boot的目标不在于为已解决的问题域提供新的解决方案，而是为平台带来另一种开发体验，从而简化对这些已有技术的使用。对于已经熟悉Spring生态系统的开发人员来说，Boot是一个很理想的选择，不过对于采用Spring技术的新人来说，Boot提供一种更简洁的方式来使用这些技术。 ​ Boot提供了许多的“starter”模块，它们定义了一组依赖，这些依赖能够添加到构建系统之中，从而解析框架及其父平台所需的特定类库。例如，spring-boot-starter-actuator依赖会引入一组基本的Spring项目，从而实现应用的快速配置和即时可用。关于这种依赖，值得强调的一点就是当开发Web应用，尤其是RESTful Web服务的时候，如果包含了spring-boot-starter-web依赖，它就会为你提供启动嵌入式Tomcat容器的自动化配置，并且提供对微服务应用有价值的端点信息，如服务器信息、应用指标（metrics）以及环境详情。除此之外，如果引入spring-boot-starter-security模块的话，actuator会自动配置Spring Security，从而为应用提供基本的认证以及其他高级的安全特性。它还会为应用结构引入一个内部的审计框架，这个框架可以用来生成报告或其他的用途，比如开发认证失败的锁定策略。 ​ Boot对Spring应用的开发进行了简化，提供了模块化方式导入依赖的能力，强调了开发RESTful Web服务的功能并提供了生成可运行jar的能力，这一切都清晰地表明在开发可部署的微服务方面Boot框架是一个强大的工具。正如前面的例子所示，借助于Boot，让一个RESTful Web工程运行起来是一件很容易的事情；在企业级基础设施领域，微服务是一种越来越流行的应用架构，因为它能够实现快速开发、更小的代码库、企业级集成以及模块化部署。 实战Domo?以SpringBoot-neutron-api项目为例，这也是一个RESTFUL项目。 1.创建一个Maven项目 我们在eclipse下创建两个maven项目，一个选择maven-archtype-quickstart，一个选择maven-archtype-webapp。将maven-archtype-webapp下的webapp目录拷贝到基于maven-archtype-quickstart创建的maven项目，然后将其删除。 如果没有src/main/resources可以按照如下方式创建 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 其余根据开发需要补充即可。下面是一些配置数据库的，主要别人的一些操作，我也看了一下公司产品的代码，大同小异，简单的贴出来。 12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!--数据库操作--&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在src/main/resources这个文件夹下面新建一个application.properties 123456789101112131415#DB Configuration:spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/testdbspring.datasource.username = rootspring.datasource.password = 123456#JPA Configuration: spring.jpa.database=MySQLspring.jpa.show-sql=true spring.jpa.generate-ddl=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernate.dialect.MySQL5Dialect spring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy #spring.jpa.database=org.hibernate.dialect.MySQL5InnoDBDialect #spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MYSQL5Dialect 待续。。。。。 参考：http://www.infoq.com/cn/articles/microframeworks1-spring-boot http://blog.csdn.net/cool__wang/article/details/49466609 http://www.cnblogs.com/dreamroute/p/5173896.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的sqlalchemy库使用]]></title>
      <url>%2F2017%2F03%2F02%2FPython%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Sqlalchemy库 本文主要参考官方文档和一些网上资料，并结合之前python-web-frame项目使用来详细说明Sqlalchemy的使用，版本号为SQLAlchemy 1.1。 Sqlalchemy的架构？ Object Relational Mapper &amp;&amp; SQL Expression Language ?下面是截取python-web-frame项目代码 12345678910111213141516171819202122232425262728293031323334#api.pydef get_engine(): global _ENGINE if _ENGINE is not None: return _ENGINE _ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) db_models.int_dbs(_ENGINE) return _ENGINE# db_models.pyBase = declarative.declarative_base()def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE)class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) def __init__(self, user_id, name, gender, age, email): self.user_id = user_id self.name = name self.gender = gender self.age = age self.email = email Connecting 123_ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) echo flag is a shortcut to setting up SQLAlchemy logging, which is accomplished via Python’s standard logging module. With it enabled, we’ll see all the generated SQL produced. echo意思说开启日志，你可以看到整个SQL是如何产生的，方便调试。 _ENGINE is an instance of Engine, and it represents the core interface to the database, adapted through a dialect that handles the details of the database and DBAPI in use. _ENGINE 意思说与数据库打交道的核心接口 Declare a Mapping 123456789101112131415Base = declarative.declarative_base()class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) 生成一个映射使用的Base. Create a Schema 12def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE) db_User类继承了Base类，它具有metadata属性，通过create_all()方法，注入与数据库打交道的核心接口_ENGINE，我们发现有一系列的命令完成数据库中user表是否存在的检测和生成。 Creating a Session 1234567891011def get_session_maker(engine): global _SESSION_MAKER if _SESSION_MAKER is not None: return _SESSION_MAKER _SESSION_MAKER = sqlalchemy.orm.sessionmaker(bind=engine) return _SESSION_MAKERdef get_session(): engine = get_engine() maker = get_session_maker(engine) session = maker() return session This custom-made Session class will create new Session objects which are bound to our database. Querying http://docs.sqlalchemy.org/en/rel_1_1/orm/query.html#sqlalchemy.orm.query.Query query()和 aliased() Common Filter Operators filter() 12345678910111213141516171819202122232425262728293031equals:query.filter(User.name == 'ed')not equals:query.filter(User.name != 'ed')LIKE:query.filter(User.name.like('%ed%'))IN:query.filter(User.name.in_(['ed', 'wendy', 'jack']))# works with query objects too:query.filter(User.name.in_( session.query(User.name).filter(User.name.like('%ed%'))))NOT IN:query.filter(~User.name.in_(['ed', 'wendy', 'jack']))IS NULL:query.filter(User.name == None)# alternatively, if pep8/linters are a concernquery.filter(User.name.is_(None))AND:# use and_()from sqlalchemy import and_query.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))# or send multiple expressions to .filter()query.filter(User.name == 'ed', User.fullname == 'Ed Jones')# or chain multiple filter()/filter_by() callsquery.filter(User.name == 'ed').filter(User.fullname == 'Ed Jones'OR:from sqlalchemy import or_query.filter(or_(User.name == 'ed', User.name == 'wendy'))MATCH:query.filter(User.name.match('wendy') Returning Lists and Scalars all() returns a list first() applies a limit of one and returns the first result as a scalar one() fully fetches all rows, and if not exactly one object identity or composite row is present in the result, raises an error 注意：The one() method is great for systems that expect to handle “no items found” versus “multiple items found” differently; such as a RESTful web service, which may want to raise a “404 not found” when no results are found, but raise an application error when multiple results are found. one_or_none() is like one(), except that if no results are found, it doesn’t raise an error; it just returns None. Like one(), however, it does raise an error if multiple results are found scalar() invokes the one() method, and upon success returns the first column of the row Using Textual SQL text() Counting count() Building a Relationship 一对多 12345678class db_User(Base): .... telephone = relationship("db_Telephone",order_by="db_Telephone.id",back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 即：一个db_user对应多个db_Telephone 一对一 12345678class db_User(Base): .... telephone = relationship("db_Telephone",uselist=False,back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 多对多 Many to Many adds an association table between two classes.多对多关系会在两个类之间增加一个关联的表。The association table is indicated by the secondary argument to relationship().这个关联的表在 relationship() 方法中通过 secondary 参数来表示。Usually, the Table uses the MetaData object associated with the declarative base class,通常的，这个表会通过 MetaData 对象来与声明基类关联，so that the ForeignKey directives can locate the remote tables with which to link:所以这个 ForeignKey 指令会使用链接来定位到远程的表： 123456789101112131415161718192021#多对多关系中的两个表之间的一个关联表post_keywords = Table('post_keywords', Base.metadata, Column('post_id', ForeignKey('posts.id'), primary_key=True), Column('keyword_id', ForeignKey('keywords.id'), primary_key=True) class Parent(Base): __tablename__ = 'left' id = Column(Integer, primary_key=True) children = relationship( "Child", secondary=association_table, back_populates="parents")class Child(Base): __tablename__ = 'right' id = Column(Integer, primary_key=True) parents = relationship( "Parent", secondary=association_table, back_populates="children") Querying with Joins Using Aliases Using EXISTS Common Relationship Operators eq() (many-to-one “equals” comparison) ne() (many-to-one “not equals” comparison) IS NULL (many-to-one comparison, also uses eq()) contains() (used for one-to-many collections) any() (used for collections) has() (used for scalar references) Query.with_parent() (used for any relationship) Eager Loading Query.options() subqueryload()第一种 Joined Load()第二种 contains_eager()第三种 Deleting db_user与db_Telephone是一对多关系，下面操作解决了删除db_user，会自动删除关联的表数据 12345678910111213141516171819202122def delete_user(self, user_id): logger.info("user.user_id: %s" % (user_id)) try: session = get_session() user=session.query( db_models.db_User).filter_by( user_id=user_id).first() session.delete(user) session.flush() session.commit() except exc.NoResultFound: logger.error("delete user occur error ...")class db_User(Base): ... telephone = relationship( "db_Telephone", order_by="db_Telephone.id", back_populates="user" , cascade="save-update, merge, delete")class db_Telephone(Base): ... user = relationship("db_User", back_populates="telephone") 参考：http://docs.sqlalchemy.org/en/rel_1_0/orm/tutorial.html http://docs.sqlalchemy.org/en/rel_1_0/core/tutorial.html http://blog.csdn.net/zd0303/article/details/50261347 http://blog.csdn.net/Jmilk/article/details/52445093#one-to-many]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python的pecan框架使用]]></title>
      <url>%2F2017%2F03%2F01%2Fpython%E7%9A%84pecan%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Pecan web框架 什么是Pecan?​ 创造Pecan是为了填补Python web框架世界的一个空缺——一个提供object-dispatch（对象分发）方式路由的超轻量级的框架。Pecan的目标并不是要成为一个“全栈”框架，因此没有支持一些额外的功能，比如session或是数据库 。相反，Pecan专注于HTTP本身。 功能包括： Object-dispatch for easy routingFull support for REST-style controllersExtensible security frameworkExtensible template language supportExtensible JSON supportEasy Python-based configuration 所以对于OpenStack来说，Pecan是一个很好的选择，因为OpenStack项目中统一使用sqlalchemy来实现ORM，API的实现也不需要模板功能，安全控制则基于Keystone体系。使用Pecan来开发REST服务，代码量很少，代码结构也清晰。 创建简单的Pecan应用？首先在linux新建一个virtualenv环境（本文是在ubantu16.04），我们首先看一下自动生成的工程目录结构。 12345678910111213141516171819202122232425262728293031323334353637383940luckylau@luckylau-Ubuntu:~$virtualenv pecan-envluckylau@luckylau-Ubuntu:~$cd pecan-env/luckylau@luckylau-Ubuntu:~/pecan-env$ source bin/activate(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pip install pecan(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pecan create test_project(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ tree test_project/test_project/├── config.py├── MANIFEST.in├── public #一些静态文件包括CSS,JS,images,为你的开发服务│ ├── css│ │ └── style.css│ └── images│ └── logo.png├── setup.cfg├── setup.py└── test_project #基于MVC模型生成的结构 ├── app.py #决定应用是如何创造的，这个文件必须包含set_app()并返回WSGI应用对象，一般情况下就用原生的，除非不能满足你定制的应用。 ├── controllers #控制层实现 │ ├── __init__.py │ ├── __init__.pyc │ ├── root.py │ └── root.pyc ├── __init__.py ├── __init__.pyc ├── model #模型实现 │ ├── __init__.py #在这里可以加入与database交互，定义表和ORM等 │ └── __init__.pyc ├── templates #模板实现 │ ├── error.html │ ├── index.html │ └── layout.html └── tests #单元测试 ├── config.py ├── __init__.py ├── test_functional.py ├── test_units.py └── test_units.pyc8 directories, 23 files 实战Demo?我们通过实际操作中补充pecan相关知识点。项目托管到github: https://github.com/Luckylau/python-web-frame 该项目用到pecan和wsme(Web Services Made Easy),首先解释一下WSME吧 WSME的全称是Web Service Made Easy，是专门用于实现REST服务的typing库，让你不需要直接操作请求和响应，而且刚好和Pecan结合得非常好，所以，OpenStack的很多项目都使用了Pecan + WSME的组合来实现API。 WSME的理念是：在大部分情况下，Web服务的输入和输出对数据类型的要求都是严格的。所以它就专门解决了这个事情，然后把其他事情都交给其他框架去实现。 WSME会自动帮你检查HTTP请求和响应中的数据是否符合预先设定好的要求。WSME的主要方式是通过装饰器来控制controller方法的输入和输出。WSME中主要使用两个控制器： ● @signature: 这个装饰器用来描述一个函数的输入和输出。 ● @wsexpose: 这个装饰器包含@signature的功能，同时会把函数的路由信息暴露给Web框架，效果就像Pecan的expose装饰器。 123456789101112131415luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── config.py│ ├── controllers│ │ ├── __init__.py│ │ └── root.py│ ├── expose.py│ ├── hooks.py│ └── __init__.py├── cmd│ ├── api.py│ └── __init__.py└── __init__.py 首先参考openstack我们人工的建立如上目录。首先我们实现config.py 代码 https://pecan.readthedocs.io/en/latest/configuration.html#application-configuration 该链接解释配置的含义。 config.py 123456789101112131415161718192021222324app = &#123; 'root': 'webdemo.api.controllers.root.RootController', 'modules': ['webdemo.api'], 'debug': True,&#125;logging = &#123; 'root': &#123;'level': 'INFO', 'handlers': ['console']&#125;, 'loggers': &#123; 'webdemo': &#123;'level': 'INFO', 'handlers': ['console']&#125; &#125;, 'handlers': &#123; 'console': &#123; 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'simple' &#125; &#125;, 'formatters': &#123; 'simple': &#123; 'format': ('%(asctime)s %(levelname)-5.5s [%(name)s]' '[%(threadName)s] %(message)s') &#125; &#125;&#125; modules At least one of the listed modules must contain an app.setup_app function which is called to create the WSGI app. In other words, this package should be where your app.py file is located, and this file should contain a setup_app function. 简单来说，modules是app.py(同时包含setup_pp功能)所在的包，pecan会扫描的。 root The root controller of your application. Remember to provide a string representing a Python path to some callable (e.g.”yourapp.controllers.root.RootController”). 简单来说，RootController所在路径 debugEnables the ability to display tracebacks in the browser and interactively debug during development. 简单来说，是否开启debug模式 app.py 123456789101112import pecanfrom webdemo.api import config as api_configdef get_pecan_config(): filename=api_config.__file__.replace('.pyc','.py') return pecan.configuration.conf_from_file(filename)def setup_app(): config=get_pecan_config() app_conf=dict(config.app) app=pecan.make_app(app_conf.pop('root'), logging=getattr(config,'logging',&#123;&#125;), **app_conf) return app expose.py 123456#让API返回JSON格式的数据import wsmeext.pecan as wsme_pecandef expose(*args, **kwargs): if 'rest_content_types' not in kwargs: kwargs['rest_content_types'] = ('json',) return wsme_pecan.wsexpose(*args, **kwargs) root.py 12345678910from pecan import restfrom wsme import types as wtypesfrom webdemo.api import exposeimport logginglogger = logging.getLogger(__name__)class RootController(rest.RestController): @expose.expose(wtypes.text) def get(self): logger.info("Method is called ...") return "python-web-frame: pecan &amp; wsme " api.py 123456789from wsgiref import simple_serverfrom webdemo.api import appdef main(): application = app.setup_app() httpd = simple_server.make_server('', 8080, application) print ("Server on port 8080 ,listening ...") httpd.serve_forever()if __name__ == '__main__': main() 我们进一步扩展该Demo，源码更新看日志： https://github.com/Luckylau/python-web-frame/commits/master 需求：设计一个管理用户的API，实现如下 GET /v1/users 获取所有用户的列表。POST /v1/users 创建一个用户。GET /v1/users/ 获取一个特定用户的详细信息。PUT /v1/users/ 修改一个用户的详细信息。DELETE /v1/users/ 删除一个用户。 1234567891011121314151617181920212223242526luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── __init__.py│ │ ├── controller.py #用户管理控制器│ │ └── users.py #用户模型│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── __init__.py└── __init__.pyc 然后我们在加入sqlalchemy库来实现数据库操作 我们可以看一个脚本预热一下 https://github.com/Luckylau/oslo.modules.sample/blob/lucky-branch/sqlalchemy.orm/db_query_ports.py 然后开始我们这个Demo的扩展 由于OpenStack项目在单元测试中使用的是sqlite的内存数据库，这样开发者运行单元测试的时候不需要安装和配置复杂的MySQL数据库，只要安装好sqlite3就可以了。而且，数据库是保存在内存中的，会提高单元测试的速度，我们的Demo也是用sqlite，sqlalchemy库的使用参考： https://luckylau.github.io/2017/03/02/Python%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3/ 12345678910111213141516171819202122232425262728293031323334webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── controller.py│ │ ├── controller.pyc│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── users.py│ │ └── users.pyc│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── db│ ├── api.py #sqlalchemy 增删改查功能│ ├── __init__.py #│ └── models.py # sqlalchemy ORM的定义├── __init__.py└── __init__.pyc5 directories, 26 files 具体的分析在源码有标注。 参考：https://pecan.readthedocs.io/en/latest/ http://www.infoq.com/cn/articles/OpenStack-demo-API3 https://pythonhosted.org/WSME/ http://www.sqlalchemy.org/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单（4）]]></title>
      <url>%2F2017%2F02%2F28%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95%EF%BC%884%EF%BC%89%2F</url>
      <content type="text"><![CDATA[2017年-至今98.《你一年的8760小时》-艾力 99.《牛棚杂忆》-季羡林 100.《愚人的坚持》-稻盛和夫，山中伸弥 101.《异类》-马尔柯姆-格拉德威尔 102.《人类动物园》-德斯蒙德莫里斯 103.《美学漫话》-宗白华 104.《逃不开的经济周期》-拉斯特维德 105.《明治维新六十年》-樱雪丸 106.《武士道》-新渡户稻造 107.《我所理解的生活》-韩寒 108.《呀，原来如此》-知乎 109《宋朝原来是这样》-醉罢君山]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的wsgi理解]]></title>
      <url>%2F2017%2F02%2F28%2Fpython%E7%9A%84wsgi%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之WSGI ​ WSGI的全称是Web Server Gateway Interface，翻译过来就是Web服务器网关接口。具体的来说，WSGI是一个规范，定义了Web服务器如何与Python应用程序进行交互，使得使用Python写的Web应用程序可以和Web服务器对接起来。WSGI一开始是在PEP-0333中定义的，最新版本是在Python的PEP-3333定义的。 为什么需要WSGI规范？在Web部署的方案上，有一个方案是目前应用最广泛的： ​ 首先，部署一个Web服务器专门用来处理HTTP协议层面相关的事情，比如如何在一个物理机上提供多个不同的Web服务（单IP多域名，单IP多端口等）这种事情。 ​ 然后，部署一个用各种语言编写（Java, PHP, Python, Ruby等）的应用程序，这个应用程序会从Web服务器上接收客户端的请求，处理完成后，再返回响应给Web服务器，最后由Web服务器返回给客户端。 ​ 要采用这种方案，Web服务器和应用程序之间就要知道如何进行交互。为了定义Web服务器和应用程序之间的交互过程，就形成了很多不同的规范。比如改进CGI性能的FasgCGI，Java专用的Servlet规范，还有Python专用的WSGI规范等。提出这些规范的目的就是为了定义统一的标准，提升程序的可移植性。在WSGI规范的最开始的PEP-333中一开始就描述了为什么需要WSGI规范。 ​ WSGI存在的目的有两个： 让Web服务器知道如何调用Python应用程序，并且把用户的请求告诉应用程序。 让Python应用程序知道用户的具体请求是什么，以及如何返回结果给Web服务器。 WSGI中的角色？​ 在WSGI中定义了两个角色，Web服务器端称为server或者gateway，应用程序端称为application或者framework（因为WSGI的应用程序端的规范一般都是由具体的框架来实现的）。我们下面统一使用server和application这两个术语。 ​ server端会先收到用户的请求，然后会根据规范的要求调用application端，如下图所示： 调用的结果会被封装成HTTP响应后再发送给客户端。 WSGI中间件 ?​ WSGI Middleware（中间件）也是WSGI规范的一部分。上一章我们已经说明了WSGI的两个角色：server和application。那么middleware是一种运行在server和application中间的应用（一般都是Python应用）。middleware同时具备server和application角色，对于server来说，它是一个application；对于application来说，它是一个server。middleware并不修改server端和application端的规范，只是同时实现了这两个角色的功能而已。 1.Server收到客户端的HTTP请求后，生成了environ_s，并且已经定义了start_response_s。 2.Server调用Middleware的application对象，传递的参数是environ_s和start_response_s。 3.Middleware会根据environ执行业务逻辑，生成environ_m，并且已经定义了start_response_m。 4.Middleware决定调用Application的application对象，传递参数是environ_m和start_response_m。Application的application对象处理完成后，会调用start_response_m并且返回结果给Middleware，存放在result_m中。 5.Middleware处理result_m，然后生成result_s，接着调用start_response_s，并返回结果result_s给Server端。Server端获取到result_s后就可以发送结果给客户端了。 从上面的流程可以看出middleware应用的几个特点： Server认为middleware是一个application。 Application认为middleware是一个server。 Middleware可以有多层。 WSGi示例代码？​ 在给出示例代码前我们需要了解wsgiref，它是官方给出的一个实现了WSGI标准用于演示用的简单Python内置库，实现了一个简单的WSGI Server和WSGI Application（在simple_server模块中），主要分为五个模块：simple_server， util， headers， handlers， validate。 注意：simple_server只支持单线程，做测试 WSGI对于应用程序有以下标准规定： 应用程序必须是一个可调用的对象，因此，应用程序可以是一个函数，一个类，或者一个重载了call的类的实例。 应用程序必须接受两个参数并且要按照位置顺序，分别是environ（环境变量），以及start_response函数（负责将响应的status code，headers写进缓冲区但不返回给客户端）。 应用程序返回的结果必须是一个可迭代的对象 由简入繁 123456789from wsgiref.simple_server import make_serverdef simple_app(environ,start_response): status="200 OK" response_headers=[('Content-type', 'text/plain')] start_response(status,response_headers) return [u"This is simple app demo".encode('utf-8')]http=make_server('',8080,simple_app)print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011from wsgiref.simple_server import make_serverclass App(): def __call__(self, environ, start_response): status = "200 OK" response_headers = [('Content-type', 'text/plain')] start_response(status, response_headers) return [u"This is App".encode('utf-8')]simple_app = App()http = make_server('', 8080, simple_app) #只要是实现了__call__方法的实例也可以的print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011121314from wsgiref.simple_server import make_serverclass class_app: def __init__(self, environ, start_response): self.env = environ self.start = start_response def __iter__(self): status = "200 OK" response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield "Class : My Own Hello World!"app = class_apphttpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 1234567891011121314151617181920212223242526272829303132from wsgiref.simple_server import make_serverURL_PATTERNS = ( ('tags', 'tag_app'), ('about', 'about_app'))class Dispatcher(object): def _match(self, path): path = path.split("/")[1] for url, app in URL_PATTERNS: print("path:%s url:%s" % (path, url)) if path == url: return app def __call__(self, environ, start_response): path = environ.get('PATH_INFO') app = self._match(path) if app: app = globals()[app] return app(environ, start_response) else: start_response("404 not found ", [('Content-type', 'text/plain')]) return ["Page dose not exists!"]def tag_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is tag page!"]def about_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is about me page!"]app = Dispatcher()httpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 源码wsgiref解析?wsgiref.simple_server 中make_server函数 12345678# wsgiref/simple_server.pydef make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): """Create a new WSGI server listening on `host` and `port` for `app`""" server = server_class((host, port), handler_class) server.set_app(app) return server make_server函数默认使用的服务器类为WSGI Server，调用了构造函数（但是它的构造函数到底藏在哪一层服务器上呢？），相对应的使用WSGIRequestHandler 类作为请求的处理类（这两个类都定义在wsgiref.simple_server模块中），在实例化一个WSGI Server后设置它的application后返回该实例。 server_class=WSGIServer WSGI Server作为一个服务器，自然免不了要调用socket来建立TCP连接，因此这里的WSGI Server是基于Python的内置网络库BaseHTTPServer.py以及SocketServer.py实现的。 WSGI Server继承了HTTPServer,HTTPServer继承了TCPServer,TCPServer继承了BaseServer，在 BaseServerr中有handle_request函数 12345678910111213141516171819#SocketServer.pydef handle_request(self): """Handle one request, possibly blocking. Respects self.timeout. """ # Support people who used socket.settimeout() to escape # handle_request before self.timeout was available. timeout = self.socket.gettimeout() if timeout is None: timeout = self.timeout #self.timeout是BaseServer类的属性，默认是None elif self.timeout is not None: timeout = min(timeout, self.timeout) fd_sets = _eintr_retry(select.select, [self], [], [], timeout) #处理EINTR，当捕获到某个信号且相应信号处理函数返回时，这个系统调用被中断，调用返回错误，设置errno为EINTR。 if not fd_sets[0]: self.handle_timeout() return self._handle_request_noblock() 12345678def _eintr_retry(func, *args): """restart a system call interrupted by EINTR""" while True: try: return func(*args) except (OSError, select.error) as e: if e.args[0] != errno.EINTR: rais 1234567891011121314151617181920#SocketServer.pydef _handle_request_noblock(self): """Handle one request, without blocking. I assume that select.select has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). """ try: request, client_address = self.get_request() except socket.error: return if self.verify_request(request, client_address): try: self.process_request(request, client_address) except: self.handle_error(request, client_address) self.shutdown_request(request) else: self.shutdown_request(request) 关于使用select解决EINTR错误请参考这里：PEP 475 – Retry system calls failing with EINTR 因为我们把timeout设置为None，导致select.select永远不会超时，因此如果一直没有客户端连接服务器，服务器就会阻塞在select函数。当一个EINTR错误提出时，select可以重复调用。 通过select函数当我们确认已经收到了来自客户端的请求连接，此时调用accept函数不会阻塞时，于是调用handle_request_noblock函数,在函数中再依次调用了verify_request, process_request, finish_request。 1234567891011121314151617181920212223242526#SocketServer.py def get_request(self): """Get the request and client address from the socket. May be overridden. """ return self.socket.accept() #定义在TCPServerdef verify_request(self, request, client_address): """Verify the request. May be overridden. Return True if we should proceed with this request. """ return Truedef process_request(self, request, client_address): """Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. """ self.finish_request(request, client_address) self.shutdown_request(request)def finish_request(self, request, client_address): """Finish one request by instantiating RequestHandlerClass.""" self.RequestHandlerClass(request, client_address, self)def shutdown_request(self, request): """Called to shutdown and close an individual request.""" self.close_request(request)def close_request(self, request): """Called to clean up an individual request.""" pass handle_request——-&gt;handle_request_noblock——–&gt;get_request——–&gt;verify_request——-&gt; process_request———&gt;finish_request———&gt;RequestHandlerClass RequestHandlerClass在simple_server 传入的是WSGIRequestHandler handler_class=WSGIRequestHandler RequestHandlerClass主要用于处理请求，生成一些必要的环境参数之后才传给负责发送响应请求的ServerHandler WSGIRequestHandler的handle()继承如下，最后追踪到wsgiref/handles.py:BaseHandler 123456789101112131415161718192021222324252627282930313233def run(self, application): """Invoke the application""" # Note to self: don't move the close()! Asynchronous servers shouldn't # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you'll break asynchronous servers by # prematurely closing. Async servers must return from 'run()' without # closing if there might still be output to iterate over. try: self.setup_environ() self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out. def finish_response(self): """Send any iterable data, then close self and the iterable Subclasses intended for use in asynchronous servers will want to redefine this method, such that it sets up callbacks in the event loop to iterate over the data, and to call 'self.close()' once the response is finished. """ try: if not self.result_is_file() or not self.sendfile(): for data in self.result: self.write(data) self.finish_content() finally: self.close() ServerHandler函数主要功能集中在run函数上，同时start_response函数也定义在同一文件中，start_response函数（在application中调用）也必须要按照PEP-333标准定义 最终所有的数据都在finish_response()中写回给客户端。finish_response函数调用了write函数，write函数每次调用时都会检查headers是否已发送，否则先发送headers在发送data。 start_response函数源码 12345678910111213141516171819202122232425def start_response(self, status, headers,exc_info=None): """'start_response()' callable as specified by PEP 333""" if exc_info: try: if self.headers_sent: # Re-raise original exception if headers sent raise exc_info[0], exc_info[1], exc_info[2] finally: exc_info = None # avoid dangling circular ref elif self.headers is not None: raise AssertionError("Headers already set!") assert type(status) is StringType,"Status must be a string" assert len(status)&gt;=4,"Status must be at least 4 characters" assert int(status[:3]),"Status message must begin w/3-digit code" assert status[3]==" ", "Status message must have a space after code" if __debug__: for name,val in headers: assert type(name) is StringType,"Header names must be strings" assert type(val) is StringType,"Header values must be strings" assert not is_hop_by_hop(name),"Hop-by-hop headers not allowed" self.status = status self.headers = self.headers_class(headers) return self.write start_response函数主要用于检测headers是不是已经发送了，如果发送了必须提出异常，同时检测headers是否有不规范的地方，最后返回一个write函数（用于向套接字相关文件写入数据，PEP要求）。 参考：https://segmentfault.com/a/1190000003069785 http://blog.csdn.net/laughing2333/article/details/51288660 http://blog.csdn.net/sraing/article/details/8455242 https://www.python.org/dev/peps/pep-3333/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（2）]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%882%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 本文从neutron-server入手： neutron\cmd\eventlet\server:main 123456789101112131415#/neutron/cmd/eventlet/server/__init__.pyfrom oslo_config import cfgfrom neutron import serverfrom neutron.server import rpc_eventletfrom neutron.server import wsgi_eventletfrom neutron.server import wsgi_pecandef main(): server.boot_server(_main_neutron_server)def _main_neutron_server(): if cfg.CONF.web_framework == 'legacy': wsgi_eventlet.eventlet_wsgi_server()# 使用原先实现 eventlet_wsgi_server 启动服务 else: wsgi_pecan.pecan_wsgi_server()#使用新实现 Pecan WSGI server启动服务def main_rpc_eventlet(): server.boot_server(rpc_eventlet.eventlet_rpc_server) 首先从整体明确这段代码做了什么。核心任务启动两个服务：api服务和rpc服务，包括RPC-server的创建，RPC-client的创建，WSGI server的创建。 server.boot_server()代码如下： 1234567891011121314151617181920#/neutron/server/__init__.pyimport sysfrom oslo_config import cfgfrom neutron._i18n import _from neutron.common import configdef boot_server(server_func): # the configuration will be read into the cfg.CONF global data structure config.init(sys.argv[1:]) config.setup_logging() config.set_config_defaults() if not cfg.CONF.config_file: sys.exit(_("ERROR: Unable to find configuration file via the default" " search paths (~/.neutron/, ~/, /etc/neutron/, /etc/) and" " the '--config-file' option!")) try: server_func() except KeyboardInterrupt: pass except RuntimeError as e: sys.exit(_("ERROR: %s") % e) 这段代码做的事情就是读取neutron\common\config配置文件，做初始化，包括日志，配置等，然后 server_func()，也即_main_neutron_server()启动。因为在api服务实现上目前有两种方式，”legacy”和”pecan”,根据读取的neutron\common\config中的配置来启动api服务，我们先看看原先的实现机制吧。 wsgi_eventlet.eventlet_wsgi_server() 1234567891011121314151617181920212223242526#/neutron/server/wsgi_eventlet.pyimport eventletfrom oslo_log import logfrom neutron._i18n import _LIfrom neutron import serviceLOG = log.getLogger(__name__)def eventlet_wsgi_server(): neutron_api = service.serve_wsgi(service.NeutronApiService) start_api_and_rpc_workers(neutron_api)def start_api_and_rpc_workers(neutron_api): pool = eventlet.GreenPool() api_thread = pool.spawn(neutron_api.wait) try: neutron_rpc = service.serve_rpc() except NotImplementedError: LOG.info(_LI("RPC was already started in parent process by " "plugin.")) else: rpc_thread = pool.spawn(neutron_rpc.wait) plugin_workers = service.start_plugin_workers() for worker in plugin_workers: pool.spawn(worker.wait) # api and rpc should die together. When one dies, kill the other. rpc_thread.link(lambda gt: api_thread.kill()) api_thread.link(lambda gt: rpc_thread.kill()) pool.waitall() neutron_api = service.serve_wsgi(service.NeutronApiService) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#/neutron/service.pydef serve_wsgi(cls): try: service = cls.create() # create(cls, app_name='neutron') service.start() # _run_wsgi(self.app_name) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_LE('Unrecoverable error: please check log ' 'for details.')) return service#/neutron/service.py：NeutronApiServiceclass NeutronApiService(WsgiService): """Class for neutron-api service.""" @classmethod def create(cls, app_name='neutron'): # Setup logging early, supplying both the CLI options and the # configuration mapping from the config file # We only update the conf dict for the verbose and debug # flags. Everything else must be set up in the conf file... # Log the options used when starting if we're in debug mode... config.setup_logging() service = cls(app_name) return service #/neutron/service.py：WsgiServiceclass WsgiService(object): """Base class for WSGI based services. For each api you define, you must also define these flags: :&lt;api&gt;_listen: The address on which to listen :&lt;api&gt;_listen_port: The port on which to listen """ def __init__(self, app_name): self.app_name = app_name self.wsgi_app = None def start(self): self.wsgi_app = _run_wsgi(self.app_name) def wait(self): self.wsgi_app.wait() #/neutron/service.py def _run_wsgi(app_name): app = config.load_paste_app(app_name) if not app: LOG.error(_LE('No known API applications configured.')) return return run_wsgi_app(app)#/neutron/service.py def run_wsgi_app(app): server = wsgi.Server("Neutron") server.start(app, cfg.CONF.bind_port, cfg.CONF.bind_host, workers=_get_api_workers()) LOG.info(_LI("Neutron service started, listening on %(host)s:%(port)s"), &#123;'host': cfg.CONF.bind_host, 'port': cfg.CONF.bind_port&#125;) return server]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron架构]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（1）]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%881%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 Neutron是OpenStack中用于管理网络的项目。neutron代码的入口配置文件neutron/setup.cfg，从[entry_points]可以看到整个项目服务的结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125[entry_points]console_scripts = neutron-bgp-dragent = neutron.cmd.eventlet.agents.bgp_dragent:main neutron-db-manage = neutron.db.migration.cli:main neutron-debug = neutron.debug.shell:main neutron-dhcp-agent = neutron.cmd.eventlet.agents.dhcp:main // neutron-keepalived-state-change = neutron.cmd.keepalived_state_change:main neutron-ipset-cleanup = neutron.cmd.ipset_cleanup:main neutron-l3-agent = neutron.cmd.eventlet.agents.l3:main // neutron-linuxbridge-agent = neutron.cmd.eventlet.plugins.linuxbridge_neutron_agent:main neutron-linuxbridge-cleanup = neutron.cmd.linuxbridge_cleanup:main neutron-macvtap-agent = neutron.cmd.eventlet.plugins.macvtap_neutron_agent:main neutron-metadata-agent = neutron.cmd.eventlet.agents.metadata:main neutron-netns-cleanup = neutron.cmd.netns_cleanup:main neutron-ns-metadata-proxy = neutron.cmd.eventlet.agents.metadata_proxy:main neutron-openvswitch-agent = neutron.cmd.eventlet.plugins.ovs_neutron_agent:main // neutron-ovs-cleanup = neutron.cmd.ovs_cleanup:main neutron-pd-notify = neutron.cmd.pd_notify:main neutron-server = neutron.cmd.eventlet.server:main // neutron-rpc-server = neutron.cmd.eventlet.server:main_rpc_eventlet neutron-rootwrap = oslo_rootwrap.cmd:main neutron-rootwrap-daemon = oslo_rootwrap.cmd:daemon neutron-usage-audit = neutron.cmd.eventlet.usage_audit:main neutron-metering-agent = neutron.cmd.eventlet.services.metering_agent:main neutron-sriov-nic-agent = neutron.cmd.eventlet.plugins.sriov_nic_neutron_agent:main neutron-sanity-check = neutron.cmd.sanity_check:mainneutron.core_plugins = ml2 = neutron.plugins.ml2.plugin:Ml2Plugin //neutron.service_plugins = dummy = neutron.tests.unit.dummy_plugin:DummyServicePlugin router = neutron.services.l3_router.l3_router_plugin:L3RouterPlugin // firewall = neutron_fwaas.services.firewall.fwaas_plugin:FirewallPlugin // lbaas = neutron_lbaas.services.loadbalancer.plugin:LoadBalancerPlugin vpnaas = neutron_vpnaas.services.vpn.plugin:VPNDriverPlugin metering = neutron.services.metering.metering_plugin:MeteringPlugin neutron.services.firewall.fwaas_plugin.FirewallPlugin = neutron_fwaas.services.firewall.fwaas_plugin:FirewallPlugin neutron.services.loadbalancer.plugin.LoadBalancerPlugin = neutron_lbaas.services.loadbalancer.plugin:LoadBalancerPlugin neutron.services.vpn.plugin.VPNDriverPlugin = neutron_vpnaas.services.vpn.plugin:VPNDriverPlugin qos = neutron.services.qos.qos_plugin:QoSPlugin bgp = neutron.services.bgp.bgp_plugin:BgpPlugin tag = neutron.services.tag.tag_plugin:TagPlugin flavors = neutron.services.flavors.flavors_plugin:FlavorsPlugin auto_allocate = neutron.services.auto_allocate.plugin:Plugin network_ip_availability = neutron.services.network_ip_availability.plugin:NetworkIPAvailabilityPlugin timestamp_core = neutron.services.timestamp.timestamp_plugin:TimeStampPluginneutron.qos.notification_drivers = message_queue = neutron.services.qos.notification_drivers.message_queue:RpcQosServiceNotificationDriver //neutron.ml2.type_drivers = flat = neutron.plugins.ml2.drivers.type_flat:FlatTypeDriver local = neutron.plugins.ml2.drivers.type_local:LocalTypeDriver vlan = neutron.plugins.ml2.drivers.type_vlan:VlanTypeDriver geneve = neutron.plugins.ml2.drivers.type_geneve:GeneveTypeDriver gre = neutron.plugins.ml2.drivers.type_gre:GreTypeDriver vxlan = neutron.plugins.ml2.drivers.type_vxlan:VxlanTypeDriver //neutron.ml2.mechanism_drivers = logger = neutron.tests.unit.plugins.ml2.drivers.mechanism_logger:LoggerMechanismDriver test = neutron.tests.unit.plugins.ml2.drivers.mechanism_test:TestMechanismDriver linuxbridge = neutron.plugins.ml2.drivers.linuxbridge.mech_driver.mech_linuxbridge:LinuxbridgeMechanismDriver macvtap = neutron.plugins.ml2.drivers.macvtap.mech_driver.mech_macvtap:MacvtapMechanismDriver openvswitch = neutron.plugins.ml2.drivers.openvswitch.mech_driver.mech_openvswitch:OpenvswitchMechanismDriver l2population = neutron.plugins.ml2.drivers.l2pop.mech_driver:L2populationMechanismDriver sriovnicswitch = neutron.plugins.ml2.drivers.mech_sriov.mech_driver.mech_driver:SriovNicSwitchMechanismDriver fake_agent = neutron.tests.unit.plugins.ml2.drivers.mech_fake_agent:FakeAgentMechanismDriverneutron.ml2.extension_drivers = test = neutron.tests.unit.plugins.ml2.drivers.ext_test:TestExtensionDriver testdb = neutron.tests.unit.plugins.ml2.drivers.ext_test:TestDBExtensionDriver port_security = neutron.plugins.ml2.extensions.port_security:PortSecurityExtensionDriver qos = neutron.plugins.ml2.extensions.qos:QosExtensionDriver dns = neutron.plugins.ml2.extensions.dns_integration:DNSExtensionDriverML2neutron.openstack.common.cache.backends = memory = neutron.openstack.common.cache._backends.memory:MemoryBackendneutron.ipam_drivers = fake = neutron.tests.unit.ipam.fake_driver:FakeDriver internal = neutron.ipam.drivers.neutrondb_ipam.driver:NeutronDbPoolneutron.agent.l2.extensions = qos = neutron.agent.l2.extensions.qos:QosAgentExtensionneutron.qos.agent_drivers = ovs = neutron.plugins.ml2.drivers.openvswitch.agent.extension_drivers.qos_driver:QosOVSAgentDriver sriov = neutron.plugins.ml2.drivers.mech_sriov.agent.extension_drivers.qos_driver:QosSRIOVAgentDriver linuxbridge = neutron.plugins.ml2.drivers.linuxbridge.agent.extension_drivers.qos_driver:QosLinuxbridgeAgentDriverneutron.agent.linux.pd_drivers = dibbler = neutron.agent.linux.dibbler:PDDibblerneutron.services.external_dns_drivers = designate = neutron.services.externaldns.drivers.designate.driver:Designate# These are for backwards compat with Icehouse notification_driver configuration values# TODO(mriedem): Remove these once liberty-eol happens.oslo.messaging.notify.drivers = neutron.openstack.common.notifier.log_notifier = oslo_messaging.notify._impl_log:LogDriver neutron.openstack.common.notifier.no_op_notifier = oslo_messaging.notify._impl_noop:NoOpDriver neutron.openstack.common.notifier.test_notifier = oslo_messaging.notify._impl_test:TestDriver neutron.openstack.common.notifier.rpc_notifier2 = oslo_messaging.notify.messaging:MessagingV2Driver neutron.openstack.common.notifier.rpc_notifier = oslo_messaging.notify.messaging:MessagingDriveroslo.config.opts = neutron = neutron.opts:list_opts neutron.agent = neutron.opts:list_agent_opts neutron.base.agent = neutron.opts:list_base_agent_opts neutron.bgp.agent = neutron.services.bgp.common.opts:list_bgp_agent_opts neutron.db = neutron.opts:list_db_opts neutron.dhcp.agent = neutron.opts:list_dhcp_agent_opts neutron.extensions = neutron.opts:list_extension_opts neutron.l3.agent = neutron.opts:list_l3_agent_opts neutron.metadata.agent = neutron.opts:list_metadata_agent_opts neutron.metering.agent = neutron.opts:list_metering_agent_opts neutron.ml2 = neutron.opts:list_ml2_conf_opts neutron.ml2.linuxbridge.agent = neutron.opts:list_linux_bridge_opts neutron.ml2.macvtap.agent = neutron.opts:list_macvtap_opts neutron.ml2.ovs.agent = neutron.opts:list_ovs_opts neutron.ml2.sriov = neutron.opts:list_ml2_conf_sriov_opts neutron.ml2.sriov.agent = neutron.opts:list_sriov_agent_opts neutron.qos = neutron.opts:list_qos_opts nova.auth = neutron.opts:list_auth_optsoslo.config.opts.defaults = neutron = neutron.common.config:set_cors_middleware_defaultsneutron.db.alembic_migrations = neutron = neutron.db.migration:alembic_migrationsneutron.interface_drivers = ivs = neutron.agent.linux.interface:IVSInterfaceDriver linuxbridge = neutron.agent.linux.interface:BridgeInterfaceDriver null = neutron.agent.linux.interface:NullDriver openvswitch = neutron.agent.linux.interface:OVSInterfaceDriverneutron.agent.firewall_drivers = noop = neutron.agent.firewall:NoopFirewallDriver iptables = neutron.agent.linux.iptables_firewall:IptablesFirewallDriver iptables_hybrid = neutron.agent.linux.iptables_firewall:OVSHybridIptablesFirewallDriver openvswitch = neutron.agent.linux.openvswitch_firewall:OVSFirewallDriver 我们按照以下顺序学习源码： neutron-server 是Neutron中唯一的一个服务进程，负责接收用户的RESTful API请求并分发处理给各种agen来完成这些的任务。根据setup.cfg文件可以看出neutron代码路径是neutron\cmd\eventlet\server:main neutron-l3-agent l3 agent部署在计算节点或者网络节点上,负责3层虚拟网络的管理。根据setup.cfg文件可以看出neutron-l3-agent的代码路径是neutron\cmd\eventlet\agents\l3:main neutron-openvswitch-agent neutron-openvswitch-agent：Open vSwitch Agent部署在计算节点或者网络节点上，进行管理OVS虚拟交换机。根据setup.cfg文件可以看出neutron-openvswitch-agent的代码路径是neutron\cmd\eventlet\plugins\ovs_neutron_agent:main neutron-dhcp-agent ml2 router firewall message_queue]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线程同步工具CountDownLatch，CyclicBarrier和Semaphore的用法]]></title>
      <url>%2F2017%2F02%2F25%2F%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7CountDownLatch%EF%BC%8CCyclicBarrier%E5%92%8CSemaphore%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
      <content type="text"><![CDATA[CountDownLatch​ CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 伪代码为： ​ Main thread start​ Create CountDownLatch for N threads​ Create and start N threads​ Main thread wait on latch​ N threads completes there tasks are returns​ Main thread resume execution 主要方法： public CountDownLatch(int count); public void countDown(); public void await() throws InterruptedException CountDownLatch实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package Demo;import java.util.concurrent.CountDownLatch;public abstract class BaseHealthChecker implements Runnable&#123; private CountDownLatch latch; private String name; private boolean isServiceUp; public BaseHealthChecker(CountDownLatch latch, String name) &#123; super(); this.latch = latch; this.name = name; this.isServiceUp=false; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public boolean isServiceUp() &#123; return isServiceUp; &#125; public void setServiceUp(boolean isServiceUp) &#123; this.isServiceUp = isServiceUp; &#125; public abstract void checkService(); @Override public void run() &#123; // TODO Auto-generated method stub try &#123; checkService(); isServiceUp=true; &#125; catch (Throwable t) &#123; // TODO: handle exception t.printStackTrace(System.err); isServiceUp=false; &#125; finally&#123; if(latch!=null)&#123; latch.countDown(); &#125; &#125; &#125; &#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class CacheHealthChecker extends BaseHealthChecker &#123; public CacheHealthChecker(CountDownLatch latch) &#123; super(latch, "Cache Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class DatabaseHealthChecker extends BaseHealthChecker &#123; public DatabaseHealthChecker(CountDownLatch latch) &#123; super(latch, "Database Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class NetworkHealthChecker extends BaseHealthChecker &#123; public NetworkHealthChecker(CountDownLatch latch) &#123; super(latch, "Network Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+" is Up"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package Demo;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ApplicationStartupUtil &#123; private static List&lt;BaseHealthChecker&gt; services; private static CountDownLatch latch; private final static ApplicationStartupUtil app=new ApplicationStartupUtil(); public ApplicationStartupUtil()&#123; &#125; public static ApplicationStartupUtil getInstance()&#123; return app; &#125; public static boolean checkExternalService()&#123; boolean re=true; latch=new CountDownLatch(3); services=new ArrayList&lt;BaseHealthChecker&gt;(); services.add(new NetworkHealthChecker(latch)); services.add(new CacheHealthChecker(latch)); services.add(new DatabaseHealthChecker(latch)); ExecutorService executors=Executors.newFixedThreadPool(services.size()); for(final BaseHealthChecker v: services)&#123; executors.execute(v); &#125; executors.shutdown(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for(final BaseHealthChecker v:services)&#123; if(! v.isServiceUp())&#123; re=false; System.out.println("All services checked ,result is "+re); &#125; &#125; System.out.println("All services checked ,result is "+re); return re; &#125;&#125; 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; boolean re=false; ApplicationStartupUtil.checkExternalService(); &#125;&#125;//输出：Checking Network ServiceChecking Cache ServiceChecking Database ServiceNetwork Service is UpCache Serviceis UpDatabase Serviceis UpAll services checked ,result is true CyclicBarrier​ CyclicBarrier 类有一个整数初始值，此值表示将在同一点同步的线程数量。当其中一个线程到达确定点，它会调用await() 方法来等待其他线程。此时CyclicBarrier阻塞该线程进入休眠等待其他线程的到达。当最后一个线程调用CyclicBarrier 类的await() 方法，它唤醒所有等待的线程并继续执行它们的任务。 ​ CountDownLatch和CyclicBarrier的区别在于：CountDownLatch 适用于一组线程和另一个主线程之间的工作协作。一个主线程等待一组工作线程的任务完毕才继续它的执行是使用 CountDownLatch 的主要场景；CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。CyclicBarrier 的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的； CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 CyclicBarrier实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.Random;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class DemoCyclicBarrier &#123; public static void main(String[] args) &#123; int thread_num=5; CyclicBarrier cyclicBarrier=new CyclicBarrier(thread_num, new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("Internal Barrier"); &#125; &#125;); ExecutorService executor=Executors.newFixedThreadPool(thread_num); for (int i=0;i&lt;5;i++)&#123; executor.execute(new worker("worker "+i, cyclicBarrier)); &#125; executor.shutdown(); &#125;&#125;class worker implements Runnable&#123; private String name; private CyclicBarrier cyclicbarrier; public worker(String name, CyclicBarrier cyclicBarrier)&#123; this.name=name; this.cyclicbarrier=cyclicBarrier; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; Thread.sleep(1000 * (new Random()).nextInt(8)); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker "+this.getName()+" is waiting"); try &#123; cyclicbarrier.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker"+this.getName()+" is working"); &#125; &#125; Semaphore​ Semaphore 直译是信号量，可能称它是许可量更容易理解。当然，因为在计算机科学中这个名字由来已久，所以不能乱改。它的功能比较好理解，就是通过构造函数设定一个数量的许可，然后通过 acquire 方法获得许可，release 方法释放许可。它还有 tryAcquire 和 acquireUninterruptibly 方法，可以根据自己的需要选择。 Semaphore实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); Semaphore semp=new Semaphore(5); for(int i=0;i&lt;10;i++)&#123; exec.execute(new workerThread(i,semp)); &#125; exec.shutdown(); &#125;&#125;class workerThread implements Runnable&#123; private int id ; private Semaphore semp; public workerThread(int id, Semaphore semp) &#123; super(); this.id = id; this.semp = semp; &#125; public int getId() &#123; return id; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; semp.acquire(); System.out.println("workerThread id "+this.getId()+" get Access"); Thread.sleep((long) (Math.random() * 10000)); System.out.println("workerThread id "+this.getId()+" finish the work"); semp.release();//注销该语句后，只会执行5个线程，其他处在阻塞中 &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;//输出(未注销semp.release())workerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 4 get AccessworkerThread id 1 get AccessworkerThread id 1 finish the workworkerThread id 5 get AccessworkerThread id 2 finish the workworkerThread id 6 get AccessworkerThread id 4 finish the workworkerThread id 7 get AccessworkerThread id 6 finish the workworkerThread id 8 get AccessworkerThread id 7 finish the workworkerThread id 9 get AccessworkerThread id 8 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 9 finish the workworkerThread id 5 finish the work//输出(注销semp.release())workerThread id 1 get AccessworkerThread id 4 get AccessworkerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 2 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 4 finish the workworkerThread id 1 finish the work 参考：1.http://www.importnew.com/15731.html 2.http://blog.csdn.net/junshuaizhang/article/details/39580751 3.http://blog.csdn.net/junshuaizhang/article/details/39667289 4.http://developer.51cto.com/art/201403/432095.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之Executor框架和线程池]]></title>
      <url>%2F2017%2F02%2F23%2FJava%E5%B9%B6%E5%8F%91%E4%B9%8BExecutor%E6%A1%86%E6%9E%B6%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[1.基础简介：​ 在Java 5之后，并发编程引入了一堆新的启动、调度和管理线程的API。Executor框架便是Java 5中引入的，其内部使用了线程池机制，它在java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。 ​ Executor框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable等。 Executor接口中之定义了一个方法execute（Runnable command），该方法接收一个Runable实例，它用来执行一个任务，任务即一个实现了Runnable接口的类。 2.ExecutorService接口：​ ExecutorService接口继承自Executor接口，它提供了更丰富的实现多线程的方法，比如，ExecutorService提供了关闭自己的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以调用ExecutorService的shutdown（）方法来平滑地关闭 。在调用该方法之后，它会停止接受任何新的任务且等待已经提交的任务执行完成(已经提交的任务会分两类：一类是已经在执行的，另一类是还没有开始执行的)，当所有已经提交的任务执行完毕后将会关闭ExecutorService。因此我们一般用该接口来实现和管理多线程。 ​ ExecutorService的生命周期包括三种状态：运行、关闭、终止。创建后便进入运行状态，当调用了shutdown（）方法时，便进入关闭状态，此时意味着ExecutorService不再接受新的任务，但它还在执行已经提交了的任务，当素有已经提交了的任务执行完后，便到达终止状态。如果不调用shutdown（）方法，ExecutorService会一直处在运行状态，不断接收新的任务，执行新的任务，服务器端一般不需要关闭它，保持一直运行即可。 3.ExecutorService中submit和execute的区别：接收的参数不一样 submit有返回值，而execute没有 ​ Method submit extends base method Executor.execute by creating and returning a Future that can be used to cancel execution and/or wait for completion. ​ 用到返回值的例子，比如说我有很多个做validation的task，我希望所有的task执行完，然后每个task告诉我它的执行结果，是成功还是失败，如果是失败，原因是什么。然后我就可以把所有失败的原因综合起来发给调用者。 submit方便Exception处理 ​ There is a difference when looking at exception handling. If your tasks throws an exception and if it was submitted with execute this exception will go to the uncaught exception handler (when you don’t have provided one explicitly, the default one will just print the stack trace to System.err). If you submitted the task with submit any thrown exception, checked or not, is then part of the task’s return status. For a task that was submitted with submit and that terminates with an exception, the Future.get will rethrow this exception, wrapped in an ExecutionException. ​ 意思就是如果你在你的task里会抛出checked或者unchecked exception，而你又希望外面的调用者能够感知这些exception并做出及时的处理，那么就需要用到submit，通过捕获Future.get抛出的异常。 ​ 比如说，我有很多更新各种数据的task，我希望如果其中一个task失败，其它的task就不需要执行了。那我就需要catch Future.get抛出的异常，然后终止其它task的执行 下面的Executor执行Runnable任务和Executor执行Callable任务便是execute和submit的例子。 4.Executors（线程池管理类）：​ Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 public static ExecutorService newCachedThreadPool() 创建一个可缓存的线程池，调用execute将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 ​ 缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse.如果没有，就建一个新的线程加入池中，缓存型池子通常用于执行一些生存期很短的异步型任务。因此在一些面向连接的daemon型SERVER中用得不多。但对于生存期短的异步任务，它是Executor的首选。能reuse的线程，必须是timeout IDLE内的池中线程，缺省 timeout是60s,超过这个IDLE时长，线程实例将被终止及移出池。注意，放入CachedThreadPool的线程不必担心其结束，超过TIMEOUT不活动，其会自动被终止。 public static ExecutorService newFixedThreadPool(int nThreads) 创建固定数目线程的线程池 ​ newFixedThreadPool与cacheThreadPool差不多，也是能reuse就用，但不能随时建新的线程。其独特之处:任意时间点，最多只能有固定数目的活动线程存在，此时如果有新的线程要建立，只能放在另外的队列中等待，直到当前的线程中某个线程终止直接被移出池子。和cacheThreadPool不同，FixedThreadPool没有IDLE机制（可能也有，但既然文档没提，肯定非常长，类似依赖上层的TCP或UDP IDLE机制之类的），所以FixedThreadPool多数针对一些很稳定很固定的正规并发线程，多用于服务器。从方法的源代码看，cache池和fixed 池调用的是同一个底层池，只不过参数不同:fixed池线程数固定，并且是0秒IDLE（无IDLE）cache池线程数支持0-Integer.MAX_VALUE(显然完全没考虑主机的资源承受能力），60秒IDLE 。 public static ExecutorService newSingleThreadExecutor() 创建一个单线程化的Executor。 ​ 单例线程，任意时间池中只能有一个线程，用的是和cache池和fixed池相同的底层池，但线程数目是1-1,0秒IDLE（无IDLE）。 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) 创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。 ​ 调度型线程池，这个池子里的线程可以按schedule依次delay执行，或周期执行。 一般来说，CachedTheadPool在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的Executor的首选，只有当这种方式会引发问题时（比如需要大量长时间面向连接的线程时），才需要考虑用FixedThreadPool。（该段话摘自《Thinking in Java》第四版） 5.Executor接口执行任务：Executor执行Runnable任务 ​ 通过Executors的以上四个静态工厂方法获得 ExecutorService实例，而后调用该实例的execute（Runnable command）方法即可。一旦Runnable任务传递到execute（）方法，该方法便会自动在一个线程上执行。下面是是Executor执行Runnable任务的示例代码： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TestCachedThreadPool&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); //ExecutorService executorService = Executors.newFixedThreadPool(3); //ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 5; i++)&#123; executorService.execute(new TestRunnable(i)); &#125; executorService.shutdown(); &#125; &#125; class TestRunnable implements Runnable&#123; private int count ; public TestRunnable(int count)&#123; this.count=count; System.out.println("Create Thread-"+count); &#125; public void run()&#123; System.out.println("线程池中的"+Thread.currentThread().getName() + "被调用来处理Thread-"+count); &#125; &#125; //输出：Create Thread-0Create Thread-1Create Thread-2线程池中的pool-1-thread-1被调用来处理Thread-0Create Thread-3线程池中的pool-1-thread-2被调用来处理Thread-1Create Thread-4线程池中的pool-1-thread-2被调用来处理Thread-4线程池中的pool-1-thread-3被调用来处理Thread-2线程池中的pool-1-thread-4被调用来处理Thread-3 ​ 从结果中可以看出，pool-1-thread-2被调用了两次，这是随机的，execute会首先在线程池中选择一个已有空闲线程来执行任务，如果线程池中没有空闲线程，它便会创建一个新的线程来执行任务 同时也可以配合ThreadFactory接口的使用 123456789101112131415161718192021222324252627282930313233343536ExecutorService daemonThreadFactory = Executors.newCachedThreadPool(new DaemonThreadFactory()); ExecutorService maxPriorityThreadFactory = Executors.newCachedThreadPool(new MaxPriorityThreadFactory()); ExecutorService minPriorityThreadFactory = Executors.newCachedThreadPool(new MinPriorityThreadFactory());//设置后台线程属性class DaemonThreadFactory implements ThreadFactory&#123; @Override public Thread newThread(Runnable arg0) &#123; // TODO Auto-generated method stub Thread t=new Thread(arg0); t.setDaemon(true); return t; &#125; &#125;//设置最高优先级属性class MaxPriorityThreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setPriority(Thread.MAX_PRIORITY); return t; &#125;&#125;//设置最低优先级属性class MinPriorityThreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setPriority(Thread.MIN_PRIORITY); return t; &#125;&#125; Executor执行Callable任务 ​ 在Java 5之后，任务分两类：一类是实现了Runnable接口的类，一类是实现了Callable接口的类。两者都可以被ExecutorService执行，但是Runnable任务没有返回值，而Callable任务有返回值。并且Callable的call()方法只能通过ExecutorService的submit(Callable task) 方法来执行，并且返回一个 Future，是表示任务等待完成的 Future。 ​ Callable接口类似于Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常而Callable又返回结果，而且当获取返回结果时可能会抛出异常。Callable中的call()方法类似Runnable的run()方法，区别同样是有返回值，后者没有。 ​ 当将一个Callable的对象传递给ExecutorService的submit方法，则该call方法自动在一个线程上执行，并且会返回执行结果Future对象。同样，将Runnable的对象传递给ExecutorService的submit方法，则该run方法自动在一个线程上执行，并且会返回执行结果Future对象，但是在该Future对象上调用get方法，将返回null。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import java.util.ArrayList; import java.util.List; import java.util.concurrent.*; public class CallableDemo&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;(); //创建10个任务并执行 for (int i = 0; i &lt; 10; i++)&#123; //使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中 Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i)); //将任务执行结果存储到List中 resultList.add(future); &#125; //遍历任务的结果 for (Future&lt;String&gt; fs : resultList)&#123; try&#123; while(!fs.isDone());//Future返回如果没有完成，则一直循环等待，直到Future返回完成 System.out.println(fs.get()); //打印各个线程（任务）执行的结果 &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125;catch(ExecutionException e)&#123; e.printStackTrace(); &#125;finally&#123; //启动一次顺序关闭，执行以前提交的任务，但不接受新任务 executorService.shutdown(); &#125; &#125; &#125; &#125; class TaskWithResult implements Callable&lt;String&gt;&#123; private int id; public TaskWithResult(int id)&#123; this.id = id; &#125; /** * 任务的具体过程，一旦任务传给ExecutorService的submit方法， * 则该方法自动在一个线程上执行 */ public String call() throws Exception &#123; System.out.println("Task id="+id+" 的call()方法被" + Thread.currentThread().getName()+"自动调用！！"); //该返回结果将被Future的get方法得到 return "Task id="+id+" 的call()方法被自动调用，任务返回的结果是：" + id + ""; &#125; &#125; //输出：Task id=0 的call()方法被pool-1-thread-1自动调用！！Task id=2 的call()方法被pool-1-thread-3自动调用！！Task id=1 的call()方法被pool-1-thread-2自动调用！！Task id=3 的call()方法被pool-1-thread-4自动调用！！Task id=4 的call()方法被pool-1-thread-5自动调用！！Task id=0 的call()方法被自动调用，任务返回的结果是：0Task id=9 的call()方法被pool-1-thread-1自动调用！！Task id=6 的call()方法被pool-1-thread-7自动调用！！Task id=5 的call()方法被pool-1-thread-6自动调用！！Task id=7 的call()方法被pool-1-thread-8自动调用！！Task id=1 的call()方法被自动调用，任务返回的结果是：1Task id=2 的call()方法被自动调用，任务返回的结果是：2Task id=8 的call()方法被pool-1-thread-9自动调用！！Task id=3 的call()方法被自动调用，任务返回的结果是：3Task id=4 的call()方法被自动调用，任务返回的结果是：4Task id=5 的call()方法被自动调用，任务返回的结果是：5Task id=6 的call()方法被自动调用，任务返回的结果是：6Task id=7 的call()方法被自动调用，任务返回的结果是：7Task id=8 的call()方法被自动调用，任务返回的结果是：8Task id=9 的call()方法被自动调用，任务返回的结果是：9 ​ 从结果中可以同样可以看出，pool-1-thread-1被调用2次处理id=0和id=9的任务，submit也是首先选择空闲线程来执行任务，如果没有，才会创建新的线程来执行任务。另外，需要注意：如果Future的返回尚未完成，则get（）方法会阻塞等待，直到Future完成返回，可以通过调用isDone（）方法判断Future是否完成了返回。 Executor执行inVokeAny任务 ​ 方法 invokeAny() 接收一個包含 Callable 对象的集合作为参数。调用该方法不会返回 Future 对象，而是返回集合中某一個 Callable 对象的结果，而且无法保证调用之后返回的结果是哪一個 Callable，只知道它是这些 Callable 中一個执行结束的 Callable 对象。如果一个任务运行完毕或者抛出异常，方法会取消其它的 Callable 的执行。 Executor执行invokeAll任务 ​ 方法 invokeAll() 会调用存在于参数集合中的所有 Callable 对象，并且返回壹個包含 Future 对象的集合，你可以通过这個返回的集合来管理每個 Callable 的执行结果。需要注意的是，任务有可能因为异常而导致运行结束，所以它可能并不是真的成功运行了。但是我们没有办法通过 Future 对象来了解到这個差异。 自定义线程池ThreadPoolExecutor ​ 自定义线程池，可以用ThreadPoolExecutor类创建，它有多个构造方法来创建线程池，用该类很容易实现自定义的线程池，这里先贴上示例程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class ThreadPoolTest&#123; public static void main(String[] args)&#123; //创建等待队列 BlockingQueue&lt;Runnable&gt; bqueue = new ArrayBlockingQueue&lt;Runnable&gt;(20); //创建线程池，池中保存的线程数为3，允许的最大线程数为5 ThreadPoolExecutor pool = new ThreadPoolExecutor(3,5,50,TimeUnit.MILLISECONDS,bqueue); //创建七个任务 Runnable t1 = new MyThreads("t1"); Runnable t2 = new MyThreads("t2"); Runnable t3 = new MyThreads("t3"); Runnable t4 = new MyThreads("t4"); Runnable t5 = new MyThreads("t5"); Runnable t6 = new MyThreads("t6"); Runnable t7 = new MyThreads("t7"); //每个任务会在一个线程上执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); pool.execute(t6); pool.execute(t7); //关闭线程池 pool.shutdown(); &#125; &#125; class MyThreads implements Runnable&#123; private String name; public String getName() &#123; return name; &#125; public MyThreads(String name) &#123; // TODO Auto-generated constructor stub this.name=name; &#125; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + "正在执行 "+this.getName()); try&#123; Thread.sleep(100); &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; //输出pool-1-thread-2正在执行 t2pool-1-thread-3正在执行 t3pool-1-thread-1正在执行 t1pool-1-thread-1正在执行 t4pool-1-thread-3正在执行 t6pool-1-thread-2正在执行 t5pool-1-thread-3正在执行 t7 ​ 从结果中可以看出，七个任务是在线程池的三个线程上执行的。这里简要说明下用到的ThreadPoolExecuror类的构造方法中各个参数的含义。 1public ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue) corePoolSize：线程池中所保存的核心线程数，包括空闲线程。 maximumPoolSize：池中允许的最大线程数。 keepAliveTime：线程池中的空闲线程所能持续的最长时间。 unit：持续时间的单位。 workQueue：任务执行前保存任务的队列，仅保存由execute方法提交的Runnable任务。 根据ThreadPoolExecutor源码前面大段的注释，我们可以看出，当试图通过excute方法讲一个Runnable任务添加到线程池中时，按照如下顺序来处理： 1、如果线程池中的线程数量少于corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务； 2、如果线程池中的线程数量大于等于corePoolSize，但缓冲队列workQueue未满，则将新添加的任务放到workQueue中，按照FIFO的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）； 3、如果线程池中的线程数量大于等于corePoolSize，且缓冲队列workQueue已满，但线程池中的线程数量小于maximumPoolSize，则会创建新的线程来处理被添加的任务； 4、如果线程池中的线程数量等于了maximumPoolSize，有4种才处理方式（该构造方法调用了含有5个参数的构造方法，并将最后一个构造方法为RejectedExecutionHandler类型，它在处理线程溢出时有4种方式，这里不再细说，要了解的，自己可以阅读下源码）。 ​ 另外，当线程池中的线程数量大于corePoolSize时，如果里面有线程的空闲时间超过了keepAliveTime，就将其移除线程池，这样，可以动态地调整线程池中线程的数量。我们大致来看下Executors的源码，newCachedThreadPool的不带RejectedExecutionHandler参数（即第五个参数，线程数量超过maximumPoolSize时，指定处理方式）的构造方法如下： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 它将corePoolSize设定为0，而将maximumPoolSize设定为了Integer的最大值，线程空闲超过60秒，将会从线程池中移除。由于核心线程数为0，因此每次添加任务，都会先从线程池中找空闲线程，如果没有就会创建一个线程（SynchronousQueue决定的，后面会说）来执行新的任务，并将该线程加入到线程池中，而最大允许的线程数为Integer的最大值，因此这个线程池理论上可以不断扩大。 再来看newFixedThreadPool的不带RejectedExecutionHandler参数的构造方法，如下： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 它将corePoolSize和maximumPoolSize都设定为了nThreads，这样便实现了线程池的大小的固定，不会动态地扩大，另外，keepAliveTime设定为了0，也就是说线程只要空闲下来，就会被移除线程池，敢于LinkedBlockingQueue下面会说。 6.ExecuteService 服务的关闭​ shutdown()方法在终止前允许执行以前提交的任务，而 shutdownNow() 方法阻止等待任务的启动并试图停止当前正在执行的任务。在终止后，执行程序没有任务在执行，也没有任务在等待执行，并且无法提交新任务。应该关闭未使用的 ExecutorService以允许回收其资源。 7.排队的策略:1、直接提交。缓冲队列采用 SynchronousQueue，它将任务直接交给线程处理而不保持它们。如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中。直接提交通常要求无界 maximumPoolSizes（Integer.MAX_VALUE） 以避免拒绝新提交的任务。newCachedThreadPool采用的便是这种策略。 2、无界队列。使用无界队列（典型的便是采用预定义容量的 LinkedBlockingQueue，理论上是该缓冲队列可以对无限多的任务排队）将导致在所有 corePoolSize 线程都工作的情况下将新任务加入到缓冲队列中。这样，创建的线程就不会超过 corePoolSize，也因此，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列。newFixedThreadPool采用的便是这种策略。 3、有界队列。当使用有限的 maximumPoolSizes 时，有界队列（一般缓冲队列使用ArrayBlockingQueue，并制定队列的最大长度）有助于防止资源耗尽，但是可能较难调整和控制，队列大小和最大池大小需要相互折衷，需要设定合理的参数。 8.参考：http://blog.csdn.net/ns_code/article/details/17465497 http://blog.csdn.net/linghu_java/article/details/17123057 http://blog.csdn.net/bairrfhoinn/article/details/16848785 http://zhangjunhd.blog.51cto.com/113473/70068/ http://www.cnblogs.com/wanqieddy/p/3853863.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HttpClient工具类]]></title>
      <url>%2F2017%2F02%2F15%2FHttpClient%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E5%B0%81%E8%A3%85%2F</url>
      <content type="text"><![CDATA[一.HttpClient 介绍：​ HttpClient相比传统JDK自带的URLConnection，增加了易用性和灵活性，它不仅是客户端发送Http请求变得容易，而且也方便了开发人员测试接口（基于Http协议的），即提高了开发的效率，也方便提高代码的健壮性。它支持在HTTP/1.1规范中定义的所有的HTTP方法：GET, HEAD, POST, PUT, DELETE, TRACE 和 OPTIONS。每有一个方法都有一个对应的类：HttpGet，HttpHead，HttpPost，HttpPut，HttpDelete，HttpTrace和HttpOptions。所有的这些类均实现了HttpUriRequest接口，故可以作为execute的执行参数使用。 HTTP请求的URI包含一个协议计划protocol scheme，主机名host name,，可选的端口optional port，资源的路径resource path，可选的查询optional query和可选的片段optional fragment。 二. 特性：​ 基于标准、纯净的Java语言。实现了Http1.0和Http1.1 ​ 以可扩展的面向对象的结构实现了Http全部的方法（GET, POST, PUT, DELETE, HEAD, OPTIONS, and TRACE）。 ​ 支持HTTPS协议。 ​ 通过Http代理建立透明的连接。 ​ 利用CONNECT方法通过Http代理建立隧道的https连接。 ​ Basic, Digest, NTLMv1, NTLMv2, NTLM2 Session, SNPNEGO/Kerberos认证方案。 ​ 插件式的自定义认证方案。 ​ 便携可靠的套接字工厂使它更容易的使用第三方解决方案。 ​ 连接管理器支持多线程应用。支持设置最大连接数，同时支持设置每个主机的最大连接数，发现并关闭过期的连接。 ​ 自动处理Set-Cookie中的Cookie。 ​ 插件式的自定义Cookie策略。 ​ Request的输出流可以避免流中内容直接缓冲到socket服务器。 ​ Response的输入流可以有效的从socket服务器直接读取相应内容。 ​ 在http1.0和http1.1中利用KeepAlive保持持久连接。 ​ 直接获取服务器发送的response code和 headers。 ​ 设置连接超时的能力。 ​ 实验性的支持http1.1 response caching。 ​ 源代码基于Apache License 可免费获取。 三. 使用方法​ 创建HttpClient对象。 ​ 创建请求方法的实例，并指定请求URL。如果需要发送GET请求，创建HttpGet对象；如果需要发送POST请求，创建HttpPost对象。 ​ 如果需要发送请求参数，可调用HttpGet、HttpPost共同的setParams(HetpParams params)方法来添加请求参数；对于HttpPost对象而言，也可调用setEntity(HttpEntity entity)方法来设置请求参数。 ​ 调用HttpClient对象的execute(HttpUriRequest request)发送请求，该方法返回一个HttpResponse。 ​ 调用HttpResponse的getAllHeaders()、getHeaders(String name)等方法可获取服务器的响应头；调用HttpResponse的getEntity()方法可获取HttpEntity对象，该对象包装了服务器的响应内容。程序可通过该对象获取服务器的响应内容。 ​ 释放连接。无论执行方法是否成功，都必须释放连接 四.封装工具类 ​ 1.HttpHeader封装 ​ 2.SSL封装 ​ 3.HttpClientBuilder封装 ​ 链接：https://github.com/Luckylau/UsefulTools 五.参考资料http://blog.csdn.net/xiaoxian8023/article/category/5968067 http://blog.csdn.net/wangpeng047/article/details/19624529]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BeanUtils.copyProperties 与 PropertyUtils.copyProperties]]></title>
      <url>%2F2017%2F02%2F06%2FBeanUtils-copyProperties-%E4%B8%8E-PropertyUtils-copyProperties%2F</url>
      <content type="text"><![CDATA[首先明确一点是BeanUtils.copyProperties 存在于spring和apache commons-beanutils，PropertyUtils.copyProperties存在于apache commons-PropertyUtils。 org.springframework.beans.BeanUtils; org.apache.commons.beanutils.BeanUtils; org.apache.commons.beanutils.PropertyUtils; 1.org.springframework.beans.BeanUtils使用：首先看一下源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void copyProperties(Object source, Object target) throws BeansException &#123; copyProperties(source, target, (Class)null, (String[])null); &#125; public static void copyProperties(Object source, Object target, Class&lt;?&gt; editable) throws BeansException &#123; copyProperties(source, target, editable, (String[])null); &#125; public static void copyProperties(Object source, Object target, String... ignoreProperties) throws BeansException &#123; copyProperties(source, target, (Class)null, ignoreProperties); &#125; private static void copyProperties(Object source, Object target, Class&lt;?&gt; editable, String... ignoreProperties) throws BeansException &#123; Assert.notNull(source, "Source must not be null"); Assert.notNull(target, "Target must not be null"); Class actualEditable = target.getClass(); if(editable != null) &#123; if(!editable.isInstance(target)) &#123; throw new IllegalArgumentException("Target class [" + target.getClass().getName() + "] not assignable to Editable class [" + editable.getName() + "]"); &#125; actualEditable = editable; &#125; PropertyDescriptor[] targetPds = getPropertyDescriptors(actualEditable); List ignoreList = ignoreProperties != null?Arrays.asList(ignoreProperties):null; PropertyDescriptor[] var7 = targetPds; int var8 = targetPds.length; for(int var9 = 0; var9 &lt; var8; ++var9) &#123; PropertyDescriptor targetPd = var7[var9]; Method writeMethod = targetPd.getWriteMethod(); if(writeMethod != null &amp;&amp; (ignoreList == null || !ignoreList.contains(targetPd.getName()))) &#123; PropertyDescriptor sourcePd = getPropertyDescriptor(source.getClass(), targetPd.getName()); if(sourcePd != null) &#123; Method readMethod = sourcePd.getReadMethod(); if(readMethod != null &amp;&amp; ClassUtils.isAssignable(writeMethod.getParameterTypes()[0], readMethod.getReturnType())) &#123; try &#123; if(!Modifier.isPublic(readMethod.getDeclaringClass().getModifiers())) &#123; readMethod.setAccessible(true); &#125; Object ex = readMethod.invoke(source, new Object[0]); if(!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers())) &#123; writeMethod.setAccessible(true); &#125; writeMethod.invoke(target, new Object[]&#123;ex&#125;); &#125; catch (Throwable var15) &#123; throw new FatalBeanException("Could not copy property \'" + targetPd.getName() + "\' from source to target", var15); &#125; &#125; &#125; &#125; &#125; &#125; 成员变量赋值是基于目标对象的成员列表, 并且会跳过ignore的以及在源对象中不存在的属性, 所以这个方法是安全的, 不会因为两个对象之间的结构差异导致错误, 但是必须保证同名的两个成员变量类型相同. 1BeanUtils.copyProperties(source, target); 2.org.apache.commons.beanutils.BeanUtils使用：2.1 对于类型为Boolean/Short/Integer/Float/Double的属性，它会转换为0: 1234567891011121314151617181920212223242526public class User &#123; private Integer intVal; private Double doubleVal; private Short shortVal; private Long longVal; private Float floatVal; private Byte byteVal; private Boolean booleanVal; &#125; User src = new User(); User dest = new User(); BeanUtils.copyProperties(dest, src); System.out.println(src); System.out.println(dest); //输出 User [intVal=null, doubleVal=null, shortVal=null, longVal=null, floatVal=null, byteVal=null, booleanVal=null] User [intVal=0, doubleVal=0.0, shortVal=0, longVal=0, floatVal=0.0, byteVal=0, booleanVal=false] 在stackoverflow上有人解释说是因为这几个类型都有对应的基本类型，在进行类型转换时，有可能遇到类似Integer -&gt; int的转换，此时显然不能对int类型的属性赋值为null，因此统一转换为0。 如何让它不要转为0呢？可以这样： 1234import org.apache.commons.beanutils.converters.IntegerConverter; IntegerConverter converter = new IntegerConverter(null); //默认为null，而不是0 BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); beanUtilsBean.getConvertUtils().register(converter, Integer.class); 2.2 对于java.util.Date/BigDecimal/java.sql.Date/java.sql.Timestamp/java.sql.Time这几个类，如果值为null，则在copy时会抛异常，需要使用对应的Conveter： 12345678910111213141516171819202122232425262728293031public class User2 &#123; private java.util.Date javaUtilDateVal; private java.sql.Date javaSqlDateVal; private java.sql.Timestamp javaSqlTimeStampVal; private BigDecimal bigDecimalVal; private java.sql.Time javaSqlTime; &#125; User2 src = new User2(); User2 dest = new User2(); BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); //如果没有下面几行，则在转换null时会抛异常，例如：org.apache.commons.beanutils.ConversionException: No value specified for 'BigDecimal' //在org.apache.commons.beanutils.converters这个包下面有很多的Converter，可以按需要使用 beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.BigDecimalConverter(null), BigDecimal.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.DateConverter(null), java.util.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimestampConverter(null), java.sql.Timestamp.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlDateConverter(null), java.sql.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimeConverter(null), java.sql.Time.class); beanUtilsBean.copyProperties(dest, src); System.out.println(src); System.out.println(dest); 2.3使用BeanUtils还会经常碰到这样变态的需求： 假设是从A复制到B：需求1：如果B中某字段有值（不为null），则该字段不复制；也就是B中该字段没值时，才进行复制，适合于对B进行补充值的情况。需求2：如果A中某字段没值（为null），则该字段不复制，也就是不要把null复制到B当中。 对于需求1，可以这样： 12345678910111213141516171819import org.apache.commons.beanutils.BeanUtilsBean; import org.apache.commons.beanutils.PropertyUtils; public class CopyWhenNullBeanUtilsBean extends BeanUtilsBean&#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; try &#123; Object destValue = PropertyUtils.getSimpleProperty(bean, name); if (destValue == null) &#123; super.copyProperty(bean, name, value); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; 对于需求2，可以这样： 123456789101112import org.apache.commons.beanutils.BeanUtilsBean; public class CopyFromNotNullBeanUtilsBean extends BeanUtilsBean &#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; if (value == null) &#123; return; &#125; super.copyProperty(bean, name, value); &#125; &#125; 2.4 使用BeanUtils时，遇到日期类型的空值时会抛错的解决办法 新建一个转换器类，该类实现Converter接口，在convert方法中实现日期类型值的转换逻辑，然后注册。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class DateConverter implements Converter&#123; public Object convert(Class type, Object value)&#123; if(value == null)&#123; return null; &#125;else if(type == Timestamp.class)&#123; return convertToDate(type, value, "yyyy-MM-dd HH:mm:ss"); &#125;else if(type == Date.class)&#123; return convertToDate(type, value, "yyyy-MM-dd"); &#125;else if(type == String.class)&#123; return convertToString(type, value); &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToDate(Class type, Object value, String pattern) &#123; SimpleDateFormat sdf = new SimpleDateFormat(pattern); if(value instanceof String)&#123; try&#123; if(CommonUtils.isEmpty(value.toString()))&#123; return null; &#125; Date date = sdf.parse((String) value); if(type.equals(Timestamp.class))&#123; return new Timestamp(date.getTime()); &#125; return date; &#125;catch(Exception pe)&#123; return null; &#125; &#125;else if(value instanceof Date)&#123; return value; &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToString(Class type, Object value) &#123; if(value instanceof Date)&#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); if (value instanceof Timestamp) &#123; sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); &#125; try&#123; return sdf.format(value); &#125;catch(Exception e)&#123; throw new ConversionException("日期转换为字符串时出错！"); &#125; &#125;else&#123; return value.toString(); &#125; &#125; &#125; 1ConvertUtils.register(new DateConverter(), java.util.Date.class); 使用： 1BeanUtils.copyProperties(target, source); 3.org.apache.commons.beanutils.PropertyUtils使用：​ 使用PropertyUtils.copyProperties()拷贝一个bean中的属性到另一个bean中,第一个参数是目标bean,第二个参数是源bean，只是拷贝具有相同的 1PropertyUtils.copyProperties(target, source); 4.三者之间的区别：4.1 org.apache.commons.beanutils.BeanUtils 与org.apache.commons.beanutils.PropertyUtils ​ 从大范围讲，两个工具类都是对两个bean之前存在name相同的属性进行处理，无论是源bean或者目标bean多出的属性均不处理。具体到BeanUtils是相同name并且类型之间支持转换的属性可以处理，而PropertyUtils不支持类型转换必须是类型和name一样才处理。 ​ 对null的处理：PropertyUtils支持为null的场景；BeanUtils对部分属性不支持null的情况，具体为：date类型不支持，异常 date为org.apache.commons.beanutils.ConversionException: No value；specified for ‘Date’；Ineger、Boolean、Long等不支持， 转为0；string支持，保持null； ​ 源bean有属性：private Long dateVal;目标bean有属性：private Date dateVal;​ 使用 PropertyUtils，会报错：Caused by: java.lang.IllegalArgumentException: argument type mismatch​ 使用BeanUtils，则相当于new date（dateVal） ​ BeanUtils的高级功能org.apache.commons.beanutils.Converter接口可以自定义类型之间的转化，PropertyUtils没有 4.2 org.apache.commons.beanutils.BeanUtils与org.springframework.beans.BeanUtils org.springframework.beans.BeanUtils中实现的方式很简单，就是对两个对象中相同名字的属性进行简单get/set，仅检查属性的可访问性。 而org.springframework.beans.BeanUtils则施加了很多的检验，包括类型的转换，甚至于还会检验对象所属的类的可访问性。 5.参考：http://www.cnblogs.com/milton/p/5830942.html http://bylijinnan.iteye.com/blog/2224808 http://caoyaojun1988-163-com.iteye.com/blog/1871316 http://chenjumin.iteye.com/blog/701190 http://www.cnblogs.com/gaojing/archive/2011/08/23/2413616.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[历史金融危机一览表]]></title>
      <url>%2F2017%2F01%2F27%2F%E5%8E%86%E5%8F%B2%E9%87%91%E8%9E%8D%E5%8D%B1%E6%9C%BA%E4%B8%80%E8%A7%88%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[历史金融危机一览表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是vxlan网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFvxlan%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[前言：​ 处在年末工作的最后一天，其实也没有心情学习了，要不就总结和整理一下之前看的vxlan网络，大部分的内容还是复制拷贝的，只是按照自己的分明别类梳理梳理。vxlan网络是云计算网络的基础，openstack本身也是一种基础性简单使用，但还是有必要从理论上来学习vxlan网络。 云计算虚拟化对传统网络带来的挑战​ 云计算、虚拟化相关技术的发展，传统的网络无法满足于规模大、灵活性要求高的云数据中心的要求，于是便有了overlay网络的概念。overlay网络中被广泛应用的就是vxlan技术。首先我们了解一下随着云计算的发展，传统网络面临哪些挑战。 1.虚拟机迁移范围受到网络架构限制 ​ 虚拟机迁移，顾名思义，就是将虚拟机从一个物理机迁移到另一个物理机，但是要求在迁移过程中业务不能中断。要做到这一点，需要保证虚拟机迁移前后，其IP地址、MAC地址等参数维持不变。这就决定了，虚拟机迁移必须发生在一个二层域中。对于传统网络就要求网络本身具备多路径多链路的冗余和可靠性。传统的网络生成树(STPSpaning Tree Protocol)技术不仅部署繁琐荣，且协议复杂，网络规模不宜过大，限制了虚拟化的网络扩展性。基于各厂家私有的的IRF/vPC等设备级的(网络N:1)虚拟化技术，虽然可以简化拓扑简化、具备高可靠性的能力，但是对于网络有强制的拓扑形状限制，在网络的规模和灵活性上有所欠缺，只适合小规模网络构建，且一般适用于数据中心内部网络。而为了大规模网络扩展的TRILL/SPB/FabricPath/VPLS等技术，虽然解决了上述技术的不足，但对网络有特殊要求，即网络中的设备均要软硬件升级而支持此类新技术，带来部署成本的上升。 2.虚拟机规模受网络设备表项规格的限制 ​ 在大二层网络环境下，数据流均需要通过明确的网络寻址以保证准确到达目的地，因此网络设备的二层地址表项大小(即MAC地址表)，成为决定了云计算环境下虚拟机的规模的上限，并且因为表项并非百分之百的有效性，使得可用的虚机数量进一步降低，特别是对于低成本的接入设备而言，因其表项一般规格较小，限制了整个云计算数据中心的虚拟机数量，但如果其地址表项设计为与核心或网关设备在同一档次，则会提升网络建设成本。虽然核心或网关设备的MAC与ARP规格会随着虚拟机增长也面临挑战，但对于此层次设备能力而言，大规格是不可避免的业务支撑要求。减小接入设备规格压力的做法可以是分离网关能力，如采用多个网关来分担虚机的终结和承载，但如此也会带来成本的上升。 3.网络隔离/分离能力限制 ​ VLAN作为当前主流的网络隔离技术，在标准定义中只有12比特，也就是说可用的VLAN数量只有4000个左右。对于公有云或其它大型虚拟化云计算服务这种动辄上万甚至更多租户的场景而言，VLAN的隔离能力显然已经力不从心。 VLAXN网络的初相识1.VXLAN网络模型 从上图可以看到，VXLAN网络中出现了以下传统数据中心网络中没有的新元素： VTEP（VXLAN Tunnel Endpoints，VXLAN隧道端点）VXLAN网络的边缘设备，是VXLAN隧道的起点和终点，VXLAN报文的相关处理均在这上面进行。总之，它是VXLAN网络中绝对的主角。VTEP既可以是独立的网络设备（比如华为的CE系列交换机），也可以是虚拟机所在的服务器。那它究竟是如何发挥作用的呢？答案稍候揭晓。 VNI（VXLAN Network Identifier，VXLAN 网络标识符）前文提到，以太网数据帧中VLAN只占了12比特的空间，这使得VLAN的隔离能力在数据中心网络中力不从心。而VNI的出现，就是专门解决这个问题的。VNI是一种类似于VLAN ID的用户标示，一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VXLAN报文封装时，给VNI分配了足够的空间使其可以支持海量租户的隔离。详细的实现，我们将在后文中介绍。 VXLAN隧道“隧道”是一个逻辑上的概念，它并不新鲜，比如大家熟悉的GRE。说白了就是将原始报文“变身”下，加以“包装”，好让它可以在承载网络（比如IP网络）上传输。从主机的角度看，就好像原始报文的起点和终点之间，有一条直通的链路一样。而这个看起来直通的链路，就是“隧道”。顾名思义，“VXLAN隧道”便是用来传输经过VXLAN封装的报文的，它是建立在两个VTEP之间的一条虚拟通道。 2.VXLAN是如何解决以上挑战 2.1解决虚拟机迁移范围受到网络架构限制问题 ​ overlay网络的本质是在三层网络中实现二层网络的扩展。三层网络可以通过路由的方式在网络中分发，而路由网络本身并无特殊网络结构限制，具备良性大规模扩展能力，并且对设备本身无特殊要求，以高性能路由转发为佳，且路由网络本身具备很强的的故障自愈能力、负载均衡能力。前面提到，为了保证业务不中断，VM的迁移就必须发生在同一个二层域内。有了VTEP的封装机制和VXLAN隧道后，所谓的 “二层域”就可以轻而易举的突破物理上的界限？也就是说，在IP网络中， “明”里传输的是跨越三层网络的UDP报文，“暗”里却已经悄悄将源VM的原始报文送达目的VM。就好像在三层的网络之上，构建出了一个虚拟的二层网络，而且只要IP网络路由可达，这个虚拟的二层网络想做多大就做多大。 2.2解决虚拟机规模受网络设备表项规格的限制问题 ​ 既然无法提升设备表项规格，那就只能限制设备上的MAC表项，将大量VM的MAC地址“隐形”。VTEP会将VM发出的原始报文封装成一个新的UDP报文，并使用物理网络的IP和MAC地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就是说，网络中的其他设备看不到VM发送的原始报文。 ​ 如果服务器作为VTEP，那从服务器发送到接入设备的报文便是经过封装后的报文，这样，接入设备就不需要学习VM的MAC地址了，它只需要根据外层封装的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表项规格的限制了。 ​ 当然，如果网络设备作为VTEP，它还是需要学习VM的MAC地址。但是，从对报文进行封装的角度来说，网络设备的性能还是要比服务器强很多。 2.3解决网络隔离/分离能力限制 ​ 一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VTEP在对报文进行VXLAN封装时，给VNI分配了24比特的空间，这就意味着VXLAN网络理论上支持多达16M（即：2^24-1）的租户隔离。相比VLAN，VNI的隔离能力得到了巨大的提升，有效得解决了云计算中海量租户隔离的问题。 3.VXLAN报文格式 VTEP对VM发送的原始以太帧（Original L2 Frame）进行了以下“包装”： VXLAN Header: ​ 增加VXLAN头（8字节），其中包含24比特的VNI字段，用来定义VXLAN网络中不同的租户。此外，还包含VXLAN Flags（8比特，取值为00001000）和两个保留字段（分别为24比特和8比特）。 UDP Header: ​ VXLAN头和原始以太帧一起作为UDP的数据。UDP头中，目的端口号（VXLAN Port）固定为4789，源端口号（UDP Src. Port）是原始以太帧通过哈希算法计算后的值。 Outer IP Header: ​ 封装外层IP头。其中，源IP地址（Outer Src. IP）为源VM所属VTEP的IP地址，目的IP地址（Outer Dst. IP）为目的VM所属VTEP的IP地址。 Outer MAC Header: ​ 封装外层以太头。其中，源MAC地址（Src. MAC Addr.）为源VM所属VTEP的MAC地址，目的MAC地址（Dst. MAC Addr.）为到达目的VTEP的路径上下一跳设备的MAC地址。 VXLAN报文转发机制以CE系列交换机的实现为例 1.建立VXLAN隧道 前面提到的“同一大二层域”，就类似于传统网络中VLAN（虚拟局域网）的概念，只不过在VXLAN网络中，它有另外一个名字，叫做Bridge-Domain，简称BD。 ​ 我们知道，不同的VLAN是通过VLAN ID来进行区分的，那不同的BD是如何进行区分的呢？其实前面已经提到了，就是通过VNI来区分的。对于CE系列交换机而言，BD与VNI是1：1的映射关系，这种映射关系是通过在VTEP上配置命令行建立起来的。配置如下： 12bridge-domain 10 //表示创建一个“大二层广播域”BD，其编号为10 vxlan vni 5000 //表示在BD 10下，指定与之关联的VNI为5000 VTEP会根据以上配置生成BD与VNI的映射关系表，该映射表可以通过命令行查看，如下所示： 12345&lt;HUAWEI&gt; display vxlan vniNumber of vxlan vni : 1VNI BD-ID State ----------------------------------5000 10 up 有了映射表后，进入VTEP的报文就可以根据自己所属的BD来确定报文封装时该添加哪个VNI。那么，报文根据什么来确定自己属于哪个BD呢？ 在回答“如何确定报文属于哪个BD”之前，必须先要回答“哪些报文要进入VXLAN隧道”。 ​ 在VXLAN网络中，VTEP上有一个叫做“二层子接口”的逻辑接口，主要做两件事：一是根据配置来检查哪些报文需要进入VXLAN隧道；二是判断对检查通过的报文做怎样的处理。在二层子接口上，可以根据需要定义不同的流封装类型（类似于传统网络中不同的接口类型）。CE系列交换机目前支持三种不同的流封装类型，分别是dot1q、untag和default，它们各自对报文的处理方式如表3-1所示。有了这张表，你就能明白哪些报文要进VXLAN隧道了。 流封装类型 允许进入VXLAN隧道的报文类型 报文进行封装前的处理 收到VXLAN报文并解封装后的处理 dot1q 只允许携带指定VLAN Tag的报文进入VXLAN隧道。（这里的“指定VLAN Tag”是通过命令进行配置的） 进行VXLAN封装前，先剥掉原始报文的外层VLAN Tag 进行VXLAN解封装后：若内层原始报文带有VLAN Tag，则先将该VLAN Tag替换为指定的VLAN Tag，再转发；若内层原始报文不带VLAN Tag，则先将其添加指定的VLAN Tag，再转发。 untag 只允许不携带VLAN Tag的报文进入VXLAN隧道。 进行VXLAN封装前，不对原始报文做处理，即不添加任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 default 允许所有报文进入VXLAN隧道，不论报文是否携带VLAN Tag。 进行VXLAN封装前，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 说明：VXLAN隧道两端二层子接口的配置并不一定是完全对等的。正因为这样，才可能实现属于同一网段但是不同VLAN的两个VM通过VXLAN隧道进行通信。 看了上面的描述，再来回答“如何确定报文属于哪个BD”就非常简单了。其实，只要将二层子接口加入指定的BD，然后根据二层子接口上的配置，就可以确定报文属于哪个BD啦！ 比如下图所示的组网，我们可以分别在VTEP的两个物理接口10GE 1/0/1和10GE 1/0/2上配置不同流封装类型的二层子接口并将其分别加入不同的BD。 基于二层物理接口10GE 1/0/1，分别创建二层子接口10GE 1/0/1.1和10GE 1/0/1.2，且分别配置其流封装类型为dot1q和untag。配置如下： 123interface 10GE1/0/1.1 mode l2 //创建二层子接口10GE1/0/1.1 encapsulation dot1q vid 10 //只允许携带VLAN Tag 10的报文进入VXLAN隧道 bridge-domain 10 //报文进入的是BD 10 123interface 10GE1/0/1.2 mode l2 //创建二层子接口10GE1/0/1.2 encapsulation untag //只允许不携带VLAN Tag的报文进入VXLAN隧道 bridge-domain 20 //报文进入的是BD 20 基于二层物理接口10GE 1/0/2，创建二层子接口10GE 1/0/2.1，且流封装类型为default。配置如下： 123interface 10GE1/0/2.1 mode l2 //创建二层子接口10GE1/0/2.1 encapsulation default //允许所有报文进入VXLAN隧道 bridge-domain 30 //报文进入的是BD 30 此时你可能会有这样的疑问，为什么要在10GE 1/0/1上创建两个不同类型的子接口？是否还可以继续在10GE 1/0/1上创建一个default类型的二层子接口？换句话说，用户应该如何选择配置哪种类型的二层子接口？三种类型的二层子接口之间，是否存在配置约束关系？ 答案是不可以。其实根据上表的描述，这一点很容易理解。因为default类型的二层子接口允许所有报文进入VXLAN隧道，而dot1q和untag类型的二层子接口只允许某一类报文进入VXLAN隧道。这就决定了，default类型的二层子接口跟其他两种类型的二层子接口是不可以在同一物理接口上共存的。否则，报文到了接口之后如何判断要进入哪个二层子接口呢。所以，default类型的子接口，一般应用在经过此接口的报文均需要走同一条VXLAN隧道的场景，即下挂的VM全部属于同一BD。例如，图3-3中VM3和VM4均属于BD 30，则10GE 1/0/2上就可以创建default类型的二层子接口。 再来看下为什么可以在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。如图上所示，VM1和VM2分别属于VLAN 10和VLAN 20，且分别属于不同的大二层域BD 10和BD 20，显然他们发出的报文要进入不同的VXLAN隧道。如果VM1和VM2发出的报文在到达VTEP的10GE 1/0/1接口时，一个是携带VLAN 10的Tag的，一个是不携带VLAN Tag的（比如二层交换机上行连接VTEP的接口上配置的接口类型是Trunk，允许通过的VLAN为10和20，PVID为VLAN 20），则为了区分两种报文，就必须要在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。所以，当经过同一物理接口的报文既有带VLAN Tag的，又有不带VLAN Tag的，并且他们各自要进入不同的VXLAN隧道，则可以在该物理接口上同时创建dot1q和untag类型的二层子接口。 现在，我们可以来看下VXLAN隧道是怎么建立起来的了。一般而言，隧道的建立不外乎手工方式和自动方式两种。 手工方式这种方式需要用户手动指定VXLAN隧道的源和目的IP地址分别为本端和对端VTEP的IP地址，也就是人为的在本端VTEP和对端VTEP之间建立静态VXLAN隧道。对于CE系列交换机，以上配置是在NVE（Network Virtualization Edge）接口下完成的。配置过程如下： 1234interface Nve1 //创建逻辑接口NVE 1 source 1.1.1.1 //配置源VTEP的IP地址（推荐使用Loopback接口的IP地址） vni 5000 head-end peer-list 2.2.2.2 vni 5000 head-end peer-list 2.2.2.3 其中，vni 5000 head-end peer-list 2.2.2.2和vni 5000 head-end peer-list 2.2.2.3的配置，表示属于VNI 5000的对端VTEP有两个，IP地址分别为2.2.2.2和2.2.2.3。根据这两条配置，VTEP上会生成如下所示的一张表： 123456789&lt;HUAWEI&gt; display vxlan vni 5000 verbose BD ID : 10 State : up NVE : 288 Source : 1.1.1.1 UDP Port : 4789 BUM Mode : head-end Group Address : - Peer List : 2.2.2.2 2.2.2.3 根据上表中的Peer List，本端VTEP就可以知道属于同一BD（或同一VNI）的对端VTEP都有哪些，这也就决定了同一大二层广播域的范围。当VTEP收到BUM（Broadcast&amp;Unknown-unicast&amp;Multicast，广播&amp;未知单播&amp;组播）报文时，会将报文复制并发送给Peer List中所列的所有对端VTEP（这就好比广播报文在VLAN内广播）。因此，这张表也被称为“头端复制列表”。当VTEP收到已知单播报文时，会根据VTEP上的MAC表来确定报文要从哪条VXLAN隧道走。而此时Peer List中所列的对端，则充当了MAC表中“出接口”的角色。在后面的报文转发流程中，你将会看到头端复制列表是如何在VXLAN网络中指导报文进行转发的。 自动方式自动方式下VXLAN隧道的建立需要借助于其他的协议，例如BGP。CE系列交换机中，自动方式建立VXLAN隧道主要应用在EVN（Ethernet Virtual Network）和VXLAN的分布式网关场景中。本文不对该方式进行详细讲述，具体实现可参考EVN的相关资料。 从前面的描述我们知道，属于同一BD的VXLAN隧道可能不止一条，比如前面的头端复制列表中，同一个源端VTEP（1.1.1.1）对应了两个对端VTEP（2.2.2.2和2.2.2.3）。那就带来了另一个问题，报文到底应该走哪一条隧道呢？我们知道，基本的二三层转发中，二层转发依赖的是MAC表，如果没有对应的MAC表，则主机发送ARP广播报文请求对端的MAC地址；三层转发依赖的是FIB表。在VXLAN中，其实也是同样的道理。下面就让我们来看下，VXLAN网络中报文的转发流程。相信看完下面的内容，关于“如何确定报文要进哪条隧道”的疑惑也就迎刃而解了。 2.VXLAN网络中报文的转发流程 同子网互通 VM_A、VM_B和VM_C同属于10.1.1.0/24网段，且同属于VNI 5000。此时，VM_A想与VM_C进行通信。 ​ 由于是首次进行通信，VM_A上没有VM_C的MAC地址，所以会发送ARP广播报文请求VM_C的MAC地址。下面就让我们根据ARP请求报文及ARP应答报文的转发流程，来看下MAC地址是如何进行学习的。 ARP请求报文转发流程 ARP请求报文的转发流程如下： VM_A发送源MAC为MAC_A、目的MAC为全F、源IP为IP_A、目的IP为IP_C的ARP广播报文，请求VM_C的MAC地址。 VTEP_1收到ARP请求后，根据二层子接口上的配置判断报文需要进入VXLAN隧道。确定了报文所属BD后，也就确定了报文所属的VNI。同时，VTEP_1学习MAC_A、VNI和报文入接口（Port_1，即二层子接口对应的物理接口）的对应关系，并记录在本地MAC表中。之后，VTEP_1会根据头端复制列表对报文进行复制，并分别进行封装。 可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_1）的IP地址，外层目的IP地址为对端VTEP（VTEP_2和VTEP_3）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2和VTEP_3后，VTEP对报文进行解封装，得到VM_A发送的原始报文。同时，VTEP_2和VTEP_3学习VM_A的MAC地址、VNI和远端VTEP的IP地址（IP_1）的对应关系，并记录在本地MAC表中。之后，VTEP_2和VTEP_3根据二层子接口上的配置对报文进行相应的处理并在对应的二层域内广播。VM_B和VM_C接收到ARP请求后，比较报文中的目的IP地址是否为本机的IP地址。VM_B发现目的IP不是本机IP，故将报文丢弃；VM_C发现目的IP是本机IP，则对ARP请求做出应答。下面，让我们看下ARP应答报文是如何进行转发的。 ARP应答报文转发流程 ARP应答报文的转发流程如下： 由于此时VM_C上已经学习到了VM_A的MAC地址，所以ARP应答报文为单播报文。报文源MAC为MAC_C，目的MAC为MAC_A，源IP为IP_C、目的IP为IP_A。 VTEP_3接收到VM_C发送的ARP应答报文后，识别报文所属的VNI（识别过程与步骤2类似）。同时，VTEP_3学习MAC_C、VNI和报文入接口（Port_3）的对应关系，并记录在本地MAC表中。之后，VTEP_3对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_3）的IP地址，外层目的IP地址为对端VTEP（VTEP_1）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_1后，VTEP_1对报文进行解封装，得到VM_C发送的原始报文。同时，VTEP_1学习VM_C的MAC地址、VNI和远端VTEP的IP地址（IP_3）的对应关系，并记录在本地MAC表中。之后，VTEP_1将解封装后的报文发送给VM_A。至此，VM_A和VM_C均已学习到了对方的MAC地址。之后，VM_A和VM_C将采用单播方式进行通信。 不同子网互通 ​ VM_A和VM_B分别属于10.1.10.0/24网段和10.1.20.0/24网段，且分别属于VNI 5000和VNI 6000。VM_A和VM_B对应的三层网关分别是VTEP_3上BDIF 10和BDIF 20的IP地址。VTEP_3上存在到10.1.10.0/24网段和10.1.20.0/24网段的路由。此时，VM_A想与VM_B进行通信。 ​ BDIF接口的功能与VLANIF接口类似，是基于BD创建的三层逻辑接口，用以实现不同子网VM之间或VXLAN网络与非VXLAN网络之间的通信。 由于是首次进行通信，且VM_A和VM_B处于不同网段，VM_A需要先发送ARP广播报文请求网关（BDIF 10）的MAC，获得网关的MAC后，VM_A先将数据报文发送给网关；之后网关也将发送ARP广播报文请求VM_B的MAC，获得VM_B的MAC后，网关再将数据报文发送给VM_B。以上MAC地址学习的过程与同子网互通中MAC地址学习的流程一致，不再赘述。现在假设VM_A和VM_B均已学到网关的MAC、网关也已经学到VM_A和VM_B的MAC，下面就让我们看下数据报文是如何从VM_A发送到VM_B的。 不同子网VM互通报文转发流程 数据报文从VM_A发送到VM_B的流程如下： VM_A先将数据报文发送给网关。报文的源MAC为MAC_A，目的MAC为网关BDIF 10的MAC_10，源IP地址为IP_A，目的IP为IP_B。 VTEP_1收到数据报文后，识别此报文所属的VNI（VNI 5000），并根据MAC表项对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP的IP地址（IP_1），外层目的IP地址为对端VTEP的IP地址（IP_3）；外层源MAC地址为本地VTEP的MAC地址（MAC_1），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文进入VTEP_3，VTEP_3对报文进行解封装，得到VM_A发送的原始报文。然后，VTEP_3会对报文做如下处理： VTEP_3发现该报文的目的MAC为本机BDIF 10接口的MAC，而目的IP地址为IP_B（10.1.20.1），所以会根据路由表查找到IP_B的下一跳。 发现下一跳为10.1.20.10，出接口为BDIF 20。此时VTEP_3查询ARP表项，并将原始报文的源MAC修改为BDIF 20接口的MAC（MAC_20），将目的MAC修改为VM_B的MAC（MAC_B）。 报文到BDIF 20接口时，识别到需要进入VXLAN隧道（VNI 6000），所以根据MAC表对报文进行封装。这里封装的外层源IP地址为本地VTEP的IP地址（IP_3），外层目的IP地址为对端VTEP的IP地址（IP_2）；外层源MAC地址为本地VTEP的MAC地址（MAC_3），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2后，VTEP_2对报文进行解封装，得到内层的数据报文，并将其发送给VM_B。 说明：VXLAN网络与非VXLAN网络之间的互通，也需要借助于三层网关。 VXLAN应用部署方式我们以下图所示的典型的“Spine-Leaf”数据中心组网为例，给大家介绍一下CE系列交换机VXLAN的应用场景和部署方案。 ​ 在上图所示的数据中心里，企业用户拥有多个部门（部门1和部门2），每个部门中拥有多个VM（VM1和VM3，VM2和VM4）。同部门的VM属于同一个网段，不同部门的VM属于不同的网段。用户希望同一部门VM之间、不同部门VM之间，VM与Internet之间均可相互访问。 VXLAN网络的子网互通 相同子网互通 部署方案如图所示，Leaf1和Leaf2作为VXLAN网络的VTEP，两个Leaf之间搭建VXLAN隧道，并在每个Leaf上部署VXLAN二层网关，即可实现同一部门VM之间的相互通信。此时Spine只作为VXLAN报文的转发节点，不感知VXLAN隧道的存在，可以是任意的三层网络设备。 不同子网互通（集中式网关） 部署方案如图4-2所示，Leaf1、Leaf2和Spine作为VXLAN网络的VTEP，Leaf1和Spine之间、Leaf2和Spine之间分别搭建VXLAN隧道，并在Spine上部署VXLAN三层网关，即可实现不同部门VM之间的相互通信。 不同子网互通（分布式网关） 出现背景细心的读者可能已经发现，在不同子网互通（集中式网关）中，同一Leaf（Leaf1）下挂的不同网段VM（VM1和VM2）之间的通信，都需要在Spine上进行绕行，这样就导致Leaf与Spine之间的链路上，存在冗余的报文，额外占用了大量的带宽。同时，Spine作为VXLAN三层网关时，所有通过三层转发的终端租户的表项都需要在该设备上生成。但是，Spine的表项规格有限，当终端租户的数量越来越多时，容易成为网络瓶颈。分布式网关的出现，很好的解决了这两个问题。 部署方案 同Leaf节点下不同部门VM之间的通信如图4-3所示，Leaf1作为VXLAN网络的VTEP，在Leaf1上部署VXLAN三层网关，即可实现同Leaf下不同部门VM之间的相互通信。此时，VM1和VM2互访时，流量只需要在Leaf1节点进行转发，不再需要经过Spine节点，从而节约了大量的带宽资源。 跨Leaf节点不同部门VM之间的通信如图4-3所示，Leaf1和Leaf2作为VXLAN网络的VTEP，在Leaf1和Leaf2上部署VXLAN三层网关。两个VXLAN三层网关之间通过BGP动态建立VXLAN隧道，并通过BGP的remote-nexthop属性发布本网关下挂的主机路由信息给其他BGP邻居，从而实现跨Leaf节点不同部门VM之间的相互通信。 说明：Leaf作为VXLAN三层网关时，只学习其下挂终端租户的表项，而不必像集中式三层网关一样，需要学习网络中所有终端租户的表项，从而解决了集中式三层网关带来表项瓶颈问题。 VXLAN网络的可靠性 随着网络的快速普及和应用的日益深入，基础网络的可靠性日益成为用户关注的焦点，如何能够保证网络传输不中断对于终端用户而言非常重要。在VXLAN网络的子网互通中，VM与Leaf之间，Leaf与Spine之间都是通过单归方式接入的。这种组网接入方式，显然已经不能满足用户对VXLAN网络可靠性的需求。这时，可以按照如下图所示方式，提升VXLAN网络的可靠性。 接入层的可靠性 通常采用堆叠（CSS）方式提升接入层的可靠性。这是因为，接入层的设备数量繁多，堆叠方式可以将多台交换机设备组合在一起，虚拟化成一台交换设备，所有配置均在这一台虚拟交换机上进行，从而简化了接入层设备的运维复杂度。此外，堆叠系统内成员交换机之间在进行冗余备份的同时，能够利用跨设备的Eth-Trunk实现设备间链路的负载分担。 参考： http://support.huawei.com/huaweiconnect/enterprise/forum.php?mod=viewthread&amp;tid=334207&amp;extra=page%3D&amp;page=1 http://blog.csdn.net/sinat_31828101/article/details/50504656]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是overlay网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFoverllay%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[​ Overlay在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于IP的基础网络技术为主。 ​ 随着云计算虚拟化的驱动，基于主机虚拟化的Overlay技术出现，在服务器的Hypervisor内vSwitch上支持了基于IP的二层Overlay技术，通过更靠近应用的边缘来提供网络虚拟化服务，其目的是使虚拟机的部署与业务活动脱离物理网络及其限制，使得云计算的网络形态不断完善。主机的vSwitch支持基于IP的Overlay之后，虚机的二层访问直接构建在Overlay之上，物理网不再感知虚机的诸多特性。 存在三种不同的构建模式: Network Overlay 方案: ​ 所有终端均采用物理交换机作为VTEP节点,所有的物理接入交换机支持VXLAN，物理服务器支持SR-IOV功能，使虚拟机通过SR-IOV技术直接与物理交换机相连，虚拟机的流量在接入交换机上进行VXLAN报文的封装和卸载，对于非虚拟化服务器，直接连接支持VXLAN的接入交换机，服务器流量在接入交换机上进行VXLAN报文封装和卸载；当VXLAN网络需要与VLAN网络通信时，采用物理交换机做VXLAN GW，实现VXLAN网络主机与VLAN网络主机的通信；采用高端交换机做VXLAN IP GW，实现VXLAN网络与WAN以及Internet的互连。 Host Overlay 方案: ​ 所有终端均采用虚拟交换机作为VTEP节点，VTEP、VXLAN GW、VXLAN IP GW均通过安装在服务器上的软件实现，vSwitch实现VTEP功能，完成VXLAN报文的封装解封装；vFW等实现VXLAN GW功能，实现VXLAN网络与VLAN网络、物理服务器的互通；vRouter作为VXLAN IP GW，实现VXLAN网络与Internet和WAN的互联。在本组网中，由于所有VXLAN报文的封装卸载都通过软件实现，会占用部分服务器资源，当访问量大时，vRouter会成为系统瓶颈。 Hybrid Overlay 方案: ​ 既有物理交换机接入，又有虚拟交换机接入，且软件VTEP和硬件VTEP之间可以基于标准协议互通。上述两种组网方案中，网络Overlay方案与虚拟机相连，需要通过一些特殊的要求或技术实现虚拟机与VTEP的对接，组网不够灵活，但是主机Overlay方案与传统网络互通时，连接也比较复杂，且通过软件实现VXLAN IP GW也会成为整个网络的瓶颈，所以最理想的组网方案应该是一个结合了网络Overlay与主机Overlay两种方案优势的混合Overlay方案。如上图所示它通过vSwitch实现虚拟机的VTEP，通过物理交换机实现物理服务器的VTEP，通过物理交换机实现VXALN GW和VXLAN IP GW；混合式Overlay组网方案对虚拟机和物理服务器都能够很好的兼容，同时通过专业的硬件交换机实现VXLAN IP GW从而承载超大规模的流量转发，是目前应用比较广泛的组网方案。 PS: OpenStack 采用的是第二种方案 ​ 另外IETF在Overlay技术领域有如下三大技术路线正在讨论，为简单起见，只讨论基于IPv4的Overlay相关内容。 1 . VXLAN。 VXLAN是将以太网报文封装在UDP传输层上的一种隧道转发模式，目的UDP端口号为4798；为了使VXLAN充分利用承载网络路由的均衡性，VXLAN通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为UDP的号；采用24比特标识二层网络分段，称为VNI(VXLAN Network Identifier)，类似于VLAN ID作用；未知目的、广播、组播等网络流量均被封装为组播转发，物理网络要求支持任意源组播(ASM)。 2. GRE/NVGRE（Generic Routing Encapsulation，通用路由协议封装）是一种 IP-over-IP 的隧道。 NVGRE是将以太网报文封装在GRE内的一种隧道转发模式；采用24比特标识二层网络分段，称为VSI(Virtual Subnet Identifier)，类似于VLAN ID作用；为了使NVGRE利用承载网络路由的均衡性，NVGRE在GRE扩展字段flow ID，这就要求物理网络能够识别到GRE隧道的扩展信息，并以flow ID进行流量分担；未知目的、广播、组播等网络流量均被封装为组播转发。 3.STT（Stateless Transport Tunneling）。 STT利用了TCP的数据封装形式，但改造了TCP的传输机制，数据传输不遵循TCP状态机，而是全新定义的无状态机制，将TCP各字段意义重新定义，无需三次握手建立TCP连接，因此称为无状态TCP；以太网数据封装在无状态TCP；采用64比特Context ID标识二层网络分段；为了使STT充分利用承载网络路由的均衡性，通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为无状态TCP的源端口号；未知目的、广播、组播等网络流量均被封装为组播转发。 参考: http://www.h3c.com.cn/About_H3C/Company_Publication/IP_Lh/2013/04/Home/Catalog/201309/796466_30008_0.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[pyinstaller使用技巧]]></title>
      <url>%2F2017%2F01%2F22%2Fpyinstaller%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[​ 不经意间发现了这个工具pyinstaller2.0。它的功能是把python脚本打包成windows的可执行文件，这样就可以方便使用程序了。为了玩一下，于是写了一个图片分类的脚本，按照jpg, gif, png后缀将图片分别存储在各自文件夹中。脚本放在github上了。https://github.com/Luckylau/Useful-Python-Sample/blob/master/useful-tools/classify_Pic.py pythoninstall2.0运行前需要安装pywin32，假如你使用的是python 2.7(64位)，需要在官网 https://sourceforge.net/projects/pywin32/files/pywin32找到对应的版本 我的环境：win 10 python 2.7 (64位) ,pywin32-220.win-amd64-py2.7 打开pyinstall-2.0文件夹 如下图，shift+右键鼠标打开cmd,注意的是文件的路径不能有中文，我之前用的路径是D:\日常资料\日常资料\图片\大雪，会出现编码问题 在cmd上执行,不用理会error报错。 pyinstaller参数有如下选项，我们用的是-F, 后面跟的是要打包的python脚本的位置。 可选的opts有： -F, –onefile 打包成一个exe文件。 -D, –onedir 创建一个目录，包含exe文件，但会依赖很多文件（默认选项）。 -c, –console, –nowindowed 使用控制台，无界面(默认) -w, –windowed, –noconsole 使用窗口，无控制台 完毕之后，会在下图所示位置生成exe文件。 我们在该目录下取得exe文件，执行效果和python脚本是一样的。大功告成~~~~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo备份小技巧]]></title>
      <url>%2F2017%2F01%2F21%2Fhexo%E5%A4%87%E4%BB%BD%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[提交到github上备份: 12345678910111213cd blog/hexo# 初始化仓库git initgit add .git commit -m &quot;init&quot;# 建一个分支git checkout -b hexo# 删除本地的master分支git branch -d master# 添加远程git remote add origin https://github.com/用户名/用户名.github.io.git# 保存git push -u origin hexo 更换环境时: 123456789101112131415#1.安装git(配置git),nodejs;#2.克隆到本地git clone https://github.com/用户名/用户名.github.io.git hexocd hexo git checkout hexo#3.安装各种npm包npm install -g hexo-clinpm installnpm install hexo-deployer-git --save#用于markdown插入图片,首先确认 _config.yml 中有 post_asset_folder:truenpm install https://github.com/CodeFalling/hexo-asset-image --save#4 部署hexo cleanhexo generatehexo deploy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python中的struct模块]]></title>
      <url>%2F2017%2F01%2F19%2FPython%E4%B8%AD%E7%9A%84struct%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[​ python的struct模块，是在查看RYU控制器Openflow协议的实现源码接触到的。RYU控制器解包和封包就是用struct模块实现的。 ​ 在C语言中，struct结构体里面可以包含不同数据类型，比如int ,char,bool等。但是一旦涉及到网络通信时，传递的是二进制数据流（binary data）。对于二进制字符串，不必担心，但是对于如int，char等基本数据类型，需要有一种机制将这些特定的结构体类型打包成二进制流的字符串然后再在网络传输，同时接收端也需要通过某种机制进行解包还原出原始的结构体数据。 ​ python中的struct模块就提供了这样的机制，该模块的主要作用就是对python基本类型值与用python字符串格式表示的C struct类型间的转化，如下图: 1.简单演示 12345678910111213141516171819import structimport binasciivalues=(2017,'luckylau0',1.19)s=struct.Struct('I9sf')packed_data = s.pack(*values)#打包unpacked_data = s.unpack(packed_data)#解包print 'Original values:', valuesprint 'Format string :', s.formatprint 'Uses :', s.size, 'bytes'print struct.calcsize('I9sf')print 'Packed Value :', binascii.hexlify(packed_data)print 'Unpacked Type :', type(unpacked_data), ' Value:', unpacked_data#输出Original values: (2017, 'luckylau0', 1.19)Format string : I9sfUses : 20 bytes20Packed Value : e10700006c75636b796c617530000000ec51983fUnpacked Type : &lt;type 'tuple'&gt; Value: (2017, 'luckylau0', 1.190000057220459) ​ 代码中，首先定义了一个元组数据，包含int、string、float三种数据类型，然后定义了struct对象，并制定了format‘I8sf’，I 表示int ,8s表示八个字符长度的字符串，f 表示 float。最后通过struct的pack和unpack进行打包和解包。通过输出结果可以发现，value被pack之后，转化为了一段二进制字节串，而unpack可以把该字节串再转换回一个元组，但是值得注意的是对于float的精度发生了改变，这是由一些比如操作系统等客观因素所决定的。 2.字节顺序 ​ 打包的后的字节顺序默认上是由操作系统的决定的，当然struct模块也提供了自定义字节顺序的功能 ​ 例如采用小端存储 s = struct.Struct(‘&lt;I3sf’) 3.利用buffer，使用pack_into和unpack_from方法 12345678910111213141516171819202122import structimport binasciiimport ctypes values1 = (1, 'abc', 2.7)values2 = ('defg',101)s1 = struct.Struct('I3sf')s2 = struct.Struct('4sI') prebuffer = ctypes.create_string_buffer(s1.size+s2.size)print 'Before :',binascii.hexlify(prebuffer)s1.pack_into(prebuffer,0,*values1)s2.pack_into(prebuffer,s1.size,*values2)print 'After pack:',binascii.hexlify(prebuffer)print s1.unpack_from(prebuffer,0)print s2.unpack_from(prebuffer,s1.size)#输出Before : 0000000000000000000000000000000000000000After pack: 0100000061626300cdcc2c406465666765000000(1, 'abc', 2.700000047683716)('defg', 101) ​ 使用二进制打包数据的场景大部分都是对性能要求比较高的使用环境，所以上面提到的pack方法都是对输入数据进行操作后重新创建了一个内存空间用于返回，也就是说我们每次pack都会在内存中分配出相应的内存资源，这有时是一种很大的性能浪费。pack_into() 和 unpack_from()的方法就是对一个已经提前分配好的buffer进行字节的填充，而不会每次都产生一个新对象对字节进行存储。在RYU控制器中就是使用这两种方法。 4.总结： struct 模块 Python的struct库是一个简单的,高效的数据封装\解封装的库。主要包含5个函数: struct.pack(fmt, v1, v2, …): 将V1,V2等值按照对应的fmt(format)进行封装。 struct.unpack(fmt, string): 将string按照fmt的格式解封。 struct.pack_into(fmt, buffer, offset, v1, v2, …): 将V1,V2等值按照对应的fmt(format)封装到buffer中，从初始位置offset开始。 struct.unpack_from(fmt, buffer[offset=0，]): 按照fmt的格式，从offset开始将buffer解封。 struct.calcsize(fmt)： 计算对应的fmt的长度。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(3)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-3%2F</url>
      <content type="text"><![CDATA[2015年-2016年（35本书）2015年（4本书） 63.《黑客与画家》-Paul Graham 64.《文明之光》-吴军 65.《向死而生》-李开复 66.《大学之路（上）》-吴军 2016年（31本书） 67.《硅谷之谜》-吴军 68.《时间的针脚》-玛利亚杜埃尼亚斯 69.《动物庄园》-奥威尔 70.《绝望锻炼了我：朴槿惠自传》-朴槿惠 71.《解忧杂货店》-东野圭吾 72.《激荡三十年上》-吴晓波 73.《疑问集》-聂鲁达 74.《硅谷钢铁侠：埃隆·马斯克的冒险人生》-阿什利·范斯 75.《鱼羊野史第一卷》-高晓松 76.《你一定爱读的极简欧洲史》-约翰·赫斯特 77.《这么慢,那么美》-罗敷 78.《一个人的朝圣》-蕾秋·乔伊斯 79.《野火集：三十周年纪念版》-龙应台 80.《我们仨》-杨绛 81.《人间失格》-太宰治 82.《在绝望中寻找希望》-俞敏洪 83.《当尼采哭泣》-欧文 D.亚隆 84.《念完哈佛念阿弥陀佛》-陈宇廷 85.《你今天真好看》-莉兹克里莫 86.《我们生活在巨大差异里》-余华 87.《梦里花落知多少》-三毛 88.《纯真博物馆》-奥尔罕帕慕克 89.《岛上书店》-加布瑞埃拉泽文 90.《我与地坛》-史铁生 91.《史玉柱自述：我的营销心得》-史玉柱 92.《飞鸟集》-泰戈尔 93.《我可以咬你一口吗？》-利兹克利莫 94.《末日巨塔-基地组织与911之路》-劳伦斯赖特 95.《菊与刀:日本文化类型》-鲁思本尼迪克特 96.《小王子》-安托万德圣埃克苏佩里 97.《爱你就像爱生命》-王小波]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(2)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-2%2F</url>
      <content type="text"><![CDATA[2012年-2014年（37本书）2012年（7本书） 26.《爱的艺术》-艾弗洛姆 27.《平凡的世界》-路遥 28.《人生课》-张岱年 29.《世间最美丽的情郎：仓央嘉措的情与诗》-王臣 30.《追风筝的人》-(美国）胡赛尼 31.《纳兰词》-纳兰性德 32.《阿德勒谈灵魂与情感》-阿尔弗雷德阿德勒 2013年（13本书） 33.《促销的本质》-山姆沃尔顿 34.《历史是个什么玩意》-袁腾飞 35.《世界如此险恶，你要内心强大2》-石勇 36.《少有人走的路1》-M·斯科特·派克 37.《世界如此险恶，你要内心强大1》-石勇 38.《明朝那些事儿》-当年明月 39.《天才在左疯子在右》-高铭 40.《哲学与人生I》-傅佩荣 41.《哲学与人生II》-傅佩荣 42.《乌合之众》（法译本）-[法]古斯塔夫·勒庞 43.《万历十五年（增订纪念本）》-[美]黄仁宇 44.《沉默的大多数》-王小波 45.《自控力》-凯利·麦格尼格尔 2014年（17本书） 46.《七里香》，《无怨的青春》，《时光九篇》，《边缘光影》，《迷途诗册》，《我折叠着我的爱》-席慕容 47.《蒙田随笔》-蒙田（上海书店出版社） 48.《读书与做人》-季羡林 49.《男人来自火星，女人来自金星1》-约翰格雷 50.《男人来自火星，女人来自金星2》-约翰格雷 51.《超越自卑》-阿尔弗雷德阿德勒 52.《苏菲的世界》-乔斯坦贾德 53.《德意志的另一行泪》-朱维毅 54.《浪潮之巅》-吴军 55.《如果在冬夜，一个旅人》-[意大利] 伊塔洛·卡尔维诺 56.《审美与人的自由》-刘晓波 57.《撒哈拉的故事》-三毛 58.《文明之光》-吴军 59.《悉达多》-[德]赫尔曼黑塞 60.《呼兰河传》-萧红 61.《月亮与六便士》-毛姆 62.《人类的群星闪耀时》-斯蒂芬茨威格]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95%2F</url>
      <content type="text"><![CDATA[2009年-2011年（25本书）1.《谈美》-朱光潜 2.《安娜·卡列尼娜》（上下册）-（俄罗斯）托尔斯泰 3.《遇见未知的自己》- 张德芬 4.《人生若只如初见古典诗词的美丽与哀愁》- 安意如 5.《宋词三百首》- 上疆村民选编 6.《世界因你不同——李开复自传》- 李开复 范海涛 7.《思无邪：追绎前生的记忆》-安意如 8.《看张·爱玲画语》-安意如 9.《林肯传 》-戴尔·卡耐基 10.《富豪发家史》-子志编著 11.《水知道答案》-〔日〕江本胜 12.《彼得大帝》-帕甫连科 13.《活着就是为了改变世界》-杰弗里·扬,威廉西蒙 14.《我是沃兹：一段硅谷和苹果的悲情罗曼史》-斯蒂夫沃兹尼亚 15.《美国通史(上)》 16.《美国通史(下)》 17.《爱情诗集》- 文爱艺 18.《麦田里的守望者》-J.D塞林格 19.《批评官员的尺度：《纽约时报》诉警察局长沙利文案》-安东尼 20.《你是那人间的四月天》-林徽因 21.《汪国真经典诗文》-汪国真 22.《中国人的品格》-罗家伦 23.《蒙田随笔》-蒙田 24.《汪国真精选集》 25.《巨流河》-齐邦媛]]></content>
    </entry>

    
  
  
</search>
