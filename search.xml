<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Neutron的安全组原理]]></title>
      <url>%2F2017%2F04%2F09%2FNeutron%E7%9A%84%E5%AE%89%E5%85%A8%E7%BB%84%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[​ Security group通过Linux IPtables来实现，为此，在Compute节点上引入了qbr*这样的Linux传统bridge（iptables规则目前无法加载到直接挂在到ovs的tap设备上）。 安全组的INPUT、OUTPUT、FORWARD ​ 其中id的前10位数字被用作虚机对外连接的qbr（同时也是tap口）的id。i或o加上前9位数字被用作安全组chain的id。所有的规则默认都在Compute节点上的filter表（默认表）中实现，分别来查看filter表的INPUT、OUTPUT、FORWARD三条链上的规则。 INPUTiptables –line-numbers -vnL INPUT 可以看到，跟安全组相关的规则被重定向到neutron-openvswi-INPUT。 查看其规则，只有一条。 iptables –line-numbers -vnL neutron-openvswi-INPUT iptables –line-numbers -vnL neutron-openvswi-o46364368-5 iptables –line-numbers -vnL neutron-openvswi-s46364368-5 这条chain主要检查从vm发出来的网包，是否是openstack所分配的IP和MAC，如果不匹配，则禁止通过。这将防止利用vm上进行一些伪装地址的攻击。 OUTPUT iptables –line-numbers -vnL OUTPUT 分别跳转到neutron-filter-top和neutron-openvswi-OUTPUT iptables –line-numbers -vnL neutron-filter-top 该chain目前无规则。 iptables –line-numbers -vnL neutron-openvswi-OUTPUT 该chain目前无规则。 FORWARD iptables –line-numbers -vnL FORWARD 同样跳转到neutron-filter-top，无规则。跳转到neutron-openvswi-FORWARD。 iptables –line-numbers -vnL neutron-openvswi-FORWARD iptables –line-numbers -vnL neutron-openvswi-sg-chain 如果是网桥从tap-XXX端口发出到VM的流量，则跳转到neutron-openvswi-i9LETTERID，例如i46364368-5；如果是从tap-XXX端口进入到网桥的（即vm发出来的）流量，则跳转到neutron-openvswi-o9LETTERID，例如o46364368-5。 neutron-openvswi-i9LETTERID允许安全组中配置的策略（允许ssh、ping等）和dhcp reply通过。默认的neutron-openvswi-sg-fallback将drop所有流量。 iptables –line-numbers -vnL neutron-openvswi-i46364368-5 iptables –line-numbers -vnL neutron-openvswi-o46364368-5 neutron-openvswi-o9LETTERID将跳转到 neutron-openvswi-s46364368-5，允许DHCP Request和匹配VM的源IP和源MAC的流量通过。 iptables –line-numbers -vnL neutron-openvswi-s46364368-5 整体逻辑 快速查找安全组规则从前面分析可以看出，某个vm的安全组相关规则的chain的名字，跟vm的id的前9个字符有关。 因此，要快速查找qbr-XXX上相关的iptables规则，可以用iptables -S列出（默认是filter表）所有链上的规则，其中含有id的链即为虚拟机相关的安全组规则。其中–physdev-in表示即将进入某个网桥的端口，–physdev-out表示即将从某个网桥端口发出。 iptables -S | grep tap4ca9818f-53 可以看出，进出tap-XXX口的FORWARD链上的流量都被扔到了neutron-openvswi-sg-chain这个链，neutron-openvswi-sg-chain上是security group具体的实现（两条规则，访问虚拟机的流量扔给neutron-openvswi-i583c7038-d；从虚拟机出来的扔给neutron-openvswi-o583c7038-d）。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron三层网络服务实现原理]]></title>
      <url>%2F2017%2F04%2F06%2FNeutron%E4%B8%89%E5%B1%82%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[​ Neutron 对虚拟三层网络的实现是通过其 L3 Agent （neutron-l3-agent）。该 Agent 利用 Linux IP 栈、route 和 iptables 来实现内网内不同网络内的虚机之间的网络流量，以及虚机和外网之间网络流量的路由和转发。为了在同一个Linux 系统上支持可能的 IP 地址空间重叠，它使用了 Linux network namespace 来提供隔离的转发上下文。 NameSpace技术​ 在二层网络上，VLAN 可以将一个物理交换机分割成几个独立的虚拟交换机。类似地，在三层网络上，Linux network namespace（netns） 可以将一个物理三层网络分割成几个独立的虚拟三层网络。 ​ Network namespace （netns）从 Linux 2.6.24 版本开始添加，直到 2.6.29 添加完成。每个 netns 拥有独立的 （virtual）network devices, IP addresses, IP routing tables, /proc/net directory, ports 等等。新创建的 netns 默认只包含 loopback device。除了这个设备，每个 network device，不管是物理的还是虚拟的网卡还是网桥等，都只能存在于一个 netns。而且，连接物理硬件的物理设备只能存在于 root netns。其它普通的网络设备可以被创建和添加到某个 netns。 添加 network namespace ​ ip netnas add &lt;network namespace name&gt; ​ Example: ​ ip netns add nstest 列表所有 netns ​ ip netns list 删除某 netns ​ ip netns delete &lt;network namespace name&gt; 在 network namespace 中运行命令 ​ ip netns exec &lt;network namespace name&gt; &lt;command&gt; ​ Example using the namespace from above: ​ ip netns exec nstest ip addr 添加 virtual interfaces 到 network namespace ​ ip link add veth-a type veth peer name veth-b #创建一对虚拟网卡veth-a 和 veth-b，两者由一根虚拟网线连接 将 veth-b 添加到 network namespace ​ ip link set veth-b netns nstest 设置 vi 的 IP 地址 ​ ip netns exec nstest ip addr add 10.0.0.2/24 dev veth-b ​ ip netns exec nstest ip link set dev veth-b up 设置默认namespace的vi地址 ​ ip addr add 10.0.0.1/24 dev veth-a​ ip link set dev veth-a up ping ​ ip netns exec nstest ping 10.0.0.1 ​ PING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. ​ bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=0.054 ms 查看路由表和 iptbales ​ ip netns exec nstest route ​ ip netns exec nstest iptables -L Iptables​ Neutron 主要用到 filter 表和 nat 表，其中， filter 用来实现安全组（Security Group）和 防火墙（FWaas）；nat 主要用来实现 router。 ​ iptables其实是个client，供用户去管理防火墙.相关的请求最后会发送相关内核模块，如ip_tables。ip_tables内核模块主要用于组织iptables使用的表,链,规则.netfilter是一套技术框架，ip_tables依托于netfilter来注册各种hooks实现对数据包的具体控制。一些厂商的防火墙，入侵检测，入侵防御系统什么的基本依托于Netfilter来实现(从事过相关开发)。 NEW,ESTABLISHED,RELATED,INVALID状态 NEW: conntrack模块看到的某个连接第一个包，它即将被匹配了。比如，我们看到一个SYN包，是我们所留意的连接的第一个包，就要匹配它。第一个包也可能不是SYN包，但它仍会被认为是NEW状态。ESTABLISHED: 已经注意到两个方向上的数据传输，而且会继续匹配这个连接的包。处于ESTABLISHED状态的连接是非常容易理解的。只要发送并接到应答，连接就是ESTABLISHED的了。一个连接要从NEW变为ESTABLISHED，只需要接到应答包即可，不管这个包是发往防火墙的，还是要由防火墙转发的。ICMP的错误和重定向等信息包也被看作是ESTABLISHED，只要它们是我们所发出的信息的应答。RELATED 当一个连接和某个已处于ESTABLISHED状态的连接有关系时，就被认为是RELATED的了。换句话说，一个连接要想是RELATED的，首先要有一个ESTABLISHED的连接。这个ESTABLISHED连接再产生一个主连接之外的连接，这个新的连接就是RELATED的了，比如ftp的父子链接。INVALID 非以上状态的包。 我们看一下某个路由器里的iptables-save 输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# Generated by iptables-save v1.6.0 on Thu Apr 6 04:19:36 2017*nat:PREROUTING ACCEPT [4:160]:INPUT ACCEPT [1:40]:OUTPUT ACCEPT [2:80]:POSTROUTING ACCEPT [2:80]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-snat - [0:0]:neutron-postrouting-bottom - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A POSTROUTING -j neutron-postrouting-bottom-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697-A neutron-l3-agent-snat -j neutron-l3-agent-float-snat-A neutron-postrouting-bottom -m comment --comment &quot;Perform source NAT on outgoing traffic.&quot; -j neutron-l3-agent-snatCOMMIT# Completed on Thu Apr 6 04:19:36 2017# Generated by iptables-save v1.6.0 on Thu Apr 6 04:19:36 2017*filter:INPUT ACCEPT [262970:10518800]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [262969:10518760]:neutron-filter-top - [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-local - [0:0]:neutron-l3-agent-scope - [0:0]-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-filter-top-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-filter-top-A OUTPUT -j neutron-l3-agent-OUTPUT-A neutron-filter-top -j neutron-l3-agent-local-A neutron-l3-agent-FORWARD -j neutron-l3-agent-scope-A neutron-l3-agent-INPUT -m mark --mark 0x1/0xffff -j ACCEPT-A neutron-l3-agent-INPUT -p tcp -m tcp --dport 9697 -j DROPCOMMIT# Completed on Thu Apr 6 04:19:36 2017# Generated by iptables-save v1.6.0 on Thu Apr 6 04:19:36 2017*raw:PREROUTING ACCEPT [262973:10518920]:OUTPUT ACCEPT [262969:10518760]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-PREROUTING - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUTCOMMIT# Completed on Thu Apr 6 04:19:36 2017# Generated by iptables-save v1.6.0 on Thu Apr 6 04:19:36 2017*mangle:PREROUTING ACCEPT [262973:10518920]:INPUT ACCEPT [262970:10518800]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [262969:10518760]:POSTROUTING ACCEPT [262969:10518760]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-floatingip - [0:0]:neutron-l3-agent-mark - [0:0]:neutron-l3-agent-scope - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-mark-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-scope-A neutron-l3-agent-PREROUTING -m connmark ! --mark 0x0/0xffff0000 -j CONNMARK --restore-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-floatingip-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j MARK --set-xmark 0x1/0xffff-A neutron-l3-agent-float-snat -m connmark --mark 0x0/0xffff0000 -j CONNMARK --save-mark --nfmask 0xffff0000 --ctmask 0xffff0000COMMIT 输出是分段的,每个段落一个表,*开头后面跟着表名。:开头的行是对链匹配次数的总结,后面跟着统计信息,[数据包:字节数]。后面跟着的是具体规则。最后跟着COMMIT表示一个表的结束。 Linux IP 栈Secondary IP我们看一个路由器的ip信息,qg-8119a20a-21接口绑定了浮动ip。 1234567891011121314151617ip netns exec qrouter-2cb693be-7abc-46f1-80cd-a17d0fc8d696 ip addr20: qg-8119a20a-21: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:73:88:35 brd ff:ff:ff:ff:ff:ff inet 180.180.18.5/24 brd 180.180.18.255 scope global qg-8119a20a-21 valid_lft forever preferred_lft forever inet 180.180.18.6/32 brd 180.180.18.6 scope global qg-8119a20a-21 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe73:8835/64 scope link valid_lft forever preferred_lft forever#解释&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;：端口的各种状态BROADCAST： device can send traffic to all hosts on the link （能够发广播）MULTICAST： device can perform and receive multicast packets （能够发多播）UP： device is functioning （enabled 状态，可通过 ip * up/down 设置。）LOWER_UP：the state of the Ethernet link（表示线已接上）inet/brd/scope：IP 地址及子网掩码，广播地址，作用域scope：global：valid everywhere ​ 这个interface有两个静态 IP 地址。第一个是主要的（primary）IP，第二个是辅助的（ secondary） 的 IP。当一个网卡配置了静态IP后，你可以添加secondary IP 给它。这样它就拥有了多个 IP 地址了。Secondary IP 不可以通过 DHCP 分配。它所有的IP 地址都关联到它唯一的一个 MAC 地址上。那为什么需要 secondary IP 地址呢？ 路由器有个 Secondary IP 的概念，这个特性可以创建逻辑子网，也就是说在一个物理网口上连接两个子网，比如这个网口接到一台交换机上，如果这个网口没有配置Secondary IP的话，那么这台交换机只能连接一个网段的主机，比如 192.168.1.1/24，但是，如果它配置了Secondary IP，那么就可以连接两个网段的主机，比如 192.168.1.1/24 和 10.0.0.1/24。 Gratuitous ARP众所周知，ARP的基本功能就是在以太网环境中，通过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。但由于ARP的广播、动态学习等特性注定了它不是一种安全的协议，所以在实际应用中，会由于各种各样的原因使ARP学习失败，从而影响网络的互通性，并进而影响用户的业务稳定运行。整个ARP的体系里基本上就是由ARP Request和Response组成的,Request就是告知对方“我要什么”，而Response是回答“我是什么”。但有些时候也会例外，他们虽然从形式上还是Request和Response的，但它们通常不会不是一问一答的，而是只有其中的一部分，所以通常被称为免费ARP或无为ARP（Gratuitous ARP）。 ​ Gratuitous ARP在主机启动的时候，请求自己的IP地址对应的MAC地址。 它常用于三个用途： ​ Change of L2 address：通告自己改变了 MAC 地址。以 ARP Response 的形式发送广播，它通常只是为了把自己的ARP信息通告/更新给局域网全体，这种Response不需要别人请求，是自己主动发送的通告。当一个网络设备的 MAC 地址发生改变时，发送该设备的 Gratuitous ARP，通知所在广播域内的已经包含该 IP 地址在其 ARP 表中的机器去更新它的 ARP 条目。 ​ Duplicate address detection：重复 MAC 地址检测。以 ARP Request的形式发送广播，请求自己的MAC地址，目的是探测局域网中是否有跟自己IP地址相同的主机，也就是常说的IP冲突。发送主机并不需要一定收到此请求的回答。如果收到一个回答，表示网络中存在与自身IP相同的主机。如果没有收到应答，则表示本机所使用的IP与网络中其它主机并不冲突。 Virtual IP：用于一组服务器做 failover 时通知周围的机器新生效的 IP 地址的 MAC. Route （Linux 路由表）​ route命令用来显示并设置Linux内核中的网络路由表，route命令设置的路由主要是静态路由。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。 route add -net 10.0.0.0 netmask 255.0.0.0 dev eth0 #增加一条经过 eth0 到达 10.0.0.0 的路由route add -net 10.0.0.0 netmask 255.0.0.0 reject #增加一条屏蔽的路由，目的地址为10.X.X.X将被拒绝。route del -net 10.0.0.0 netmask 255.0.0.0route del -net 10.0.0.0 netmask 255.0.0 rejectroute del default gw 10.0.36.254route add default gw 10.0.36.254 基于VRRP的路由高可用什么是VRRP？​ Virtual Redundent Routing Protocol 虚拟冗余路由协议，是一种可以解决这种问题的容错协议。VRRP协议的目的就是为了解决路由单点故障问题，VRRP通过竞选(election)协议来动态的将路由任务交给LAN中虚拟路由器中的某台VRRP路由器。它的原理如下： 在这之前我们先了解一下相关术语： 虚拟路由器：由一个 Master 路由器和多个 Backup 路由器组成。主机将虚拟路由器当作默认网关。VRID：虚拟路由器的标识，有相同 VRID 的一组路由器构成一个虚拟路由器。通常用（0-255）标识Master路由器：虚拟路由器中承担报文转发任务的路由器。Backup路由器： Master路由器出现故障时能够代替 Master路由器工作的路由器。虚拟 IP：地址虚拟路由器的 IP 地址，一个虚拟路由器可以拥有一个或多个IP 地址。IP 地址拥有者：接口IP地址与虚拟IP地址相同的路由器被称为 IP 地址拥有者。虚拟 MAC 地址：一个虚拟路由器拥有一个虚拟 MAC 地址。虚拟 MAC 地址的格式为 00-00-5E-00-01-{VRID}。通常情况下虚拟路由器回应 ARP 请求使用的是虚拟 MAC 地址，只有虚拟路由器做特殊配置的时候才回应接口的真实 MAC 地址。priority优先级：VRRP 根据优先级来确定虚拟路由器中每台路由器的地位。用0-255来表示，数字越小优先级越低。VRRP优先级的取值范围为0到255（数值越大表明优先级越高），可配置的范围是1到254，优先级0为系统保留给路由器放弃Master位置时候使用，255则是系统保留给IP地址拥有者使用。当路由器为IP地址拥有者时，其优先级始终为255。因此，当虚拟路由器内存在IP地址拥有者时，只要其工作正常，则为Master路由器。抢占方式：默认，如果 Backup 路由器工作在抢占方式下，当它收到 VRRP 报文后会将自己的优先级与通告报文中的优先级进行比较。如果自己的优先级比当前的 Master 路由器的优先级高就会主动抢占成为 Master 路由器否则将保持 Backup 状态。非抢占方式：如果 Backup 路由器工作在非抢占方式下则只要 Master 路由器没有出现故障Backup 路由器即使随后被配置了更高的优先级也不会成为Master 路由器。 VRRP协议报文：封装在IP报文中，发送到分配给 VRRP 的 IP 组播地址。在IP报文头中，源地址为发送报文接口的主 IP 地址（不是虚拟IP地址），目的地址是224.0.0.18，TTL是255，协议号是112。目前，VRRP协议包括两个版本：VRRPv2和VRRPv3，VRRPv2仅适用于IPv4网路，VRRPv3适用于IPv4和IPv6两种网络。 VRRP 节点三种状态：初始状态（Initialize）、活动状态（Master）、备份状态（Backup）。其中，只有处于Master状态的设备才可以转发那些发送到虚拟IP地址的报文。 然后我们结合上图来描述一下VRRP的机制。 ​ Device A 和 B 组成一个 VRRP 组，它的虚拟 IP（VIP） 为 10.0.0.3/24。其中，通过选举机制，A 是 Master Router，B 是 Backup Router。一个 VRRP 组内可以由多个设备，但是只有一个是 Master 设备。注意 Device A 和 B 可以由自己的 IP 地址，VIP 可以和其中的某 IP 相同，也可以不同。 ​ 当前，Router A 作为 Master router 向局域网内的机器提供路由服务，Router B 作为 Backup router。它的任务是周期性地接受 A 发出的心跳。在规定的时间段内，如果都没有收到 A 发出的心跳，则启动一个选举过程，重新选出 Master。 ​ 局域网内的机器将虚拟路由器当作默认网关，它们仅仅知道这个虚拟路由器的IP 地址 10.0.0.3，而并不知道具体的 Master 路由器的 IP 地址以及 Backup 路由器的IP 地址。它们将自己的缺省路由下一跳地址设置为10.0.0.3。于是，网络内的主机就通过这个虚拟的路由器来与其它网络进行通信。如果 Master 路由器坏掉，Backup 路由器将会通过选举策略选出一个新的 Master 路由器，继续向网络内的主机提供路由服务。从而实现网络内的主机不间断地与外部网络进行通信。 它的优势： ​ 操作简单：它不需要改变组网情况，也不需要在主机上做任何配置，只需要在相关路由器上配置极少的几条命令，就能实现下一跳网关的备份，并且不会给主机带来任何负担。和其他方法比较起来，VRRP更加能够满足用户的需求。​ 简化网络管理：在具有多播或广播能力的局域网（如以太网）中，借助 VRRP 能在某台设备出现故障时仍然提供高可靠的缺省链路，有效避免单一链路发生故障后网络中断的问题，而无需修改动态路由协议、路由发现协议等配置信息，也无需修改主机的默认网关配置。​ 适应性强：VRRP报文封装在IP报文中，支持各种上层协议。​ 网络开销小：VRRP只定义了一种报文——VRRP通告报文，并且只有处于Master状态的路由器可以发送VRRP报文。 什么是keepalived ？​ Keepalived 是 VRRP 的一个非常好的开源实现，它是一个基于 VRRP 协议来实现的 WEB 服务高可用方案，可以利用其来避免单点故障。在neutron的路由高可用中，需要安装keepalived 即可。 Keepalived组件如下：​ keepalived是模块化设计，不同模块负责不同的功能：​ core：keepalived的核心；负责主进程的启动和维护全局配置文件的加载解析等​ check：负责healthchecker(健康检查)包括了各种健康检查方式以及对应的配置文件的解析​ vrrp VRRPD：子进程用来实现VRRP协议​ libipfwc iptables(ipchains)库配置LVS​ libipvs*：配置LVS keepalived进程如下： ​ Keepalived 使用三个进程，其中 Watchdog 是控制进程，VRRP Stack and Checkers 是它的两个子进程。 ​ Watchdog 通过心跳机制来确保子进程处于运行状态。 ​ Checkers：负责真实服务器的健康检测，用于负载均衡。 ​ VRRP Stack：实现 VRRP 协议，提供 HA。 neutron如何实现？Neutron L3 HA 的提出就是为了保证 OpenStack 环境三层网络的高可用性。 ​ QR 和 QG 分别连接内网和外网，这是 router 本来就有的端口；HA 端口是 HA router 才特有的。一个非 HA router，只会存在于一个 Neutron L3 agent 所在的 Network node 中。而一个 HA router 会在多个 Neutron L3 agent 所在的 Network node 里创建 instance，这包括创建相应的 namespace 和端口。每个 HA router instance 里面的 QR 和 QG 都有相同的设备名和 MAC 地址(Media Access Control Address)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#Master的信息root@netagent10038219:~# ip netns exec qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever28: ha-65bc01fe-af: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:1f:d2:bd brd ff:ff:ff:ff:ff:ff inet 169.254.192.1/18 brd 169.254.255.255 scope global ha-65bc01fe-af valid_lft forever preferred_lft forever inet 169.254.0.1/24 scope global ha-65bc01fe-af valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe1f:d2bd/64 scope link valid_lft forever preferred_lft forever30: qr-fe09d52e-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:58:13:ad brd ff:ff:ff:ff:ff:ff inet 1.1.1.1/24 scope global qr-fe09d52e-c6 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe58:13ad/64 scope link nodad valid_lft forever preferred_lft forever32: qg-21bed7aa-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:a9:28:e7 brd ff:ff:ff:ff:ff:ff inet 10.99.1.101/32 scope global qg-21bed7aa-c6 valid_lft forever preferred_lft forever inet 10.99.1.102/32 scope global qg-21bed7aa-c6 valid_lft forever preferred_lft forever inet 10.99.1.103/24 scope global qg-21bed7aa-c6 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fea9:28e7/64 scope link nodad valid_lft forever preferred_lft forever#Slave信息root@netagent10038220:~# ip netns exec qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever26: ha-557abd6c-48: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:3f:75:8d brd ff:ff:ff:ff:ff:ff inet 169.254.192.2/18 brd 169.254.255.255 scope global ha-557abd6c-48 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe3f:758d/64 scope link valid_lft forever preferred_lft forever29: qr-fe09d52e-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:58:13:ad brd ff:ff:ff:ff:ff:ff32: qg-21bed7aa-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:a9:28:e7 brd ff:ff:ff:ff:ff:ff Slave 和 Master router instance 的区别在于 Master router instance 的网络端口上是有 IP 地址的。这些 IP 实际上是 VIP，它们只会存在于 Master router instance 上。每个 router instance 上都有一个 HA 端口，这些端口都有不同的 IP。这些端口是用来进行 VRRP 广播通信的。每个 router instance 里面都运行着一个 keepalived 进程。Keepalived 是一个实现了 VRRP 的软件工具，Neutron 利用 keepalived 实现的 L3 HA的。 对于Master 我们查看一下它发的VRRP广播 123456root@netagent10038219:~# ip netns exec qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b tcpdump -i ha-65bc01fe-aftcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ha-65bc01fe-af, link-type EN10MB (Ethernet), capture size 262144 bytes05:01:11.336576 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 2005:01:13.337818 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 2005:01:15.339083 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20 HA 端口向广播地址 224.0.0.18 发送信息。这是由 VRRP 协议规定的。如果 Master router instance 出现故障，不能发出广播信息，导致 Slave router instance 未在一定的时间内收到广播信息。剩下的 Slave router instance 会选取出一个来作为新的 Master router instance。这个 instance 会获取 VIP，从而为 OpenStack 提供三层网络。虽然提供服务的 router instance 变了，但是 IP 没有改变，所以从使用者的角度来看，网络服务没有发生改变。 vrid 是 HA router 对应的 id，每个 tenant 下面，不同的 router 对应不同的 vrid。需要注意的是，由于 VRRP 协议的限制，vrid 是一个 8 bit 数据。因此每个 tenant 下面，最多只能创建 255 个 HA router。prio 是 instance 的优先级，这个目前是不可配置的，每个 instance 的优先级一样。authtype 是 instance 之间通信的认证方式，默认是不需要认证。intvl 是广播之间的间隔时间，默认是 2 秒，这个可以配置。 每个 HA router 一旦被创建，Neutron L3 agent 会为每个 router instance 创建一个 keepalived 进程，在这之前会先生成一个 keepalived 的配置文件供 keepalived 的进程使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869root@netagent10038219:~# ps -aux | grep &apos;23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b&apos;root 4310 0.0 0.8 155892 73080 ? S Mar17 0:05 /usr/bin/python /usr/local/bin/neutron-keepalived-state-change --router_id=23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --namespace=qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --conf_dir=/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --monitor_interface=ha-65bc01fe-af --monitor_cidr=169.254.0.1/24 --pid_file=/var/lib/neutron/external/pids/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.monitor.pid --state_path=/var/lib/neutron --user=0 --group=0root 4810 0.0 0.0 54252 564 ? Ss Mar17 0:59 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 4811 0.0 0.0 56496 3856 ? S Mar17 2:31 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 6330 0.0 0.8 140156 71188 ? S Mar28 0:02 /usr/bin/python /usr/local/bin/neutron-ns-metadata-proxy --pid_file=/var/lib/neutron/external/pids/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid --metadata_proxy_socket=/var/lib/neutron/metadata_proxy --router_id=23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --state_path=/var/lib/neutron --metadata_port=9697 --metadata_proxy_user=0 --metadata_proxy_group=0 --log-file=neutron-ns-metadata-proxy-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.log --log-dir=/var/log/neutronroot 28706 0.0 0.0 13080 2544 pts/1 S+ 05:47 0:00 grep --color=auto 23d7334d-a55f-4b4b-9dfa-4d1ee4b3080broot@netagent10038219:/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b# lskeepalived.conf neutron-keepalived-state-change.log statevrrp_instance VR_1 &#123; state BACKUP interface ha-65bc01fe-af virtual_router_id 1 priority 50 garp_master_delay 60 nopreempt advert_int 2 track_interface &#123; ha-65bc01fe-af &#125; virtual_ipaddress &#123; 169.254.0.1/24 dev ha-65bc01fe-af &#125; virtual_ipaddress_excluded &#123; 1.1.1.1/24 dev qr-fe09d52e-c6 10.99.1.101/32 dev qg-21bed7aa-c6 10.99.1.102/32 dev qg-21bed7aa-c6 10.99.1.103/24 dev qg-21bed7aa-c6 fe80::f816:3eff:fe58:13ad/64 dev qr-fe09d52e-c6 scope link fe80::f816:3eff:fea9:28e7/64 dev qg-21bed7aa-c6 scope link &#125; virtual_routes &#123; 0.0.0.0/0 via 10.99.1.1 dev qg-21bed7aa-c6 &#125;&#125;========================================================================================root@netagent10038220:~# ps -aux | grep &apos;23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b&apos;root 4330 0.0 0.8 155896 72840 ? S Mar17 0:04 /usr/bin/python /usr/local/bin/neutron-keepalived-state-change --router_id=23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --namespace=qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --conf_dir=/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --monitor_interface=ha-557abd6c-48 --monitor_cidr=169.254.0.1/24 --pid_file=/var/lib/neutron/external/pids/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.monitor.pid --state_path=/var/lib/neutron --user=0 --group=0root 4882 0.0 0.0 54252 568 ? Ss Mar17 0:59 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 4883 0.0 0.0 56540 4304 ? S Mar17 1:46 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 25801 0.0 0.0 13080 2548 pts/0 S+ 05:48 0:00 grep --color=auto 23d7334d-a55f-4b4b-9dfa-4d1ee4b3080broot@netagent10038220:/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b# lskeepalived.conf neutron-keepalived-state-change.log statevrrp_instance VR_1 &#123; state BACKUP interface ha-557abd6c-48 virtual_router_id 1 priority 50 garp_master_delay 60 nopreempt advert_int 2 track_interface &#123; ha-557abd6c-48 &#125; virtual_ipaddress &#123; 169.254.0.1/24 dev ha-557abd6c-48 &#125; virtual_ipaddress_excluded &#123; 1.1.1.1/24 dev qr-fe09d52e-c6 10.99.1.101/32 dev qg-21bed7aa-c6 10.99.1.102/32 dev qg-21bed7aa-c6 10.99.1.103/24 dev qg-21bed7aa-c6 fe80::f816:3eff:fe58:13ad/64 dev qr-fe09d52e-c6 scope link fe80::f816:3eff:fea9:28e7/64 dev qg-21bed7aa-c6 scope link &#125; virtual_routes &#123; 0.0.0.0/0 via 10.99.1.1 dev qg-21bed7aa-c6 &#125;&#125; ​ 总的来说，要使用 HA router，首先必须有多个 Neutron L3 agent 在不同的 Network node 上运行。一旦创建了一个 HA router，Neutron 会通过多个 L3 agent 创建相应的 namespace 和端口，这样就有了这个 HA router 的多个 instance。同时，L3 agent 还会创建 keepalived 进程，每个 keepalived 进程都有 router 的全部信息。这样，每个 Network node 上都有 HA router 的一个 instance 和管理这个 router instance 的 keepalived 进程。​ 当一切就绪之后，这些 router instance 会进行一次选举，胜出的作为 Master instance，剩下的作为 Slave instance。由于所有的 router instance 的优先级都是一样的，选举的结果是随机的。也就是说，如果创建多个 HA router，这些 router 的 Master instance 可能分布在多个 Network node 上。​ 选举结束后，Master router instance 负责提供 L3 网络服务，并同时向其他的 Slave router instance 发广播报告自身的状况。一旦由于各种原因，广播中断，Slave router instance 会重新选举出新的 Master router instance，继续提供 L3 网络服务，并同时发送广播报告自身的状况。 DHCP服务neutron dhcp为租户网络提供DHCP服务，即IP地址动态分配，另外还会提供metadata请求服务。3个主要的部件：DHCP agent scheduler：负责DHCP agent与network的调度。DHCP agent：为租户网络提供DHCP的功能，提供metadata request服务。DHCP driver：即dnsmasq，用于管理DHCP server。 Dnsmasq 是被 Neutron 用来提供 DHCP 和 DNS 服务的一个开源程序，即DHCP driver部分。它提供 DNS 缓存和 DHCP 服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。作为DHCP 服务器，dnsmasq 可以为局域网电脑提供内网ip地址和路由。DNS和DHCP两个功能可以同时或分别单独实现。dnsmasq轻量且易配置，适用于主机较少的网络。 根据整个dhcp处理的流程，dhcp模块主要由Neutron api、core plugin（如linux bridge plugin，ovs plugin等）、dhcp agent scheduler、dhcp agent、dhcp driver（dnsmasq）构成。 对应架构图中数字，有以下几个接口：1.network/subnet/port的操作2.agent management/agent scheduler的操作3.network/subnet/port操作会发送rpc请求到dhcp agent。4.agentscheduler db发送rpc请求到dhcp agent。5.dhcp agent通过DhcpPluginApi发送rpc请求到core plugin，操作相应的数据库。6.dhcp agent调用dhcp driver进行dhcp相关操作。 虚机获取固定IP （Fixed IP）主要分为两个步骤： ​ 在创建虚机过程中，Neutron 随机生成 MAC 和 从配置数据中分配一个固定IP 地址，并保存到 Dnsmasq 的 hosts 文件中，让 Dnsmasq 做好准备。 ​ 虚机在启动时向 Dnsmasq 获取 IP 地址 红色为创建虚拟机的数据流 绿色为虚拟机启动的数据流 创建虚机时的数据流 Controller 节点上的 Neutron Server 接到该请求后，会开始下面的过程： 步骤 2 ~ 6：Neutron Server 生成 MAC 和 IP。 其中 MAC 是由任意数组成的；Fixed IP 是从保存在数据库中的管理员配置的网络和地址数据生成的。 步骤 7 ~ 10： 调用 L3 Agent 和 OVS 执行一些操作。 步骤 12 ~ 14：通过 AMQP 的 cast 消息给 Neutron 节点上的 DHCP Agent，告诉它 Port 创建结束以及 新分配的 Port 的数据。 步骤 13：返回Port 给 nova-compute。 步骤 15：Neturon 节点上的 DHCP Agent 根据接收到的 Port 创建完成通知，重新生成 Dnsmasq 的 hosts 文件，然后让 Dnsmasq 重新加载该文件。Nova 拿到 Port 的数据后，会写入虚机的 libvirt.xml 文件。 参考：http://man.linuxde.net/route http://fishcried.com/2016-02-19/iptables/ http://www.cnblogs.com/sammyliu/p/4636091.html http://www.embeddedlinux.org.cn/linux_net/0596002556/understandlni-CHP-28-SECT-3.html https://www.ibm.com/developerworks/cn/cloud/library/1506_xiaohh_openstackl3/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux的iptables原理]]></title>
      <url>%2F2017%2F04%2F06%2FLinux%E7%9A%84iptables%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[​ 在Linux系统中，对于防火墙的实现一般分为包过滤防火墙，TCP-Wrapper即程序管控，代理服务器等几种方式。其中，iptables作为一种基于包过滤方式的防火墙工具，在实际中应用非常广泛，是非常重要的一个安全工具。真正实现防火墙功能的是 netfilter，它是一个 linux 内核模块，做实际的包过滤。实际上，除了 iptables 以外，还有很多类似的用户空间工具。 iptables的“链”与“表”netfilter 使用表（table）和 链（chain）来组织网络包的处理规则（rule）。它默认定义了以下表和链： 表 表功能 链 链功能 raw PREROUTING OUTPUT RAW 拥有最高的优先级，它使用PREROUTING和OUTPUT两个链，因此 RAW 可以覆盖所有包。在raw表中支持一个特殊的目标:TRACE，使内核记录下每条匹配该包的对应iptables规则信息。使用raw表内的TRACE target 即可实现对iptables规则的跟踪调试。比如：# iptables -t raw -A OUTPUT -p icmp -j TRACE # ipt ables -t raw -A PREROUTING -p icmp -j TRACE Filter 包过滤 FORWARD 过滤目的地址和源地址都不是本机的包 INPUT 过滤目的地址是本机的包 OUTPUT 过滤源地址是本机的包 Nat 网络地址转换 PREROUTING 在路由前做地址转换，使得目的地址能够匹配上防火墙的路由表，常用于转换目的地址。 POSTROUTING 在路由后做地址转换。这意味着不需要在路由前修改目的地址。常用于转换源地址。 OUTPUT 对防火墙产生的包做地址转换（很少量地用于 SOHO 环境中） Mangle TCP 头修改 PREROUTING POSTROUTING OUTPUT INPUT FORWARD 在路由器修改 TCP 包的 QoS（很少量地用在 SOHO 环境中） 先是透过路由判断， 决定了输出的路径后，再透过 filter 的 OUTPUT 链来传送的， mangle 这个表格很少被使用，如果将上图的mangle 拿掉的话，那就容易看的多了： 如果你的防火墙事实上是用来管制 LAN 内的其他主机的话，那么你就必须要再针对 filter 的 FORWARD 这条链，还有 nat 的 PREROUTING, POSTROUTING 以及 OUTPUT 进行额外的规则订定才行。 iptables实现SNAT与DNATNAT 服务器的重点就在于上面流程NAT table 的两条重要的链：PREROUTING 与 POSTROUTING。 举例如下： SNAT封包传送和封包接收 ​ 客户端所发出的封包表头中，来源会是 192.168.1.100 ，然后传送到 NAT 这部主机；NAT 这部主机的内部接口 (192.168.1.2) 接收到这个封包后，会主动分析表头数据， 因为表头数据显示目的并非 Linux 本机，所以开始经过路由， 将此封包转到可以连接到 Internet 的 Public IP 处；由于 private IP 与 public IP 不能互通，所以 Linux 主机透过 iptables 的 NAT table 内的 Postrouting 链将封包表头的来源伪装成为 Linux 的 Public IP ，并且将两个不同来源 (192.168.1.100 及 public IP) 的封包对应写入暂存内存当中， 然后将此封包传送出去了；​ 此时 Internet 上面看到这个封包时，都只会知道这个封包来自那个 Public IP 而不知道其实是来自内部啦。 好了，那么如果 Internet 回传封包呢？又会怎么作？ ​ 在 Internet 上面的主机接到这个封包时，会将响应数据传送给那个 Public IP 的主机；当 Linux NAT 服务器收到来自 Internet 的回应封包后，会分析该封包的序号，并比对刚刚记录到内存当中的数据， 由于发现该封包为后端主机之前传送出去的，因此在 NAT Prerouting 链中，会将目标 IP 修改成为后端主机，亦即那部 192.168.1.100，然后发现目标已经不是本机 (public IP)， 所以开始透过路由分析封包流向；封包会传送到 192.168.1.2 这个内部接口，然后再传送到最终目标 192.168.1.100 机器上去！ SNAT 主要是应付内部 LAN 连接到 Internet 的使用方式，至于 DNAT 则主要用在内部主机想要架设可以让 Internet 存取的服务器啦！ DNAT封包传送 ​ 假设我的内部主机 192.168.1.210 启动了 WWW 服务，这个服务的 port 开启在 port 80 ， 那么 Internet 上面的主机 (61.xx.xx.xx) 要如何连接到我的内部服务器呢？当然啦， 还是得要透过 Linux NAT 服务器嘛！所以这部 Internet 上面的机器必须要连接到我们的 NAT 的 public IP 才行。外部主机想要连接到目的端的 WWW 服务，则必须要连接到我们的 NAT 服务器上头；我们的 NAT 服务器已经设定好要分析出 port 80 的封包，所以当 NAT 服务器接到这个封包后， 会将目标 IP 由 public IP 改成 192.168.1.210 ，且将该封包相关信息记录下来，等待内部服务器的响应；上述的封包在经过路由后，来到 private 接口处，然后透过内部的 LAN 传送到 192.168.1.210 上头！ ​ 192.186.1.210 会响应数据给 61.xx.xx.xx ，这个回应当然会传送到 192.168.1.2 上头去；经过路由判断后，来到 NAT Postrouting 的链，然后透过刚刚的记录，将来源 IP 由 192.168.1.210 改为 public IP 后，就可以传送出去了！ iptables常用命令 注释： 如果想查看特别的表时使用-t指定,如果查看单独的链需要在操作后面指定. 如果是查看规则定义,使用-S. -S比-L查看规则时更加清晰. 如果查看匹配状况使用-nvL.配合watch使用. --line-number用于查看规则号. iptables [-t tables][-L] [-nv] 选项与参数： -t ：后面接 table ，例如 nat 或 filter ，若省略此项目，则使用默认的 filter -L ：列出目前的 table 的规则 -n ：不进行 IP 与 HOSTNAME 的反查，显示讯息的速度会快很多！ -v ：列出更多的信息，包括通过该规则的封包总位数、相关的网络接口等 iptables-save [-t table] （列出完整的防火墙规则） 选项与参数： -t ：可以仅针对某些表格来输出，例如仅针对 nat 或 filter 等等 ​ 这个命令主要是把内存态的规则保存到文件,然后下次启动的时候用iptables-restore来载入规则. 但是这个命令常常用来查看防火墙规则.比iptables用得都多, 主要是输出结果的格式比较紧凑直观.而且能方便的能看到所有表的规则. iptables [-t tables][-FXZ] 选项与参数：-F ：清除所有的已订定的规则；-X ：杀掉所有使用者 “自定义” 的 chain (应该说的是 tables ）啰；-Z ：将所有的 chain 的计数与流量统计都归零 参考：http://fishcried.com/2016-02-19/iptables/ http://cn.linux.vbird.org/linux_server/0250simple_firewall_3.php]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是openstack?]]></title>
      <url>%2F2017%2F04%2F05%2F%E4%BB%80%E4%B9%88%E6%98%AFopenstack%2F</url>
      <content type="text"><![CDATA[​ OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它不是一个软件，而是由几个主要的组件组合起来完成一些具体的工作。可以搭建公有云，私有云，企业云。​ OpenStack基本上是一个软件项目，有近55万行代码。分解成核心项目、孵化项目，以及支持项目和相关项目。​ OpenStack是一个框架，一个可以建立公有云和私有云的基础架构。它并不是一个现成的产品，要想开展基础架构方面的工作，企业需要顾问和开发人员。很多时候还需要第三方的集成工具。KVM(Kernel-based Virtual Machine)是一个开源的系统虚拟化模块，它需要硬件支持，如Intel VT技术或者AMD V技术，是基于硬件的完全虚拟化，完全内置于Linux。 ​ OpenStack几乎支持所有的虚拟化管理程序，不论是开源的(Xen与KVM)还是厂商的(Hyper-V与VMware)。但在以前，OpenStack是基于KVM开发的，KVM常常成为默认的虚拟机管理程序。两者都使用相同的开放源理念与开发方法。 OpenStack组件 Compute (Nova) 计算服务 Identity Service (Keystone) 认证服务 Image Service (Glance) 镜像服务 Networking (Neutron/Quantum) 网络服务 Dashboard (Horizon) 仪表板 Object Storage (Swift) 对象存储 Block Storage (Cinder) 块存储 Orchestration (Heat) 编排 Telemetry (Ceilometer) 监控 Database Service (Trove) 数据库服务 Data Processing (Sahara) 数据处理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron二层网络服务实现原理]]></title>
      <url>%2F2017%2F04%2F05%2FNeutron%E4%BA%8C%E5%B1%82%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[网络​ 网络（network）是一个隔离的二层网段，类似于物理网络世界中的虚拟 LAN (VLAN)。更具体来讲，它是为创建它的租户而保留的一个广播域，或者被显式配置为共享网段。端口和子网始终被分配给某个特定的网络。根据网络的类型，Neutron network 可以分为： ​ VLAN network（虚拟局域网） ：基于物理 VLAN 网络实现的虚拟网络。共享同一个物理网络的多个 VLAN 网络是相互隔离的，甚至可以使用重叠的 IP 地址空间。每个支持 VLAN network 的物理网络可以被视为一个分离的 VLAN trunk，它使用一组独占的 VLAN ID。有效的 VLAN ID 范围是 1 到 4094。 ​ Flat network：基于不使用 VLAN 的物理网络实现的虚拟网络。每个物理网络最多只能实现一个虚拟网络。local network（本地网络）：一个只允许在本服务器内通信的虚拟网络，不知道跨服务器的通信。主要用于单节点上测试。​ GRE network （通用路由封装网络）：一个使用 GRE 封装网络包的虚拟网络。GRE 封装的数据包基于 IP 路由表来进行路由，因此 GRE network 不和具体的物理网络绑定。​ VXLAN network（虚拟可扩展网络）：基于 VXLAN 实现的虚拟网络。同 GRE network 一样， VXLAN network 中 IP 包的路由也基于 IP 路由表，也不和具体的物理网络绑定。 关系： （1）tenant —- 1:n —– network ——- 1：n ——- subnet （一个 tenant 可以拥有多个 network，一个 network 可以包含多个 subnet） （2）network ——- 1: n ——- port —— 1:1 — subnet（一个network 可以有多个 port， 每个 port 连接一个 subnet）（若创建虚机时指定的是 net-id，那么虚机将随机地从该 network 包含的 subnet 中分配 IP） （3）VM —– 1 : n —- NIC —– 1:1 — port（一个 VM 可以有多个 NIC，每个 NIC 连接一个 port）（可以在创建虚机时指定一个或者多个 port） （4）Tenant —– 1 : n —- Router —– 1 : n —— subnet/ext-network （一个 tenant 可以拥有多个 router，每个 router 在 Neutron network 节点上使用一个 Linux network namespace，其 ID 就是 neutron router-list 得到的 router 的 ID； 一个 router 连接一个通向外网的 gateway 和多个该 tenant 的 subnet） （5）network —- 1 : 1 —- Dnamasq —– 1: n —– subnet （一个 network 有一个 Dnsmasq 进程，该进程为多个启动了 DHCP 的 subnet 服务，分配它们拥有的 IP 给虚机） Neutron 管理的实体如下： 网络： 隔离的 L2 域，可以是虚拟、逻辑或交换，同一个网络中的主机彼此 L2 可见。 子网： IP 地址块，其中每个虚拟机有一个 IP，同一个子网的主机彼此 L3 可见。 端口： 网络上虚拟、逻辑或交换端口。 Linux相关技术​ Neutron 的设计目标是实现“网络即服务”，为了达到这一目标，在设计上遵循了基于“软件定义网络”实现网络虚拟化的原则，在实现上充分利用了 Linux 系统上的各种网络相关的技术。​ 理解了 Linux 系统上的这些概念将有利于快速理解 Neutron 的原理和实现。 涉及的 Linux 网络技术bridge：网桥，Linux中用于表示一个能连接不同网络设备的虚拟设备，linux中传统实现的网桥类似一个hub设备，而ovs管理的网桥一般类似交换机。br-int：bridge-integration，综合网桥，常用于表示实现主要内部网络功能的网桥。br-ex：bridge-external，外部网桥，通常表示负责跟外部网络通信的网桥。GRE：General Routing Encapsulation，一种通过封装来实现隧道的方式。在openstack中一般是基于L3的gre，即original pkt/GRE/IP/EthernetVETH：虚拟ethernet接口，通常以pair的方式出现，一端发出的网包，会被另一端接收，可以形成两个网桥之间的通道。qvb：neutron veth, Linux Bridge-sideqvo：neutron veth, OVS-sideTAP设备：模拟一个二层的网络设备，可以接受和发送二层网包。TUN设备：模拟一个三层的网络设备，可以接受和发送三层网包。iptables：Linux 上常见的实现安全策略的防火墙软件。Vlan：虚拟 Lan，同一个物理 Lan 下用标签实现隔离，可用标号为1-4094。VXLAN：一套利用 UDP 协议作为底层传输协议的 Overlay 实现。一般认为作为 VLan 技术的延伸或替代者。namespace：用来实现隔离的一套机制，不同 namespace 中的资源之间彼此不可见。 GRE网络, Vlan网络, Vxlan网络举例GRE网络 ​ 在 VM1 中，虚拟机的网卡实际上连接到了物理机的一个 TAP 设备（即 A，常见名称如 tap-XXX）上，A 则进一步通过 VETH pair（A-B）连接到网桥 qbr-XXX 的端口 vnet0（端口 B）上，之后再通过 VETH pair（C-D）连到 br-int 网桥上。一般 C 的名字格式为 qvb-XXX，而 D的名字格式为 qvo-XXX。注意它们的名称除了前缀外，后面的 id 都是一样的，表示位于同一个虚拟机网络到物理机网络的连接上。 br-tun转发逻辑： ​ 表 10 负责学习。有一条规则，基于 learn 行动来创建反向（内部网包从 gre 端口发出去）的规则。如下所示： learn 行动并非标准的 openflow 行动，是 openvswitch 自身的扩展行动，这个行动可以根据流内容动态来修改流表内容。这条规则首先创建了一条新的流（该流对应 vm 从 br-tun 的 gre 端口发出的规则）： 其中 table=20 表示规则添加在表 20； NXM_OF_VLAN_TCI[0..11] 表示匹配包自带的vlan id； NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[] 表示 L2 目标地址需要匹配当前包的 L2 源地址； load:0-&gt;NXM_OF_VLAN_TCI[]，去掉vlan； load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[]，添加 tunnel 号为原始 tunnel 号； output:NXM_OF_IN_PORT[]，发出端口为原始包抵达的端口。向表 20 添加完规则后，最后将匹配的当前网包从端口 1（即 patch-int）发出。 举例VLAN网络： ​ 路由是L3 agent来实现，每个子网在br-int上有一个端口（qr-YYY和qr-ZZZ，已配置IP，分别是各自内部子网的网关），L3 agent绑定到上面。要访问外部的公共网络，需要通过L3 agent发出，而不是经过int-br-ex到phy-br-ex（实际上并没有网包从这个veth pair传输）。如果要使用外部可见的floating IP，L3 agent仍然需要通过iptables来进行NAT。 在多租户情况下 举例VXLAN网络： ​ 表10主要作用是学习外部（从 tunnel）进来的包，往表 20 中添加对返程包的正常转发规则，并且从 patch-int 扔给 br-int。 使用了 openvswitch 的 learn 动作。该动作能根据处理的流来动态修改其它表中的规则。 table=20 说明是修改表 20 中的规则，后面是添加的规则内容； NXM_OF_VLAN_TCI[0..11]，匹配跟当前流同样的 VLAN 头，其中 NXM 是 Nicira Extensible Match 的缩写； NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[]，包的目的 mac 跟当前流的源 mac 匹配； load:0-&gt;NXM_OF_VLAN_TCI[]，将 vlan 号改为 0； load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[]，将 tunnel 号修改为当前的 tunnel 号； output:NXM_OF_IN_PORT[]，从当前入口发出。 参考：http://www.cnblogs.com/sammyliu/p/4622563.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(4)]]></title>
      <url>%2F2017%2F03%2F31%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-4%2F</url>
      <content type="text"><![CDATA[2017年-至今98.《你一年的8760小时》-艾力 99.《牛棚杂忆》-季羡林 100.《愚人的坚持》-稻盛和夫，山中伸弥 101.《异类》-马尔柯姆-格拉德威尔 102.《人类动物园》-德斯蒙德莫里斯 103.《美学漫话》-宗白华 104.《逃不开的经济周期》-拉斯特维德 105.《明治维新六十年》-樱雪丸 106.《武士道》-新渡户稻造 107.《我所理解的生活》-韩寒 108.《呀，原来如此》-知乎 109《宋朝原来是这样》-醉罢君山 110《我看到的世界和你们不一样》-眭澔平 111《沸腾十五年》-林军 112《吾国吾民》-林语堂 113《亲密行为》-德斯蒙德莫里斯 114《人人都爱经济学》-王福重]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[经济学的经典著作]]></title>
      <url>%2F2017%2F03%2F31%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%9A%84%E7%BB%8F%E5%85%B8%E8%91%97%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[1.色诺芬：《经济论》2.托马斯·孟：《英国得自对外贸易的财富》3.托马斯·莫尔：《乌托邦》4.弗朗索瓦·魁奈：《经济表》5.威廉·配弟：《赋税论》6.亚当·斯密：《国民财富的性质和原因的研究》7.让·萨伊：《政治经济学概论》8.托马斯·马尔萨斯：《人口原理》9.大卫·李嘉图：《政治经济学及赋税原理》 10.布阿吉尔贝尔：《法国的辩护书》11.西斯蒙第：《政治经济学新原理》12.约翰·穆勒：《政治经济学原理及其在社会哲学上的若干应用》13.杜阁：《关于财富的形成和分配的考察》14.洛克：《论降低利息和提高货币价值的后果》15.魏克赛尔：《利息与价格》16.马克思：《资本论》17.康芒斯：《制度经济学》18.凡勃伦：《有闲阶级论》19.古诺：《财富理论的数学原理的研究》20.卡尔·门格尔：《国民经济学原理》21.杰文斯：《政治经济学理论》22.瓦尔拉斯：《纯粹经济学要义》23.庞巴维克：《资本实证论》24.戈森：《人类交换规律与人类行为准则的发展》25.汤普逊：《最能促进人类幸福的财富分配原理的研究》26.马歇尔：《经济学原理》27.约翰·希克斯：《价值与资本》28.李斯特：《政治经济学的国民体系》29.熊彼特：《资本主义、社会主义与民主》30.熊彼特：《经济发展理论》31.熊彼特：《经济分析史》32.凯恩斯：《就业、利息和货币通论》33.琼·罗宾逊：《不完全竞争经济学》34.萨缪尔森：《经济分析基础》35.肯尼斯·阿罗：《社会选择与个人价值》36.加尔布雷思：《经济学与公共目标》37.布坎南：《民主财政论》38.舒尔茨：《论人力资本投资》39.西蒙·库兹涅茨：《各国的经济增长》40.加里·贝克尔：《人类行为的经济分析》41.弗里德曼：《自由选择》42.弗里德曼：《价格理论》43.保罗·斯威齐：《资本主义发展论：一种解说》44.里昂惕夫：《投入产出经济学》45.罗伯特·索洛：《经济增长理论》46.泰勒尔：《产业组织理论》47.冯·哈耶克：《通向奴役之路》48.冯·哈耶克：《个人主义与经济秩序》 49.冯·米瑟斯：《自由与繁荣的国度》 50.道格拉斯·诺斯：《西方世界的兴起》51.约翰·纳什：《纳什博弈论论文集》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[经济学的100个关键词]]></title>
      <url>%2F2017%2F03%2F31%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%9A%84100%E4%B8%AA%E5%85%B3%E9%94%AE%E8%AF%8D%2F</url>
      <content type="text"><![CDATA[1.经济学（economics）：研究一个社会如何利用稀缺的资源进行有价值的生产，并把生产成果在社会成员之间进行分配的科学。2.稀缺（scarcity）：相对于人类无穷的欲望，资源总是显得不足的状态。3.效率（efficiency）：社会对资源的利用达到最佳状态，没有再改进的余地，即如果不让某个社会成员的境况变差，就不能让任何其他成员的境况变得更好。4.生产什么，如何生产，为谁生产（what，how and whom）：一个经济社会面临的基本问题，也叫资源配置，社会必须就这三个问题做出选择，以实现社会福利的最大化。5.微观经济学（microeconomics）：研究单个消费者、单个厂商、单个市场的经济学分支，其核心是价格的决定。6.宏观经济学（macroeconomics）：研究一个经济总体运行的经济学分支。7.计划经济（planned economy）：由中央计划当局决定生产什么、如何生产、为谁生产的经济。8.市场经济（market economy）：由市场特别是价格决定生产什么、如何生产、为谁生产的经济。9.亚当·斯密（Adam Smith，1723～1790年）：英国古典经济学的伟大代表，1776年出版《国民财富的性质和原因的研究》，从而创立了近代经济学体系。提出了著名的“看不见的手”的学说。他的另一部著作是1759年出版的《道德情操论》。 10.边际（marginal）：某个变量的微小变动，引起的其他变量的改变量。11.总收益（total revenue）：企业出售产品得到的全部货币。12.边际收益（marginal benifit）：某种活动的微小增加所增加的总收益。13.机会成本（opportunity cost）：一件事情的机会成本是把做这件事的资源用于其他事情，所能产出的最大价值。14.均衡（equilibrium）：本来是物理学上的概念，指物体受到大小相等方向相反的两个力的作用，而保持一种暂时不动的状态。经济学界借用这个概念，分析消费者、厂商以及宏观经济达到的最佳状态及其实现条件。15.经济人假设（economic man’s hypothesis）：每个人都是在给定约束下，追求自己利益极大化的人，是经济学最基本的假设。16.看不见的手（invisible hand）：最早由亚当·斯密在《国民财富的性质和原因的研究》中提出。他认为社会中存在着一种不同于人为秩序的“自然秩序”。看不见的手，实际上就是价格机制，在价格机制的诱导下，经济可以有效地运行，达到最佳状态，不需要政府的干预。 我:17.博弈论（game theory）：研究在当事人之间的决策互相影响的条件下，人们如何行动的一种方法。18.纳什均衡（Nash equilibrium）：博弈当事人战略的组合，其中每个人的战略都是在假定其他人战略不变的情况下的最佳战略。19.静态博弈（static game）：博弈的参加者同时做决策，或者虽然不同时，但是后行动者不知道先行动者的决策的一种博弈。20.战略（strategy）：博弈的参加者在什么条件下选择什么样的行动，以保证自身利益最大化。21.动态博弈（dynamic game）：博弈参加者的行动有先后，后行动者可以观察到先行动者的行为的一种博弈。22.需求（demand）：在其他条件不变的情况下，在给定价格下，消费者愿意并且能够购买的某种商品的数量。23.供给（supply）：在其他条件不变的情况下，在给定价格下，生产者愿意并且能够提供给市场的商品的数量。24.价格（price）：每单位商品、劳务的货币度量。25.市场（market）：买者和卖者相互作用决定价格的机制或者制度安排。26.均衡价格（equilibrium price）：需求量和供给量相等时的价格。27.效用（utility）：人们从物品的消费中得到的快乐和满足，可以用效用单位表示。28.边际效用（marginal utility）：新增加的一单位商品所增加的总效用。29.边际效用递减规律（law of diminishing marginal utility）：不断地增加对某种商品的消费，所增加的总效用越来越少。30.生产函数（production function）：在技术不变的条件下，一定量的投入与最大产出量之间关系的函数。31.边际产量（marginal product）：保持其他投入不变，单独增加某一种投入的一单位所增加的总产量。32.边际收益递减规律（law of diminishing marginal returns）：在技术和其他投入不变的条件下，单独增加某一种投入的一单位，所增加的总产量越来越少。33.企业家才能（entrepreneurship）：协调生产经营活动以及创新的能力。34.经济利润（economic profit）：总收益与总成本的差。35.正常利润（normal profit）：企业家才能的报酬，是生产成本的一部分。36.会计利润（accounting profit）：总收益减去会计成本。37.固定成本（fixed cost）：与产量无关的成本，或者说产量为零时的总成本。38.可变成本（variable cost）：随着产量变动而变动的成本，产量为零时，总可变成本是零。39.平均可变成本（average variable cost）：总可变成本除以总产量。 40.完全竞争（perfect competition）：一种市场结构，在这个市场上，存在过多的厂商，每个厂商的产量与总产量相比都是微不足道的，每个厂商都是价格的接受者，而不能影响价格。 41.垄断（monopoly）：只有一个厂商的市场结构，厂商对于价格有决定权。42.价格歧视（price discrimination）：出售同样的商品，向不同类型的买者收取不同的价格。43.消费者剩余（consumer surplus）：消费者愿意支付的价格与其实际支付的价格之差。44.自然垄断（natural monopoly）：指一个企业能以低于两个或者更多的企业生产时的成本为整个市场服务。45.垄断竞争（monopolistic competition）：一种市场结构，在其中，每个厂商生产的产品都与其他厂商有所差别，因此对消费者构成垄断；同时，每家厂商的产品差别又非常小，它们之间又存在竞争的关系。46.寡头（oligopoly）：少数几家大的厂商占据了市场的绝大部分份额。47.国内生产总值（gross domestic product，GDP）：一个国家在给定时期内，所生产的全部最终产品和劳务的市场价格的和。48.最终产品（final goods）：用于消费，不再进入下一阶段生产过程的产品。49.附加值（value added）：某一个环节上的附加值指的是售价与购进价格的差额。50.总需求（aggregate demand）：在给定时期内，在给定的价格水平下，一个经济中所有部门愿意购买的总和。51.大萧条（Great Depression）：指1929～1933年席卷整个资本主义世界的严重经济危机。52.萨伊定律（Say’s Law）：法国经济学家让·巴蒂斯特·萨伊（1767～1832）认为，供给能够创造它自己的需求，生产能够创造自己的销路，因此，不会有卖不出去的商品。萨伊定律可以概括凯恩斯之前全部经济学的精髓，即市场供求的力量可以自动达到充分就业状态，政府干预是不必要的。53.约翰·梅纳德·凯恩斯（John Maynard Keynes，1833～1946年）：英国人，1905年毕业于剑桥大学，后在英国财政部工作，1919年参加巴黎和会，写作《合约的经济后果》，获得世界性声誉。任剑桥大学经济学讲师，是20世纪以及有史以来最伟大的经济学家之一，1936年发表《就业、利息和货币通论》，创立现代宏观经济学体系，推翻了萨伊定律，主张国家干预经济。 54.财政（public finance）：政府的收支活动。55.公共物品（public goods）：每个人不管是否付费都可以消费的物品。56.税收（taxation）：政府利用强制力，无偿从居民或者企业取得的收入。57.财政政策（fiscal policy）：政府改变购买支出和转移支付规模，以及改变税收，调节总需求的手段。58.乘数效应（multiplier effect）：某些支出的变化，引起总产量数倍的变化。59.挤出效应（crowding out effect）：如果财政支出过多，企业和个人获得资金就困难了，利率就将提高，企业和个人的投资支出、消费支出就会减少，政府的支出就“挤出”了民间支出。60.货币（money）：被人们普遍接受的交易媒介或者支付手段。61.银行（bank）：从储户手里获得资金，借给需要资金的人，从中获取收益的企业。62.货币供给量（money supply）：一个经济中的货币总量。63.M1：现金和活期存款（支票存款）。64.M2：现金、活期存款和储蓄存款的和。65.中央银行（central bank）：银行的银行。66.货币政策（monetary policy）：中央银行控制货币供给量的手段。67.准备金（reserve）：商业银行吸收的存款中，按法律规定交给中央银行的部分。68.公开市场操作（open-market operation）：中央银行买进和卖出政府债券以影响货币供给量的行为。69.贴现率（discount rate）：商业银行向中央银行借款的利率。70.失业（unemployment）：年龄在16岁以上，有工作能力并且愿意接受现行工资条件，却没有被雇佣而正在寻找工作的人。71.失业率（unemployment rate）：失业人口占全部劳动力人口的百分比。72.自然失业率（natural rate of unemployment）：摩擦性失业率及结构性失业率的和。73.通货膨胀（inflation）：一般价格水平的上升，通常用CPI的变动程度来衡量。74.消费者价格指数（consumer price index，CPI）：计算方法是选取固定的“一篮子”商品，加权计算购买它们所需要的花费。 55.需求拉动型通货膨胀（demand-pull inflation）：因为总需求过大造成的通货膨胀。76.成本推动型通货膨胀（cost-push inflation）：由于成本上升造成的通货膨胀。77.惯性通货膨胀（inertial inflation）：如果大家都认为价格要上涨，并且据此调整所有合同，通货膨胀就将真的发生，并且持续下去。78.经济增长（economic growth）：一个国家潜在产出的持续增加。79.潜在产出（potential product）：一个国家最大的生产能力，可以用充分就业时的总产量衡量。80.72规则（rule 72）：用72除以一个变量的年平均增长率，就得到这个变量要翻一番所需要的年数。81.马尔萨斯的人口理论（Theory of Population of Thomas Robert Malthus）：托马斯·马尔萨斯（1766～1834），英国人，著名经济学家，以人口理论闻名于世。他认为，因为人口以几何级数增长，而生活资料以算术级数增长，所以，到一定时候，人类将面临饥饿的威胁。因此他提出要控制人口，并认为可以采取诸如战争和瘟疫等极端手段。82.人力资本（human capital）：个人通过教育和自身经历形成的可以用于生产的知识和技能。83.技术进步（technological progress）：生产工艺、过程的改进，或者新产品开发，使得在投入不变的情况下，产出仍然可以增加。84.国际贸易（international trade）：国家之间交换商品和相互提供劳务的活动，也叫世界贸易。85.绝对优势（absolute advantage）：如果一个国家生产某种产品的直接成本即会计成本比别的国家低，就说这个国家在这个产品的生产上具有绝对优势。首先由亚当·斯密在《国民财富的性质和原因的研究》中提出。86.比较优势（comparative advantage）：如果一个国家生产某种产品的机会成本比别的国家低，就说这个国家在这个产品的生产上具有比较优势。最早由英国伟大的经济学家大卫·李嘉图（David Ricardo，1772～1823）在1817年出版的《政治经济学及赋税原理》中提出。87.关税（customs，tariff）：一个国家对进出口物品征收的税。是最古老的税种之一。88.世界贸易组织（World Trade Organization，WTO）：一个独立于联合国的永久性国际组织，其前身为关税与贸易总协定（GATT），1995年1月1日正式开始运作，总部设在日内瓦。该组织的基本宗旨是通过实施非歧视、关税减让以及透明公平的贸易政策，来达到推动世界贸易自由化的目标。89.自由贸易（free trade）：不使用关税和非关税手段限制国际贸易的主张和政策。90.贸易保护主义（trade protectionism）：主张通过关税和非关税壁垒阻止外国产品进入本国市场，以保护本国产业的主张和政策。 91.关税壁垒（tariff barriers）：通过对进口产品征税阻止外国产品进入本国市场，或者对出口产品征税阻止本国产品出口。一般是指进口税。92.非关税壁垒（non-tariff barriers，NTB）：关税以外的阻止自由贸易的措施。93.配额（quota）：规定进口商品数量的做法。94.倾销（dumping）：进口产品的销售价格低于出口国的国内市场价格或低于其生产成本。95.汇率（foreign exchange rate）：一种货币与另一种货币相互交换的比率。96.外汇市场（foreign exchange market）：不同货币相互交换的场所。97.固定汇率制度（fixed exchange rates）：一个国家的货币采取盯住某一汇率水平而不变的制度。98.浮动汇率制度（floating exchange rates）：汇率由外汇市场决定，政府不规定汇率水平的制度。99.金本位制（gold standard）：一国规定其货币单位与某一固定量的黄金等价的制度。100.购买力平价理论（theory of purchasing power parity）：汇率的作用应该使不同货币在各国的购买力相等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(13)]]></title>
      <url>%2F2017%2F03%2F31%2F%E4%BD%A0%E6%87%82python%E5%90%97-13%2F</url>
      <content type="text"><![CDATA[Python垃圾回收机制​ Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。简单来说就是以引用计数为主，标记-清除和分代收集两种机制为辅 引用计数机制引用计数是啥？python里每一个东西都是对象，它们的核心就是一个结构体：PyObject 1234typedef struct_object &#123; int ob_refcnt; struct_typeobject *ob_type;&#125; PyObject; PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少 123456#define Py_INCREF(op) ((op)-&gt;ob_refcnt++) //增加计数#define Py_DECREF(op) \ //减少计数 if (--(op)-&gt;ob_refcnt != 0) \ ; \ else \ __Py_Dealloc((PyObject *)(op)) 当引用计数为0时，该对象生命就结束了。 导致引用计数+1的情况 ​ 对象被创建，例如a=23​ 对象被引用，例如b=a​ 对象被作为参数，传入到一个函数中，例如func(a)​ 对象作为一个元素，存储在容器中，例如list1=[a,a] 导致引用计数-1的情况 ​ 对象的别名被显式销毁，例如del a ​ 对象的别名被赋予新的对象，例如a=24 ​ 一个对象离开它的作用域，例如f函数执行完毕时，func函数中的局部变量 ​ 对象所在的容器被销毁，或从容器中删除对象 1234567891011121314151617181920212223242526272829303132333435import sysdef func(c): print 'in func function', sys.getrefcount(c) - 1if __name__ == '__main__': print 'init', sys.getrefcount(11) - 1 # 11初始化的引用值 a = 11 # 11被a引用 print 'after a=11', sys.getrefcount(11) - 1 b = a print 'after b=a', sys.getrefcount(11) - 1 #a被b引用 func(11) print 'after func(a)', sys.getrefcount(11) - 1 list1 = [a, 12, 14] print 'after list1=[a,12,14]', sys.getrefcount(11) - 1 a=12 print 'after a=12', sys.getrefcount(11) - 1 del a print 'after del a', sys.getrefcount(11) - 1 del b print 'after del b', sys.getrefcount(11) - 1 list1.pop(0) print 'after pop list1',sys.getrefcount(11)-1 del list1 print 'after del list1', sys.getrefcount(11) - 1#outputinit 30after a=11 31after b=a 32in func function 34after func(a) 32after list1=[a,12,14] 33after a=12 32after del a 32after del b 31after pop list1 30after del list1 30 引用计数机制的优点： 1、简单 2、实时性：一旦没有引用，内存就直接释放了。不用像其他机制等到特定时机。实时性还带来一个好处：处理回收内存的时间分摊到了平时。 引用计数机制的缺点： 1、维护引用计数消耗资源 2、循环引用 循环引用如何内存泄漏？有 del() 函数的对象间的循环引用是导致内存泄漏的主凶。但没有del()函数的对象间的循环引用是可以被垃圾回收器回收掉的。 首先我们要看一下没有内存泄漏的例子： 123456789101112131415161718192021222324252627282930313233343536373839import gcimport sysclass cycleLeak(object): def __init__(self): self._text = '#' * 10 def __del__(self): passdef make_cycle_ref(): _cycleLeak = cycleLeak() print '_cycleLeak ref count0: %d' % (sys.getrefcount(_cycleLeak)) del _cycleLeak try: print '_cycleLeak ref count1: %d' % (sys.getrefcount(_cycleLeak)) except UnboundLocalError: print '_cycleLeak is invalid !'def test_gcLeak(): gc.enable() # gc.set_debug(gc.DEBUG_LEAK) gc.set_debug(gc.DEBUG_COLLECTABLE | gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_INSTANCES | gc.DEBUG_OBJECTS) print 'begin gcleak test ....' make_cycle_ref() print 'gc begin collecting ....' _unreachable = gc.collect() print 'unreachable object num : %d ' % (_unreachable) ''' gc.garbage是一个list对象，列表项是垃圾收集器发现的不可达（即垃圾对象）、但又不能释放(不可回收)的对 象，通常gc.garbage中的对象是引用对象还中的对象。因Python不知用什么顺序来调用对象的__del__函数，导 致对象始终存活在gc.garbage中，造成内存泄露 ''' print 'garbage object num : %d' % (len(gc.garbage))if __name__ == '__main__': test_gcLeak()#outputbegin gcleak test ...._cycleLeak ref count0: 2 #对象_gcleak的引用计数为2_cycleLeak is invalid ! #因为执行了del函数，_gcleak变为了不可达的对象gc begin collecting .... #开始垃圾回收unreachable object num : 0 #本次垃圾回收发现的不可达的对象个数为0garbage object num : 0 #整个解释器中垃圾对象的个数为0 我们通过自我引用引起内存泄露，在上述程序中将 make_cycle_ref()添加如下： 123456789101112131415161718def make_cycle_ref(): _cycleLeak = cycleLeak() _cycleLeak._self=_cycleLeak #自我引用 print '_cycleLeak ref count0: %d' % (sys.getrefcount(_cycleLeak)) del _cycleLeak try: print '_cycleLeak ref count1: %d' % (sys.getrefcount(_cycleLeak)) except UnboundLocalError: print '_cycleLeak is invalid !'#outputbegin gcleak test ...._cycleLeak ref count0: 3_cycleLeak is invalid !gc begin collecting ....gc: uncollectable &lt;cycleLeak 0x7f4f50779350&gt;gc: uncollectable &lt;dict 0x7f4f5077a6e0&gt;unreachable object num : 2 #本次回收不可达的对象个数为2garbage object num : 1 #整个解释器中垃圾个数为1 我们互相引用导致内存泄漏,代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import gcimport sysclass cycleLeakA(object): def __init__(self): self._text = '#' * 10 def __del__(self): passclass cycleLeakB(object): def __init__(self): self._text = '#' * 10 def __del__(self): passdef make_cycle_ref(): _cycleLeakA = cycleLeakA() _cycleLeakB = cycleLeakB() _cycleLeakA._ref=_cycleLeakB _cycleLeakB._ref = _cycleLeakA print '_cycleLeak ref count0: _cycleLeakA %d ,_cycleLeakB %d' % (sys.getrefcount(_cycleLeakA),sys.getrefcount(_cycleLeakB)) del _cycleLeakA del _cycleLeakB try: print '_cycleLeak ref count1: _cycleLeakA %d ,_cycleLeakB %d' % (sys.getrefcount(_cycleLeakA),sys.getrefcount(_cycleLeakB)) except UnboundLocalError: print '_cycleLeak is invalid !'def test_gcLeak(): gc.enable() gc.set_debug(gc.DEBUG_COLLECTABLE | gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_INSTANCES | gc.DEBUG_OBJECTS ) print 'begin gcleak test ....' make_cycle_ref() print 'gc begin collecting ....' _unreachable = gc.collect() print 'unreachable object num : %d ' % (_unreachable) print 'garbage object num : %d' % (len(gc.garbage))if __name__ == '__main__': test_gcLeak()#outputbegin gcleak test ...._cycleLeak ref count0: _cycleLeakA 3 ,_cycleLeakB 3_cycleLeak is invalid !gc begin collecting ....unreachable object num : 4 garbage object num : 2gc: uncollectable &lt;cycleLeakA 0x7f59f3a04710&gt;gc: uncollectable &lt;cycleLeakB 0x7f59f3a04750&gt;gc: uncollectable &lt;dict 0x7f59f3a05a28&gt;gc: uncollectable &lt;dict 0x7f59f3a056e0&gt; 注意：如果我们将class cycleLeak(object)的__del__属性删除，garbage object num将会是0，为什么呢？因为如果循环引用中，两个对象都定义了__del__方法，gc模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的__del__方法，所以为了安全起见，gc模块会把对象放到gc.garbage中，但是不会销毁对象。 上述的例子使用了gc模块，我们简单的介绍一下gc模块 常用函数： gc.set_debug(flags) 设置gc的debug日志，一般设置为gc.DEBUG_LEAK ，也可以是上述事例gc.collect([generation]) 显式进行垃圾回收，可以输入参数，0代表只检查第一代的对象，1代表检查一，二代的对象，2代表检查一，二，三代的对象，如果不传参数，执行一个full collection，也就是等于传2。返回不可达（unreachable objects）对象的数目gc.get_count() 获取当前自动执行垃圾回收的计数器，返回一个长度为3的列表 解释如下： 12345678910111213import gcclass A(object): passif __name__ == '__main__': print 'gc.get_count()' ,gc.get_count() a=A() print 'gc.get_count()', gc.get_count() del a print 'gc.get_count()', gc.get_count()#outputgc.get_count() (581, 8, 0)gc.get_count() (582, 8, 0)gc.get_count() (581, 8, 0) （581，8，0）其中 581指距离上一次一代垃圾检查Python分配内存的数目减去释放内存的数目 8指距离上一次二代垃圾检查，一代垃圾检查的次数 0是指距离上一次三代垃圾检查，二代垃圾检查的次数 gc.set_threshold(threshold0[, threshold1[, threshold2]) 设置自动执行垃圾回收的频率。 解释如下： gc模快有一个自动垃圾回收的阀值，即通过gc.get_threshold函数获取到的长度为3的元组，例如(700,10,10)每一次计数器的增加，gc模块就会检查增加后的计数是否达到阀值的数目，如果是，就会执行对应的代数的垃圾检查，然后重置计数器。 例如，假设阀值是(700,10,10)： 当计数器从(699,3,0)增加到(700,3,0)，gc模块就会执行gc.collect(0),即检查一代对象的垃圾，并重置计数器为(0,4,0) 当计数器从(699,9,0)增加到(700,9,0)，gc模块就会执行gc.collect(1),即检查一、二代对象的垃圾，并重置计数器为(0,0,1) 当计数器从(699,9,9)增加到(700,9,9)，gc模块就会执行gc.collect(2),即检查一、二、三代对象的垃圾，并重置计数器为(0,0,0) 使用方法： 必须要import gc模块，并且is_enable()=True才会启动自动垃圾回收。这个机制的主要作用就是发现并处理不可达的垃圾对象。垃圾回收=垃圾检查+垃圾回收在Python中，采用分代收集的方法。把对象分为三代，一开始，对象在创建的时候，放在一代中，如果在一次一代的垃圾检查中，改对象存活下来，就会被放到二代中，同理在一次二代的垃圾检查中，该对象存活下来，就会被放到三代中。 标记-清除？标记-清除机制，顾名思义，首先标记对象（垃圾检测），然后清除垃圾（垃圾回收）。基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。 首先初始所有对象标记为白色，并确定根节点对象（这些对象是不会被删除），标记它们为黑色（表示对象有效）。将有效对象引用的对象标记为灰色（表示对象可达，但它们所引用的对象还没检查），检查完灰色对象引用的对象后，将灰色标记为黑色。重复直到不存在灰色节点为止。最后白色结点都是需要清除的对象。 这里所采用的高级机制作为引用计数的辅助机制，用于解决产生的循环引用问题。而循环引用只会出现在“内部存在可以对其他对象引用的对象”，比如：list，class等。为了要将这些回收对象组织起来，需要建立一个链表。自然，每个被收集的对象内就需要多提供一些信息，下面代码是回收对象里必然出现的。 123456789/* GC information is stored BEFORE the object structure. */typedef union _gc_head &#123; struct &#123; union _gc_head *gc_next; union _gc_head *gc_prev; Py_ssize_t gc_refs; &#125; gc; long double dummy; /* force worst-case alignment */&#125; PyGC_Head; 一个对象的实际结构如图所示： 通过PyGC_Head的指针将每个回收对象连接起来，形成了一个链表，也就是在1里提到的初始化的所有对象。 分代收集？分代技术是一种典型的以空间换时间的技术，这也正是java里的关键技术。这种思想简单点说就是：对象存在时间越长，越可能不是垃圾，应该越少去收集。分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 举例： 当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 这样的思想，可以减少标记-清除机制所带来的额外操作。分代就是将回收对象分成数个代，每个代就是一个链表（集合），代进行标记-清除的时间与代内对象存活时间成正比例关系。 12345678910111213141516171819/*** Global GC state ***/ struct gc_generation &#123; PyGC_Head head; int threshold; /* collection threshold */ int count; /* count of allocations or collections of younger generations */ &#125;;//每个代的结构 #define NUM_GENERATIONS 3//代的个数#define GEN_HEAD(n) (&amp;generations[n].head) /* linked lists of container objects */static struct gc_generation generations[NUM_GENERATIONS] = &#123; /* PyGC_Head, threshold, count */ &#123;&#123;&#123;GEN_HEAD(0), GEN_HEAD(0), 0&#125;&#125;, 700, 0&#125;, &#123;&#123;&#123;GEN_HEAD(1), GEN_HEAD(1), 0&#125;&#125;, 10, 0&#125;, &#123;&#123;&#123;GEN_HEAD(2), GEN_HEAD(2), 0&#125;&#125;, 10, 0&#125;, &#125;; PyGC_Head *_PyGC_generation0 = GEN_HEAD(0); 从上面代码可以看出python里一共有三代，每个代的threshold值表示该代最多容纳对象的个数。默认情况下，当0代超过700,或1，2代超过10，垃圾回收机制将触发。0代触发将清理所有三代，1代触发会清理1,2代，2代触发后只会清理自己。 整个过程包括链表建立，确定根节点，垃圾标记，垃圾回收。 链表建立0代触发将清理所有三代，1代触发会清理1,2代，2代触发后只会清理自己。在清理0代时，会将三个链表（代）链接起来，清理1代的时，会链接1,2两代。在后面三步，都是针对的这个建立之后的链表。 确定根节点如下图的例子，ist1与list2循环引用，list3与list4循环引用，a是一个外部引用。 对于这样一个链表，我们如何得出根节点呢。python里是在引用计数的基础上又提出一个有效引用计数的概念。顾名思义，有效引用计数就是去除循环引用后的计数。下面是计算有效引用计数的相关代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* Set all gc_refs = ob_refcnt. After this, gc_refs is &gt; 0 for all objects * in containers, and is GC_REACHABLE for all tracked gc objects not in * containers. */static voidupdate_refs(PyGC_Head *containers)&#123; PyGC_Head *gc = containers-&gt;gc.gc_next; for (; gc != containers; gc = gc-&gt;gc.gc_next) &#123; assert(gc-&gt;gc.gc_refs == GC_REACHABLE); gc-&gt;gc.gc_refs = Py_REFCNT(FROM_GC(gc)); assert(gc-&gt;gc.gc_refs != 0); &#125;&#125;/* A traversal callback for subtract_refs. */static intvisit_decref(PyObject *op, void *data)&#123; assert(op != NULL); if (PyObject_IS_GC(op)) &#123; PyGC_Head *gc = AS_GC(op); /* We're only interested in gc_refs for objects in the * generation being collected, which can be recognized * because only they have positive gc_refs. */ assert(gc-&gt;gc.gc_refs != 0); /* else refcount was too small */ if (gc-&gt;gc.gc_refs &gt; 0) gc-&gt;gc.gc_refs--; &#125; return 0;&#125;/* Subtract internal references from gc_refs. After this, gc_refs is &gt;= 0 * for all objects in containers, and is GC_REACHABLE for all tracked gc * objects not in containers. The ones with gc_refs &gt; 0 are directly * reachable from outside containers, and so can't be collected. */static voidsubtract_refs(PyGC_Head *containers)&#123; traverseproc traverse; PyGC_Head *gc = containers-&gt;gc.gc_next; for (; gc != containers; gc=gc-&gt;gc.gc_next) &#123; traverse = Py_TYPE(FROM_GC(gc))-&gt;tp_traverse; (void) traverse(FROM_GC(gc), (visitproc)visit_decref, NULL); &#125;&#125; update_refs函数里建立了一个引用的副本。 visit_decref函数对引用的副本减1，subtract_refs函数里traverse的作用是遍历对象里的每一个引用，执行visit_decref操作。 最后，链表内引用计数副本非0的对象，就是根节点了。 垃圾标记 接下来，python建立两条链表，一条存放根节点，以及根节点的引用对象。另外一条存放unreachable对象。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/* A traversal callback for move_unreachable. */static intvisit_reachable(PyObject *op, PyGC_Head *reachable)&#123; if (PyObject_IS_GC(op)) &#123; PyGC_Head *gc = AS_GC(op); const Py_ssize_t gc_refs = gc-&gt;gc.gc_refs; if (gc_refs == 0) &#123; /* This is in move_unreachable's 'young' list, but * the traversal hasn't yet gotten to it. All * we need to do is tell move_unreachable that it's * reachable. */ gc-&gt;gc.gc_refs = 1; &#125; else if (gc_refs == GC_TENTATIVELY_UNREACHABLE) &#123; /* This had gc_refs = 0 when move_unreachable got * to it, but turns out it's reachable after all. * Move it back to move_unreachable's 'young' list, * and move_unreachable will eventually get to it * again. */ gc_list_move(gc, reachable); gc-&gt;gc.gc_refs = 1; &#125; /* Else there's nothing to do. * If gc_refs &gt; 0, it must be in move_unreachable's 'young' * list, and move_unreachable will eventually get to it. * If gc_refs == GC_REACHABLE, it's either in some other * generation so we don't care about it, or move_unreachable * already dealt with it. * If gc_refs == GC_UNTRACKED, it must be ignored. */ else &#123; assert(gc_refs &gt; 0 || gc_refs == GC_REACHABLE || gc_refs == GC_UNTRACKED); &#125; &#125; return 0;&#125;/* Move the unreachable objects from young to unreachable. After this, * all objects in young have gc_refs = GC_REACHABLE, and all objects in * unreachable have gc_refs = GC_TENTATIVELY_UNREACHABLE. All tracked * gc objects not in young or unreachable still have gc_refs = GC_REACHABLE. * All objects in young after this are directly or indirectly reachable * from outside the original young; and all objects in unreachable are * not. */static voidmove_unreachable(PyGC_Head *young, PyGC_Head *unreachable)&#123; PyGC_Head *gc = young-&gt;gc.gc_next; /* Invariants: all objects "to the left" of us in young have gc_refs * = GC_REACHABLE, and are indeed reachable (directly or indirectly) * from outside the young list as it was at entry. All other objects * from the original young "to the left" of us are in unreachable now, * and have gc_refs = GC_TENTATIVELY_UNREACHABLE. All objects to the * left of us in 'young' now have been scanned, and no objects here * or to the right have been scanned yet. */ while (gc != young) &#123; PyGC_Head *next; if (gc-&gt;gc.gc_refs) &#123; /* gc is definitely reachable from outside the * original 'young'. Mark it as such, and traverse * its pointers to find any other objects that may * be directly reachable from it. Note that the * call to tp_traverse may append objects to young, * so we have to wait until it returns to determine * the next object to visit. */ PyObject *op = FROM_GC(gc); traverseproc traverse = Py_TYPE(op)-&gt;tp_traverse; assert(gc-&gt;gc.gc_refs &gt; 0); gc-&gt;gc.gc_refs = GC_REACHABLE; (void) traverse(op, (visitproc)visit_reachable, (void *)young); next = gc-&gt;gc.gc_next; &#125; else &#123; /* This *may* be unreachable. To make progress, * assume it is. gc isn't directly reachable from * any object we've already traversed, but may be * reachable from an object we haven't gotten to yet. * visit_reachable will eventually move gc back into * young if that's so, and we'll see it again. */ next = gc-&gt;gc.gc_next; gc_list_move(gc, unreachable); gc-&gt;gc.gc_refs = GC_TENTATIVELY_UNREACHABLE; &#125; gc = next; &#125;&#125; 标记之后，链表如下图： 垃圾回收回收的过程，就是销毁不可达链表内对象。下面代码就是list的清除方法： 12345678910111213141516171819202122232425/* Methods */static voidlist_dealloc(PyListObject *op)&#123; Py_ssize_t i; PyObject_GC_UnTrack(op); Py_TRASHCAN_SAFE_BEGIN(op) if (op-&gt;ob_item != NULL) &#123; /* Do it backwards, for Christian Tismer. There's a simple test case where somehow this reduces thrashing when a *very* large list is created and immediately deleted. */ i = Py_SIZE(op); while (--i &gt;= 0) &#123; Py_XDECREF(op-&gt;ob_item[i]); &#125; PyMem_FREE(op-&gt;ob_item); &#125; if (numfree &lt; PyList_MAXFREELIST &amp;&amp; PyList_CheckExact(op)) free_list[numfree++] = op; else Py_TYPE(op)-&gt;tp_free((PyObject *)op); Py_TRASHCAN_SAFE_END(op)&#125; 参考：http://www.cnblogs.com/hackerl/p/5901553.html http://www.jianshu.com/p/1e375fb40506 http://www.cnblogs.com/Xjng/p/5128269.html http://www.cnblogs.com/kaituorensheng/p/4449457.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(12)]]></title>
      <url>%2F2017%2F03%2F31%2F%E4%BD%A0%E6%87%82python%E5%90%97-12%2F</url>
      <content type="text"><![CDATA[python的拷贝1234567891011121314151617import copyif __name__ == '__main__': a=[1,2,3,[4,5,6]] b=a c=copy.copy(a) #浅拷贝 d=copy.deepcopy(a) #深拷贝 a.append(7) a[3].append(8) print 'a', a print 'b', b print 'c', c print 'd', d#outputa [1, 2, 3, [4, 5, 6, 8], 7]b [1, 2, 3, [4, 5, 6, 8], 7]c [1, 2, 3, [4, 5, 6, 8]]d [1, 2, 3, [4, 5, 6]]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(11)]]></title>
      <url>%2F2017%2F03%2F30%2F%E4%BD%A0%E6%87%82python%E5%90%97-11%2F</url>
      <content type="text"><![CDATA[lambda函数lambda的使用大量简化了代码，使代码简练清晰; lambda函数也叫匿名函数，即，函数没有具体的名称,而用def创建的方法是有名称的; 1234567891011121314def add_action(x): return x+100if __name__ == '__main__': list=[1,2,3,4] print map(add_action,list)#output[101, 102, 103, 104]#等价于if __name__ == '__main__': print map(lambda x : x+100,[1,2,3,4])#output[101, 102, 103, 104] lambda高效操作列表filter(bool_func,seq)：此函数的功能相当于过滤器。调用一个布尔函数bool_func来迭代遍历每个seq中的元素；返回一个使bool_seq返回值为true的元素的序列。 12345678910filter(lambda x : x%2 == 0,[1,2,3,4,5])#output[2,4]#filter的实现如下：def filter(bool_func,seq): filtered_seq = [] for eachItem in seq: if bool_func(eachItem): filtered_seq.append(eachItem) return filtered_seq map(func,seq1[,seq2…])：将函数func作用于给定序列的每个元素，并用一个列表来提供返回值；如果func为None，func表现为身份函数，返回一个含有每个序列中元素集合的n个元组的列表。 123456789map(lambda x : x+100,[1,2,3,4])#output[101,102,103,104]#map的实现如下：def map(func,seq): mapped_seq = [] for eachItem in seq: mapped_seq.append(func(eachItem)) return mapped_seq reduce(func,seq[,init])：func为二元函数，将func作用于seq序列的元素，每次携带一对（先前的结果以及下一个序列的元素），连续的将现有的结果和下一个值作用在获得的随后的结果上，最后减少我们的序列为一个单一的返回值：如果初始值init给定，第一个比较会是init和第一个序列元素而不是序列的头两个元素。 1234567891011121314reduce(lambda x,y : x + y,[1,2,3,4],initial=10) reduce(lambda x,y : x + y,[1,2,3,4],10) #等价#output20#reduce的实现如下：def reduce(bin_func,seq,initial=None): lseq = list(seq) if initial is None: res = lseq.pop(0) else: res = initial for eachItem in lseq: res = bin_func(res,eachItem) return res 参考：http://blog.csdn.net/prince2270/article/details/4681299]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(10)]]></title>
      <url>%2F2017%2F03%2F30%2F%E4%BD%A0%E6%87%82python%E5%90%97-10%2F</url>
      <content type="text"><![CDATA[Python的闭包和装饰器“learning about descriptors creates a deeper understanding of how python works and an appreciation for the elegance of its design”。 ​ 在python中，一般存在以下几个变量类型，local：函数内部作用域；enclosing：函数内部与内嵌函数之间；global：全局作用域；build-in：内置作用域。解释器在遇到变量的时候，会按照如下的顺序进行查找：L &gt; E &gt; G &gt; B，简称LEGB。 LEGB的理解？我们看一下如下代码： 123456789101112131415161718192021222324252627global valpassline = 60def func(val): print "0x%x" % id(val) #val对于func函数是local变量，对于in_func是enclosing变量 passline = 90 #我们看到结果是fail，说明passline最终取值是90 if val &gt;= passline: print "pass" else: print "fail" def in_func(): print 'val',val return in_funcdef Max(val1, val2): # max is a built-in fun return max(val1, val2) if __name__ == '__main__': fff = func(89) fff() print fff.__closure__ print Max(90, 100)#output0x10d38a8failval 89(&lt;cell at 0x7fa84c2750f8: int object at 0x10d38a8&gt;,)100 ​ 在python中，函数是一个对象（可以通过type函数查看），在内存中占用空间；函数执行完成之后内部的变量会被解释器回收，但是如果某变量被返回，则不会回收，因为引用计数器的值不为0；既然函数也是一个对象，他也拥有自己的属性；对于python函数来说，返回的不一定是变量，也可以是函数。我们在func函数中又定义了一个函数in_func，它目的是打印输出变量val，可是在输出过程查找变量的时候发现本地没有，于是它就会去func函数里面找，并且找到了val，val就是我们所说的对于in_func是enclosing变量。 ​ 分析代码执行的过程，我们发现func函数返回了in_func函数给了fff，但是没有打印出val，也就是没有返回变量，意味着在调用func完成之后val变量应该已经被解释器回收，但是在执行了 fff() 函数之后却仍然输出了val的值89，为什么呢？其原因就是：如果引用了enclosing作用域变量的话，会将变量添加到函数属性中，当再次查找变量时，不是去代码中查找，而是去函数属性中查找。因为上述结果我们看到fff()函数的__closure__属性拥有一个变量，这个变量的ID和func函数中val变量的ID一样0x10d38a8。 上面的代码是用来判断学生的成绩是否及格，即在百分制中60分及格，如果现在需要添加新的功能，即150分制中90分作为及格线，如何完成代码呢？最简单的就是我们创建两个函数，分别为func_100和func_150来完成判断，判断逻辑完全一样，代码如下： 12345678910111213141516171819def func_150(val): passline = 90 if val &gt;= passline: print "pass" else: print "fail"def func_100(val): passline = 60 if val &gt;= passline: print "pass" else: print "fail"if __name__ == '__main__': func_100(89) func_150(89)#outputpassfail 使用闭包()实现如下,可见闭包就是内部函数中对enclosing作用域的变量进行引用。 12345678910111213141516171819202122232425262728def set_passline(passline): print '0x%x' % id(passline) def cmp(val): if val &gt;= passline: print "pass" else: print "fail" return cmpif __name__ == '__main__': f_100 = set_passline(60) print type(f_100) print f_100.__closure__ f_100(89) print "****************" f_150 = set_passline(90) print type(f_150) print f_150.__closure__ f_150(89)#output0x24a9398&lt;type 'function'&gt;(&lt;cell at 0x7fa5730a30f8: int object at 0x24a9398&gt;,)pass****************0x24a9890&lt;type 'function'&gt;(&lt;cell at 0x7fa5730a3130: int object at 0x24a9890&gt;,)fail 什么是装饰器？“装饰器的功能是将被装饰的函数当作参数传递给与装饰器对应的函数（名称相同的函数），并返回包装后的被装饰的函数” 简而言之：@a 就是将 b 传递给 a()，并返回新的 b = a(b) 装饰器是闭包的一种应用？​ 闭包：在计算机科学中，闭包（Closure）是词法闭包（Lexical Closure）的简称，是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 ​ 上面提到了两个关键的地方： 自由变量 和 函数。望文知意，可以形象的把它理解为一个封闭的包裹，这个包裹就是一个函数，当然还有函数内部对应的逻辑，包裹里面的东西就是自由变量，自由变量可以在随着包裹到处游荡。当然还得有个前提，这个包裹是被创建出来的。 ​ 在通过Python的语言介绍一下，一个闭包就是你调用了一个函数A，这个函数A返回了一个函数B给你。这个返回的函数B就叫做闭包。你在调用函数A的时候传递的参数就是自由变量。 我们再来看装饰器发现其本身就是闭包的一种应用。 1234567891011121314151617def make_bold(fn): def wrapped(): return '&lt;b&gt;' + fn() + '&lt;b&gt;' return wrappeddef make_italic(fn): def wrapped(): return '&lt;i&gt;' + fn() + '&lt;i&gt;' return wrapped@make_italic # hello=make_italic(make_bold(hello))@make_bold # hello=make_bold (hello)def hello(): return 'hello,python'if __name__ == '__main__': print hello()#output&lt;i&gt;&lt;b&gt;hello,python&lt;b&gt;&lt;i&gt; ​ 闭包的最大特点是可以将父函数的变量与内部函数绑定，并返回绑定变量后的函数（也即闭包），此时即便生成闭包的环境（父函数）已经释放，闭包仍然存在，这个过程很像类（父函数）生成实例（闭包），不同的是父函数只在调用时执行，执行完毕后其环境就会释放，而类则在文件执行时创建，一般程序执行完毕后作用域才释放，因此对一些需要重用的功能且不足以定义为类的行为，使用闭包会比使用类占用更少的资源，且更轻巧灵活，现举一例：假设我们仅仅想打印出各类动物的叫声，分别以类和闭包来实现： 123456789101112131415161718class Animal(): def __init__(self,animal): self.animal=animal def sound(self,voice): print self.animal , ':',voicedef Voice(animal): def sound(voice): print animal , ':' ,voice return soundif __name__ == '__main__': dog=Animal('dog') dog.sound('wangwang') cat=Voice('cat') cat('miaomiao')#outputdog : wangwangcat : miaomiao ​ 可以看到输出结果是完全一样的，但显然类的实现相对繁琐，且这里只是想输出一下动物的叫声，定义一个 Animal 类未免小题大做，而且 voice 函数在执行完毕后，其作用域就已经释放，但 Animal 类及其实例 dog 的相应属性却一直贮存在内存中。 参考：http://www.jb51.net/article/63331.htm http://www.cnblogs.com/cotyb/p/5243252.html https://segmentfault.com/a/1190000004461404]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(3)]]></title>
      <url>%2F2017%2F03%2F27%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-3%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： 网络的工作原理 实现 IP 编址方案和 IP 服务，以满足中型企业分支机构网络的网络需求 DoD 模型​ DoD 模型的进程/应用层包含大量的协议，以集成分布在 OSI 上三层(应用层、表示层和会话层)的各种活动和职责 。 ​ 主机到主机层的功能与 OSI 模型的传输层相同，定义了用于为应用程序提供传输服务的协议，它负责解决的问题包括进行可靠的端到端通信和确保正确地传输数据，还对分组进行排序，并确保数据的完整性。 ​ 因特网层对应 OSI 模型的网络层，指定了与通过整个网络对分组进行逻辑传输相关的协议。它负责对主机进行编址一一给它们分配 IP (因特网协议)地址，还在多个网络之间路由分组。 ​ DoD 模型的最底端是网络接入层，它在主机和网络之间交换数据。网络接入层对应 OSI 模型的数据链路层和物理层，它负责硬件编址，并定义了用于实际传输数据的协议。 DoD模型中的协议 进程/应用层协议包括如下协议和应用程序： Telnet ​ 它让远程客户端机器( Telnet 客户端)的用户能够访问另一台机器( Telnet 服务器)的资源。 要建立 Telnet会话，用户首先运行 Telnet 客户端软件，然后登录 Telnet 服务器 。 FTP （File Transfer Protocol ，文件传输协议 ） ​ 让你能够传输文件，这可在任何两台使用它的机器之间进行。然而， FTP 不仅仅是协议，还是程序。作为协议， FTP 供应用程序使用;作为程序， FTP 供用户手工执行与文件相关的任务。FTP 让你能够访问目录和文件以及执行某些类型的目录操作，如将其移到其他目录中。 TFTP （Trivial File Transfer Protocol ，简单文件传输协议 ） ​ 是 FTP 的简化版，但如果你知道自己要什么以及到哪里去寻找，也可使用它。另外，它使用起来非常简单，速度也很快。然而，它提供的功能没有 FTP 丰富。 TFTP 没有提供目录浏览功能，除发送和接收文件外什么也不能做。 NFS （NetworkFile System ，网络文件系统 ） ​ 是一种致力于文件共享的协议，让两种不同的文件系统能够互操作。其工作原理大致如下:假设 NFS 服务器端软件运行在 Windows 服务器上，而 NFS 客户端软件运行在 Unix 主机上， NFS让 Windows服务器的部分 RAM 看起来像存储的是 Unix 文件，可被 Unix 用户使用。虽然 Windows 文件系统和 Unix 文件系统不同一一它们在是否区分大小写、文件名长度、安全性等方面不同，但 Unix 用户和 Windows 用户可像通常那样访问相同的文件，就像文件位于他们通常使用的文件系统中一样。 SMTP （SimpleMail Transfer Protocol，简单邮件传输协议 ） ​ 解决了无处不在的邮件收发需求，它使用假脱机(排队)的方式传递邮件。邮件到达目的地后，将被存储到设备(通常是磁盘)中。目标端的服务器软件定期检查队列，看其中是否有邮件。发现邮件后，它将把它们投递给收件人。 SMTP用于发送电子邮件，而 POP3 或 IMAP 用于接收邮件。 POP （Post Office Protocol ，邮局协议 ） ​ 提供了一种对到来邮件进行存储的机制，其最新版本为POP3 。 这种协议的工作原理如下:客户端设备连接到POP3 服务器后，可下载发送给它的邮件。它不允许选择性地下载邮件，但邮件下载后，客户端/服务器交互就结束了，用户可在本地随意删除和操作邮件。 MAP4 （Internet Message Access Proωcol，因特网消息访问协议 ） ​ 让你能够控制邮件的下载方式，因此使用它可获得亟需的安全性。它让你能够查看邮件头或下载邮件的一部分一一你可以咬住鱼饵，而不是将其整个吞下，进而被藏在鱼饵中的鱼钩钩住。使用 IMAP 时，你可选择将邮件以层次方式存储在电子邮件服务器中，并链接到文档和用户组。lMAP 甚至提供了搜索命令，让你能够根据主题、邮件头或内容搜索邮件。可以想见，它提供了一些身份验证功能一一实际上它支持 MIT 开发的 Kerberos 身份验证方案。 lMAP4 是最新的版本。 TLS （Transport Layer Security，传输层安全 ） ​ 及其前身 SSL ( Secure Sockets Layer，安全套接字层)都是加密协议，非常适合用于确保在线数据传输的安全，如 Web 浏览、即时通信、因特阿传真等。 SIP （VoIP，Session lnitiation Protocol，会话发起协议 ） ​ 是一种非常流行的信令胁议，用于建立和拆除多媒体通信会话，其应用非常广泛，可用于因特网上的语音和视频呼叫、视频会议、流媒体分发、即时通信、状态信息( presence information )、在线游戏等。 RTP （Real-time Transport，实时传输协议） ​ 是一种分组格式标准，用于通过因特网传输 语音和视频。 虽然它最初被设计为一种组播协议，但现在也被用于单播应用程序中。它常被用于流式媒体、视频会议和一键通( push to talk )系统，这使其成了 VoIP (Voice over IP，四语音)行业的事实标准。 LDP（Line Printer Daemon ，行式打印机守护进程） ​ 协议设计用于共享打印机。 LPD 和 LPR (Line Printer ，行式打印机)程序相互协作，使得能够将打印作业排队并使用 TCPIIP 将其发送给网络打印机 。 XWindow ​ XWindow 是为客户端/服务器操作设计的 ， 是一种编写基于 GUI (Graphical User Interface ，图形用户界面)的客户端/服务器应用程序的协议。其基本思想是，让运行在一台计算机上的客户端程序能够通过窗口服务器显示另一台计算机的内容。 SNMP ​ SNMP (Simple Network Management Protocol ，简单网络管理协议)收集并操作有价值的网络信息。它运行在管理工作站上，定期或随机地轮询网络中的设备，要求它们暴露特定的信息，以收集数据。在一切正常的情况下， SNMP将收到基线 (baseline) 信息 ， 即描述健康网络运行特征的报告。该协议还可充当网络的看门狗，将任何突发事件迅速告知管理员 。 SSH ​ 安全外壳 (SSH) 协议通过标准 TCPIIP 连接建立安全的 Telnet会话，用于执行如下操作:登录系统、在远程系统中运行程序以及在系统间传输文件等。它在执行这些操作时都使用健壮的加密连接。你可将其视为用于替代 rsh 、 rlogin 甚至 Telnet 的新一代协议。 HTTP​ 所有出色的网站都会包含图像、文本、链接等，这一切都是拜 HTTP ( Hypertext Transfer Protocol ,超文本传输协议)所赐。 它用于管理 Web 浏览器和 Web 服务器之间的通信，在你单击链接时打开相应的资源，而不管该资源实际位于何地。 HTTPS​ HTTPS(Hyp巳rtext Transfer Protoco1 Secure ，安全超文本传输协议)使用 SSL ( Secure Socket Layer ,安全套接字层)，有时也称为 SHTTP 或 S-HTTP( 这是一个 HTTP 扩展，不使用 SSL )，但这无关紧要。顾名思义，它是安全版盯TP ，提供了一系列安全工具，可确保 Web 浏览器和 Web 服务器之间的通信安全。当你在网上预订或购物时，浏览器需要使用它来填写表格、签名、验证和加密 HTTP 消息。 NTP​ NTP (Network Time Protoco1 ，网络时间协议)用于将计算机时钟与标准时间源(通常是原子钟)同步，由特拉华大学的 DavidMills 教授开发 。 NTP 将设备同步，确保给定网络中所有计算机的时间一致。这虽然听起来非常简单，但却非常重要，因为当今的很多交易都需要指出时间和日期。想想你的数据库吧，如果服务器不与相连的计算机同步，哪怕只相差几秒，也会带来严重的混乱(甚至崩溃)。如果某台机器在凌晨 1:50 发起交易，而服务器将交易时间记录为 1:45 ，交易将无法完成。 NNTP​ NNTP (Network News TransferProtoco1 ，网络新闻传输协议)用于访问 Usenet新闻服务器，这种服务器存储了大量称为新闻组的留言板。你可能知道，这些新闻组可以是任何有特定兴趣的人群。例如，如果你是某款经典车型的发烧友或 WWII 飞机爱好者很可能有大量基于这些兴趣爱好的新闻组供你加入。 NNTP 是在RFC977 中定义的。鉴于新闻阅读器程序的配置非常复杂，我们通常依靠很多网站(甚至搜索引擎)来访问各种资源。 SCP​ FTP 很好，它易于使用，是一种用户友好型文件传输方式一一前提是你不需要安全地传输这些文件。这是因为使用 FTP 传输数据时，将随文件请求以明文方式发送用户名和密码，根本没有加密，任何人都能看到。这就像绝境中的孤注一掷，你只是将信息发送出去，并析祷信息不要被坏人拦截。在这样的场合， SCP ( Secure Copy Protoco1 ，安全复制协议)可提供帮助，它通过 SSH 保护你金贵的文件。它首先在发送主机和接收主机之间建立一条安全的加密连接，并一直保持这种状态，直到文件传输完毕。有了 SCP ，你孤注一掷抛出的球将只能被目标接收方获得!然而，在当今的网络中，更健壮的 SFTP 比 SCP 更常用。 LDAP​ 如果管理的网络规模适当，你很可能会在某个地方存储目录，记录所有的网络资源，如设备和用户。但如何访问这些目录呢?通过 LDAP (Lightweight Directory Access Protocol ，轻量级目录访问协议)。该协议对如何访问目录进行了标准化，其第 l 版和第 2 版分别是在RFC 1487 和RFC 1777 中定义的。这两个版本存在一些缺陷，为解决这些问题，人们开发了第 3 版 LDAP (当前最常用的版本)，这是在RFC3377 中定义的。 IGMP （Internet Group Management Protocol ，因特网组管理协议）​ IGMP是一种用于管理 IP 组播会话的TCPIIP 协议，它这样完成其职责:通过网络发送唯一的 IGMP 消息，以揭示组播组信息，并找出主机所属的组播组。 IP 网络中的主机也使用 IGMP 消息来加入和退出组播组。 IGMP 消息非常方便用于跟踪组成员关系以及激活组播流。 LPR​ 在纯粹的 TCP/IP 环境中打印时，人们通常结合使用 LPR (行式打印机)和 LPD (Line Printer Daemon ，行式打印机守护进程)来完成打印作业。 LPD 安装在所有打印设备上，负责处理打印机和打印作业。 LPR 运行于客户端(发送主机)，用于将数据从主机发送到网络打印资掘，让你能够得到打印输出。 DNS （ Domain Name Service，域名服务） ​ 解析主机名，DNS 用于解析 FQDN (Fully Qualified Domain Name ，全限定域名)，FQDN 是一种层次结构，可根据域名标识符查找系统。 DHCP/BootP （Dynamic Host Configuration Protocol，动态主机配置协议 ） ​ 给主机分配 IP 地址，让管理工作更轻松，非常适合用于各种规模的网络。 DHCP 与 BootP (Bootstrap Protocol ，自举协议)的差别在于， BootP 给主机分配地址，但必须手工将主机的硬件地址输入到 BootP表中。你可将 DHCP 视为动态的 BootP。但别忘了， BootP也可用于发送操作系统，让主机使用它启动，而 DHCP 没有这样的功能。DHCP 是无连接的，这意味着它在传输层使用 UDP 。DHCP 服务器和客户端之间的交互如下： DHCP 客户端广播一条 DHCP 发现消息，旨在寻找 DHCP 服务器(端口 67 )； 收到 DHCP 发现消息的 DHCP 服务器向主机发回一条单播 DHCP 提议消息； 客户端向服务器广播一条 DHCP 请求消息，请求提议的 IP 地址和其他信息； 服务器以单播方式发回一条 DHCP 确认消息，完成交互。 APIPA （Automatic Private IP Addressing ，自动私有 IP编址 ） ​ 客户端可在 DHCP 服务器不可用时自动给自己配置 IP 地址和子网掩码(主机用来通信的基本 IP 信息 )。APIPA 使用的Ip 地址范围为169.254.0.1-169.254.255.254 ，客户端还会给自己配置默认的 B 类子网掩码一255.255.0.0 。 主机到主机层协议TCP （Transmission Control Protocol，传输控制协议 ） ​ 接收来自应用程序的大型数据块，并将其划分成数据段。它给每个数据段编号，让接收主机的 TCP 技能够按应用程序希望的顺序排列数据段。发送数据段后，发送主机的 TCP 等待来自接收端 TCP 的确认，并重传未得到确认的数据段。 TCP 数据段的格式 TCP 报头长 20B (在包含选项时为 24B)，你必须理解 TCP 数据段中的每个字段。 源端口 发送主机的应用程序的端口号 目标端口 目标主机的应用程序的端口号 序列号 一个编号， TCP 用来将数据按正确的顺序重新排列(称为排序)、 重传丢失或受损的数据。 确认号 TCP 期待接下来收到的数据段。 报头长度 TCP 报头的长度，以 32 位字为单位。它指出了数据的开始位置， TCP 报头的长度为 32 位的整数倍，即使包含选项时亦如此。 保留 总是设置为零。 编码位/标志 用于建立和终止会话的控制功能。 窗口大小 发送方愿意接受的窗口大 。 校验和 CRC (Cyclic Redundancy Check ，循环冗余校验) 由于 TCP 不信任低层，因此检查所有数据。 CRC 检查报头和数据字段。 紧急 仅当设置了编码位中的紧急指针字段时，该字段才有效。如果设置了紧急指针，该字段表示非紧急数据的开头位置相对于当前序列号的偏移量，单位为字节。 选项 长度为 0 或 32 位的整数倍 也就是说，没有选项时，长度为 0。然而，如果包含选项时导致该字段的长度不是 32 位的整数倍，必须填充零，以确保该字段的长度为 32 位的整数倍。 数据 传递给传输层的 TCP 协议的信息，包括上层报头。 UDP ​ 在有些情况下，开发人员选择 UDP 而不是 TCP 是绝对明智的，例如当进程/应用层已确保了可靠性时。 NFS (Network File System，网络文件系统)处理了自己的可靠性问题，这使得使用 TCP 既不现实也多余。但归根结底，使用 UDP 还是 TCP 取决于应用程序开发人员，而不是想更快地传输数据的用户。 ​ UDP 不对数据段排序，也不关心数据段到达目的地的顺序。 ​ UDP 不建立虚电路，也不在发送信息前与接收方联系。 UDP 数据段的格式 : 源端口号 发送主机的应用程序的端口号。 目标端口号 目标主机上被请求的应用程序的端口号。 长度 UDP 报头和 UDP 数据的总长度。 校验和 UDP 报头和 UDP 数据的校验和。 数据 上层数据。 对比总结： 端口 源主机从范围 1024-65535 中选择一个源端口 ，目的主机的端口一般是知名端口。 数据链路层和网络层协议分别使用硬件地址和逻辑地址标识发送主机，但 TCP 和上层协议不这样做，它们使用端口号。 因特网层协议​ 在 DoD 模型中，因特网层的作用有两个:路由选择以及提供单个到上层的网络接口。在网络中，并非条条道路通罗马，而是条条道路通 IP ，因特网层以及上层的所有协议都使用 IP 。接下来将介绍因特网层协议: 因特网协议 (IP) 因特网控制消息协议 (ICMP ) 地址解析协议 (ARP) 逆向地址解析协议 (RARP) 代理 ARP 免费 ARP IP ( Internet Protocol ，因特网协议 ) ​ 该层的其他协议都只是为它提供支持。IP 掌控全局，可以说”一切尽收它眼底”，从这种意义上说，它了解所有互联的网络。它之所以能够这样，是因为网络中的所有机器都有一个软件(逻辑)地址，这种地址称为 IP地址。 ​ IP 查看每个分组的地址，然后使用路由选择表判断接下来应将分组发送到哪里，从而选择最佳路径。在 DoD 模型底部的网络接入层协议不像 IP 那样胸怀整个网络，它们只处理物理链路(本地网络)。 ​ 要标识网络中的设备，需要回答两个问题:设备位于哪个网络中?它在该网络中的 ID 是多少?对于第一个问题，答案是软件(逻辑)地址(正确的街道); 对于第二个问题，答案是硬件地址(正确的邮箱)。网络中的所有主机都有一个逻辑 ID，称为 IP 地址，它属于软件(逻辑)地址，包含宝贵的编码信息，极大地简化了路由选择这种复杂的任务。 ​ 网络中的所有主机都有一个逻辑 ID，称为 IP 地址，它属于软件(逻辑)地址，包含宝贵的编码信息，极大地简化了路由选择这种复杂的任务。IP 接收来自主机到主机层的数据段，并在必要时将其划分成数据报(分组)。在接收端， IP 将数据报重组成数据段。每个数据报都包含发送方和接收方的 IP 地址，路由器(第 3 层设备)收到数据报后，将根据分组的目标 IP 地址做出路由选择决策。 IP 报头 如下： 版本 IP 版本号。 报头长度报头的长度 单位为 32 位字。 优先级和服务类型 服务类型指出应如何处理数据报，前 3 位为优先级位，当前称为区分服务位。总长度整个分组的长度 包括报头和数据。 标识 唯一的 IP分组值，用于区分不同的数据报。 标志 指出是否进行了分段。 分段偏移 在分组太大，无法放入一个帧中时，提供了分段和重组功能。它还使得因特网上可有不同的 MTU (Maximum Transmission Unit，最大传输单元)。 存活时间 生成分组时给它指定的存活时间。如果分组到达目的地之前 TTL就已到期，分组将被丢弃。这可避免 IP 分组因寻找目的地不断在网络中传输。 协议 上层协议的端口 (TCP 为端口 6 ， UDP 为端口 7)。还支持网络层协议，如 ARP和ICMP (在有些分析器中，该字段称为类型字段)。稍后我们将更详细地讨论该字段。 报头 校验和对报头执行 CRC 的结果。 源IP 地址 发送方的 32 位 IP 地址。 目标 IP 地址 接收方的 32 位 IP 地址。 选顶用于网络测试、调试、安全等。 数据位于选项字段后，为上层数据。 可能在IP报头的协议字段中指定的协议号 ICMP ( Internet Control Message Protocol ，因特网控制消息协议) ​ 运行在网络层， IP 使用它来获得众多服务。 ICMP 是一种管理协议，为IP提供消息收发服务，其消息是以 IP 数据报的形式传输的。 ICMP 分组具有如下特征: 可向主机提供有关网络故障的信息。 封装在IP数据报中。 与 ICMP相关的常见事件和消息: 目标不可达 如果路由器不能再向前转发 IP 数据报，它将使用 ICMP 向发送方发送一条消息，以通告这种情况。 缓冲区已满 如果用于接收数据报的路由器内存缓冲区已满，路由器将使用 ICMP 发送这种消息，直到拥塞解除。 超过跳数/时间 对于每个 IP 数据报，都指定了它可穿越的最大路由器数量(跳数)。如果数据报还未达到目的地就达到了该上限，最后一台收到该数据报的路由器将把它删除。然后，该路由器将使用 ICMP 发送一条协告，让发送方知道其数据报已被删除。 Ping Packet Internet Groper (Ping , 分组因特网探测器) 使用 ICMP 回应请求和应答消息，以检查互联网络中机器的物理连接性和逻辑连接性。 Traceroute 使用 ICMP 超时来发现分组在互联网络中传输时经过的路径。 虽然 ICMP 运行在因特网(网络)层，它仍使用 IP 来发出Ping 请求，你注意到这一点了吗?在 P 报头中，类型字段的值为 OxOl ，这表明数据报中的数据属于ICMP 协议。别忘了，条条道路通罗马，同样，所有数据段或数据都必须通过 IP 传送。 ARP (Address Resolution Protocol ，地址解析协议) ​ 根据已知的 IP 地址查找主机的硬件地址 ， 其工作原理如下: IP需要发送数据报时，它必须将目标端的硬件地址告知网络接入层协议，如以太网或无线。(上层协议已经将目标端的 IP 地址告诉它)如果 IP 在 ARP 援存中没有找到目标主机的硬件地址，它将使用 ARP 获悉这种信息。 RARP 如果 IP 主机为无盘计算机，一开始它不知道自己的 IP 地址，但知道自己的 MAC 地址。无盘机器可使用RARP (Reverse Address Resolution Protocol，逆向地址解析协议)来获悉其IP 地址，这是通过发送一个分组实现的，该分组包含元盘计算机的 MAC 地址和一个请求( 请求提供分配给该 MAC 地址的 IP 地址 )。名叫 RARP 服务器的专用机器将对此作出响应，从而解决身份危机。RARP 使用它知道的信息(即机器的 MAC 地址)来获悉机器的 IP 地址，从而完成身份标识。 RARP 将以太网 (MAC) 地址解析为IP 地址。 代理 ARP 在网络中，我们不能给主机配置多个默认网关。请想一想，如果默认网关(路由器)发生故障，结果将如何呢?主机不能自动将数据发送给另一台路由器，而你必须重新配置主机。但代理 ARP 可帮助主机前往远程子网，而无需配置路由选择甚至默认网关。 使用代理 ARP 的优点之一是，我们可在网络中的一台路由器上启用它，而不影响网络中其他路由器的路由选择表。然而，使用代理 ARP 也存在一个严重的缺陆:使用代理 ARP 将增加网段中的流量，而为处理所有的 IP 地址到 MAC 地址的映射，主机的 ARP 表比通常情况下大。 代理 ARP 并非一种独立的协议，而是路由器代表其他设备(通常是 PC) 运行的一种服务，路由器禁止这些设备查询远程设备，虽然在这些设备看来，它们与远程设备位于同一个子网中。这让路由器能够在响应 ARP查询时提供自己的 MAC地址，从而将远程 IP地址解析为有效的 MAC地址。 IP 编址IP 地址是分配给 IP 网络中每台机器的数字标识符，它指出了设备在网络中的具体位置。 基本术语 比特 一个比特相当于一位，其取值为 1 或 0 。 字节 1 B 为 7 或 8 位，这取决于是否使用奇偶校验。 我们都假定是8位。 八位组 (Octet) 由 8 位组成，是普通的 8 位二进制数 ，术语字节和八位组可互换使用。 网络地址 在路由选择中，使用它将分组发送到远程网络 。 广播地址 应用程序和主机用于将信息发送给网络中所有节点的地址。 A 类地址 在 A 类地址中，第一个字节为网络地址，余下的 3B 为节点地址，A 类网络地址的第一个字节的第一位必须为 0 ，A 类地址第一个字节的取值为 0-127（2的7次方） A 类地址的网路地址数目126个 A 类地址用3B表示节点地址，主机数目为2的24次方-2（全为0和全为1）=16 777 214 个 B类地址 在 B 类地址中，前 2B 为网络地址，余下的 2B 为节点地址 ，B 类网络地址的第一个字节的第一位必须为 1 ，且第二位必须为 0， B 类网络地址第一个字节的取值为 128 -191 B类地址的网路地址要以二进制10开头，因此有2的14次方=16 384 B类地址用 2B 表示节点地址 ，主机数目为2的16次方-2（全为0和全为1）=65534 个 C 类地址 C 类地址的前 3 个字节为网络部分，余下的一个字节表示节点地址，C 类网络地址的第一个字节的前两位必须为 1 ，而第三位必须为 0 ， C 类网络地址第一个字节的取值为 192-223 C类地址的网路地址要以二进制110开头，因此有2的21次方-2（全为0和全为1）=2097 152 个 C 类网络用1B 用作节点地址，主机数目为 2的8次方 - 2 (全为 1 和全为 0 )，即 254 个节点地址 私有IP地址 D 类和 E 类网络地址范围 第一个字节为 224-255 的地址被保留用于 D 类和 E 类网络。 D 类 (224 - 239 )用作组播地址，而 E 类( 240 - 255 )用于科学用途。 IPv4 地址类型第 2 层广播地址 表示 LAN 中的所有节点 ，即FF:FF:FF:FF:FF:FF 。 广播（第 3 层） 地址表示网络中的所有节点 其目标地址的主机位都为 1 。 单播地址 这是特定接口的地址，用于将分组发送给单个目标主机 。 组播地址 用于将分组传输到不同网络中的众多设备，常用一对多来形容 。组播确实支持点到多点通信，这类似于广播，但工作原理不同。组播的关键点在于，它让多个接收方能够接收消息，却不会将消息传递给广播域中的所有主机。然而，这并非默认行为，而是在配置正确的情况下，使用组播达到的。组播地址的范围为 244.0.0.0 - 239.255.255.255]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python的stevedore模块]]></title>
      <url>%2F2017%2F03%2F27%2Fpython%E7%9A%84stevedore%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之stevedore模块]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（3）]]></title>
      <url>%2F2017%2F03%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%883%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 首先从控制节点入手，neutron-server包括 neutron-server：neutron\cmd\eventlet\server:main neutron-rpc-server：neutron\cmd\eventlet\server:main_rpc_eventlet两部分 本文主要描述rpc服务的创建和初始化过程，包括RPC-server的创建，RPC-client的创建。 123456789101112131415161718192021222324252627def eventlet_wsgi_server(): neutron_api = service.serve_wsgi(service.NeutronApiService) start_api_and_rpc_workers(neutron_api)def start_api_and_rpc_workers(neutron_api): pool = eventlet.GreenPool() api_thread = pool.spawn(neutron_api.wait) try: neutron_rpc = service.serve_rpc() except NotImplementedError: LOG.info(_LI("RPC was already started in parent process by " "plugin.")) else: rpc_thread = pool.spawn(neutron_rpc.wait) plugin_workers = service.start_plugin_workers() for worker in plugin_workers: pool.spawn(worker.wait) # api and rpc should die together. When one dies, kill the other. rpc_thread.link(lambda gt: api_thread.kill()) api_thread.link(lambda gt: rpc_thread.kill()) pool.waitall()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(9)]]></title>
      <url>%2F2017%2F03%2F27%2F%E4%BD%A0%E6%87%82python%E5%90%97-9%2F</url>
      <content type="text"><![CDATA[python的单例模式1.使用__new__方法​ 实现__new__方法 并在将一个类的实例绑定到类变量_instance上, 如果cls._instance为None说明该类还没有实例化过,实例化该类,并返回;如果cls._instance不为None,直接返回cls._instance 。 123456789101112131415161718192021class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, 'instance'): cls.instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls.instanceclass Person(Singleton): def __init__(self, name, age): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',24) person2=Person('lau',26) print id(person1) print id(person2)#output140057479545680140057479545680 2.使用修饰符方法​ 使用装饰器(decorator), 这是一种更pythonic,更elegant的方法,单例类本身根本不知道自己是单例的,因为他本身(自己的代码)并不是单例的。 12345678910111213141516171819202122232425def singleton(cls): instances = &#123;&#125; def _singleton(*args, **kw): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return _singleton@singletonclass Person(object): def __init__(self, name=None, age=None): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',24) person2=Person('lau',26) person3=Person() print id(person1) print id(person2) print id(person3) #output140059880903312140059880903312140059880903312 3.使用metaclass方法​ Person=Singleton(),Person其实为元类Singleton创建的一个实例类。创建Person的实例person1时，Person(‘lucky’,23)=Singleton.__call__(cls,args, *kwargs)，这样就将Person的所有实例都指向了Person的属性_instance上，这种方法与使用__new__方法其实是相同的。 12345678910111213141516171819202122232425262728class Singleton(type): def __call__(cls,*args, **kwargs): if not hasattr(cls, '_instance'): cls._instance = super(Singleton, cls).__call__(*args, **kwargs) return cls._instanceclass Person(object): __metaclass__ = Singleton def __init__(self, name=None, age=None): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',23) print person1.name print person1.age person2=Person() person3=Person() print id(person1) print id(person2) print id(person3)#outputlucky23139786319061776139786319061776139786319061776 4.共享属性​ 所谓单例就是所有引用(实例、对象)拥有相同的状态(属性)和行为(方法) 同一个类的所有实例天然拥有相同的行为(方法),只需要保证同一个类的所有实例具有相同的状态(属性)即可。所有实例共享属性的最简单最直接的方法就是__dict__属性指向(引用)同一个字典(dict)。 创建实例时把所有实例的__dict__指向同一个字典,这样它们具有相同的属性和方法。 123456789101112131415161718192021222324252627class Singleton(object): _state = &#123;&#125; def __new__(cls, *args, **kw): ob = super(Singleton, cls).__new__(cls, *args, **kw) ob.__dict__ = cls._state return obclass Person(Singleton): def __init__(self, name=None, age=None): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',23) person2=Person('lau',24) person3=Person() print id(person1) print id(person2) print id(person3) print id(person1.__dict__) print id(person2.__dict__)#output139890509018064139890509018128139890509018192139890509022944139890509022944 5.import方法作为python的模块是天然的单例模式 12345678910111213141516# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonif __name__ == '__main__': print id(my_singleton) print id(my_singleton)#output140353398006352140353398006352]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(8)]]></title>
      <url>%2F2017%2F03%2F24%2F%E4%BD%A0%E6%87%82python%E5%90%97-8%2F</url>
      <content type="text"><![CDATA[__init__与__new__的区别__init__与__new__的主要区别如下： __new__是一个静态方法,而__init__是一个实例方法. __new__方法会返回一个创建的实例,而__init__什么都不返回. 只有在__new__返回一个cls的实例时后面的__init__才能被调用. 当创建一个新实例时调用__new__,初始化一个实例时用__init__ __new__的使用我们先看一下普通例子： 123456789101112class Person(object): def __init__(self,name,age): self.name=name self.age=age def __str__(self): return "&lt;Person &lt;%s %s&gt;" %(self.name,self.age)if __name__ == '__main__': person=Person("luckylau",23) print person# output&lt;Person &lt;luckylau 23&gt; 这是__init__最普通的用法了。但__init__其实不是实例化一个类的时候第一个被调用 的方法。当使用 Persion(name, age) 这样的表达式来实例化一个类时，最先被调用的方法 其实是 __new__ 方法,等价于以下过程： 123456789101112131415class Person(object): def __new__(cls, name,age): print " __new__ called " return super(Person,cls).__new__(cls,name,age) def __init__(self,name,age): print " __init__ called " self.name=name self.age=age def __str__(self): return "&lt;Person &lt;%s %s&gt;" %(self.name,self.age)if __name__ == '__main__': person=Person("luckylau",23) print person 1.person = Person(name, age)2.首先执行使用name和age参数来执行Person类的__new__方法，这个__new__方法会 返回Person类的一个实例（通常情况下是使用 super(Persion, cls).__new__(cls, … …) 这样的方式），3.然后利用这个类实例来调用类的__init__方法，上一步里面__new__产生的实例也就是 __init__里面的 self。所以，__init__ 和 __new__ 最主要的区别在于：1.__init__ 通常用于初始化一个新实例，控制这个初始化的过程，比如添加一些属性， 做一些额外的操作，发生在类实例被创建完以后。它是实例级别的方法。2.__new__ 通常用于控制生成一个新实例的过程。它是类级别的方法。 因此一个应用就是__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。 12345678910class PositiveInteger(int): def __new__(cls, value): print " __new__ called " return super(PositiveInteger,cls).__new__(cls,abs(value))if __name__ == '__main__': num=PositiveInteger(-123) print num#output123 12345678910class PositiveInteger(int): def __init__(cls, value): print " __new__ called " return super(PositiveInteger,cls).__init__(cls,abs(value))if __name__ == '__main__': num=PositiveInteger(-123) print num#output-123 还有一个应用便是__new__来实现单例 123456789101112131415161718class Person(object): def __new__(cls,*args,**kwargs): if not hasattr(cls,'instance'): cls.instance=super(Person,cls).__new__(cls,*args,**kwargs) return cls.instance def __init__(self,name,age): self.name=name self.age=ageif __name__ == '__main__': person=Person("lucky",23) person2=Person("lau",24) print id(person) print id(person2)#output140094508307088140094508307088]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(2)]]></title>
      <url>%2F2017%2F03%2F23%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： 以太网 以太网数据封装 以太网回顾？包括以下内容： 冲突域，广播域，CSMNCD，半双工，全双工，以太网编址 ,以太网帧，以太网物理层，以太网布线 ​ 广播域指的是网段中的一组设备，它们侦昕在该网段上发送的所有广播。广播域的边界通常为诸如交换机和路由器等物理介质，但广播域也可能是一个逻辑网段，其中每台主机都可通过数据链路层(硬件地址)广播访问其他所有主机。 ​ 冲突域是一个以太网术语，指的是这样一种网络情形，即网段上的一台设备发送分组时，该物理网段上的其他所有设备都必须债昕它。这很糟糕，因为如果同一个物理网段中的两台设备同时传输数据，将发生冲突(即两台设备的数字信号将在线路上相互干扰)，导致设备必须在以后重传数据。冲突对网络性能有严重的负面影响，因此绝对要避免冲突。 ​ CSMNCD (Carrier Sense Multiple Access with Collision Detection ，载波侦听多路访问/冲突检测)这是一种帮助设备均衡地共享带宽的协议，可避免两台设备同时在网络介质上传输数据。 帮助最大限度地减少冲突，从而提高数据传输效率。主机想通过网络传输数据时，它首先检查线路上是否有数字信号。如果没有其他主机传输数据，该主机将开始传输数据。但到这里并非万事大吉，传输主机将持续地监视线路，确保没有其他主机开始传输。如果该主机在线路上检测到其他信号，它将发送一个扩展的拥堵信号 (jam signal)，使网段上的所有节点都不再发送数据(想想电话忙音吧)。检测到拥堵信号后，其他节点将等待一段时间再尝试传输。后退算法决定了发生冲突的工作站多长时间后可重新传输，如果连续 15 次尝试都导致冲突，尝试传输的节点将超时。 以太网 LAN 中发生冲突后，将出现如下’情况: 拥堵信号告诉所有设备发生了冲突； 冲突激活随机后退算法； 以太网网段中的每台设备都暂停传输，直到其后退定时器到期； 定时器到期后，所有主机的传输优先级都相同。 CSMAlCD 网络持续发生严重冲突时，将导致如下结果: 延迟; 低吞吐量; 拥塞; 半双工以太网使用 CSMA/CD 协议，以帮助防范冲突，并在发生冲突时支持重传。如果集线器与交换机相连，它必须运行在半双工模式下，因为终端必须能够检测冲突。半双工以太网的效率只有30%-40% ，因为在大型 100BaseT 网络中，通常最大传输速度只有 30 - 40 Mbitls。 全双工以太网同时使用两对导线,与半双工以太网只使用一对导线不同 。在传输设备的发射器和接收设备的接收器之间，全双工使用一条点到点连接，这意味着使用全双工时，数据传输速度比半双工时快。你元需担心冲突，因为全双工提供了一条”多车道高速公路”，而不像半双工那样提供一条”单车道公路”。全双工以太网在两个方向的效率都为 100% 。全双工以太网可用于下面 6 种情形: 交换机到主机的连接; 交换机到交换机的连接; 主机到主机的连接(使用交叉电缆); 交换机到路由器的连接(使用交叉电缆); 路由器到路由器的连接(使用交叉电缆); 路由器到主机的连接(使用交叉电缆)。 基本上除集线器外，其他所有设备都可在全双工模式下运行。 以太网编址 MAC (硬件)地址长 48 位 (6 B)，采用十六进制格式。 I/G (Individual/Group) 位： 值为 0 ，我们就可认为相应的地址为某台设备的 MAC 地址，很可能出现在 MAC 报头的源地址部分;值为 1 ，我们就可认为相应的地址为以太网中的广播地址或组播地址或者令牌环和FDDI 中的广播地址或功能地址 。 G/L位(全局/本地位，也称为 U/L位): 值为 0 ，则表示相应的地址为全局管理地址，由 IEEE 分配; 值为 1， 则表示相应的地址为本地管理地址 ; OUI ( Organizationally Unique Identifier，组织唯一标识符)： 由 IEEE 分配给组织的，它包含 24位 (3 B)，而组织给其生产的每个网卡都分配一个唯一的( 据说如此，但不保证 ) 全局管理地址，该地址长 24 位 (3 B)。 右边 24 位为本地管理(制造商分配)的编码，特定制造商生产第一个网卡时，通常将这部分设置为 24 个 0 ，然后依次递增，直到将其生产的第 1677 216 个网卡设置为 24 个 1 。 数据链路层负责将比特合并成字节，再将字节封装成帧。在数据链路层，我们使用帧封装来自网络层的分组，以便通过特定类型的介质进行传输。 以太网帧 数据链路层负责将比特合并成字节，再将字节封装成帧。在数据链路层，我们使用帧封装来自网络层的分组，以便通过特定类型的介质进行传输。下图是以太网帧和802.3帧。 前导码交替的 0 和 1 ，在每个分组的开头提供 5 MHz 的时钟信号，让接收设备能够跟踪到来的比特流。 帧起始位置分隔符 (SFD) I同步前导码为 7B，而 SFD (同步)为 lBo SFD 的值为 10101011 ,其中最后两个 l 让接收方能够识别中间的 0 和 1 交替模式，进而同步并检测到数据开头。 目标地址 (DA) 包含一个 48 位的值，且 LSB (Least Significant Bit，最低有效位)优先。接收方根据 DA 判断到来的分组是否是发送给特定节点的。 目标地址可以是单播地址、广播地址或组播 MAC 地址。 别忘了， 广播地址全为 1 (在十六进制格式下全为 F) ， 广播发送给所有设备，而组播只发送给网络中一组类似的节点。 源地址 (SA) SA 是一个 48 位的 MAC 地址 ， 用于标识传输设备，也使用 LSB 优先格式。在 SA 字段中，不能包含广播地址或组播地址。 长度或类型 802.3 帧使用长度字段，而 Etbemet_II 帧使用类型字段标识网络层协议。 802.3不能标识上层协议，只能用于专用 LAN，如 IPX。 数据这是网络层传递给数据链路层的帧，其长度为 46-1500 B。 帧校验序列 (FCS) FCS 字段位子，用于存储 CRC (Cyclic Redundancy Check ，循环冗余校验 ) 结果的帧的帧尾 。 CRC 是一种数学算法，创建每个帧时都将运行它 。 作为接收方的主机收到帧并运行 CRC 时，其结果必须相同，否则，接收方将认为发生了错误，进而将帧丢弃。 以太网物理层 ，IEEE 对 802.3进行了扩展，制定了两个新标准: 802.3u ( 快速以太网)和 802 .3ab (使用 5 类电缆的吉比特以太网)，然后又制定了标准 802.3ae (使用光纤和同轴电缆，速度为 10 Gbitls )。 IEEE 802.3 标准： 以太网布线 有三种，直通电缆 交叉电缆 反转电缆。 (1)主机到主机。交叉电缆(2) 主机到交换机或集线器。直通电缆(3) 路由器到主机。交叉电缆(4) 交换机到交换机。交叉电缆(5) 路由器到交换机或集线器。直通电缆(6) 集线器到集线器。交叉电缆(7) 集线器到交换机。交叉电缆(8) 主机到路由器的控制台串行通信 (COM) 端口。 反转电缆 二进制和十进制和十六进制转换？ 半字节（4位） 字节（8位） 8 4 2 1 128 64 32 16 8 4 2 1 二进制转十进制 10010110: 128+16+4+2=150 十六进制转二进制 0x6A : 6 =0110 A=1010 即为01101010 二进制转十六进制 11001101 : 1100=12 1101=13 即为0xCD 数据封装？​ 为通信和交换信息，每层都使用 PDU ( Protocol Data Unit，协议数据单元 )0 PDU包含在模型每一层给数据添加的控制信息。这些控制信息通常被添加在数据字段前面的报头中，但也可能被添加在报尾中。 ​ OSI 模型每一层都对数据进行封装来形成 PDU ， PDU 的名称随报头提供的信息而异。这些 PDU信息仅在接收设备的对等层被读取，然后被剥离，然后数据被交给下一层。 封装过程如下： (1) 用户信息被转换为数据，以便通过网络传输；(2) 数据被转换为数据段，并在发送主机和接收主机之间建立一条可靠的连接；(3) 数据段被转换为分组或数据报，并在报头中加入逻辑地址，使得能够在互联网络中路由分组；(4) 分组或数据报被转换为帧，以便在本地网络中传输。使用硬件(以太网)地址来唯一地标识本地网络中的主机；(5) 帧被转换为比特，并使用数字编码和时钟同步方案 ； 解释上述过程如下： ​ 事实上由上层将数据流交给传输层。作为技术人员，我们并不关心数据流来自何方。我们的职责是，在接收设备处可靠地重建数据流，并将其交给上层。 使用面向连接的协议(即 TCP) 时，传输层将数据流转换为数据段，并创建一条虚电路以建立可靠的会话。 接下来，它对每个数据段进行编号，并使用确认和流量控制。如果你使用的是 TCP，虚电路将由源端口号和目标端口号以及源 IP 地址和目标 P 地址(称为套接字)标识。别忘了，主机只能使用不小于 1024 的端口号( 0-1023 为知名端口号)。目标端口号标识了上层进程(应用程序)，在接收主机可靠地重建数据流后，数据流将被交给该进程(应用程序)。 问与答？以太网帧包含哪些字段？ 源 MAC 地址、目标 MAC 地址、标识网络层协议的以太类型( Ether-Type )、数据以及存储 CRC 结果的 FCS]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(7)]]></title>
      <url>%2F2017%2F03%2F21%2F%E4%BD%A0%E6%87%82python%E5%90%97-7%2F</url>
      <content type="text"><![CDATA[python的新式类和旧式类​ python的新式类是2.2版本引进来的，我们可以将之前的类叫做经典类或者旧式类。为什么要在2.2中引进new style class呢？官方给的解释是：为了统一类(class)和类型(type)。 使用环境是python 2.7 新式类与旧式类的区别 12345678910111213141516171819202122class C(object): passclass B: passif __name__ == '__main__': c = C() b = B() print type(c) print c.__class__ print type(b) print b.__class__ print "**********************" print dir(C) print dir(B)#output&lt;class '__main__.C'&gt;&lt;class '__main__.C'&gt;&lt;type 'instance'&gt;__main__.B**********************['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']['__doc__', '__module__'] ​ 如上所示b是旧式类的一个实例，c是新式类的一个实例。c的__class__与type返回的结果是一样的，得到统一。而b的__class__与type返回的结果并不相同。同时我们还发现新式类有更多的属性和方法，旧式类只有区区的2个方法。 ​ 我们也发现为了向前兼容，默认情况下用户定义的类为经典类，新类需要继承自所有类的基类 object 或者继承自object的新类。那么为了确保自己使用的是新式类，有两种以下方法： 元类，在类模块代码的最前面加入如下代码 __metaclass__ = classname(自定义的某个新式类)。 类都从内建类object直接或者间接地继承。 新式类的属性和方法内置的object对象是所有内置，object对象定义了一系列特殊的方法实现所有对象的默认行为。 1.__new__，__init__方法这两个方法是用来创建object的子类对象，静态方法__new__()用来创建类的实例，然后再调用__init__()来初始化实例。 123456789101112class C(object): passclass B: passif __name__ == '__main__': c = C("ooo") b = B("ooo")#outputTypeError: object() takes no parameters #新式类TypeError: this constructor takes no arguments #旧式类 新式类都有一个__new__的静态方法，它的原型是object.__new__(cls[, …])cls是一个类对象，如上面代码，当你调用C(args, **kargs)来创建一个类C的实例时，python的内部调用是C.__new__(C, args, kargs)，然后返回值是类C的实例c，在确认c是C的实例后，python再调用C.__init__(c, *args, kargs)来初始化实例c。所以调用一个实例c = C(”ooo“)，实际执行的代码为： 123c = C.__new__(C, "ooo")if isinstance(c, C): C.__init__(c, "ooo") 可以使用__new__来实现Singleton单例模式： 12345678910111213141516171819202122class Singleton(object): _singleton=&#123;&#125; def __new__(cls, *args, **kwargs): if not cls._singleton.has_key(cls): cls._singleton[cls]=object.__new__(cls) return cls._singleton[cls]class B(object): #做对比 passif __name__ == '__main__': a=Singleton() print id(a) b=Singleton() print id(b) c=B() print id(c) d=B() print id(d)#output140573118190288140573118190288140573118190352140573118190416 使用id()操作，可以看到两个实例指向同一个内存地址。Singleton的所有子类也有这一特性，只有一个实例对象，如果它的子类定义了__init__()方法，那么必须保证它的__init__方法能够安全的同一个实例进行多次调用。 2.__delattr__, __getattribute__, __setattr__方法对象使用这些方法来处理属性的访问 __getattribute__ 对新式类的实例来说，所有属性和方法的访问操作都是通过getattribute完成，这是由object基类实现的。如果有特殊的要求，可以重载getattribute方法，下面实现一个不能使用append方法的list： 12345678910111213141516class listNoappend(list): def __getattribute__(self, item): if item == 'append': raise AttributeError(item) return list.__getattribute__(self, item)if __name__ == '__main__': a = listNoappend() print type(a) print dir(a) a.append("abc")#output&lt;class '__main__.listNoappend'&gt;['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__dict__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']a.append("abc")raise AttributeError(item)AttributeError: append 3.__hash__, __repr__, __str__方法print(someobj)会调用someobj.__str__()， 如果__str__没有定义，则会调用someobj.__repr__()， __str__()和__repr__()的区别： 默认的实现是没有任何作用的，__repr__的目标是对象信息唯一性，__str__的目标是对象信息的可读性 容器对象的__str__一般使用的是对象元素的__repr__，如果重新定义了__repr__，而没有定义__str__，则默认调用__str__时，调用的是__repr__，也就是说好的编程习惯是每一个类都需要重写一个__repr__方法，用于提供对象的可读信息，而重写__str__方法是可选的。实现__str__方法，一般是需要更加好看的打印效果，比如你要制作一个报表的时候等。可以允许object的子类重载这些方法，或者添加新的方法。 4.__slots__属性​ 通常每一个实例x都会有一个__dict__属性，用来记录实例中所有的属性和方法，也是通过这个字典，可以让实例绑定任意的属性。而__slots__属性作用就是，当类C有比较少的变量，而且拥有__slots__属性时，类C的实例 就没有__dict__属性，而是把变量的值存在一个固定的地方。如果试图访问一个__slots__中没有的属性，实例就会报错。这样操作有什么好处呢？__slots__属性虽然令实例失去了绑定任意属性的便利，但是因为每一个实例没有__dict__属性，却能有效节省每一个实例的内存消耗，有利于生成小而精干的实例。 ​ 在一个实际的企业级应用中，当一个类生成上百万个实例时，即使一个实例节省几十个字节都可以节省一大笔内存，这种情况就值得使用__slots__属性。 __slots__是一个类变量，__slots__属性可以赋值一个包含类属性名的字符串元组，或者是可迭代变量，或者是一个字符串。 只有在新式类中生效，如下对比： 1234567891011121314151617181920212223242526272829class A: #做对比 def __init__(self,x,y): self.x=x self.y=y __slots__='x','y'class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__='x','y'if __name__ == '__main__': a=A(3,6) print a.x print a.y a.z=7 print a.z b = B(3, 6) print b.x print b.y b.z=6 print b.z#output36736AttributeError: 'B' object has no attribute 'z' 需要注意的几点： 当一个类的父类没有定义__slots__属性，父类中的__dict__属性总是可以访问到的，所以只在子类中定义__slots__属性，而不在父类中定义是没有意义的。 如果定义了__slots__属性，还是想在之后添加新的变量，就需要把__dict__字符串添加到__slots__的元组里。 12345class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__=('x','y',"__dict__") 定义了__slots__属性，还会消失的一个属性是__weakref__，这样就不支持实例的weak reference，如果还是想用这个功能，同样，可以把’__weakref__‘字符串添加到元组里。 __slots__功能是通过descriptor实现的，会为每一个变量创建一个descriptor。 __slots__的功能只影响定义它的类，因此，子类需要重新定义__slots__才能有它的功能。 12345678910111213141516171819class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__=('x','y')class C(B): passif __name__ == '__main__': b = B(3, 6) c=C(3,6) c.z=9 print c.z b.z=9 print b.z# output9'B' object has no attribute 'z' 5.__getitem__方法​ 在python中，隐式调用实例的私有特殊方法时，新的对象模型和经典对象模型表现上不太一样。在经典对象模型中，无论是显示调用还是隐式调用特殊方法，都会调用实例中后绑定的特殊方法。而在新的对象模型中，除非显式地调用实例的特殊方法，否则python总是会去调用类中定义的特殊方法，如果没有定义的话，就报错。 123456789101112131415161718def getItem(index): return index + 1class OldStyle: passclass NewStyle(object): passif __name__ == '__main__': old = OldStyle() old.__getitem__=getItem print old[2] new =NewStyle() new.__getitem__=getItem print new.__getitem__(2) #显示调用 print new[2]# output33TypeError: 'NewStyle' object does not support indexing 调用old[1]，将产生一个隐式的getitem方法的调用，在新式类中，因为类中没有定义这个方法，也不是object基类有的方法，所以报错。需要显示地调用才可以运行。 新式类的继承​ 新式类同样支持多继承，但是如果新式类想要从多个内置类型中继承生成一个新类的话，则这些内置类必须是经过精心设计，能够互相兼容的。显然，python也没会让你随意的从多个内置类中进行多继承，想创建一个超级类不是那么容易的。。。通常情况下，至多可以继承一个内置类，比如list, set, dict等。 下图是MRO(Method Resolution Order ,方法解析顺序)，分别是旧式类和新式类的方法顺序。旧式类深度优先的方式进行查找，新式类广度优先的方式查找 1234567891011121314151617class D: def __init__(self): self.x = "d"class B(D): passclass C(D): def __init__(self): self.x = "c"class A(B,C): passif __name__ == '__main__': a=A() print a.x print A.__mro__#output dAttributeError: class A has no attribute '__mro__' 1234567891011121314151617class D(object): def __init__(self): self.x = "d"class B(D): passclass C(D): def __init__(self): self.x = "c"class A(B,C): #当B,C变成C，B时候 A.__mro__的输出顺序也会变 passif __name__ == '__main__': a=A() print a.x print A.__mro__#outputc(&lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;type 'object'&gt;) 另一个注意的是协作式调用父类方法使用： 1234567891011121314151617181920212223242526272829303132class A(object): def foo(self): print "AAAAA"class B(A): def foo(self): print "BBBBB" A.foo(self)class C(A): def foo(self): print "CCCCC" A.foo(self)class D(B,C): def foo(self): print "DDDDD" B.foo(self) C.foo(self)if __name__ == '__main__': d=D() print d.foo() print D.__mro__#outputDDDDDBBBBBAAAAACCCCCAAAAANone(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;) ​ 可以看到，基类A的方法重复运行了两次。怎样才能确保父类中的方法只被顺序的调用一次呢？在新的对象系统中，有一种特殊的方法super(aclass, obj)，可以返回obj实例的一个特殊类型superobject(超对象， 不是简单的父类的对象)，当我们使用超对象调用父类的方法时，就能保证只被运行一次： 12345678910111213141516171819202122232425262728class A(object): def foo(self): print "AAAAA"class B(A): def foo(self): print "BBBBB" super(B,self).foo()class C(A): def foo(self): print "CCCCC" super(C, self).foo()class D(B,C): def foo(self): print "DDDDD" super(D, self).foo()if __name__ == '__main__': d=D() print d.foo()#outputDDDDDBBBBBCCCCCAAAAANone ​ 可以看到，D的父类中所有的foo方法都得到执行，并且基类A的foo方法只执行了一次。如果养成了使用super去调用父类方法的习惯，那么你的类就可以适应无论多么复杂的继承调用结构。super()可以看成是更加安全调用父类方法的一种新方式。 新式类的Descriptor​ descriptor可以说是一个绑定了特定访问方法的类属性，这些访问方法是重写了descriptor protocol中的三个方法，分别是__get__, __set__, __del__方法。如果三个中任一一个方法在对象中定义了，就说这个对象是一个descriptor对象，可以把这个对象赋值给其它属性。descriptor protocol可以看成是一个有三个方法的接口。 ​ 通常对一个实例的属性的访问操作，如get, set, delete是通过实例的__dict__字典属性进行的，例如下面代码: 123456789class Person(object): name="lucky"if __name__ == '__main__': person=Person() person.name="Lau" print person.name#outputLau ​ 对于操作person.name，会一个查找链，首先通过实例对象的__dict__属性访问，即person.dict[‘x’]（实例的字典），再通过类型对象的__dict__属性访问，即type(person).dict[‘x’]，等价于Person.dict[‘name’]（类的字典），再通过父类对象的__dict__属性访问，person.class.base.dict[‘name’],等价于Parent.dict[‘name’]，type(a)的父类的字典。 ​ 如果这个需要被查找的属性是一个定义了descriptor协议方法的对象，那么python就不会按照默认的查找方式，而是调用descriptor协议中定义的方法__get__方法获取，同样的道理，给name赋值的时候是通过调用__set__方法实现而不是通过__dict__属性。 12345678910111213141516171819class DescriptorName(object): def __init__(self,name): self.name=name def __get__(self, instance, owner): print '__get__' , instance,owner return self.name def __set__(self, instance, value): print '__set__',instance,value self.name=valueclass Person(object): name=DescriptorName("Lucky")if __name__ == '__main__': person=Person() person.name="Lau" print person.name#output__set__ &lt;__main__.Person object at 0x7f9b2458c490&gt; Lau__get__ &lt;__main__.Person object at 0x7f9b2458c490&gt; &lt;class '__main__.Person'&gt;Lau 上面的例子是基于类的方式来创建描述符，你还可以通过property()函数来创建描述符 123456789101112131415161718192021222324252627282930class Person(object): def __init__(self, name): self.name = name self._email=None def get_email(self): print ' get_email is invoked' return self._email def set_email(self, value): print ' set_email is invoked' self._email = value def del_email(self): print 'del_email is invoked' del self._email email = property(get_email, set_email, del_email, 'this is email property')if __name__ == '__main__': person = Person("Luckylau") person.email="laujunbupt0913@163.com" # set_email is invoked print person.email # get_email is invoked del person.email # del_email is invoked#outputset_email is invokedget_email is invokedlaujunbupt0913@163.comdel_email is invoked property()函数返回的是一个描述符对象，它可接收四个参数property(fget=None, fset=None, fdel=None, doc=None) fget：属性获取方法 fset：属性设置方法 fdel：属性删除方法 doc： docstring 使用纯python的方式来实现property函数如下： 1234567891011121314151617181920212223242526272829303132333435363738class Property(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, instance, owner): if instance is None: return self if self.fget is None: raise AttributeError("unreadable attribute") return self.fget(instance) def __set__(self, instance, value): if self.fset is None: raise AttributeError("can't set attribute") self.fset(instance, value) def __delete__(self, instance): if self.fdel is None: raise AttributeError("can't del attribute") self.fdel(instance) def getter(self, fget): print "Property getter is invoked " return type(self)(fget, self.fset, self.fdel, self.__doc__) def setter(self, fset): print "Property setter is invoked " return type(self)(self.fget, fset, self.fdel, self.__doc__) def deleter(self, fdel): print "Property deleter is invoked " return type(self)(self.fget, self.fset, fdel, self.__doc__) 同时你还可以用property装饰器创建描述符 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Property(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, instance, owner): if instance is None: return self if self.fget is None: raise AttributeError("unreadable attribute") return self.fget(instance) def __set__(self, instance, value): if self.fset is None: raise AttributeError("can't set attribute") self.fset(instance, value) def __delete__(self, instance): if self.fdel is None: raise AttributeError("can't del attribute") self.fdel(instance) def getter(self, fget): print "Property getter is invoked " return type(self)(fget, self.fset, self.fdel, self.__doc__) def setter(self, fset): print "Property setter is invoked " return type(self)(self.fget, fset, self.fdel, self.__doc__) def deleter(self, fdel): print "Property deleter is invoked " return type(self)(self.fget, self.fset, fdel, self.__doc__)class Person(object): def __init__(self,name): self.name=name self._email = None @Property def email(self): pass @email.getter def email(self): print " get_email is invoked " return self._email @email.setter def email(self, value): print " set_email is invoked " self._email = value @email.deleter def email(self): print " del_email is invoked " del self._emailif __name__ == '__main__': p = Person("Luckylau") print "**************" p.email = "laujunbupt0913@163.com" print "**************" print p.email#outputProperty getter is invoked Property setter is invoked Property deleter is invoked ********** set_email is invoked ********** get_email is invoked laujunbupt0913@163.com 参考：http://www.pythontab.com/html/2015/pythonjichu_1113/982.html http://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html http://blog.csdn.net/imzoer/article/details/8737642]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(6)]]></title>
      <url>%2F2017%2F03%2F20%2F%E4%BD%A0%E6%87%82python%E5%90%97-6%2F</url>
      <content type="text"><![CDATA[*args和 **kwargs用args和*kwargs只是为了方便并没有强制使用它们。 当你不确定你的函数里将要传递多少参数时你可以用*args.例如,它可以传递任意数量的参数: 123456789def print_everything(*args): for count, thing in enumerate(args): print '&#123;0&#125;. &#123;1&#125;'.format(count, thing)if __name__ == '__main__': print_everything('apple', 'banana', 'cabbage')#output0. apple1. banana2. cabbage 相似的,**kwargs允许你使用没有事先定义的参数名: 12345678def table_things(**kwargs): for name, value in kwargs.items(): print '&#123;0&#125; = &#123;1&#125;'.format(name, value)if __name__ == '__main__': table_things(apple='fruit', cabbage='vegetable')#outputcabbage = vegetableapple = fruit 你也可以混着用.命名参数首先获得参数值然后所有的其他参数都传递给*args和**kwargs.命名参数在列表的最前端.*args和**kwargs可以同时在函数的定义中,但是*args必须在**kwargs前面. 当调用函数时你也可以用*和**语法.例如: 12345678def print_three_things(a, b, c): print 'a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;'.format(a,b,c)if __name__ == '__main__': mylist = ['aardvark', 'baboon', 'cat'] print_three_things(*mylist)#outputa = aardvark, b = baboon, c = cat 就像你看到的一样,它可以传递列表(或者元组)的每一项并把它们解包.注意必须与它们在函数里的参数相吻合.当然,你也可以在函数定义或者函数调用时用* 参考：http://stackoverflow.com/questions/3394835/args-and-kwargs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(1)]]></title>
      <url>%2F2017%2F03%2F17%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： OSI模型 OSI模型：​ OSI 模型包含 7 层，它们分为两组:上 3 层指定了终端中的应用程序如何彼此通信以及如何与用户交流;下 4 层指定了如何进行端到端的数据传输。 请记住，这3 层都对联网和网络地址一无所知，那是下 4 层的职责 。 ISO的功能如下： ​ 应用层是实际应用程序之间的接口。这意味着诸如 MicrosoftWord 等应用程序并不位于应用层中，而是与应用层协议交互。 ​ 表示层向应用层提供数据，并负责数据转换和代码格式化。 ​ 会话层负责在表示层实体之间建立、管理和终止会话，还X才设备或节点之间的对话进行控制。 为此提供了 3 种不同的模式:单工、半双工和全双工。 ​ 传输层将数据进行分段并重组为数据流。位于传输层的服务将来自上层应用的数据进行分段和重组，并将它们合并到同一个数据流中。它们提供了端到端的数据传输服务，并可在互联网络上的发送主机和目标主机之间建立逻辑连接。另外，对上层应用程序进行多路复用、建立会话以及拆除虚电路，并提供透明的数据传输，从而对高层隐藏随网络而异的信息。 ​ 网络层(第 3 层)管理设备编址、跟踪设备在网络中的位置并确定最佳的数据传输路径，这意味着网络层必须在位于不同网络中的设备之间传输数据流。 ​ 数据链路层将报文封装成数据帧，并添加定制的报头，其中包含目标硬件地址和源硬件地址 。路由器运行在网络层，根本不关心主机位于什么地方，而只关心网络(包括远程网络)位于什么地方以及前往这些网络(包括远程网络)的最佳路径。路由器只关心网络，这是好事!对本地网络中每台设备进行唯一标识的工作由数据链路层负责。数据链路层使用硬件地址，让主机能够给本地网络中的其他主机发送分组以及穿越路由器发送分组。每当在路由器之间传输分组时，分组都将被使用数据链路层控制信息封装成帧，但接收路由器会将这些信息剥离，只保留完整的原始分组。在每一跳都将重复这种将分组封装成帧的过程，直到分组最终到达正确的接收主机。在整个传输过程中，分组本身从未被修改过，而只是被必要的控制信息封装，以便能够通过不同的介质进行传输，明白这一点至关重要。 IEEE 以太网数据链路层包含两个子层，如下：介质访问控制 (MAC) 子层 (802.3)和逻辑链路控制 (LLC) 子层 (802.2) 。介质访问控制 (MAC) 子层 (802.3)，它采用”先到先服务”的访问方式，带宽由大家共享，因此称为竟用介质访问( contention media access )。 逻辑链路控制 (LLC) 子层 (802.2)负责识别网络层协议并对其进行封装。 ​ 物理层有两项功能:发送和接收比特。比特的取值只能为 0 或 1一一使用数字值的摩尔斯码。物理层直接与各种通信介质交流。 总结: 应用层、表示层和会话层属于上层，负责用户界面和应用程序之间的通信。传输层提供分段、排序和虚电路。网络层提供逻辑网络编址以及在互联网络中路由的功能。数据链路层提供了将数据封装成帧并将其放到网络介质上的功能。物理层负责将收到的 0 和 1 编码成数字信号，以便在网段中传输。 问与答：1.对数据流进行分段发生在 OSI模型的哪一层? 传输层 解释：传输层从上层接收大型数据，将其分割成较小的片段，这些片段称为数据段。 2.下面哪 4 项描述了路由器的主要功能?A. 分组交换 B. 冲突防范 C. 分组过滤D. 增大广播域 E. 互联网络通信 F. 广播转发G. 路径选择 A 、 C 、 E 、 G。路由器提供分组交换、分组过滤、互联网络通信以及路径选择功能。虽然路由器确实分割或终止冲突域，但这不是路由器的主要功能，因此选项 B 不正确。 3.路由器运行在第？层; LAN 交换机运行在第？层;以太网集线器运行在第？层;字处理程序运行在第？层。A. 3 , 3 ， 1 、 7 B.3 、 2 、 1 、无C.3 、 2 、 1 、 7 D.2 、 3 、 1 、 7E.3 , 3, 2 、无 路由器运行在第 3 层， LAN 交换机运行在第 2 层，以太网集线器运行在第 1 层。字处理程序与应用层接口通信，但并非运行在第 7 层，因此答案为”无”。 4.下面哪 3 种有关全双工以太网运行方式的说法是正确的?A.在全双工模式下不会发生冲突B. 每个全双工节点都必须有一个专用的交换机端口C. 以太网集线器端口被预先配置为全双工模式D. 在全双工环境中，在传输数据前，主机的网卡必须检查网络介质是否可用E 主机的网卡和交换机端口必须能够以全双工模式运行 A 、 B 、 E。全双工意味着可使用两对导线同时发送和接收数据。每个节点都必须有专用的交换机端口，这意味着不会发送冲突。主机的网卡和交换机端口都必须支持全双工模式，并设置为这种模式。 5. (1) 哪一层选择通信伙伴并判断其可用性、判断建立连接所需资掘的可用性、协调参与通信的应用程序，并就控制数据完整性和错误恢复的流程达成一致?(2) 哪一层负责将来自数据链路层的数据分组转换为电信号?(3) 哪一层实现路由选择，在终端系统之间建立连接并选择路径?(4) 哪一层定义了如何对数据进行格式化、表示、编码和转换，以便在网络中使用?(5) 哪一层负责在应用程序之间建立、管理和终止会话?(6) 哪一层确保通过物理链路可靠地传输数据，且主要与物理地址、线路管理、网络拓扑、错误通知、按顺序传输帧以及流量控制有关?(7) 哪一层用于让终端节点能够通过网络进行可靠的通信，提供建立、维护、拆除虚电路的机制，提供传输错误检测和恢复的机制，并提供流量控制机制?(8) 哪一层提供逻辑地址，供路由器用来决定传输路径?(9) 哪一层指定了电平、线路速度和电缆针脚，并在设备之间传输比特?(10) 哪一层将比特合并成字节，再将字节封装成帧，使用 MAC 地址，并提供错误检测功能?(11) 哪一层负责在网络中将来自不同应用程序的数据分开。(12) 哪一层的数据表示为帧?(13) 哪一层的数据表示为数据段?(14) 哪一层的数据表示为分组?(15) 哪一层的数据表示为比特?(16) 按封装顺序排列下列各项:分组帧比特数据段(17) 哪一层对数据进行分段和重组?(1 8) 哪一层实际传输数据，并处理错误通知、网络拓扑和流量控制?(19) 哪一层管理设备编址、跟踪设备在网络中的位置并决定传输数据的最佳路径?(20) MAC 地址长多少位?以什么方式表示? (1) 应用层负责寻找服务器提供的网络资源，并提供流量控制和错误控制功能(如果应用程序开发人员选择这样做)(2) 物理层接收来自数据链路层的帧，将 0 和 1 编码成数字信号，以便在网络介质上传输(3) 网络层提供了在互联网络中进行路由选择的功能，还提供了逻辑地址(4) 表示层确保数据为应用层能够理解的格式(5) 会话层在应用程序之间建立、维护并终止会话 (6) 数据链路层的 PDU 称为帧，该层还提供物理编址以及将分组放到网络介质上的其他选项(7) 传输层使用虚电路在主机之间建立可靠的连接(8)网络层提供了逻辑地址(这通常是 IP 地址)和路由选择功能(9) 物理层负责在设备之间建立电气和机械连接(10) 数据链路层负责将数据分组封装成帧(11) 会话层在不同主机的应用程序之间建立会话(12) 数据链路层将从网络层收到的分组封装成帧(13) 传输层将用户数据分段(14) 网络层将来自传输层的数据段封装成分组(15) 物理层负责以数字信号的形式传输 l 和 o (比特)(16) 数据段、分组、帧、比特(17) 传输层(18) 数据链路层(19) 网络层(20) 长 48 位 (6B) 表示为一个十六进制数 6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(5)]]></title>
      <url>%2F2017%2F03%2F17%2F%E4%BD%A0%E6%87%82python%E5%90%97-5%2F</url>
      <content type="text"><![CDATA[python的format函数使用语法 它通过{}和:来代替%。 用法 ^、&lt;、&gt;分别是居中、左对齐、右对齐，后面带宽度:号后面带填充的字符，只能是一个字符，不指定的话默认是用空格填充 精度常跟类型f一起使用 b、d、o、x分别是二进制、十进制、八进制、十六进制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Person(): def __init__(self, name, age): self.name = name self.age = age def __str__(self): return 'This guy is &#123;self.name&#125;,&#123;self.age&#125; old'.format(self=self)if __name__ == '__main__': # 元组表达 info = ("luckylau", 23) print "info : %s" % (info,) #对于元组，后面的逗号不能少，会报错 print '&#123;1&#125;,&#123;0&#125;'.format(*info) #对于元组，星号不能少，会报错 # 通过位置映射 print '&#123;0&#125;,&#123;1&#125;'.format('test', '123') print '&#123;0&#125;,&#123;1&#125;,&#123;0&#125;'.format('test', '123') # 通过关键字映射 print "&#123;name&#125;,&#123;age&#125;".format(name="luckylau", age=23) # 通过对象属性 print str(Person("luckylau",23)) # 数组表达 info=["luckylau",23] print "info : %s" % (info,) print 'info :&#123;1&#125;,&#123;0&#125;'.format(*info) #星号不能少 print "info : %s" % (info) print 'info :&#123;0[1]&#125;,&#123;0[0]&#125;'.format(info) # 字典的表达 info=&#123;"name":"luckylau","age":23&#125; print "info : %s " %(info) print "info : %s" % (info,) print 'info : &#123;name&#125;,&#123;age&#125;'.format(**info) #两个星号一个不能少 # 对齐 print '&#123;:&gt;8&#125;'.format('189') print '&#123;:0&gt;8&#125;'.format('189') # 精度 print '&#123;:.2f&#125;'.format(321.33345) # 转二进制 print '&#123;:b&#125;'.format(17)#outputinfo : ('luckylau', 23)23,luckylautest,123test,123,testluckylau,23This guy is luckylau,23 oldinfo : ['luckylau', 23]info :23,luckylauinfo : ['luckylau', 23]info :23,luckylauinfo : &#123;'age': 23, 'name': 'luckylau'&#125; info : &#123;'age': 23, 'name': 'luckylau'&#125;info : luckylau,23 18900000189321.3310001]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(4)]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BD%A0%E6%87%82python%E5%90%97-4%2F</url>
      <content type="text"><![CDATA[Python 的类的下划线命名_xxx 单下划线开头的变量，标明是一个受保护(protected)的变量，原则上不允许直接访问，但外部类还是可以访问到这个变量，这只是程序员之间的一个约定，用于警告说明这是一个私有变量，外部类不要去访问它。 1234567891011121314class Person(object): def __init__(self, name): self._name = nameclass Student(Person): def __init__(self, age): super(Student,self).__init__("luckylau") self._age = ageif __name__ == '__main__': stu = Student(20) print stu._age print stu._name # 约定不能出现这样的代码来访问name属性,但实际是可以访问的。#output20luckylau __xxx 双下划线开头的，表示的是私有类型(private)的变量。只能是允许这个类本身进行访问了, 连子类也不可以,用于命名一个类属性（类变量），调用时名字被改变，双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。 12345678910111213141516class Person(object): def __init__(self, name): self.__name = nameclass Student(Person): def __init__(self, age): super(Student,self).__init__("luckylau") self._age = ageif __name__ == '__main__': stu = Student(20) print stu.__name #AttributeError: 'Student' object has no attribute '__name' 子类不能访问 print stu._Person__name #这样可以访问 person=Person("luckylau") #AttributeError: 'Person' object has no attribute '__name' 实例不能访问 print person.__name #AttributeError: 'Person' object has no attribute '__name' 实例不能访问 print person._Person__name #这样可以访问 print person.__dict__ #&#123;'_Person__name': 'luckylau'&#125; __xxx__ 以双下划线开头，并且以双下划线结尾的，是内置变量，内置变量是可以直接访问的，不是 private 变量，所以，不要自己定义这类变量。 123456__init____file____dirt__...]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(3)]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BD%A0%E6%87%82python%E5%90%97-3%2F</url>
      <content type="text"><![CDATA[@staticmethod和@classmethod的区别什么是python的修饰符Decorators？​ 装饰器模式可以在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责，也能够处理那些可以撤销的职责。经常用于日志记录、性能测试等场合。 ​ 想象一下这个很常见的场景，你写了一个方法： 1234567891011121314151617181920def A(n): if n &gt; 2: print n print "aaaaaa" else: print A.__name__def B(n): if n &gt;2: print n print "bbbbbb" else: print B.__name__if __name__ == '__main__': A(3) B(3)#ouptput3aaaaaa3bbbbbb 用修饰符优美的表达式 12345678910111213141516171819202122def decorator(fn): def inner(n): if n&gt;2: print n else: print fn.__name__ return inner@decoratordef A(n): print "aaaaaa"@decoratordef B(n): print "bbbbbb"if __name__ == '__main__': A(3) B(3)# output3aaaaaa3bbbbbb 当有多个修饰符时候，由远及近影响，如下： 123456789101112131415def tag_wrap(tag): def decorator(fn): def inner(s): return '&lt;%s&gt;%s&lt;%s&gt;' % (tag, fn(s), tag) return inner return decorator@tag_wrap('a')@tag_wrap('b')@tag_wrap('c')def greet(name): return 'Hello, %s!' % nameif __name__ == '__main__': print(greet('world'))#output&lt;a&gt;&lt;b&gt;&lt;c&gt;Hello, world!&lt;c&gt;&lt;b&gt;&lt;a&gt; 我们再举一个日志的例子 12345678910111213141516171819202122232425262728293031323334def log_calls(fn): def inner(*args, **kwargs): out = apply(fn, args, kwargs) with open('logfile.log', 'a') as logfile: logfile.write('%s called with args %s and kwargs %s, returning %s\n' % (fn.__name__, args, kwargs, out)) return out return inner@log_callsdef fizz_buzz_or_number(i): if i % 15 == 0: return 'fizzbuzz' elif i % 3 == 0: return 'fizz' elif i % 5 == 0: return 'buzz' else: return iif __name__ == '__main__': for i in range(1, 31): print(fizz_buzz_or_number(i))#outputfizz_buzz_or_number called with args (1,) and kwargs &#123;&#125;, returning 1fizz_buzz_or_number called with args (2,) and kwargs &#123;&#125;, returning 2fizz_buzz_or_number called with args (3,) and kwargs &#123;&#125;, returning fizzfizz_buzz_or_number called with args (4,) and kwargs &#123;&#125;, returning 4fizz_buzz_or_number called with args (5,) and kwargs &#123;&#125;, returning buzzfizz_buzz_or_number called with args (6,) and kwargs &#123;&#125;, returning fizzfizz_buzz_or_number called with args (7,) and kwargs &#123;&#125;, returning 7... @staticmethod和@classmethodPython其实有3个方法,即静态方法(staticmethod),类方法(classmethod)和实例方法 @staticmethod和@classmethod本身也是装饰器的一种特例。先看下面的例子： 12345678910111213141516171819202122232425262728293031def foo(x): print "executing foo(%s)"%(x)class A(object): def foo(self,x): print "executing foo(%s,%s)"%(self,x) @classmethod def class_foo(cls,x): #不需要self参数，但第一个参数需要是表示自身类的cls参数 print "executing class_foo(%s,%s)"%(cls,x) @staticmethod def static_foo(x): #不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样 print "executing static_foo(%s)"%xif __name__ == '__main__': a=A() a.class_foo(3) a.foo(3) a.static_foo(3) A.class_foo(3) A.static_foo(3) A.foo(3) #outputexecuting class_foo(&lt;class '__main__.A'&gt;,3)executing foo(&lt;__main__.A object at 0x7f79857c9350&gt;,3)executing static_foo(3)executing class_foo(&lt;class '__main__.A'&gt;,3)executing static_foo(3)A.foo(3)TypeError: unbound method foo() must be called with A instance as first argument (got int instance instead) \ 实例方法 类方法 静态方法 a = A() a.foo(x) a.class_foo(x) a.static_foo(x) A 不可用 A.class_foo(x) A.static_foo(x 参考：http://pythoncentral.io/difference-between-staticmethod-and-classmethod-in-python/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[云计算中的IAAS，PASS，SAAS的区别]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84IAAS%EF%BC%8CSAAS-PASS%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[什么是云计算？​ “云”其实是互联网的一个隐喻，“云计算”其实就是使用互联网来接入存储或者运行在远程服务器端的应用，数据，或者服务。任何一个使用基于互联网的方法来计算，存储和开发的公司，都可以从技术上叫做从事云的公司。 IAAS,SAAS,PASS的通俗解释？ IAAS,SAAS,PASS的概念？Iaas（基础设施即服务Infrastructure as a Service） ​ IaaS就是专门提供基础设施服务，IaaS公司会提供场外服务器，存储和网络硬件，你可以租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。一些大的IaaS公司包括Amazon, Microsoft, VMWare, Rackspace和Red Hat.不过这些公司又都有自己的专长，比如Amazon和微软给你提供的不只是IaaS，他们还会将其计算能力出租给你来host你的网站。 Paas（平台即服务Platform-as-a-Service） ​ 第二层就是所谓的PaaS，某些时候也叫做中间件。你公司所有的开发都可以在这一层进行，节省了时间和资源。PaaS公司在网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统。这节省了你在硬件上的费用，也让分散的工作室之间的合作变得更加容易。网页应用管理，应用设计，应用虚拟主机，存储，安全以及应用开发协作工具等。一些大的PaaS提供者有Google App Engine,Microsoft Azure，Force.com,Heroku，Engine Yard。最近兴起的公司有AppFog,Mendix和Standing Cloud. Saas（软件即服务Software-as-a-Service） ​ 第三层也就是所谓SaaS。这一层是和你的生活每天接触的一层，大多是通过网页浏览器来接入。任何一个远程服务器上的应用都可以通过网络来运行，就是SaaS了。你消费的服务完全是从网页如Netflix,MOG,Google Apps,Box.net,Dropbox或者苹果的iCloud那里进入这些分类。尽管这些网页服务是用作商务和娱乐或者两者都有，但这也算是云技术的一部分。一些用作商务的SaaS应用包括Citrix的Go To Meeting，Cisco的WebEx，Salesforce的CRM，ADP，Workday和SuccessFactors。 参考:https://www.zhihu.com/question/21641778]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂java吗(1)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82java%E5%90%97-1%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(2)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82python%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[深刻理解Python中的元类(metaclass)问题 ：什么是metaclass？在哪些情况会使用？ 类也是对象​ 在理解元类之前，你需要先掌握Python中的类。Python中类的概念借鉴于Smalltalk，这显得有些奇特。在大多数编程语言中，类就是一组用来描述如何生成一个对象的代码段。在Python中这一点仍然成立： 1234567class ObjectCreator(object): passif __name__ == '__main__': my_object=ObjectCreator() print my_object#output&lt;__main__.ObjectCreator object at 0x7f8fd686d450&gt; ​ 但是，Python中的类还远不止如此。类同样也是一种对象。是的，没错，就是对象。只要你使用关键字class，Python解释器在执行的时候就会创建一个对象。将在内存中创建一个对象，名字就是ObjectCreator。这个对象（类）自身拥有创建对象（类实例）的能力，而这就是为什么它是一个类的原因。但是，它的本质仍然是一个对象，于是乎你可以对它做如下的操作： 1) 你可以将它赋值给一个变量 2) 你可以拷贝它 3) 你可以为它增加属性 4) 你可以将它作为函数参数进行传递 下面的代码段： 1234567891011121314151617181920class ObjectCreator(object): passdef echo(o): print oif __name__ == '__main__': echo(ObjectCreator) #作为函数参数进行传递 echo(ObjectCreator()) print hasattr(ObjectCreator, 'new_attribute') ObjectCreator.new_attribute = 'foo' #增加属性 print hasattr(ObjectCreator, 'new_attribute') print ObjectCreator.new_attribute ObjectCreatorMirror = ObjectCreator #赋值给一个变量 print ObjectCreatorMirror()#output&lt;class '__main__.ObjectCreator'&gt;&lt;__main__.ObjectCreator object at 0x7f94fa648450&gt;FalseTruefoo&lt;__main__.ObjectCreator object at 0x7f94fa558e10&gt; 动态地创建类​ 因为类也是对象，你可以在运行时动态的创建它们，就像其他任何对象一样。首先，你可以在函数中创建类，使用class关键字即可。 1234567891011121314151617def choose_class(name): if name == 'foo': class Foo(object): pass return Foo # 返回的是类，不是类的实例 else: class Bar(object): pass return Barif __name__ == '__main__': MyClass = choose_class('foo') print MyClass # 函数返回的是类，不是类的实例 print MyClass() # 你可以通过这个类创建类实例，也就是对象#output&lt;class '__main__.Foo'&gt;&lt;__main__.Foo object at 0x7f401385a450&gt; ​ 但这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是通过什么东西来生成的才对。当你使用class关键字时，Python解释器自动创建这个对象。但就和Python中的大多数事情一样，Python仍然提供给你手动处理的方法。还记得内建函数type吗？这个古老但强大的函数能够让你知道一个对象的类型是什么，就像这样： 12345678910111213class ObjectCreator(object): passif __name__ == '__main__': print type(1) print type("1") print type(ObjectCreator) print type(ObjectCreator()) # output&lt;type 'int'&gt;&lt;type 'str'&gt;&lt;type 'type'&gt;&lt;class '__main__.ObjectCreator'&gt; 这里，type有一种完全不同的能力，它也能动态的创建类。type可以接受一个类的描述作为参数，然后返回一个类。（我知道，根据传入参数的不同，同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后兼容性） type可以像这样工作： 1type(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）) 可以手动像这样创建： 1234567891011if __name__ == '__main__': MyShinyClass = type('MyShinyClass', (), &#123;&#125;) # 返回一个类对象 等价于 # class MyShinyClass(object): # pass # print MyShinyClass print MyShinyClass() # 创建一个该类的实例#output&lt;class '__main__.MyShinyClass'&gt;&lt;__main__.MyShinyClass object at 0x7fc8bb86a450&gt; ​ 你会发现我们使用“MyShinyClass”作为类名，并且也可以把它当做一个变量来作为类的引用。类和变量是不同的，这里没有任何理由把事情弄的复杂。 1234567891011121314if __name__ == '__main__': foo = type('Foo', (), &#123;'bar': False&#125;) #等价于class Foo(object): # bar = False print foo print foo.bar f = foo() #将foo当成一个普通的类一样使用 print f print f.bar #output &lt;class '__main__.Foo'&gt; False &lt;__main__.Foo object at 0x7f9868844450&gt; False type 接受一个字典来为类定义属性，并且可以将foo当成一个普通的类一样使用 12345678910if __name__ == '__main__': foo = type('Foo', (), &#123;'bar': False&#125;) class foochild(foo): pass FooChild = type('foochild', (foo,), &#123;&#125;) print FooChild print FooChild.bar # bar属性是由foo继承而来#output &lt;class '__main__.foochild'&gt; False 你可以看到，在Python中，类也是对象，你可以动态的创建类。这就是当你使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的。 到底什么是元类​ 元类就是用来创建类的“东西”。你创建类就是为了创建类的实例对象，不是吗？但是我们已经学习到了Python中的类也是对象。好吧，元类就是用来创建这些类（对象）的，元类就是类的类。 你已经看到了type可以让你像这样做： 1MyClass = type('MyClass', (), &#123;&#125;) ​ 这是因为函数type实际上是一个元类。type就是Python在背后用来创建所有类的元类。现在你想知道那为什么type会全部采用小写形式而不是Type呢？好吧，我猜这是为了和str保持一致性，str是用来创建字符串对象的类，而int是用来创建整数对象的类。type就是创建类对象的类。你可以通过检查class属性来看到这一点。Python中所有的东西，注意，我是指所有的东西——都是对象。这包括整数、字符串、函数以及类。它们全部都是对象，而且它们都是从一个类创建而来。 1234567891011121314151617181920212223242526def foo(): passclass Bar(object): passif __name__ == '__main__': age=35 name="lucky" b = Bar() print age.__class__ print name.__class__ print foo.__class__ print b.__class__ print Bar.__class__ print age.__class__.__class__ print name.__class__.__class__ print b.__class__.__class__# output&lt;type 'int'&gt;&lt;type 'str'&gt;&lt;type 'function'&gt;&lt;class '__main__.Bar'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt; 因此，元类就是创建类这种对象的东西。如果你喜欢的话，可以把元类称为“类工厂”（不要和工厂类搞混了:D） type就是Python的内建元类，当然了，你也可以创建自己的元类。 创建自己的元类首先了解metaclass**属性** 12class Foo(object): __metaclass__ = something 你可以在写一个类的时候为其添加metaclass属性,如果你这么做了，Python就会用元类来创建类Foo。小心点，这里面有些技巧。你首先写下class Foo(object)，但是类对象Foo还没有在内存中创建。Python会在类的定义中寻找metaclass属性，如果找到了，Python就会用它来创建类Foo，如果没有找到，就会用内建的type来创建这个类。把下面这段话反复读几次。当你写如下代码时 : 12class Foo(Bar): pass Python做了如下的操作： Foo中有metaclass这个属性吗？如果是，Python会在内存中通过metaclass创建一个名字为Foo的类对象（我说的是类对象，请紧跟我的思路）。如果Python没有找到metaclass，它会继续在Bar（父类）中寻找metaclass属性，并尝试做和前面同样的操作。如果Python在任何父类中都找不到metaclass，它就会在模块层次中去寻找metaclass，并尝试做同样的操作。如果还是找不到metaclass,Python就会用内置的type来创建这个类对象。 现在的问题就是，你可以在metaclass中放置些什么代码呢？答案就是：可以创建一个类的东西。那么什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东东都可以。 ​ 元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。假想一个很傻的例子，你决定在你的模块里所有的类的属性都应该是大写形式。有好几种方法可以办到，但其中一种就是通过在模块级别设定metaclass。采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改成大写形式就万事大吉了。 ​ 幸运的是，metaclass实际上可以被任意调用，它并不需要是一个正式的类（我知道，某些名字里带有‘class’的东西并不需要是一个class，画画图理解下，这很有帮助）。所以，我们这里就先以一个简单的函数作为例子开始。 123456789101112131415161718192021222324252627282930313233343536373839404142import six# 元类会自动将你通常传给‘type’的参数作为自己的参数传入def upper_attr(future_class_name, future_class_parents, future_class_attr): ''' 返回一个类对象，将属性都转为大写形式 :param future_class_name: :param future_class_parents: :param future_class_attr: :return: ''' # 选择所有不以'__'开头的属性 attrs = ((name, value)for name, value in future_class_attr.items() if not name.startswith('__')) # 将它们转为大写形式 uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 通过'type'来做类对象的创建 return type(future_class_name, future_class_parents, uppercase_attr)#__metaclass__ = upper_attr #这会作用到这个模块中的所有类class Foo(object): # 我们也可以只在这里定义__metaclass__，这样就只会作用于这个类中 __metaclass__ = upper_attr bar = 'bar'@six.add_metaclass(upper_attr) #还可以这么设置metaclassclass Doo(object): doo = "doo" if __name__ == '__main__': print hasattr(Foo, 'bar') print hasattr(Foo, 'BAR') if hasattr(Foo, 'BAR'): f = Foo() print f.BAR print hasattr(Doo, 'DOO')#outputFalseTruebarTrue 现在让我们再做一次，这一次用一个真正的class来当做元类: 1234567891011121314# 请记住，'type'实际上是一个类，就像'str'和'int'一样# 所以，你可以从type继承class UpperAttrMetaClass(type): # __new__ 是在__init__之前被调用的特殊方法 # __new__是用来创建对象并返回之的方法 # 而__init__只是用来将传入的参数初始化给对象 # 你很少用到__new__，除非你希望能够控制对象的创建 # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情 # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用 def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type(future_class_name, future_class_parents, uppercase_attr) 但是，这种方式其实不是OOP。我们直接调用了type，而且我们没有改写父类的new方法。现在让我们这样去处理: 12345678class UpperAttrMetaclass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 复用type.__new__方法 # 这就是基本的OOP编程，没什么魔法 return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr) 你可能已经注意到了有个额外的参数upperattr_metaclass，这并没有什么特别的。类方法的第一个参数总是表示当前的实例，就像在普通的类方法中的self参数一样。当然了，为了清晰起见，这里的名字我起的比较长。但是就像self一样，所有的参数都有它们的传统名称。因此，在真实的产品代码中一个元类应该是像这样的： 12345class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__') uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type.__new__(cls, name, bases, uppercase_attr) 如果使用super方法的话，我们还可以使它变得更清晰一些，这会缓解继承（是的，你可以拥有元类，从元类继承，从type继承） 123456789101112131415class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return super(UpperAttrMetaclass, cls).__new__(cls, name, bases, uppercase_attr)class doo(): __metaclass__ = UpperAttrMetaclass doo="doo"if __name__ == '__main__': foo=UpperAttrMetaclass("Foo",(),&#123;'bar' :"foo"&#125;) print hasattr(foo, 'bar') print hasattr(doo, 'DOO')#outputFalseTrue 就是这样，除此之外，关于元类真的没有别的可说的了。使用到元类的代码比较复杂，这背后的原因倒并不是因为元类本身，而是因为你通常会使用元类去做一些晦涩的事情，依赖于自省，控制继承等等。确实，用元类来搞些“黑暗魔法”是特别有用的，因而会搞出些复杂的东西来。但就元类本身而言，它们其实是很简单的： 1) 拦截类的创建 2) 修改类 3) 返回修改之后的类 为什么要用metaclass类而不是函数?由于metaclass可以接受任何可调用的对象，那为何还要使用类呢，因为很显然使用类会更加复杂啊？这里有好几个原因： 1） 意图会更加清晰。当你读到UpperAttrMetaclass(type)时，你知道接下来要发生什么。 2） 你可以使用OOP编程。元类可以从元类中继承而来，改写父类的方法。元类甚至还可以使用元类。 3） 你可以把代码组织的更好。当你使用元类的时候肯定不会是像我上面举的这种简单场景，通常都是针对比较复杂的问题。将多个方法归总到一个类中会很有帮助，也会使得代码更容易阅读。 4） 你可以使用new, init以及call这样的特殊方法。它们能帮你处理不同的任务。就算通常你可以把所有的东西都在new里处理掉，有些人还是觉得用init更舒服些。 5） 哇哦，这东西的名字是metaclass，肯定非善类，我要小心！ 现在回到我们的大主题上来，究竟是为什么你会去使用这样一种容易出错且晦涩的特性？好吧，一般来说，你根本就用不上它： 12Metaclasses are deeper magic that 99% of users should never worry about. If you wonder whether you need them, you don&apos;t (the people who actually need them know with certainty that they need them, and don&apos;t need an explanation about why).Python Guru Tim Peters “元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类。” —— Python界的领袖 Tim Peters 元类的主要用途是创建API。一个典型的例子是Django ORM。它允许你像这样定义： 123class Person(models.Model): name = models.CharField(max_length=30) age = models.IntegerField() 但是如果你像这样做的话： 12guy = Person(name='bob', age='35')print guy.age 这并不会返回一个IntegerField对象，而是会返回一个int，甚至可以直接从数据库中取出数据。这是有可能的，因为models.Model定义了metaclass， 并且使用了一些魔法能够将你刚刚定义的简单的Person类转变成对数据库的一个复杂hook。Django框架将这些看起来很复杂的东西通过暴露出一个简单的使用元类的API将其化简，通过这个API重新创建代码，在背后完成真正的工作。 结语：首先，你知道了类其实是能够创建出类实例的对象。好吧，事实上，类本身也是实例，当然，它们是元类的实例。Python中的一切都是对象，它们要么是类的实例，要么是元类的实例，除了type。type实际上是它自己的元类，在纯Python环境中这可不是你能够做到的，这是通过在实现层面耍一些小手段做到的。其次，元类是很复杂的。对于非常简单的类，你可能不希望通过使用元类来对类做修改。你可以通过其他两种技术来修改类： 1） Monkey patching 2) class decorators 当你需要动态修改类时，99%的时间里你最好使用上面这两种技术。当然了，其实在99%的时间里你根本就不需要动态修改类 :D 参考：http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python http://blog.jobbole.com/21351/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(1)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82python%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[Python的函数参数传递示例一： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c=2 print "test after" print id(c) return cif __name__ == '__main__': a=1 print "main before" print id(a) test(a) print "main after" print id(a) print a# outputmain before12460376test before12460376test after12460352main after124603761 示例二： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c.append(1) print "test after" print id(c) return cif __name__ == '__main__': a=[] print "main before" print id(a) test(a) print "main after" print id(a) print a #output main before139625132046312test before139625132046312test after139625132046312main after139625132046312[1] 示例三： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c=[2,3] print "test after" print id(c) return cif __name__ == '__main__': a=[1] print "main before" print id(a) test(a) print "main after" print id(a) print a# outputmain before139900695660520test before139900695660520test after139900695661672main after139900695660520[1] 总结： ​ 对象有两种,“可更改”（mutable）与“不可更改”（immutable）对象。在python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。对于不可更改对象而言一定是“值传递”引用，如示例一；对于可更改对象也可以“值传递”，如示例三；对于示例二，传入的是可变对象，并且函数对其进行操作，属于“引用传递”。 函数参数的定义有四种形式： F(arg1,arg2,…) F(arg2=,arg3=…) F(*arg1) F(**arg1) 12345678910111213141516171819202122232425262728293031323334def test(x,y=5,*a,**b): print x,y,a,bif __name__ == '__main__': test(1) test(1, 2) test(1, 2, 3) test(1, 2, 3, 4) test(1, 2, (3, 4),5) test(1, 2, 3, 4, 5,a=2) test(x=1) test(x=1,y=2) test(x=1,y=2,a=3) test(x=1,y=2,a=3,b=4) test(x=1, y=2, a=3, b=4,c=5) test(1, 2, z=1) test(1, 2, 3, a=1) test(1, 2, 3, 4, a=1) test(1, 2, 3, 4, a=1, b=2, c=3) #output 1 5 () &#123;&#125; 1 2 () &#123;&#125; 1 2 (3,) &#123;&#125; 1 2 (3, 4) &#123;&#125; 1 2 ((3, 4), 5) &#123;&#125; 1 2 (3, 4, 5) &#123;'a': 2&#125; 1 5 () &#123;&#125; 1 2 () &#123;&#125; 1 2 () &#123;'a': 3&#125; 1 2 () &#123;'a': 3, 'b': 4&#125; 1 2 () &#123;'a': 3, 'c': 5, 'b': 4&#125; 1 2 () &#123;'z': 1&#125; 1 2 (3,) &#123;'a': 1&#125; 1 2 (3, 4) &#123;'a': 1&#125; 1 2 (3, 4) &#123;'a': 1, 'c': 3, 'b': 2&#125; 首先按顺序把“arg”这种形式的实参给对应的形参； 第二，把“arg=”这种形式的实参赋值给形参； 第三，把多出来的“arg”这种形式的实参组成一个tuple给带一个星号的形参； 第四，把多出来的“key=value”这种形式的实参转为一个dictionary给带两个星号的形参。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LoadBalancerv2的原理分析]]></title>
      <url>%2F2017%2F03%2F10%2FLoadBalancerv2%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[​ OpenStack 是直接采用各种开源可用的负载均衡项目来完成负载均衡的任务，默认使用 HAProxy。LBaaSv2 本质来说，其实也是根据用户提出的负载均衡要求，生成符合的HAProxy配置文件并启动 HAProxy，然后由 HAProxy 进行负载均衡。 High Availability Proxy（HAProxy）？​ HAProxy 是个著名的开源的软件 TCP（四层）/HTTP（七层） 负载均衡器和代理（proxy）软件，可以运行在 Linux，Solaris 和 FreeBSD 等系统上。目前，它已经被许多大公司采用，包括GitHub, Imgur, Instagram, and Twitter 等。它类似 Nginx 的，采用了单进程和事件驱动模型；它使用的内存量低而且稳定，能够处理大量并发请求。 在这里我简单罗列HAProxy配置。 haproxy 配置中分成五部分内容，分别如下：​ global：参数是进程级的，通常是和操作系统相关。这些参数一般只设置一次，如果配置无误，就不需要再次进行修改。​ defaults：配置默认参数，这些参数可以被用到frontend，backend，Listen组件。​ frontend：接收请求的前端虚拟节点，Frontend可以更加规则直接指定具体使用后端的backend。​ backend：后端服务集群的配置，是真实服务器，一个Backend对应一个或者多个实体服务器。​ Listen Fronted和backend的组合体。 neutron的LoadBalancerv2配置文件在 /etc/haproxy/haproxy.cfg中 12345678910111213141516171819202122232425262728293031323334353637###########全局配置######### global log /dev/log local0 #[日志输出配置，所有日志都记录在本机，通过local0输出] log /dev/log local1 notice #定义haproxy 日志级别[error warringinfo debug] chroot /var/lib/haproxy stats socket /run/haproxy/admin.sock mode 660 level admin stats timeout 30s user haproxy group haproxy #可以由配置项 user_group 指定，默认为 nogroup daemon #以后台形式运行harpoxy # Default SSL material locations ca-base /etc/ssl/certs crt-base /etc/ssl/private # Default ciphers to use on SSL-enabled listening sockets. # For more information, see ciphers(1SSL). This list is from: # https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS ssl-default-bind-options no-sslv3 ########默认配置############ defaults log global mode http option httplog option dontlognull timeout connect 5000 timeout client 50000 timeout server 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.http 我们事先创建了qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2，我们看看它的配置文件 12root@netagent:~# ip netns listqlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 该负载均衡是1个LoadBalance对应1个listener,1个pool。 在/var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy.conf 中 12345678910111213141516171819202122232425262728293031323334# Configuration for loadbalance1global daemon user nobody group haproxy log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy_stats.sock mode 0666 level userdefaults log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 62ac018e-f6fc-4d60-80df-13b1e4cdc6f6 option tcplog maxconn 100 option forwardfor bind 2.2.2.20:80 mode http default_backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 mode http balance roundrobin timeout check 1 option httpchk GET /index.html http-check expect rstatus 201|200|202 server d56fc582-33cd-4fc7-b95f-16534c8a4860 2.2.2.5:80 weight 1 check inter 1s fall 5 server cc2230bf-f3b8-4beb-8584-71b0f3a0ba5c 2.2.2.4:80 weight 1 check inter 1s fall 5 server b490cadb-cff1-4e7a-92c7-a134c0f8b321 2.2.2.6:80 weight 1 check inter 1s fall 5 LBaasv2 可以看做 OpenStack Neutron 对各种物理负载均衡器的虚拟化。它的概念可以和 HAProxy 中的概念进行类比： HAProxy 的概念 LBaasv2 的概念 说明 Driver LBaas v2也是采取 driver 模型来支持多种物理的负载均衡器。LBaasv2 默认实现了 HAProxy driver，同时，它也支持多个其他 Vendor driver。 Frontend Listener LBaasv2采用Listener方式将流量转移到不同的pool中的member。 Backend Pool 代表Listener所监听的负载后端的虚拟机池。 Backend server Member Member 对应的是 pool 里面处理网络请求的一个 OpenStack Nova 虚机 Health check Health monitor 它用来监测 pool 里面 member 的状态，支持 HTTP, TCP, 和 ping 等多种检测方法。在 Nuetron 中这是可选的，如果没有 Health monitor，pool 会一直认为所有的 member 都是 ACTIVE 状态，这样所有的 member 会一直出现在 VIP 的分发列表中，哪怕 member 对应的实例不能响应网络请求。这在实际应用中会造成负载均衡的响应异常。 LoadBalancerv2的使用场景？ ​ 由上图可知道，一个LoadBalancerv2可以对应多个Pool,我们另外又建立一个pool如下所示： 在/var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy.conf 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# Configuration for loadbalance1global daemon user nobody group haproxy #可以由配置项 user_group 指定，默认为 nogroup log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy_stats.sock mode 0666 level user defaults #不用管 log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 62ac018e-f6fc-4d60-80df-13b1e4cdc6f6 option tcplog maxconn 100 option forwardfor # 当 mode 为 ”http“时，设置 forwardfor，使得通过 X-Forward-For 头来保存原始的源 IP 地址 bind 2.2.2.20:80 #监听Listener的vip:port mode http #监听Protocol default_backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 #对应的监听池frontend bf144f31-cdbb-4426-b90b-4bdbc67501f1 option tcplog maxconn 100 option forwardfor bind 2.2.2.20:100 mode http default_backend 8b50ed30-5290-421c-9d31-fb3751a26be2backend 8b50ed30-5290-421c-9d31-fb3751a26be2 mode http balance roundrobin server bef852d0-9164-46ee-ace5-92462e8d89ef 2.2.2.14:100 weight 1 server 8aeb5cc2-7301-4931-ac3b-e0d0ca891e88 2.2.2.15:100 weight 1 server 250a919f-dfc1-41b6-8378-2b4015f1acd0 2.2.2.16:100 weight 1backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 mode http balance roundrobin timeout check 1 option httpchk GET /index.html http-check expect rstatus 201|200|202 server cc2230bf-f3b8-4beb-8584-71b0f3a0ba5c 2.2.2.4:80 weight 1 check inter 1s fall 5 #member1 的配置，包括 ip，port（member 提供服务的端口，此时没有指定check port，因此也是健康检查的 TCP端口），weight；check 指定做健康检查；inter 指定两次连续检查之间的间隔，默认2s (1s）；fall 指定 Max Retries 或者连续几次检查失败即认为member 是 DOWN 的次数 （5） server d56fc582-33cd-4fc7-b95f-16534c8a4860 2.2.2.5:80 weight 1 check inter 1s fall 5 server b490cadb-cff1-4e7a-92c7-a134c0f8b321 2.2.2.6:80 weight 1 check inter 1s fall 5 访问wget -O - http://2.2.2.2:80 和wget -O - http://2.2.2.2:100都成功。 以上是vip与pool的members同在一个subnet下，下面我们验证一下vip与pool的members不在同一个subnet。 我们创建一个新的Loadbalance和一个listener,vip地址为7.7.7.7,然后创建一个pool,注意一个虚拟机可以加入多个pool,所以我们还把上面的虚拟机加入这个新建的pool中。然后通过路由器subnet7.7.7.0/24和subnet2.2.2.0/24连通。也就是说vip7.7.7.7能与member2.2.2.4,2.2.2.5,2.2.2.6是联通的。 配置如下/var/lib/neutron/lbaas/v2/5081116f-8928-40d7-8aaa-e30c336ca713/haproxy.conf 12345678910111213141516171819202122232425262728293031# Configuration for loadbalance3global daemon user nobody group haproxy log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/5081116f-8928-40d7-8aaa-e30c336ca713/haproxy_stats.sock mode 0666 level userdefaults log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 84800dd3-0507-4628-b54b-a23226bec4f8 option tcplog maxconn 100 option forwardfor bind 7.7.7.7:80 mode http default_backend 3583deda-e9ca-40bb-ba23-0fec204c099fbackend 3583deda-e9ca-40bb-ba23-0fec204c099f mode http balance roundrobin server 48b36860-8e4d-476e-9196-ad052c317f44 2.2.2.5:80 weight 1 server f8732b2a-bfaa-4e5f-b8bb-f88c9fed899b 2.2.2.4:80 weight 1 server 004f7950-4031-4de3-98b2-ca30e39c4e4e 2.2.2.6:80 weight 1 也就是说只要vip与member可通信即可，不一定要在同一个subnet中。 另外，如果要从外网访问的话，则还需要创建一个 floating ip 并且把它关联到 lb 的vip 上。 haproxy 所在的namespace 其实只有一个IP地址，分别接收外部连接以及和成员之间的连接。 LoadBalancerv2的多agent模式？​ LoadBalancerv2服务可以独立部署在服务器上，包括2个服务，neutron-openvswitch-agent 和neutron-lbassv2-agent。假设有2个节点都部署了LoadBalancerv2服务，当neutron-server发出创建请求时，会在这两个节点选择一个创建对应得namespace空间。 LoadBalancerv2的流程分析？​ 我们以qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2为例子来分析这个过程。 12345678910111213ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever9: tap83f82fcf-d1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:d1:c8:b1 brd ff:ff:ff:ff:ff:ff inet 2.2.2.20/24 brd 2.2.2.255 scope global tap83f82fcf-d1 #vip的地址 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fed1:c8b1/64 scope link valid_lft forever preferred_lft forever ​ 该接口tap83f82fcf-d1挂在ovs上，并被打上它所在network的vlan_id的: 12345678910111213Bridge br-int fail_mode: secure Port patch-tun Interface patch-tun type: patch options: &#123;peer=patch-int&#125; Port br-int Interface br-int type: internal Port &quot;tap83f82fcf-d1&quot; tag: 1 Interface &quot;tap83f82fcf-d1&quot; type: internal ​ 对于LoadBalancerv2创建过程（在v2中指Create a load balancer和Create listener完成，我们发现当只是完成Create a load balancer时候，并没有出现namespace，当Create listener完成时才会有namespace出现）我们对等如下操作： 12345678910111213141516171819202122232425ovs-vsctl --if-exists del-port tap83f82fcf-d1 --add-port br-int tap83f82fcf-d1 --set Interface tap83f82fcf-d1 type=internal --set Interface tap83f82fcf-d1 external-ids:iface-id=83f82fcf-d141-4774-87a0-ace79196bc88 --set Interface tap83f82fcf-d1 external-ids:iface-status=active --set Interface tap83f82fcf-d1 external-ids:attached-mac=fa:16:3e:d1:c8:b1#iface-id 和 attached-mac可以在数据库中查到ip link set tap83f82fcf-d1 address fa:16:3e:d1:c8:b1ip netns add qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 sysctl -w net.ipv4.conf.all.promote_secondaries=1ip link set tap83f82fcf-d1 netns qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip link set lo upip link set tap83f82fcf-d1 netns qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip link set tap83f82fcf-d1 upip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip addr show tap83f82fcf-d1 permanent scope globalip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip -4 addr add 2.2.2.20/24 brd 255.255.255.0 scope global dev tap83f82fcf-d1ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip route list dev tap83f82fcf-d1 scope linkip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 route add default gw 2.2.2.1ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 arping -U -I tap83f82fcf-d1 -c 3 2.2.2.20 LoadBalancerv2的源码解读？​ LoadBalancerv2的代码结构如下： 1.Create a load balancer 2.Create a listener 3.Create a pool 4.Add member 5.Create a health monitor 参考：http://blog.csdn.net/zhu_tianwei/article/details/41117323]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IO的同步与异步，阻塞与非阻塞]]></title>
      <url>%2F2017%2F03%2F08%2FIO%E7%9A%84%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5%EF%BC%8C%E9%98%BB%E5%A1%9E%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
      <content type="text"><![CDATA[​ 同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？我们以Linux环境下的network IO来讨论。 ​ 对于一个network IO (以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 1 等待数据准备 (Waiting for the data to be ready) 2 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I/O Models ”有以下5种： blocking IO nonblocking IO IO multiplexing signal driven IO asynchronous IO。其中signal driven IO不常见，以下分析4中模型。然后再区分IO的同步与异步，阻塞与非阻塞。 I/O Models1.阻塞式I/O模型 blocking IO 在linux中，默认情况下所有的socket都是blocking ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据；对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。这时在用户进程这边，整个进程挂起，被阻塞。kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。​ 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 2.非阻塞I/O模型 non-blocking IO linux下，可以通过设置socket使其变为non-blocking。 ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据；对于network io来说，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程没有被挂起，可以干些别的，但是需要不断的主动询问kernel数据好了没有，直到准备好，发起一个系统调用。但是在第二个阶段仍然是block的。 3.I/O复用模型 IO multiplexing ​ I/O复用最常见的就是select和epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 ​ 当用户进程调用了select，那么整个进程会被block，不能干别的，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。这个和阻塞式I/O模型 blocking IO的区别在于这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 4.异步I/O模型 Asynchronous I/O ​ 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 四者的区别：blocking vs non-blocking：调用blocking IO会一直block住对应的进程直到操作完成，准备阶段和拷贝阶段都被blocking，而non-blocking IO在kernel还准备数据的情况下会立刻返回，只是在拷贝阶段blocking。 synchronous IO和asynchronous IO： 首先看定义：（简单来说：同步I/O：导致请求进程阻塞，直到I/O操作完成；异步I/O: 不导致请求进程阻塞。） A synchronous I/O operation causes the requesting process to be blocked until that I/O operationcompletes; An asynchronous I/O operation does not cause the requesting process to be blocked; blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 ​ 有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 通俗的例子： 3个人排队去买包子，甲买肉馅馒头，乙买素馅馒头，丙买白馒头。 如果是阻塞式I/O模型，按照先后到来顺序处理甲乙丙，甲到来时候，店铺老板说我在做啊，你就在这等着我做完，哪里也不要去，肉馅馒头做好后给甲，甲可以走了，接着处理乙，乙处理完，再处理丙。 如果是非阻塞式I/O模型，假设还是甲乙丙顺序来，甲询问说我要肉馅馒头，老板说还没有做好，这时侯甲就离开搞其他的事情了，乙到了，询问说我要素馅馒头，老板说还没有做好，这时侯乙就离开搞其他的事情了，丙到了，询问说我要白馒头，老板说还没有做好，这时侯丙就离开搞其他的事情了。只不过甲乙丙还会时不时来询问我要的好了没有，假设白馒头非常好做，某个时刻老板做好了，正巧碰到丙又来询问，老板此刻说你的好了，此时丙哪里也不要去了，什么也不要做了，等着老板把白馒头返回给他。此后甲和乙时不时还来询问我要的好了没有。。可见这时候甲乙丙并不需要一直等待，可以做其他事情，同时并不一定是甲先来一定会被先处理。 如果是I/O复用模型，假设还是甲乙丙顺序来，然后甲乙丙会把自己的需求告诉店小二，然后店小二负责去询问老板肉馅馒头，素馅馒头，白馒头做好了没有。如果在I/O复用模型中，socket没有non-blocking时候，甲乙丙不能走，其他事情也不能做，干等着。店小二通知说素馅馒头好了，这时候乙去见老板拿自己所需要的。我们看到这时候并不是按甲乙丙顺序处理的，虽然甲乙丙被店小二阻塞了，但给人感觉是“并发”，哪个先准备好，先处理哪个。 如果是异步I/O模型，假设还是甲乙丙顺序来，店老板立即给甲乙丙返回一个纸条“好的”，甲乙丙各自散去了，该干嘛就干嘛，这时候店老板做馒头，无论是先做好了甲还是乙丙，就通知他们并把相应的馒头交给他们。甲乙丙也不需要时不时的来询问，更不需要去等待啦。 参考：http://blog.csdn.net/historyasamirror/article/details/5778378 https://www.zhihu.com/question/19732473]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Openstack 负载均衡 LoadBalancerv2]]></title>
      <url>%2F2017%2F03%2F07%2FOpenstack%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1LoadBalancerv2%2F</url>
      <content type="text"><![CDATA[​ 最近研究了一下Openstack负载均衡，yum源和源码级别的安装都尝试成功了。网上有很多文章都是LoadBalancerv1，这个已经被放弃了。所以写一下自己是如何使用LoadBalancerv2。当然在介绍之前还是从负载均衡基础知识开始吧。（Mitaka版本的LoadBalancerv2） 负载均衡的概念和分类？​ 负载均衡（Load Balancing）是将来访的网络流量在运行相同应用的多个服务器之间进行分发的一种核心网络服务。它的功能由负载均衡器（load balancer）提供。负载均衡器可以是一个硬件设备，也可以由软件实现。它充当反向代理，在多个服务器之间分发网络或者应用流量。它常用来增加应用的访问容量（并发用户数）和可靠性，它也会通过降低服务器的负载来提高应用的总体性能。 负载均衡器的分类 负载均衡器一般可以分为两类：第4层负载均衡器和第7层负载均衡器。 第 4 层负载平衡器：基于网络和传输层协议（IP，TCP，FTP，UDP等）来均衡负载。 第7层的负载均衡器：基于应用层协议比如 HTTP, SMTP, SNMP, FTP, Telnet 等均衡负载。比如对 HTTP 来说，第七层的负载均衡器能根据应用的特定数据比如 HTTP 头，cookies 或者应用消息中的数据来做进一步的请求分发。 负载分发算法 ​ 两种类型的负载均衡器都能接收请求，然后根据特定的算法将请求分发到特定的服务器。一些行业标准的算法是： ​ 轮询 (Round robin)：轮流分发到各个（活动）服务器​ 加权轮循 (Weighted round robin)：每个服务器有一定的加权（weight），轮询时考虑加权。​ 最少连接 (Least connections)：转发到有最少连接数的服务器​ 最少响应时间 (Least response time)：转发到响应时间最短的服务器 可靠性和可用性 ​ 负载均衡器通过监控应用的健康状态来确保可靠性和可用性，并且只转发请求到能及时做出响应的服务和应用。 Session persistence （会话保持） ​ 用户(浏览器)在和服务端交互的时候，通常会在本地保存一些信息，而整个过程叫做一个会话(Session)并用唯一的Session ID进行标识。会话的概念不仅用于购物车这种常见情况，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制，此外HTTP客户端也会额外缓存一些数据在本地，这样就可以减少请求提高性能了。如果负载均衡可能将这个会话的请求分配到不同的后台服务端上，这肯定是不合适的，必须通过多个backend共享这些数据，效率肯定会很低下，最简单的情况是保证会话一致性——相同的会话每次请求都会被分配到同一个backend上去。 ​ 会话保持表示在一个会话期间，转发一个用户的请求到同一个后端服务器。这对购物车或者付款类的请求非常重要。 常用的方法包括： ​ Source IP：相同来源的请求转发到同一个服务器​ HTTP Cookie：该模式下，loadbalancer 为客户端的第一次连接生成 cookie，后续携带该 cookie 的请求会被某个 member 处理​ APP Cookie：该模式下，依靠后端应用服务器生成的 cookie 决定被某个 member 处理 负载均衡的实现方式？http重定向 ​ 当http代理（比如浏览器）向web服务器请求某个URL后，web服务器可以通过http响应头信息中的Location标记来返回一个新的URL。这意味着HTTP代理需要继续请求这个新的URL，完成自动跳转。 缺陷：1、吞吐率限制​ 主站点服务器的吞吐率平均分配到了被转移的服务器。现假设使用RR（Round Robin）调度策略，子服务器的最大吞吐率为1000reqs/s，那么主服务器的吞吐率要达到3000reqs/s才能完全发挥三台子服务器的作用，那么如果有100台子服务器，那么主服务器的吞吐率可想而知得有大？相反，如果主服务的最大吞吐率为6000reqs/s，那么平均分配到子服务器的吞吐率为2000reqs/s，而现子服务器的最大吞吐率为1000reqs/s，因此就得增加子服务器的数量，增加到6个才能满足。 2、重定向访问深度不同​ 有的重定向一个静态页面，有的重定向相比复杂的动态页面，那么实际服务器的负载差异是不可预料的，而主站服务器却一无所知。因此整站使用重定向方法做负载均衡不太好。 ​ 我们需要权衡转移请求的开销和处理实际请求的开销，前者相对于后者越小，那么重定向的意义就越大，例如下载。你可以去很多镜像下载网站试下，会发现基本下载都使用了Location做了重定向。 DNS负载均衡 ​ DNS负责提供域名解析服务，当访问某个站点时，实际上首先需要通过该站点域名的DNS服务器来获取域名指向的IP地址，在这一过程中，DNS服务器完成了域名到IP地址的映射，同样，这样映射也可以是一对多的，这时候，DNS服务器便充当了负载均衡调度器，它就像http重定向转换策略一样，将用户的请求分散到多台服务器上，但是它的实现机制完全不同。 ​ 相比http重定向，基于DNS的负载均衡完全节省了所谓的主站点，或者说DNS服务器已经充当了主站点的职能。但不同的是，作为调度器，DNS服务器本身的性能几乎不用担心。因为DNS记录可以被用户浏览器或者互联网接入服务商的各级DNS服务器缓存，只有当缓存过期后才会重新向域名的DNS服务器请求解析。也说是DNS不存在http的吞吐率限制，理论上可以无限增加实际服务器的数量。 缺陷：1、没有用户能直接看到DNS解析到了哪一台实际服务器，加服务器运维人员的调试带来了不便。2、策略的局限性。例如你无法将HTTP请求的上下文引入到调度策略中，而在前面介绍的基于HTTP重定向的负载均衡系统中，调度器工作在HTTP层面，它可以充分理解HTTP请求后根据站点的应用逻辑来设计调度策略，比如根据请求不同的URL来进行合理的过滤和转移。3、如果要根据实际服务器的实时负载差异来调整调度策略，这需要DNS服务器在每次解析操作时分析各服务器的健康状态，对于DNS服务器来说，这种自定义开发存在较高的门槛，更何况大多数站点只是使用第三方DNS服务。4、DNS记录缓存，各级节点的DNS服务器不同程序的缓存会让你晕头转向。5、基于以上几点，DNS服务器并不能很好地完成工作量均衡分配，最后，是否选择基于DNS的负载均衡方式完全取决于你的需要。 反向代理负载均衡 ​ 几乎所有主流的Web服务器都热衷于支持基于反向代理的负载均衡。它的核心工作就是转发HTTP请求。相比前面的HTTP重定向和DNS解析，反向代理的调度器扮演的是用户和实际服务器中间人的角色：1、任何对于实际服务器的HTTP请求都必须经过调度器2、调度器必须等待实际服务器的HTTP响应，并将它反馈给用户（前两种方式不需要经过调度反馈，是实际服务器直接发送给用户） 特性：1、调度策略丰富。例如可以为不同的实际服务器设置不同的权重，以达到能者多劳的效果。2、对反向代理服务器的并发处理能力要求高，因为它工作在HTTP层面。3、反向代理服务器进行转发操作本身是需要一定开销的，比如创建线程、与后端服务器建立TCP连接、接收后端服务器返回的处理结果、分析HTTP头部信息、用户空间和内核空间的频繁切换等，虽然这部分时间并不长，但是当后端服务器处理请求的时间非常短时，转发的开销就显得尤为突出。例如请求静态文件，更适合使用前面介绍的基于DNS的负载均衡方式。4、反向代理服务器可以监控后端服务器，比如系统负载、响应时间、是否可用、TCP连接数、流量等，从而根据这些数据调整负载均衡的策略。5、反射代理服务器可以让用户在一次会话周期内的所有请求始终转发到一台特定的后端服务器上（粘滞会话），这样的好处一是保持session的本地访问，二是防止后端服务器的动态内存缓存的资源浪费。 IP层负载均衡LVS-NAT ​ 我们需要在HTTP层面以下实现负载均衡，这些负载均衡调度器的工作必须由Linux内核来完成，因为我们希望网络数据包在从内核缓冲区进入进程用户地址空间之前，尽早地被转发到其他实际服务器上。而且正因为可以将调度器工作在应用层之下，这些负载均衡系统可以支持更多的网络服务协议，比如ftp，smtp，dns，以及流媒体和VoIP等应用。 ​ DNAT： 反向NAT，将实际服务器放置在内部网络，而作为网关的NAT服务器将来自用户端的数据包转发给内部网络的实际服务器(需要修改的是数据包的目标地址和端口)。比较著名的例子是LVS。NAT调度器的吞吐率很高是因为其在内核中进行请求转发的较低开销。 但是NAT服务器的带宽却成为了瓶颈。幸运的是，LVS提供了另一种负载均衡的方式，那就是直接路由。 直接路由LVS-DR ​ 不同于NAT机制，直接路由的负载均衡调度器工作在数据链路层上，简单地说，它通过修改数据包的目标mac地址，将数据包转发到实际服务器上，并且重要的是，实际服务器的响应数据包将直接发送给客户端，不经过调度器。适用于视频网站（响应的数据包远远超过请求的数据包）。对于LVS-DR，一旦调度器失效，你可以马上将LVS-DR切换到DNS-RR模式 常见的开源软件负载均衡器？​ 负载均衡器 目前有2种，一种是通过硬件来进行进行，常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；另外一种就是类似于LVS/HAProxy、Nginx的基于Linux的开源免费的负载均衡软件策略,这些都是通过软件级别来实现，所以费用非常低廉。 Nginx、LVS及HAProxy是目前最常用的开源软件负载均衡器。 LVS LVS：使用集群技术和Linux操作系统实现一个高性能、高可用的服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。 LVS的特点是： 1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的； 2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； 3、工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived； 4、无流量，保证了均衡器IO的性能不会收到大流量的影响； 5、应用范围比较广，可以对所有应用做负载均衡； 6、软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了；其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。 7、如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。 Nginx Nginx的特点是： 1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是许多朋友喜欢它的原因之一； 2、Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在； 3、Nginx安装和配置比较简单，测试起来比较方便； 4、也可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； 5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测； 6、Nginx仅能支持http和Email，这样就在适用范围上面小很多，这个它的弱势； 7、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web架构，大有和以前最流行的LAMP架构分庭抗争之势，在高流量的环境中也有很好的效果。 8、Nginx现在作为Web反向加速缓存越来越成熟了，很多朋友都已在生产环境下投入生产了，而且反映效果不错，速度比传统的Squid服务器更快，有兴趣的朋友可以考虑用其作为反向代理加速器。 HAProxy HAProxy的特点是： 1、HAProxy是支持虚拟主机的，以前有朋友说这个不支持虚拟主机，我这里特此更正一下。 2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作 3、支持url检测后端的服务器出问题的检测会有很好的帮助。 4、它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。 5、HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。 6、HAProxy的算法现在也越来越多了，具体有如下8种： roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的； static-rr，表示根据权重，建议关注； leastconn，表示最少连接者先处理，建议关注； source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注； ri，表示根据请求的URI； rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name； hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求； rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 负载均衡部署模式？基本的负载均衡场景有3种： Two-Arm (or sometimes called In-Line)（双臂）模式One-Arm（单臂）模式Direct Server Response模式 Two-Arm (or sometimes called In-Line)（双臂）模式 双臂模式有 switched mode（“bridge mode” or “transparent mode”） 和routed mode两种，routed mode要优于switched mode，实际生产环境也没有switched mode方式。 ​ 对于routed mode模式来说，As you can agree, the Load-Balancer is also a router between the “Front End” and “Back End” networks. As such, he can simply do destination IP NAT in client request coming to the load-balanced virtual IP and forward the packet to one of the servers in server farm. During this proces, the destination physical server is chosen by the load-balancing algorithm.Return traffic is going back via the Load-Balancer and the source IP is again changed to the virtual load-balanced IP in the response to the Client. One-Arm（单臂）模式 ​ the Load-Balancer is using only one interface and this interface is on the same L2 network with all the servers. ​ The traffic that the client initializes will get to the Load-Balancer that has the virtual load-balanced IP. The load-sharing algorithm will pick a physical server to which the Load-Balancer will forward the traffic with destination IP NATed to the physical IP of the server and forward it out the same interface towards the physical server.BUT the Load-balancer also needs to do source IP nat so that the server reply will go back from the server to the Load-Balancer and not directly back to the Client, who is not expecting a reply directly from physical server IP. From the physical servers perspective, all the traffic is coming from Load-Balancer Direct Server Response (or sometimes called Direct Server Return) ​ As we hopefully all know, switches learn about MAC addresses as they see frames coming on ports with source MACs. Also imagine that we have a router that has to know the MAC address of the Load-Balanced IP on the last L3 hop. With the picture below, you can already spot the “trick” this scenario tries to present here once you notice the disabled ARP on physical servers ​ In this scenario, Load-balancer only sees the incoming part of client-server traffic and all the returning traffic from physical servers is coming directly back to the client IP. The biggest advantages of this solution is that there is no NAT and the Load-Balancer throughput is only used in one way, so less performance impact for the Load-Balancer system. Disabling ARP on a physical server is not a difficult task. ​ Disadvantages however are that you have to manually configure the Load-Balancer with all the server MAC addresses and might be more difficult to troubleshoot with only one way traffic seen by the Load-Balancer on the whole L2 segment. LoadBalancerv2初体验？1.部署 我们假设LoadBalancerv2服务在网络节点启动，以yum源的方式安装。源码是： https://github.com/openstack/neutron-lbaas/tree/stable/mitaka 在控制节点(neutron-server)操作如下: 12345678910111213141516171819202122232425262728293031yum install openstack-neutron-lbaascd /etc/neutron/#1.3编辑neutron.conf文件service_plugins =router, neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2#1.4 编辑lbaas_agent.ini 文件[DEFAULT]interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverovs_use_veth = Truedevice_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver[haproxy]user_group =haproxy#1.5 编辑neutron_lbaas.conf文件service_provider =LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default#然后执行neutron-db-manage --subproject neutron-lbaas upgrade headsystemctl restart neutron-server 在网络节点操作如下： 12345678910111213141516171819202122232425262728293031yum install haproxyyum install openstack-neutron-lbaascd /etc/neutron/#1.4 编辑neutron.conf文件service_plugins =router, neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2#1.5 编辑lbaas_agent.ini 文件[DEFAULT]interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverovs_use_veth = Truedevice_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver[haproxy]user_group =haproxy#1.6 编辑neutron_lbaas.conf文件service_provider =LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default#1.7启动服务systemctl start neutron-lbaasv2-agent.service 另外可以安装前端界面 1.8安装neutron-lbaas-dashboard这个是在openstack_dashboard安装的节点，一般是controller节点 123456789git clone https://git.openstack.org/openstack/neutron-lbaas-dashboardcd neutron-lbaas-dashboardpython setup.py installcp neutron_lbaas_dashboard/enabled/1480project_loadbalancersv2_panel.py /usr/share/openstack-dashboard/openstack_dashboard/local/enabled/systemctl restart httpd.service memcached.service 2.创建负载均衡 Load balancerThe load balancer occupies a neutron network port and has an IP address assigned from a subnet.ListenerLoad balancers can listen for requests on multiple ports. Each one of those ports is specified by a listener.PoolA pool holds a list of members that serve content through the load balancer.MemberMembers are servers that serve traffic behind a load balancer. Each member is specified by the IP address and port that it uses to serve traffic.Health monitorMembers may go offline from time to time and health monitors divert traffic away from members that are not responding properly. Health monitors are associated with pools.由于lbaas dashboard有些问题，所以在后台用命令行创建， dashboard可显示，但不能任何操作 [root@controller ~]# source admin-openrc.sh [root@controller ~]# neutron subnet-list 创建loadbalancer[root@controller ~]# neutron lbaas-loadbalancer-create –name lb1 96f0db98-45fb-48ef-afae-808425fbb2bc添加lbaas-listener[root@controller ~]# neutron lbaas-listener-create –loadbalancer lb1 –protocol HTTP –protocol-port 80 –name listener1创建pool[root@controller ~]# neutron lbaas-pool-create –lb-algorithm ROUND_ROBIN –listener listener1 –protocol HTTP –name pool1添加member[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.4 –protocol-port 80 pool1[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.5 –protocol-port 80 pool1[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.6 –protocol-port 80 pool1添加监控[root@controller ~]# neutron lbaas-healthmonitor-create –delay 3 –type HTTP –max-retries 3 –timeout 3 –pool pool1 [root@controller ~]# neutron lbaas-loadbalancer-show lb1 3.简单验证： 我们对member成员进行模拟http服务，即172.16.1.4,172.16.1.5,172.16.1.6分别运行 172.16.1.4while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver1’ | sudo nc -l -p 80 ; done172.16.1.5while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver2’ | sudo nc -l -p 80 ; done172.16.1.6while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver3’ | sudo nc -l -p 80 ; done 然后创建一个客户端访问负载均衡的vip 172.16.1.9 ,多次执行,如下图wget -O - http:// 172.16.1.9 （第一次）wget -O - http:// 172.16.1.9 （第二次）wget -O - http:// 172.16.1.9 （第三次）wget -O - http:// 172.16.1.9（第四次） 我们发现第一次是server1响应 第二次是server2响应 第三次是server3响应 第四次是server1响应 参考：http://networkgeekstuff.com/networking/basic-load-balancer-scenarios-explained/ https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html http://www.cnblogs.com/sammyliu/p/4656176.html http://blog.csdn.net/u013628152/article/details/51318414]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python yield 使用浅析]]></title>
      <url>%2F2017%2F03%2F06%2FPython-yield-%E4%BD%BF%E7%94%A8%E6%B5%85%E6%9E%90%2F</url>
      <content type="text"><![CDATA[yield的概念？1.简单的斐波那契數列第一版： 12345678def fab(max): n, a, b = 0, 0, 1 while n &lt; max: print b a, b = b, a + b n = n + 1if __name__ == '__main__': fab(5) 缺点：直接在 fab 函数中用 print 打印数字会导致该函数可复用性较差，因为 fab 函数返回 None，其他函数无法获得该函数生成的数列。 2.简单的斐波那契數列第二版： 1234567891011def fab(max): n, a, b = 0, 0, 1 L = [] while n &lt; max: L.append(b) a, b = b, a + b n = n + 1 return Lif __name__ == '__main__': for n in fab(5): print n 缺点：该函数在运行中占用的内存会随着参数 max 的增大而增大，如果要控制内存占用，最好不要用 List。 3.简单的斐波那契數列第三版： 根据range与xrange的思想设计： 123456789101112131415161718class Fab(object): def __init__(self,max): self.max=max self.n,self.a,self.b=0,0,1 def __iter__(self): return self def next(self): if self.n&lt;self.max: r=self.b self.a, self.b = self.b, self.a + self.b self.n=self.n+1 return r raise StopIterationif __name__ == '__main__': for n in Fab(5): print n 缺点：代码远远没有第一版的 fab 函数来得简洁。 如果我们想要保持第一版 fab 函数的简洁性，同时又要获得 iterable 的效果，yield 就派上用场了。 123456789def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': for n in fab(5): print n ​ yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator，调用 fab(5) 不会执行 fab 函数，而是返回一个 iterable 对象！在 for 循环执行时，每次循环都会执行 fab 函数内部的代码，执行到 yield b 时，fab 函数就返回一个迭代值，下次迭代时，代码从 yield b 的下一条语句继续执行，而函数的本地变量看起来和上次中断执行前是完全一样的，于是函数继续执行，直到再次遇到 yield。 12345678910111213def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': f=fab(5) print (f.next()) print (f.next()) print (f.next()) print (f.next()) print (f.next()) 一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。比如在读取文件时候很好使用的。 123456789def read_file(fpath): BLOCK_SIZE = 1024 with open(fpath, 'rb') as f: while True: block = f.read(BLOCK_SIZE) if block: yield block else: return Iterables，Generators，Yield？​ 当你创建了一个列表,你可以一个一个的读取它的每一项,这叫做iteration。所有你可以用在for...in...语句中的都是可迭代的:比如lists,strings,files…因为这些可迭代的对象你可以随意的读取所以非常方便易用,但是你必须把它们的值放到内存里,当它们有很多值时就会消耗太多的内存. 1234if __name__ == '__main__': mylist = [x * x for x in range(3)] for i in mylist: print i ​ 生成器也是迭代器的一种,但是你只能迭代它们一次.原因很简单,因为它们不是全部存在内存里,它们只在要调用的时候在内存里生成。 1234if __name__ == '__main__': mygenerator = (x * x for x in range(3)) for i in mygenerator: print i ​ 生成器和迭代器的区别就是用()代替[],还有你不能用for i in mygenerator第二次调用生成器:首先计算0,然后会在内存里丢掉0去计算1,直到计算完4. 1234567891011121314def createGenerator(): mylist = range(3) for i in mylist: yield i * iif __name__ == '__main__': mygenerator = createGenerator() print(mygenerator) for i in mygenerator: print i#output&lt;generator object createGenerator at 0x7f5930639730&gt;014 ​ 在这里这个例子好像没什么用,不过当你的函数要返回一个非常大的集合并且你希望只读一次的话,那么它就非常的方便了.要理解Yield你必须先理解当你调用函数的时候,函数里的代码并没有运行.函数仅仅返回生成器对象,这就是它最微妙的地方:-)然后呢,每当for语句迭代生成器的时候你的代码才会运转.一旦函数运行并没有碰到yeild语句就认为生成器已经为空了.原因有可能是循环结束或者没有满足if/else之类的. 1234567891011121314151617181920212223242526272829303132class Bank(): # 让我们建个银行,生产许多ATM crisis = False def create_atm(self): while not self.crisis: yield "$100"if __name__ == '__main__': hsbc = Bank() # 当一切就绪了你想要多少ATM就给你多少 corner_street_atm = hsbc.create_atm() print(corner_street_atm.next()) print(corner_street_atm.next()) print([corner_street_atm.next() for cash in range(5)]) hsbc.crisis = True # cao,经济危机来了没有钱了! print(corner_street_atm.next()) wall_street_atm = hsbc.create_atm() # 对于其他ATM,它还是True print(wall_street_atm.next()) hsbc.crisis = False # 麻烦的是,尽管危机过去了,ATM还是空的 print(corner_street_atm.next()) brand_new_atm = hsbc.create_atm() # 只能重新新建一个atm了 for cash in brand_new_atm: print cash#output$100$100['$100', '$100', '$100', '$100', '$100']&lt;type 'exceptions.StopIteration'&gt;&lt;type 'exceptions.StopIteration'&gt;&lt;type 'exceptions.StopIteration'&gt;$100$100... yield的源码分析？在解释生成器之前，需要讲解一下Python虚拟机的调用原理。 1234567891011121314151617181920212223242526272829303132333435typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* code segment */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* points after the last local */ /* Next free slot in f_valuestack. Frame creation sets to f_valuestack. Frame evaluation usually NULLs it, but a frame that yields sets it to the current stack top. */ PyObject **f_stacktop; PyObject *f_trace; /* Trace function */ /* If an exception is raised in this frame, the next there are used to * record the exception info (if any) originally in the thread state. See * comments before set_exc_info() -- it's not obvious. * Invariant: if _type is NULL, then so are _value and _traceback. * Desired invariant: all three are NULL, or all three are non-NULL. That * one isn't currently true, but "should be". */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; PyThreadState *f_tstate; int f_lasti; /* Last instruction if called */ /* Call PyFrame_GetLineNumber() instead of reading this field directly. As of 2.3 f_lineno is only valid when tracing is active (i.e. when f_trace is set). At other times we use PyCode_Addr2Line to calculate the line from the current bytecode index. */ int f_lineno; /* Current line number */ int f_iblock; /* index in f_blockstack */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */&#125; PyFrameObject; 生成器的源码在Objects/genobject.c 12345678910111213141516PyObject *PyGen_New(PyFrameObject *f)&#123; PyGenObject *gen = PyObject_GC_New(PyGenObject, &amp;PyGen_Type); # 创建生成器对象 if (gen == NULL) &#123; Py_DECREF(f); return NULL; &#125; gen-&gt;gi_frame = f; # 赋予代码块 Py_INCREF(f-&gt;f_code); # 引用计数+1 gen-&gt;gi_code = (PyObject *)(f-&gt;f_code); gen-&gt;gi_running = 0; # 0表示为执行，也就是生成器的初始状态 gen-&gt;gi_weakreflist = NULL; _PyObject_GC_TRACK(gen); # GC跟踪 return (PyObject *)gen;&#125; send与next 123456789101112static PyObject *gen_iternext(PyGenObject *gen)&#123; return gen_send_ex(gen, NULL, 0);&#125;static PyObject *gen_send(PyGenObject *gen, PyObject *arg)&#123; return gen_send_ex(gen, arg, 0);&#125; 从上面的代码中可以看到，send和next都是调用的同一函数gen_send_ex，区别在于是否带有参数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static PyObject *gen_send_ex(PyGenObject *gen, PyObject *arg, int exc)&#123; PyThreadState *tstate = PyThreadState_GET(); PyFrameObject *f = gen-&gt;gi_frame; PyObject *result; if (gen-&gt;gi_running) &#123; # 判断生成器是否已经运行 PyErr_SetString(PyExc_ValueError, "generator already executing"); return NULL; &#125; if (f==NULL || f-&gt;f_stacktop == NULL) &#123; # 如果代码块为空或调用栈为空，则抛出StopIteration异常 /* Only set exception if called from send() */ if (arg &amp;&amp; !exc) PyErr_SetNone(PyExc_StopIteration); return NULL; &#125; if (f-&gt;f_lasti == -1) &#123; # f_lasti=1 代表首次执行 if (arg &amp;&amp; arg != Py_None) &#123; # 首次执行不允许带有参数 PyErr_SetString(PyExc_TypeError, "can't send non-None value to a " "just-started generator"); return NULL; &#125; &#125; else &#123; /* Push arg onto the frame's value stack */ result = arg ? arg : Py_None; Py_INCREF(result); # 该参数引用计数+1 *(f-&gt;f_stacktop++) = result; # 参数压栈 &#125; /* Generators always return to their most recent caller, not * necessarily their creator. */ f-&gt;f_tstate = tstate; Py_XINCREF(tstate-&gt;frame); assert(f-&gt;f_back == NULL); f-&gt;f_back = tstate-&gt;frame; gen-&gt;gi_running = 1; # 修改生成器执行状态 result = PyEval_EvalFrameEx(f, exc); # 执行字节码 gen-&gt;gi_running = 0; # 恢复为未执行状态 /* Don't keep the reference to f_back any longer than necessary. It * may keep a chain of frames alive or it could create a reference * cycle. */ assert(f-&gt;f_back == tstate-&gt;frame); Py_CLEAR(f-&gt;f_back); /* Clear the borrowed reference to the thread state */ f-&gt;f_tstate = NULL; /* If the generator just returned (as opposed to yielding), signal * that the generator is exhausted. */ if (result == Py_None &amp;&amp; f-&gt;f_stacktop == NULL) &#123; Py_DECREF(result); result = NULL; /* Set exception if not called by gen_iternext() */ if (arg) PyErr_SetNone(PyExc_StopIteration); &#125; if (!result || f-&gt;f_stacktop == NULL) &#123; /* generator can't be rerun, so release the frame */ Py_DECREF(f); gen-&gt;gi_frame = NULL; &#125; return result;&#125; 参考：http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/ http://www.cnblogs.com/coder2012/p/4990834.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的eventlet使用与理解]]></title>
      <url>%2F2017%2F03%2F06%2FPython%E7%9A%84eventlet%E4%BD%BF%E7%94%A8%E4%B8%8E%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Eventlet eventlet在openstack，还有ryu控制器中使用频率很高，有必要总结一下用法。 什么是协程？​ 说到Coroutine，我们必须提到两个更远的东西。在操作系统（os）级别，有进程（process）和线程（thread）两个（仅从我们常见的讲）实际的“东西”（不说概念是因为这两个家伙的确不仅仅是概念，而是实际存在的，os的代码管理的资源）。这两个东西都是用来模拟“并行”的，写操作系统的程序员通过用一定的策略给不同的进程和线程分配CPU计算资源，来让用户“以为”几个不同的事情在“同时”进行“。在单CPU上，是os代码强制把一个进程或者线程挂起，换成另外一个来计算，所以，实际上是串行的，只是“概念上的并行”。在现在的多核的cpu上，线程可能是“真正并行的”。 ​ Coroutine，翻译成”协程“，初始碰到的人马上就会跟上面两个概念联系起来。直接先说区别，Coroutine是编译器级的，Process和Thread是操作系统级的。Coroutine的实现，通常是对某个语言做相应的提议，然后通过后成编译器标准，然后编译器厂商来实现该机制。Process和Thread看起来也在语言层次，但是内生原理却是操作系统先有这个东西，然后通过一定的API暴露给用户使用，两者在这里有不同。Process和Thread是os通过调度算法，保存当前的上下文，然后从上次暂停的地方再次开始计算，重新开始的地方不可预期，每次CPU计算的指令数量和代码跑过的CPU时间是相关的，跑到os分配的cpu时间到达后就会被os强制挂起。Coroutine是编译器的魔术，通过插入相关的代码使得代码段能够实现分段式的执行，重新开始的地方是yield关键字指定的，一次一定会跑到一个yield对应的地方。 总之，对于Coroutine，是编译器帮助做了很多的事情，来让代码不是一次性的跑到底，而不是操作系统强制的挂起。代码每次跑多少，是可预期的。但是，Process和Thread，在这个层面上完全不同，这两个东西是操作系统管理的。 python-eventlet又是什么?官方网站对eventlet的描述是： ​ Eventlet is built around the concept of green threads (i.e. coroutines, we use the terms interchangeably) that are launched to do network-related work. Green threads differ from normal threads in two main ways: ​ Green threads are so cheap they are nearly free. You do not have to conserve green threads like you would normal threads. In general, there will be at least one green thread per network connection.Green threads cooperatively yield to each other instead of preemptively being scheduled. The major advantage from this behavior is that shared data structures don’t need locks, because only if a yield is explicitly called can​ another green thread have access to the data structure. It is also possible to inspect primitives such as queues to see if they have any pending data. ​ 大概意思是Eventlet是以绿色线程（协同线程）的概念建立起来的网络库，绿色线程和普通线程的区别是：1.绿色线程的开销小 2.绿色线程共享数据，无需锁，同一时刻只有一个线程能访问数据，通过类似队列的去查找等待的数据。 ​ eventlet是一个用来处理和网络相关的python库函数，而且可以通过协程来实现并发，在eventlet里，把“协程”叫做 greenthread(绿色线程)。所谓并发，就是开启了多个greenthread，并且对这些greenthread进行管理，以实现非阻塞式的 I/O。比如说用eventlet可以很方便的写一个性能很好的web服务器，或者是一个效率很高的网页爬虫，这都归功于eventlet的“绿色线程”，以及对“绿色线程”的管理机制。更让人不可思议的是，eventlet为了实现“绿色线程”，竟然对python的和网络相关的几个标准库函数进行了改写，并且可以以补丁（patch）的方式导入到程序中，因为python的库函数只支持普通的线程，而不支持协程，eventlet称之为“绿化”。​ 它通过greenlet提供的协程功能，让开发者可以不用将以往的多线程等并发程序的开发方式转变成异步状态机模型，就能直接使用select/epoll/kqueue等操作系统提供的支持高并发IO接口，并且能尽可能地发挥它们在并发上的优势。 eventlet的结构如下图所示,eventlet实现的”并发” 更准确的讲, 是 IO多路复用。 python-eventlet API?Greenthread Spawn (spawn，孵化的意思，即如何产生greenthread) 主要有3个函数可以创建绿色线程： 1)eventlet.spawn(func, args, *kwargs)： ​ 创建一个绿色线程去运行func这个函数，后面的参数是传递给这个函数的参数。返回值是一个eventlet.GreenThread对象，这个对象可以用来接受func函数运行的返回值。在绿色线程池还没有满的情况下，这个绿色线程一被创建就立刻被执行。其实，用这种方法去创建线程也是可以理解的，线程被创建出来，肯定是有一定的任务要去执行，这里直接把函数当作参数传递进去，去执行一定的任务，就好像标准库中的线程用run()方法去执行任务一样。 2)eventlet.spawn_n(func, args, *kwargs)： 这个函数和spawn()类似，不同的就是它没有返回值，因而更加高效，这种特性，使它也有存在的价值。 3)eventlet.spawn_after(seconds, func, args, *kwargs)： 这个函数和spawn()基本上一样，都有一样的返回值，不同的是它可以限定在什么时候执行这个绿色线程，即在seconds秒之后，启动这个绿色线程。 Greenthread Control 1）eventlet.sleep(seconds=0) 悬挂当前的绿色线程，以允许其它的绿色线程执行 2）class eventlet.GreenPool ​ 这是一个类，在这个类中用set集合来容纳所创建的绿色线程，并且可以指定容纳线程的最大数量（默认是1000个），它的内部是用Semaphore和Event这两个类来对池进行控制的，这样就构成了线程池。其中，有几个比较重要的方法： ​ free() ​ imap(function, *iterables) ​ resize(new_size) ​ running() ​ spawn(function, args, *kwargs) ​ spawn_n(function, args, *kwargs) ​ starmap(function, iterable) ​ waitall() ​ waiting() 3）class eventlet.GreenPile 这也是一个类，而且是一个很有用的类，在它内部维护了一个GreenPool对象和一个Queue对象。这个GreenPool对象可以是从外部传递进来的，也可以是在类内部创建的，GreenPool对象主要是用来创建绿色线程的，即在GreenPile内部调用了GreenPool.spawn()方法。而Queue对象则是用来保存spawn()方法的返回值的，即Queue中保存的是GreenThread对象。并且它还实现了next()方法，也就意味着GreenPile对象具有了迭代器的性质。所以如果我们要对绿色线程的返回值进行操作的话，用这个类是再好不过的了。 next()Wait for the next result, suspending the current greenthread until it is available. Raises StopIteration when there are no more results. spawn(func, args, *kw)Runs func in its own green thread, with the result available by iterating over the GreenPile object 4）class eventlet.Queue ​ 基类是LightQueue，它实现了大部分的队列的常用方法。它是用collections做为实现队列的基本数据结构的。而且这个LightQueue的实现，不单单实现了存取操作，在本质上它实现了一个生产者和消费者问题，定义了两个set()类型的成员变量putters和getters，前者用来存放在队列满时，被阻塞的绿色线程，后者用来存放当队列空时，被阻塞的绿色线程。类中的putting()和getting()方法就是分别得到被阻塞的绿色线程的数量。Queue继承了LightQueue，并且又增加了它自己的两个方法：task_done()和join()。task_done()是被消费者的绿色线程所调用的，表示在这个项上的所有工作都做完了，join()是阻塞，直到队列中所有的任务都完成。LifoQueue和PriorityQueue是存放数据的两种不同的方式。 5）class eventlet.Timeout This class is a way to add timeouts to anything. It raises exception in the current greenthread after timeout seconds. When exception is omitted or None, the Timeout instance itself is raised. Patching Functions 这里就是之前所说的“绿化”，经过eventlet“绿化”过的模块都在eventlet.green中，导入他们主要有两种方法： 1) eventlet.import_patched(modulename, additional_modules, *kw_additional_modules) 1234567from eventlet.green import socketfrom eventlet.green import SocketServerBaseHTTPServer = eventlet.import_patched('BaseHTTPServer', ('socket', socket), ('SocketServer', SocketServer))BaseHTTPServer = eventlet.import_patched('BaseHTTPServer', socket=socket, SocketServer=SocketServer) 2）eventlet.monkey_patch(all=True, os=False, select=False, socket=False, thread=False, time=False) 12import eventleteventlet.monkey_patch(socket=True, select=True) Network Convenience Functions（和网络相关的函数） eventlet.connect(addr, family=, bind=None) 主要执行了以下几个步骤：新建了一个TCP类型的socket，绑定本地的ip和端口，和远程的地址进行连接 123456def connect(addr, family=socket.AF_INET, bind=None): sock = socket.socket(family, socket.SOCK_STREAM) if bind is not None: sock.bind(bind) sock.connect(addr) return sock eventlet.listen(addr, family=, backlog=50) 和connect()类似，只是把connect()换成了listen()，backlog指定了最大的连接数量 1234567def listen(addr, family=socket.AF_INET, backlog=50): sock = socket.socket(family, socket.SOCK_STREAM) if sys.platform[:3]=="win": sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #这段不知道具体是做什么的 sock.bind(addr) sock.listen(backlog) return sock eventlet.wrap_ssl(sock, a, *kw) 给socket加上ssl(安全套接层)，对数据进行加密 eventlet.serve(sock, handle, concurrency=1000) 这个函数直接创建了一个socket服务器，在它内部创建了一个GreenPool对象，默认的最大绿色线程数是1000，然后是一个循环来接受连接 123456789101112def serve(sock, handle, concurrency=1000): pool = greenpool.GreenPool(concurrency) server_gt = greenthread.getcurrent() while True: try: conn, addr = sock.accept() gt = pool.spawn(handle, conn, addr) gt.link(_stop_checker, server_gt, conn) conn, addr, gt = None, None, None except StopServe: return eventlet 中的wsgi？流程描述： 服务器开一个socket等待客户端连接；请求来了，服务器会读出传来的数据，然后根据HTTP协议做一些初步的封装，接着就可以调用事先注册的应用程序了，并将请求的数据塞进去；等响应处理完毕了再把数据通过socket发出去。 123456789101112131415161718192021222324server参数介绍：def server(sock, # Server socket, must be already bound to a port and listening(IP和端口并开启监听). site, # WSGI application function(事件处理函数，发送start_response响应头然后返回响应内容) log=None, # File-like object that logs should be written to.If not specified, sys.stderr is used.(日志处理，默认为sys.stderr用来重定向标准错误信息的) environ=None, # Additional parameters that go into the environ dictionary of every request(每次请求的参数，写入一个字典中) max_size=None, #Maximum number of client connections opened at any time by this server.(默认为1024) max_http_version=DEFAULT_MAX_HTTP_VERSION, # Set to "HTTP/1.0" to make the server pretend it only supports HTTP 1.0. # This can help with applications or clients that don't behave properly using HTTP 1.1.(HTTP协议版本,默认为HTTP/1.1) protocol=HttpProtocol, # Protocol class.（协议类，默认为HttpProtocol） server_event=None, # Used to collect the Server object(搜集服务器对象信息) minimum_chunk_size=None, # Minimum size in bytes for http chunks. This can be used to improve performance of applications which yield many small strings, though # using it technically violates the WSGI spec. This can be overridden on a per request basis by setting environ['eventlet.minimum_write_chunk_size']. # 设置最小的Chunk大小，可以通过设置environ['eventlet.minimum_write_chunk_size']来覆盖.Chunk表示服务器发送给客户端的分块传输编码（Chunked transfer encoding） log_x_forwarded_for=True, # If True (the default), logs the contents of the x-forwarded-for header in addition to the actual client ip address in the 'client_ip' field of the log line. # 默认为True,记录客户端IP日志,X-Forwarded-For(XFF)是用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段。 custom_pool=None, # A custom GreenPool instance which is used to spawn client green threads.If this is supplied, max_size is ignored.(协程池，如果启用则可以忽略前面的max_size参数) keepalive=True, # If set to False, disables keepalives on the server; all connections will be closed after serving one request.（控制客户端连接数是否保持alive） log_output=True, # A Boolean indicating if the server will log data or not.(确定服务端是否输出日志) log_format=DEFAULT_LOG_FORMAT, # A python format string that is used as the template to generate log lines.(日志输出格式) url_length_limit=MAX_REQUEST_LINE, # A maximum allowed length of the request url. If exceeded, 414 error is returned.（最大的url长度限制，默认为8192） debug=True, # True if the server should send exception tracebacks to the clients on 500 errors.If False, the server will respond with empty bodies.(是否发送调式信息给客户端) socket_timeout=None, # Timeout for client connections' socket operations. Default None means wait forever.(Socket超时时间设置，单位是秒) capitalize_response_headers=True) # Normalize response headers' names to Foo-Bar(是否标准化相应头) Client端： 12345678#客户端代码：import eventletc=eventlet.connect(('127.0.0.1', 6000))while True: data=raw_input('Enter data:') c.sendall(data) rc=c.recv(1024) print rc Server端： 123456789101112#服务端代码：import eventletdef handle(client): while True: c = client.recv(1024) print c client.sendall(c)server = eventlet.listen(('127.0.0.1', 6000))pool = eventlet.GreenPool(10000)while True: new_sock, address = server.accept() pool.spawn_n(handle, new_sock) python-eventlet 的Demo?官方上引以为傲的“网页爬虫”，用到了绿色线程池和imap()函数 123456789101112131415urls = [ "http://www.google.com/intl/en_ALL/images/logo.gif", "http://python.org/images/python-logo.gif", "http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif",]import eventletfrom eventlet.green import urllib2def fetch(url): return urllib2.urlopen(url).read()pool = eventlet.GreenPool()for body in pool.imap(fetch, urls): print("got body", len(body)) 源码级别的分析？eventlet主要依赖另外2个python package: greenletpython-epoll (或其他类似的异步IO库, 如poll/select等) 主要做了3个工作: 封装greenlet封装epoll改写python标准库中相关的module, 以便支持epoll 什么是epoll？ epoll是linux实现的一个基于事件的异步IO库, 在之前类似的异步IO库poll上改进而来。 下面两个例子会演示如何用epoll将阻塞的IO操作用epoll改写为异步非阻塞： blocking IO import socket 12345678910111213141516171819202122EOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)try: while True: connectiontoclient, address = serversocket.accept() request = b'' while EOL1 not in request and EOL2 not in request: request += connectiontoclient.recv(1024) print('-'*40 + '\n' + request.decode()[:-2]) connectiontoclient.send(response) connectiontoclient.close()finally: serversocket.close() ​ 需要注意的是程序会在connectiontoclient, address = serversocket.accept()这一行block住, 直到获取到新的连接, 程序才会继续往下运行.同时, 这个程序同一个时间内只能处理一个连接, 如果有很多用户同时访问8080端口, 必须要按先后 顺序依次处理这些连接, 前面一个连接成功返回后, 才会处理后面的连接. non-blocking IO by using epoll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import socket, selectEOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)serversocket.setblocking(0)epoll = select.epoll()epoll.register(serversocket.fileno(), select.EPOLLIN)try: connections = &#123;&#125;; requests = &#123;&#125;; responses = &#123;&#125; while True: events = epoll.poll(1) for fileno, event in events: if fileno == serversocket.fileno(): connection, address = serversocket.accept() connection.setblocking(0) epoll.register(connection.fileno(), select.EPOLLIN) connections[connection.fileno()] = connection requests[connection.fileno()] = b'' responses[connection.fileno()] = response elif event &amp; select.EPOLLIN: requests[fileno] += connections[fileno].recv(1024) if EOL1 in requests[fileno] or EOL2 in requests[fileno]: epoll.modify(fileno, select.EPOLLOUT) print('-'*40 + '\n' + requests[fileno].decode()[:-2]) elif event &amp; select.EPOLLOUT: byteswritten = connections[fileno].send(responses[fileno]) responses[fileno] = responses[fileno][byteswritten:] if len(responses[fileno]) == 0: epoll.modify(fileno, 0) connections[fileno].shutdown(socket.SHUT_RDWR) elif event &amp; select.EPOLLHUP: epoll.unregister(fileno) connections[fileno].close() del connections[fileno]finally: epoll.unregister(serversocket.fileno()) epoll.close() serversocket.close() 可以看到, 例子中首先使用serversocket.setblocking(0)将socket设为异步的模式,然后 用select.epoll()新建了一个epoll, 接着用epoll.register(serversocket.fileno(),select.EPOLLIN)将该socket上的IO输入事件(select.EPOLLIN)注册到epoll里.这样做了以后, 就可以将 上面例子中会在socket.accept()这步阻塞的MainLoop改写为基于异步IO事件的epoll循环了.events = epoll.poll(1) ​ 简单的说, 如果有很多用户同时连接到8080端口, 这个程序会同时accept()所有的socket连接, 然后通过这行代码将发生IO事件socket放到events中, 并在后面循环中处理. 没有发生IO事件的 socket不会在loop中做处理. 这样使用epoll就实现了一个简单的并发web服务器. 注意, 这里提到的并发, 和我们通常所理解线程/进程的并发并不太一样, 更准确的说, 是 IO多路复用 . 什么是greenlet？ greentlet是python中实现我们所谓的”Coroutine(协程)”的一个基础库. 12345678910111213141516from greenlet import greenletdef test1(): print 12 gr2.switch() print 34def test2(): print 56 gr1.switch() print 78 gr1 = greenlet(test1) gr2 = greenlet(test2) gr1.switch()#输出125634 ​ 程序先分别为两个函数定义了2个greenlet: gr1和gr2.gr1.switch()显式切换到gr1上执行, gr1中输出”12”后gr2.switch()显式切换到gr2上执行输出56, 又gr1.switch()显式切换到gr1上, 输出34. test1()执行结束,gr1 die. 于是 test2()里的78不会输出.可以发现greenlet仅仅是实现了一个最简单的”coroutine”, 而eventlet中的greenthread是在 greenlet的基础上封装了一些更high-level的功能, 比如greenlet的调度等. 什么是eventlet.green？ 从epoll的运行机制可以看出, 要使用异步IO, 必须要将相关IO操作改写成non-blocking的方式. 但是我们用eventlet.spawn()的函数,并没有针对epoll做任何改写, 那eventlet是怎么实现 异步IO的呢?这也是eventlet这个package最凶残的地方, 它自己重写了python标准库中IO相关的操作, 将它们 改写成支持epoll的模式, 放在eventlet.green中.比如说, socket.accept()被改成了这样 123456789101112def accept(self): if self.act_non_blocking: return self.fd.accept() fd = self.fd while True: res = socket_accept(fd) if res is not None: client, addr = res set_nonblocking(client) return type(self)(client), addr trampoline(fd, read=True, timeout=self.gettimeout(), timeout_exc=socket.timeout("timed out")) ​ 然后在eventlet.spawn()的时候, 通过 一些高阶魔法和”huge hack”, 将这些改写过得模块”patch”到spawn出的greenthread上, 从而 实现epoll的IO多路复用, 相当凶残.其中的hub和greenthread分别对应eventlet.hubs.hub和eventlet.greenthread, 本质都是 一个greenlet的实例.hub中封装前面提到的epoll, epoll的事件循环是由hub.run()这个方法里实现.每当用户调用 eventlet.spawn(), 就会在当前python线程的pool里产生一个新的greenthread. 由于greenthread 里的IO相关的python标准库被改写成non-blocking的模式(参考上面的socket.accept()).每当greenthread里做IO相关的操作时, 最终都会返回到hub中的epoll循环, 然后根据epoll中的 IO事件, 调用响应的函数. 具体如下面所示.greenthread.sleep(), 实际上也是将CPU控制权交给hub,然后由hub调度下一个需要运行的 greenthread. 123456789101112131415161718192021222324252627282930313233def wait(self, seconds=None): readers = self.listeners[READ] writers = self.listeners[WRITE] if not readers and not writers: if seconds: sleep(seconds) return try: presult = self.poll.poll(int(seconds * self.WAIT_MULTIPLIER)) except select.error, e: if get_errno(e) == errno.EINTR: return raise SYSTEM_EXCEPTIONS = self.SYSTEM_EXCEPTIONS for fileno, event in presult: try: if event &amp; READ_MASK: readers.get(fileno, noop).cb(fileno) if event &amp; WRITE_MASK: writers.get(fileno, noop).cb(fileno) if event &amp; select.POLLNVAL: self.remove_descriptor(fileno) continue if event &amp; EXC_MASK: readers.get(fileno, noop).cb(fileno) writers.get(fileno, noop).cb(fileno) except SYSTEM_EXCEPTIONS: raise except: self.squelch_exception(fileno, sys.exc_info()) clear_sys_exc_info() 参考:http://blog.csdn.net/xiangmin2587/article/details/8182775 http://blog.csdn.net/qq910894904/article/details/41699541 http://www.cnblogs.com/wonderKK/p/4062591.html http://eventlet.net/doc/ http://eventlet.net/doc/modules/wsgi.html http://www.xuebuyuan.com/1379840.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java框架之SpringBoot]]></title>
      <url>%2F2017%2F03%2F03%2Fjava%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBoot%2F</url>
      <content type="text"><![CDATA[SpringBoot非常受欢迎，在github我也用SpringBoot封装neutron-api，地址为： https://github.com/Luckylau/SpringBoot-NeutronApi 总觉得应该普及一下基本知识。 什么是SpringBoot？​ Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式，Boot致力于在蓬勃发展的快速应用开发领域（rapid application development）成为领导者。 ​ Boot的目标不在于为已解决的问题域提供新的解决方案，而是为平台带来另一种开发体验，从而简化对这些已有技术的使用。对于已经熟悉Spring生态系统的开发人员来说，Boot是一个很理想的选择，不过对于采用Spring技术的新人来说，Boot提供一种更简洁的方式来使用这些技术。 ​ Boot提供了许多的“starter”模块，它们定义了一组依赖，这些依赖能够添加到构建系统之中，从而解析框架及其父平台所需的特定类库。例如，spring-boot-starter-actuator依赖会引入一组基本的Spring项目，从而实现应用的快速配置和即时可用。关于这种依赖，值得强调的一点就是当开发Web应用，尤其是RESTful Web服务的时候，如果包含了spring-boot-starter-web依赖，它就会为你提供启动嵌入式Tomcat容器的自动化配置，并且提供对微服务应用有价值的端点信息，如服务器信息、应用指标（metrics）以及环境详情。除此之外，如果引入spring-boot-starter-security模块的话，actuator会自动配置Spring Security，从而为应用提供基本的认证以及其他高级的安全特性。它还会为应用结构引入一个内部的审计框架，这个框架可以用来生成报告或其他的用途，比如开发认证失败的锁定策略。 ​ Boot对Spring应用的开发进行了简化，提供了模块化方式导入依赖的能力，强调了开发RESTful Web服务的功能并提供了生成可运行jar的能力，这一切都清晰地表明在开发可部署的微服务方面Boot框架是一个强大的工具。正如前面的例子所示，借助于Boot，让一个RESTful Web工程运行起来是一件很容易的事情；在企业级基础设施领域，微服务是一种越来越流行的应用架构，因为它能够实现快速开发、更小的代码库、企业级集成以及模块化部署。 实战Domo?以SpringBoot-neutron-api项目为例，这也是一个RESTFUL项目。 1.创建一个Maven项目 我们在eclipse下创建两个maven项目，一个选择maven-archtype-quickstart，一个选择maven-archtype-webapp。将maven-archtype-webapp下的webapp目录拷贝到基于maven-archtype-quickstart创建的maven项目，然后将其删除。 如果没有src/main/resources可以按照如下方式创建 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 其余根据开发需要补充即可。下面是一些配置数据库的，主要别人的一些操作，我也看了一下公司产品的代码，大同小异，简单的贴出来。 12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!--数据库操作--&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在src/main/resources这个文件夹下面新建一个application.properties 123456789101112131415#DB Configuration:spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/testdbspring.datasource.username = rootspring.datasource.password = 123456#JPA Configuration: spring.jpa.database=MySQLspring.jpa.show-sql=true spring.jpa.generate-ddl=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernate.dialect.MySQL5Dialect spring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy #spring.jpa.database=org.hibernate.dialect.MySQL5InnoDBDialect #spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MYSQL5Dialect 待续。。。。。 参考：http://www.infoq.com/cn/articles/microframeworks1-spring-boot http://blog.csdn.net/cool__wang/article/details/49466609 http://www.cnblogs.com/dreamroute/p/5173896.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的sqlalchemy库使用]]></title>
      <url>%2F2017%2F03%2F02%2FPython%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Sqlalchemy库 本文主要参考官方文档和一些网上资料，并结合之前python-web-frame项目使用来详细说明Sqlalchemy的使用，版本号为SQLAlchemy 1.1。 Sqlalchemy的架构？ Object Relational Mapper &amp;&amp; SQL Expression Language ?下面是截取python-web-frame项目代码 12345678910111213141516171819202122232425262728293031323334#api.pydef get_engine(): global _ENGINE if _ENGINE is not None: return _ENGINE _ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) db_models.int_dbs(_ENGINE) return _ENGINE# db_models.pyBase = declarative.declarative_base()def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE)class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) def __init__(self, user_id, name, gender, age, email): self.user_id = user_id self.name = name self.gender = gender self.age = age self.email = email Connecting 123_ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) echo flag is a shortcut to setting up SQLAlchemy logging, which is accomplished via Python’s standard logging module. With it enabled, we’ll see all the generated SQL produced. echo意思说开启日志，你可以看到整个SQL是如何产生的，方便调试。 _ENGINE is an instance of Engine, and it represents the core interface to the database, adapted through a dialect that handles the details of the database and DBAPI in use. _ENGINE 意思说与数据库打交道的核心接口 Declare a Mapping 123456789101112131415Base = declarative.declarative_base()class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) 生成一个映射使用的Base. Create a Schema 12def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE) db_User类继承了Base类，它具有metadata属性，通过create_all()方法，注入与数据库打交道的核心接口_ENGINE，我们发现有一系列的命令完成数据库中user表是否存在的检测和生成。 Creating a Session 1234567891011def get_session_maker(engine): global _SESSION_MAKER if _SESSION_MAKER is not None: return _SESSION_MAKER _SESSION_MAKER = sqlalchemy.orm.sessionmaker(bind=engine) return _SESSION_MAKERdef get_session(): engine = get_engine() maker = get_session_maker(engine) session = maker() return session This custom-made Session class will create new Session objects which are bound to our database. Querying http://docs.sqlalchemy.org/en/rel_1_1/orm/query.html#sqlalchemy.orm.query.Query query()和 aliased() Common Filter Operators filter() 12345678910111213141516171819202122232425262728293031equals:query.filter(User.name == 'ed')not equals:query.filter(User.name != 'ed')LIKE:query.filter(User.name.like('%ed%'))IN:query.filter(User.name.in_(['ed', 'wendy', 'jack']))# works with query objects too:query.filter(User.name.in_( session.query(User.name).filter(User.name.like('%ed%'))))NOT IN:query.filter(~User.name.in_(['ed', 'wendy', 'jack']))IS NULL:query.filter(User.name == None)# alternatively, if pep8/linters are a concernquery.filter(User.name.is_(None))AND:# use and_()from sqlalchemy import and_query.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))# or send multiple expressions to .filter()query.filter(User.name == 'ed', User.fullname == 'Ed Jones')# or chain multiple filter()/filter_by() callsquery.filter(User.name == 'ed').filter(User.fullname == 'Ed Jones'OR:from sqlalchemy import or_query.filter(or_(User.name == 'ed', User.name == 'wendy'))MATCH:query.filter(User.name.match('wendy') Returning Lists and Scalars all() returns a list first() applies a limit of one and returns the first result as a scalar one() fully fetches all rows, and if not exactly one object identity or composite row is present in the result, raises an error 注意：The one() method is great for systems that expect to handle “no items found” versus “multiple items found” differently; such as a RESTful web service, which may want to raise a “404 not found” when no results are found, but raise an application error when multiple results are found. one_or_none() is like one(), except that if no results are found, it doesn’t raise an error; it just returns None. Like one(), however, it does raise an error if multiple results are found scalar() invokes the one() method, and upon success returns the first column of the row Using Textual SQL text() Counting count() Building a Relationship 一对多 12345678class db_User(Base): .... telephone = relationship("db_Telephone",order_by="db_Telephone.id",back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 即：一个db_user对应多个db_Telephone 一对一 12345678class db_User(Base): .... telephone = relationship("db_Telephone",uselist=False,back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 多对多 Many to Many adds an association table between two classes.多对多关系会在两个类之间增加一个关联的表。The association table is indicated by the secondary argument to relationship().这个关联的表在 relationship() 方法中通过 secondary 参数来表示。Usually, the Table uses the MetaData object associated with the declarative base class,通常的，这个表会通过 MetaData 对象来与声明基类关联，so that the ForeignKey directives can locate the remote tables with which to link:所以这个 ForeignKey 指令会使用链接来定位到远程的表： 123456789101112131415161718192021#多对多关系中的两个表之间的一个关联表post_keywords = Table('post_keywords', Base.metadata, Column('post_id', ForeignKey('posts.id'), primary_key=True), Column('keyword_id', ForeignKey('keywords.id'), primary_key=True) class Parent(Base): __tablename__ = 'left' id = Column(Integer, primary_key=True) children = relationship( "Child", secondary=association_table, back_populates="parents")class Child(Base): __tablename__ = 'right' id = Column(Integer, primary_key=True) parents = relationship( "Parent", secondary=association_table, back_populates="children") Querying with Joins Using Aliases Using EXISTS Common Relationship Operators eq() (many-to-one “equals” comparison) ne() (many-to-one “not equals” comparison) IS NULL (many-to-one comparison, also uses eq()) contains() (used for one-to-many collections) any() (used for collections) has() (used for scalar references) Query.with_parent() (used for any relationship) Eager Loading Query.options() subqueryload()第一种 Joined Load()第二种 contains_eager()第三种 Deleting db_user与db_Telephone是一对多关系，下面操作解决了删除db_user，会自动删除关联的表数据 12345678910111213141516171819202122def delete_user(self, user_id): logger.info("user.user_id: %s" % (user_id)) try: session = get_session() user=session.query( db_models.db_User).filter_by( user_id=user_id).first() session.delete(user) session.flush() session.commit() except exc.NoResultFound: logger.error("delete user occur error ...")class db_User(Base): ... telephone = relationship( "db_Telephone", order_by="db_Telephone.id", back_populates="user" , cascade="save-update, merge, delete")class db_Telephone(Base): ... user = relationship("db_User", back_populates="telephone") 参考：http://docs.sqlalchemy.org/en/rel_1_0/orm/tutorial.html http://docs.sqlalchemy.org/en/rel_1_0/core/tutorial.html http://blog.csdn.net/zd0303/article/details/50261347 http://blog.csdn.net/Jmilk/article/details/52445093#one-to-many]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python的pecan框架使用]]></title>
      <url>%2F2017%2F03%2F01%2Fpython%E7%9A%84pecan%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Pecan web框架 什么是Pecan?​ 创造Pecan是为了填补Python web框架世界的一个空缺——一个提供object-dispatch（对象分发）方式路由的超轻量级的框架。Pecan的目标并不是要成为一个“全栈”框架，因此没有支持一些额外的功能，比如session或是数据库 。相反，Pecan专注于HTTP本身。 功能包括： Object-dispatch for easy routingFull support for REST-style controllersExtensible security frameworkExtensible template language supportExtensible JSON supportEasy Python-based configuration 所以对于OpenStack来说，Pecan是一个很好的选择，因为OpenStack项目中统一使用sqlalchemy来实现ORM，API的实现也不需要模板功能，安全控制则基于Keystone体系。使用Pecan来开发REST服务，代码量很少，代码结构也清晰。 创建简单的Pecan应用？首先在linux新建一个virtualenv环境（本文是在ubantu16.04），我们首先看一下自动生成的工程目录结构。 12345678910111213141516171819202122232425262728293031323334353637383940luckylau@luckylau-Ubuntu:~$virtualenv pecan-envluckylau@luckylau-Ubuntu:~$cd pecan-env/luckylau@luckylau-Ubuntu:~/pecan-env$ source bin/activate(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pip install pecan(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pecan create test_project(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ tree test_project/test_project/├── config.py├── MANIFEST.in├── public #一些静态文件包括CSS,JS,images,为你的开发服务│ ├── css│ │ └── style.css│ └── images│ └── logo.png├── setup.cfg├── setup.py└── test_project #基于MVC模型生成的结构 ├── app.py #决定应用是如何创造的，这个文件必须包含set_app()并返回WSGI应用对象，一般情况下就用原生的，除非不能满足你定制的应用。 ├── controllers #控制层实现 │ ├── __init__.py │ ├── __init__.pyc │ ├── root.py │ └── root.pyc ├── __init__.py ├── __init__.pyc ├── model #模型实现 │ ├── __init__.py #在这里可以加入与database交互，定义表和ORM等 │ └── __init__.pyc ├── templates #模板实现 │ ├── error.html │ ├── index.html │ └── layout.html └── tests #单元测试 ├── config.py ├── __init__.py ├── test_functional.py ├── test_units.py └── test_units.pyc8 directories, 23 files 实战Demo?我们通过实际操作中补充pecan相关知识点。项目托管到github: https://github.com/Luckylau/python-web-frame 该项目用到pecan和wsme(Web Services Made Easy),首先解释一下WSME吧 WSME的全称是Web Service Made Easy，是专门用于实现REST服务的typing库，让你不需要直接操作请求和响应，而且刚好和Pecan结合得非常好，所以，OpenStack的很多项目都使用了Pecan + WSME的组合来实现API。 WSME的理念是：在大部分情况下，Web服务的输入和输出对数据类型的要求都是严格的。所以它就专门解决了这个事情，然后把其他事情都交给其他框架去实现。 WSME会自动帮你检查HTTP请求和响应中的数据是否符合预先设定好的要求。WSME的主要方式是通过装饰器来控制controller方法的输入和输出。WSME中主要使用两个控制器： ● @signature: 这个装饰器用来描述一个函数的输入和输出。 ● @wsexpose: 这个装饰器包含@signature的功能，同时会把函数的路由信息暴露给Web框架，效果就像Pecan的expose装饰器。 123456789101112131415luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── config.py│ ├── controllers│ │ ├── __init__.py│ │ └── root.py│ ├── expose.py│ ├── hooks.py│ └── __init__.py├── cmd│ ├── api.py│ └── __init__.py└── __init__.py 首先参考openstack我们人工的建立如上目录。首先我们实现config.py 代码 https://pecan.readthedocs.io/en/latest/configuration.html#application-configuration 该链接解释配置的含义。 config.py 123456789101112131415161718192021222324app = &#123; 'root': 'webdemo.api.controllers.root.RootController', 'modules': ['webdemo.api'], 'debug': True,&#125;logging = &#123; 'root': &#123;'level': 'INFO', 'handlers': ['console']&#125;, 'loggers': &#123; 'webdemo': &#123;'level': 'INFO', 'handlers': ['console']&#125; &#125;, 'handlers': &#123; 'console': &#123; 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'simple' &#125; &#125;, 'formatters': &#123; 'simple': &#123; 'format': ('%(asctime)s %(levelname)-5.5s [%(name)s]' '[%(threadName)s] %(message)s') &#125; &#125;&#125; modules At least one of the listed modules must contain an app.setup_app function which is called to create the WSGI app. In other words, this package should be where your app.py file is located, and this file should contain a setup_app function. 简单来说，modules是app.py(同时包含setup_pp功能)所在的包，pecan会扫描的。 root The root controller of your application. Remember to provide a string representing a Python path to some callable (e.g.”yourapp.controllers.root.RootController”). 简单来说，RootController所在路径 debugEnables the ability to display tracebacks in the browser and interactively debug during development. 简单来说，是否开启debug模式 app.py 123456789101112import pecanfrom webdemo.api import config as api_configdef get_pecan_config(): filename=api_config.__file__.replace('.pyc','.py') return pecan.configuration.conf_from_file(filename)def setup_app(): config=get_pecan_config() app_conf=dict(config.app) app=pecan.make_app(app_conf.pop('root'), logging=getattr(config,'logging',&#123;&#125;), **app_conf) return app expose.py 123456#让API返回JSON格式的数据import wsmeext.pecan as wsme_pecandef expose(*args, **kwargs): if 'rest_content_types' not in kwargs: kwargs['rest_content_types'] = ('json',) return wsme_pecan.wsexpose(*args, **kwargs) root.py 12345678910from pecan import restfrom wsme import types as wtypesfrom webdemo.api import exposeimport logginglogger = logging.getLogger(__name__)class RootController(rest.RestController): @expose.expose(wtypes.text) def get(self): logger.info("Method is called ...") return "python-web-frame: pecan &amp; wsme " api.py 123456789from wsgiref import simple_serverfrom webdemo.api import appdef main(): application = app.setup_app() httpd = simple_server.make_server('', 8080, application) print ("Server on port 8080 ,listening ...") httpd.serve_forever()if __name__ == '__main__': main() 我们进一步扩展该Demo，源码更新看日志： https://github.com/Luckylau/python-web-frame/commits/master 需求：设计一个管理用户的API，实现如下 GET /v1/users 获取所有用户的列表。POST /v1/users 创建一个用户。GET /v1/users/ 获取一个特定用户的详细信息。PUT /v1/users/ 修改一个用户的详细信息。DELETE /v1/users/ 删除一个用户。 1234567891011121314151617181920212223242526luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── __init__.py│ │ ├── controller.py #用户管理控制器│ │ └── users.py #用户模型│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── __init__.py└── __init__.pyc 然后我们在加入sqlalchemy库来实现数据库操作 我们可以看一个脚本预热一下 https://github.com/Luckylau/oslo.modules.sample/blob/lucky-branch/sqlalchemy.orm/db_query_ports.py 然后开始我们这个Demo的扩展 由于OpenStack项目在单元测试中使用的是sqlite的内存数据库，这样开发者运行单元测试的时候不需要安装和配置复杂的MySQL数据库，只要安装好sqlite3就可以了。而且，数据库是保存在内存中的，会提高单元测试的速度，我们的Demo也是用sqlite，sqlalchemy库的使用参考： https://luckylau.github.io/2017/03/02/Python%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3/ 12345678910111213141516171819202122232425262728293031323334webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── controller.py│ │ ├── controller.pyc│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── users.py│ │ └── users.pyc│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── db│ ├── api.py #sqlalchemy 增删改查功能│ ├── __init__.py #│ └── models.py # sqlalchemy ORM的定义├── __init__.py└── __init__.pyc5 directories, 26 files 具体的分析在源码有标注。 参考：https://pecan.readthedocs.io/en/latest/ http://www.infoq.com/cn/articles/OpenStack-demo-API3 https://pythonhosted.org/WSME/ http://www.sqlalchemy.org/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的wsgi理解]]></title>
      <url>%2F2017%2F02%2F28%2Fpython%E7%9A%84wsgi%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之WSGI ​ WSGI的全称是Web Server Gateway Interface，翻译过来就是Web服务器网关接口。具体的来说，WSGI是一个规范，定义了Web服务器如何与Python应用程序进行交互，使得使用Python写的Web应用程序可以和Web服务器对接起来。WSGI一开始是在PEP-0333中定义的，最新版本是在Python的PEP-3333定义的。 为什么需要WSGI规范？在Web部署的方案上，有一个方案是目前应用最广泛的： ​ 首先，部署一个Web服务器专门用来处理HTTP协议层面相关的事情，比如如何在一个物理机上提供多个不同的Web服务（单IP多域名，单IP多端口等）这种事情。 ​ 然后，部署一个用各种语言编写（Java, PHP, Python, Ruby等）的应用程序，这个应用程序会从Web服务器上接收客户端的请求，处理完成后，再返回响应给Web服务器，最后由Web服务器返回给客户端。 ​ 要采用这种方案，Web服务器和应用程序之间就要知道如何进行交互。为了定义Web服务器和应用程序之间的交互过程，就形成了很多不同的规范。比如改进CGI性能的FasgCGI，Java专用的Servlet规范，还有Python专用的WSGI规范等。提出这些规范的目的就是为了定义统一的标准，提升程序的可移植性。在WSGI规范的最开始的PEP-333中一开始就描述了为什么需要WSGI规范。 ​ WSGI存在的目的有两个： 让Web服务器知道如何调用Python应用程序，并且把用户的请求告诉应用程序。 让Python应用程序知道用户的具体请求是什么，以及如何返回结果给Web服务器。 WSGI中的角色？​ 在WSGI中定义了两个角色，Web服务器端称为server或者gateway，应用程序端称为application或者framework（因为WSGI的应用程序端的规范一般都是由具体的框架来实现的）。我们下面统一使用server和application这两个术语。 ​ server端会先收到用户的请求，然后会根据规范的要求调用application端，如下图所示： 调用的结果会被封装成HTTP响应后再发送给客户端。 WSGI中间件 ?​ WSGI Middleware（中间件）也是WSGI规范的一部分。上一章我们已经说明了WSGI的两个角色：server和application。那么middleware是一种运行在server和application中间的应用（一般都是Python应用）。middleware同时具备server和application角色，对于server来说，它是一个application；对于application来说，它是一个server。middleware并不修改server端和application端的规范，只是同时实现了这两个角色的功能而已。 1.Server收到客户端的HTTP请求后，生成了environ_s，并且已经定义了start_response_s。 2.Server调用Middleware的application对象，传递的参数是environ_s和start_response_s。 3.Middleware会根据environ执行业务逻辑，生成environ_m，并且已经定义了start_response_m。 4.Middleware决定调用Application的application对象，传递参数是environ_m和start_response_m。Application的application对象处理完成后，会调用start_response_m并且返回结果给Middleware，存放在result_m中。 5.Middleware处理result_m，然后生成result_s，接着调用start_response_s，并返回结果result_s给Server端。Server端获取到result_s后就可以发送结果给客户端了。 从上面的流程可以看出middleware应用的几个特点： Server认为middleware是一个application。 Application认为middleware是一个server。 Middleware可以有多层。 WSGi示例代码？​ 在给出示例代码前我们需要了解wsgiref，它是官方给出的一个实现了WSGI标准用于演示用的简单Python内置库，实现了一个简单的WSGI Server和WSGI Application（在simple_server模块中），主要分为五个模块：simple_server， util， headers， handlers， validate。 注意：simple_server只支持单线程，做测试 WSGI对于应用程序有以下标准规定： 应用程序必须是一个可调用的对象，因此，应用程序可以是一个函数，一个类，或者一个重载了call的类的实例。 应用程序必须接受两个参数并且要按照位置顺序，分别是environ（环境变量），以及start_response函数（负责将响应的status code，headers写进缓冲区但不返回给客户端）。 应用程序返回的结果必须是一个可迭代的对象 由简入繁 123456789from wsgiref.simple_server import make_serverdef simple_app(environ,start_response): status="200 OK" response_headers=[('Content-type', 'text/plain')] start_response(status,response_headers) return [u"This is simple app demo".encode('utf-8')]http=make_server('',8080,simple_app)print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011from wsgiref.simple_server import make_serverclass App(): def __call__(self, environ, start_response): status = "200 OK" response_headers = [('Content-type', 'text/plain')] start_response(status, response_headers) return [u"This is App".encode('utf-8')]simple_app = App()http = make_server('', 8080, simple_app) #只要是实现了__call__方法的实例也可以的print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011121314from wsgiref.simple_server import make_serverclass class_app: def __init__(self, environ, start_response): self.env = environ self.start = start_response def __iter__(self): status = "200 OK" response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield "Class : My Own Hello World!"app = class_apphttpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 1234567891011121314151617181920212223242526272829303132from wsgiref.simple_server import make_serverURL_PATTERNS = ( ('tags', 'tag_app'), ('about', 'about_app'))class Dispatcher(object): def _match(self, path): path = path.split("/")[1] for url, app in URL_PATTERNS: print("path:%s url:%s" % (path, url)) if path == url: return app def __call__(self, environ, start_response): path = environ.get('PATH_INFO') app = self._match(path) if app: app = globals()[app] return app(environ, start_response) else: start_response("404 not found ", [('Content-type', 'text/plain')]) return ["Page dose not exists!"]def tag_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is tag page!"]def about_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is about me page!"]app = Dispatcher()httpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 源码wsgiref解析?wsgiref.simple_server 中make_server函数 12345678# wsgiref/simple_server.pydef make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): """Create a new WSGI server listening on `host` and `port` for `app`""" server = server_class((host, port), handler_class) server.set_app(app) return server make_server函数默认使用的服务器类为WSGI Server，调用了构造函数（但是它的构造函数到底藏在哪一层服务器上呢？），相对应的使用WSGIRequestHandler 类作为请求的处理类（这两个类都定义在wsgiref.simple_server模块中），在实例化一个WSGI Server后设置它的application后返回该实例。 server_class=WSGIServer WSGI Server作为一个服务器，自然免不了要调用socket来建立TCP连接，因此这里的WSGI Server是基于Python的内置网络库BaseHTTPServer.py以及SocketServer.py实现的。 WSGI Server继承了HTTPServer,HTTPServer继承了TCPServer,TCPServer继承了BaseServer，在 BaseServerr中有handle_request函数 12345678910111213141516171819#SocketServer.pydef handle_request(self): """Handle one request, possibly blocking. Respects self.timeout. """ # Support people who used socket.settimeout() to escape # handle_request before self.timeout was available. timeout = self.socket.gettimeout() if timeout is None: timeout = self.timeout #self.timeout是BaseServer类的属性，默认是None elif self.timeout is not None: timeout = min(timeout, self.timeout) fd_sets = _eintr_retry(select.select, [self], [], [], timeout) #处理EINTR，当捕获到某个信号且相应信号处理函数返回时，这个系统调用被中断，调用返回错误，设置errno为EINTR。 if not fd_sets[0]: self.handle_timeout() return self._handle_request_noblock() 12345678def _eintr_retry(func, *args): """restart a system call interrupted by EINTR""" while True: try: return func(*args) except (OSError, select.error) as e: if e.args[0] != errno.EINTR: rais 1234567891011121314151617181920#SocketServer.pydef _handle_request_noblock(self): """Handle one request, without blocking. I assume that select.select has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). """ try: request, client_address = self.get_request() except socket.error: return if self.verify_request(request, client_address): try: self.process_request(request, client_address) except: self.handle_error(request, client_address) self.shutdown_request(request) else: self.shutdown_request(request) 关于使用select解决EINTR错误请参考这里：PEP 475 – Retry system calls failing with EINTR 因为我们把timeout设置为None，导致select.select永远不会超时，因此如果一直没有客户端连接服务器，服务器就会阻塞在select函数。当一个EINTR错误提出时，select可以重复调用。 通过select函数当我们确认已经收到了来自客户端的请求连接，此时调用accept函数不会阻塞时，于是调用handle_request_noblock函数,在函数中再依次调用了verify_request, process_request, finish_request。 1234567891011121314151617181920212223242526#SocketServer.py def get_request(self): """Get the request and client address from the socket. May be overridden. """ return self.socket.accept() #定义在TCPServerdef verify_request(self, request, client_address): """Verify the request. May be overridden. Return True if we should proceed with this request. """ return Truedef process_request(self, request, client_address): """Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. """ self.finish_request(request, client_address) self.shutdown_request(request)def finish_request(self, request, client_address): """Finish one request by instantiating RequestHandlerClass.""" self.RequestHandlerClass(request, client_address, self)def shutdown_request(self, request): """Called to shutdown and close an individual request.""" self.close_request(request)def close_request(self, request): """Called to clean up an individual request.""" pass handle_request——-&gt;handle_request_noblock——–&gt;get_request——–&gt;verify_request——-&gt; process_request———&gt;finish_request———&gt;RequestHandlerClass RequestHandlerClass在simple_server 传入的是WSGIRequestHandler handler_class=WSGIRequestHandler RequestHandlerClass主要用于处理请求，生成一些必要的环境参数之后才传给负责发送响应请求的ServerHandler WSGIRequestHandler的handle()继承如下，最后追踪到wsgiref/handles.py:BaseHandler 123456789101112131415161718192021222324252627282930313233def run(self, application): """Invoke the application""" # Note to self: don't move the close()! Asynchronous servers shouldn't # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you'll break asynchronous servers by # prematurely closing. Async servers must return from 'run()' without # closing if there might still be output to iterate over. try: self.setup_environ() self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out. def finish_response(self): """Send any iterable data, then close self and the iterable Subclasses intended for use in asynchronous servers will want to redefine this method, such that it sets up callbacks in the event loop to iterate over the data, and to call 'self.close()' once the response is finished. """ try: if not self.result_is_file() or not self.sendfile(): for data in self.result: self.write(data) self.finish_content() finally: self.close() ServerHandler函数主要功能集中在run函数上，同时start_response函数也定义在同一文件中，start_response函数（在application中调用）也必须要按照PEP-333标准定义 最终所有的数据都在finish_response()中写回给客户端。finish_response函数调用了write函数，write函数每次调用时都会检查headers是否已发送，否则先发送headers在发送data。 start_response函数源码 12345678910111213141516171819202122232425def start_response(self, status, headers,exc_info=None): """'start_response()' callable as specified by PEP 333""" if exc_info: try: if self.headers_sent: # Re-raise original exception if headers sent raise exc_info[0], exc_info[1], exc_info[2] finally: exc_info = None # avoid dangling circular ref elif self.headers is not None: raise AssertionError("Headers already set!") assert type(status) is StringType,"Status must be a string" assert len(status)&gt;=4,"Status must be at least 4 characters" assert int(status[:3]),"Status message must begin w/3-digit code" assert status[3]==" ", "Status message must have a space after code" if __debug__: for name,val in headers: assert type(name) is StringType,"Header names must be strings" assert type(val) is StringType,"Header values must be strings" assert not is_hop_by_hop(name),"Hop-by-hop headers not allowed" self.status = status self.headers = self.headers_class(headers) return self.write start_response函数主要用于检测headers是不是已经发送了，如果发送了必须提出异常，同时检测headers是否有不规范的地方，最后返回一个write函数（用于向套接字相关文件写入数据，PEP要求）。 参考：https://segmentfault.com/a/1190000003069785 http://blog.csdn.net/laughing2333/article/details/51288660 http://blog.csdn.net/sraing/article/details/8455242 https://www.python.org/dev/peps/pep-3333/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（2）]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%882%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 首先从控制节点入手，neutron-server包括 neutron-server：neutron\cmd\eventlet\server:main neutron-rpc-server：neutron\cmd\eventlet\server:main_rpc_eventlet两部分 本文主要描述Paste + PasteDeploy + Routes + WebOb实现neutron-server的api服务过程。 123456789101112131415#/neutron/cmd/eventlet/server/__init__.pyfrom oslo_config import cfgfrom neutron import serverfrom neutron.server import rpc_eventletfrom neutron.server import wsgi_eventletfrom neutron.server import wsgi_pecandef main(): server.boot_server(_main_neutron_server)def _main_neutron_server(): if cfg.CONF.web_framework == 'legacy': wsgi_eventlet.eventlet_wsgi_server()# 使用原先实现 eventlet_wsgi_server 启动服务 else: wsgi_pecan.pecan_wsgi_server()#使用新实现 Pecan WSGI server启动服务def main_rpc_eventlet(): server.boot_server(rpc_eventlet.eventlet_rpc_server) 这段代码是控制节点的核心，包含了neutron-server和neutron-rpc-server，其任务也即：api服务和rpc服务，包括RPC-server的创建，RPC-client的创建，WSGI server的创建。 server.boot_server()代码如下： 1234567891011121314151617181920#/neutron/server/__init__.pyimport sysfrom oslo_config import cfgfrom neutron._i18n import _from neutron.common import configdef boot_server(server_func): # the configuration will be read into the cfg.CONF global data structure config.init(sys.argv[1:]) config.setup_logging() config.set_config_defaults() if not cfg.CONF.config_file: sys.exit(_("ERROR: Unable to find configuration file via the default" " search paths (~/.neutron/, ~/, /etc/neutron/, /etc/) and" " the '--config-file' option!")) try: server_func() except KeyboardInterrupt: pass except RuntimeError as e: sys.exit(_("ERROR: %s") % e) ​ boot_server做的事情就是读取neutron\common\config配置文件，做初始化，包括日志，配置等，然后 server_func()，也即_main_neutron_server()启动。因为在api服务实现上目前有两种方式，”legacy”和”pecan”,根据读取的neutron\common\config中的配置来启动api服务。我们看”legacy”模式，也即 Paste + PasteDeploy + Routes + WebOb，这几个不同的模块分别负责应用的WSGI化、URL路由和请求处理等功能。 wsgi_eventlet.eventlet_wsgi_server() 123456789#/neutron/server/wsgi_eventlet.pyimport eventletfrom oslo_log import logfrom neutron._i18n import _LIfrom neutron import serviceLOG = log.getLogger(__name__)def eventlet_wsgi_server(): neutron_api = service.serve_wsgi(service.NeutronApiService) start_api_and_rpc_workers(neutron_api) neutron_api = service.serve_wsgi(service.NeutronApiService)，主要是创建服务，并启动。关键在于NeutronApiService，NeutronApiService继承了WsgiService类，调用了它的start方法，即_run_wsgi(app_name) 1234567891011121314151617181920212223242526272829303132333435363738394041424344#/neutron/service.pydef serve_wsgi(cls): try: service = cls.create() # create(cls, app_name='neutron') service.start() # _run_wsgi(self.app_name) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_LE('Unrecoverable error: please check log ' 'for details.')) return service#/neutron/service.py：NeutronApiServiceclass NeutronApiService(WsgiService): """Class for neutron-api service.""" @classmethod def create(cls, app_name='neutron'): # Setup logging early, supplying both the CLI options and the # configuration mapping from the config file # We only update the conf dict for the verbose and debug # flags. Everything else must be set up in the conf file... # Log the options used when starting if we're in debug mode... config.setup_logging() service = cls(app_name) return service #/neutron/service.py：WsgiServiceclass WsgiService(object): """Base class for WSGI based services. For each api you define, you must also define these flags: :&lt;api&gt;_listen: The address on which to listen :&lt;api&gt;_listen_port: The port on which to listen """ def __init__(self, app_name): self.app_name = app_name self.wsgi_app = None def start(self): self.wsgi_app = _run_wsgi(self.app_name) def wait(self): self.wsgi_app.wait() #/neutron/service.py def _run_wsgi(app_name): app = config.load_paste_app(app_name) if not app: LOG.error(_LE('No known API applications configured.')) return return run_wsgi_app(app) _run_wsgi(app_name)包括load_paste_app()和run_wsgi_app()。load_paste_app()从api-paste.ini文件加载composite为neutron的相关信息，生成一个应用。这个很关键，我们看看api-paste.ini文件 12345678910111213141516171819202122232425262728293031323334[composite:neutron]use = egg:Paste#urlmap/: neutronversions/v2.0: neutronapi_v2_0[composite:neutronapi_v2_0]use = call:neutron.auth:pipeline_factorynoauth = cors request_id catch_errors extensions neutronapiapp_v2_0keystone = cors request_id catch_errors authtoken keystonecontext extensions neutronapiapp_v2_0[filter:request_id]paste.filter_factory = oslo_middleware:RequestId.factory[filter:catch_errors]paste.filter_factory = oslo_middleware:CatchErrors.factory[filter:cors]paste.filter_factory = oslo_middleware.cors:filter_factoryoslo_config_project = neutron[filter:keystonecontext]paste.filter_factory = neutron.auth:NeutronKeystoneContext.factory[filter:authtoken]paste.filter_factory = keystonemiddleware.auth_token:filter_factory[filter:extensions]paste.filter_factory = neutron.api.extensions:plugin_aware_extension_middleware_factory[app:neutronversions]paste.app_factory = neutron.api.versions:Versions.factory[app:neutronapiapp_v2_0]paste.app_factory = neutron.api.v2.router:APIRouter.factory 最终调用了/v2.0: neutronapi_v2_0，具体是neutron.api.v2.router:APIRouter.factory，v2版api的实现是在neutron.api.v2.router:APIRouter，位于neutron\neutron\api\v2\router.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class APIRouter(base_wsgi.Router): @classmethod def factory(cls, global_config, **local_config): return cls(**local_config) def __init__(self, **local_config): mapper = routes_mapper.Mapper() #获取NeutornManage的core_plugin，这个定义在/etc/neutron/neutron.conf, #比如我的是core_plugin = ml2,service_plugins = router plugin = manager.NeutronManager.get_plugin() #扫描特定路径下的extensions ext_mgr = extensions.PluginAwareExtensionManager.get_instance() #扩展资源，包括networks，subnets,ports,subnetpools ext_mgr.extend_resources("2.0", attributes.RESOURCE_ATTRIBUTE_MAP) col_kwargs = dict(collection_actions=COLLECTION_ACTIONS, member_actions=MEMBER_ACTIONS) #定义的局部方法 def _map_resource(collection, resource, params, parent=None): allow_bulk = cfg.CONF.allow_bulk allow_pagination = cfg.CONF.allow_pagination allow_sorting = cfg.CONF.allow_sorting controller = base.create_resource( collection, resource, plugin, params, allow_bulk=allow_bulk, parent=parent, allow_pagination=allow_pagination, allow_sorting=allow_sorting) path_prefix = None if parent: path_prefix = "/%s/&#123;%s_id&#125;/%s" % (parent['collection_name'], parent['member_name'], collection) mapper_kwargs = dict(controller=controller, requirements=REQUIREMENTS, path_prefix=path_prefix, **col_kwargs) return mapper.collection(collection, resource, **mapper_kwargs) mapper.connect('index', '/', controller=Index(RESOURCES)) for resource in RESOURCES: _map_resource(RESOURCES[resource], resource, attributes.RESOURCE_ATTRIBUTE_MAP.get( RESOURCES[resource], dict())) resource_registry.register_resource_by_name(resource) for resource in SUB_RESOURCES: _map_resource(SUB_RESOURCES[resource]['collection_name'], resource, attributes.RESOURCE_ATTRIBUTE_MAP.get( SUB_RESOURCES[resource]['collection_name'], dict()), SUB_RESOURCES[resource]['parent']) # Certain policy checks require that the extensions are loaded # and the RESOURCE_ATTRIBUTE_MAP populated before they can be # properly initialized. This can only be claimed with certainty # once this point in the code has been reached. In the event # that the policies have been initialized before this point, # calling reset will cause the next policy check to # re-initialize with all of the required data in place. policy.reset() super(APIRouter, self).__init__(mapper) 我们好好分析上述代码做了什么，这是很关键的部分。 创建plugin(包括core plugin和service plugin) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#/neutron/api/v2/router.py:APIRouter plugin = manager.NeutronManager.get_plugin()#/neutron/manager.py:NeutronManager @classmethod def get_plugin(cls): # Return a weakref to minimize gc-preventing references. return weakref.proxy(cls.get_instance().plugin)#/neutron/manager.py:NeutronManager @classmethod def get_instance(cls): # double checked locking if not cls.has_instance(): cls._create_instance() return cls._instance#/neutron/manager.py:NeutronManager @classmethod @utils.synchronized("manager") def _create_instance(cls): if not cls.has_instance(): cls._instance = cls()#/neutron/manager.py:NeutronManagerclass NeutronManager(object): """Neutron's Manager class. Neutron's Manager class is responsible for parsing a config file and instantiating the correct plugin that concretely implements neutron_plugin_base class. The caller should make sure that NeutronManager is a singleton. """ _instance = None def __init__(self, options=None, config_file=None): # If no options have been provided, create an empty dict if not options: options = &#123;&#125; msg = validate_pre_plugin_load() if msg: LOG.critical(msg) raise Exception(msg) # NOTE(jkoelker) Testing for the subclass with the __subclasshook__ # breaks tach monitoring. It has been removed # intentionally to allow v2 plugins to be monitored # for performance metrics. plugin_provider = cfg.CONF.core_plugin LOG.info(_LI("Loading core plugin: %s"), plugin_provider) self.plugin = self._get_plugin_instance(CORE_PLUGINS_NAMESPACE, plugin_provider) msg = validate_post_plugin_load() if msg: LOG.critical(msg) raise Exception(msg) # core plugin as a part of plugin collection simplifies # checking extensions # TODO(enikanorov): make core plugin the same as # the rest of service plugins self.service_plugins = &#123;constants.CORE: self.plugin&#125; self._load_service_plugins() # Used by pecan WSGI self.resource_plugin_mappings = &#123;&#125; self.resource_controller_mappings = &#123;&#125; ​ get_plugin函数返回NeutronManager的plugin(core plugin)的弱引用，那么core plugin是什么对象呢?core plugin和service plugin在NeutronManager的__init__函数创建的。其中core plugin和service plugin分别根据neutron.conf配置文件中的core_plugin参数和service_plugins参数进行创建。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#/neutron/manager.py:NeutronManager def _get_plugin_instance(self, namespace, plugin_provider): plugin_class = self.load_class_for_provider(namespace, plugin_provider) return plugin_class() @staticmethod#/neutron/manager.py:NeutronManager def load_class_for_provider(namespace, plugin_provider): """Loads plugin using alias or class name :param namespace: namespace where alias is defined :param plugin_provider: plugin alias or class name :returns plugin that is loaded :raises ImportError if fails to load plugin """ try: return utils.load_class_by_alias_or_classname(namespace, plugin_provider) except ImportError: raise ImportError(_("Plugin '%s' not found.") % plugin_provider)#/neutron/common/utils.py def load_class_by_alias_or_classname(namespace, name):"""Load class using stevedore alias or the class name:param namespace: namespace where the alias is defined:param name: alias or class name of the class to be loaded:returns class if calls can be loaded:raises ImportError if class cannot be loaded"""if not name: LOG.error(_LE("Alias or class name is not set")) raise ImportError(_("Class not found."))try: # Try to resolve class by alias mgr = driver.DriverManager(namespace, name) # 利用stevedore模块创建core_plugin class_to_load = mgr.driverexcept RuntimeError: e1_info = sys.exc_info() # Fallback to class name try: class_to_load = importutils.import_class(name) except (ImportError, ValueError): LOG.error(_LE("Error loading class by alias"), exc_info=e1_info) LOG.error(_LE("Error loading class by class name"), exc_info=True) raise ImportError(_("Class not found."))return class_to_load 在def load_class_by_alias_or_classname(namespace, name)中我们调用mgr = driver.DriverManager(namespace, name)加载core_plugin，即ml2。 在配置文件setup.cfg中ml2 = neutron.plugins.ml2.plugin:Ml2Plugin，我们查看它的源码，如下： 123456789101112131415#/neutron/plugins/ml2/plugin.py:Ml2Plugin def __init__(self): # First load drivers, then initialize DB, then initialize drivers self.type_manager = managers.TypeManager() # self.extension_manager = managers.ExtensionManager() # self.mechanism_manager = managers.MechanismManager() # super(Ml2Plugin, self).__init__() self.type_manager.initialize() # 初始化 self.extension_manager.initialize() # 初始化 self.mechanism_manager.initialize() # 初始化 self._setup_dhcp() self._start_rpc_notifiers() self.add_agent_status_check(self.agent_health_check) self._verify_service_plugins_requirements() LOG.info(_LI("Modular L2 Plugin initialization complete")) 由于type_manager，extension_manager和mechanism_manager的创建都类似，所以这里我们主要分析type_manager代码流程，其余的简要说明。 12345678910111213141516class TypeManager(stevedore.named.NamedExtensionManager): """Manage network segment types using drivers.""" def __init__(self): # Mapping from type name to DriverManager self.drivers = &#123;&#125; LOG.info(_LI("Configured type driver names: %s"), cfg.CONF.ml2.type_drivers) super(TypeManager, self).__init__('neutron.ml2.type_drivers', cfg.CONF.ml2.type_drivers, invoke_on_load=True) LOG.info(_LI("Loaded type driver names: %s"), self.names()) self._register_types() self._check_tenant_network_types(cfg.CONF.ml2.tenant_network_types) self._check_external_network_type(cfg.CONF.ml2.external_network_type) TypeManager对象中的drivers即为type driver对象。drivers根据/etc/neutron/plugins/ml2/ml2_conf.ini配置文件中的type_drivers参数去构造。在我的OpenStack环境中type_drivers参数值如下 type_drivers = vxlan,flat 两个driver对象的创建在TypeManager类的父类stevedore.named.NamedExtensionManager中完成。且创建两个对象被/stevedore/extension.py:Extension包裹。然后调用self._register_types()，将创建完成的typedriver对象register到self.drivers字典中 1234567891011121314#/neutron/plugins/ml2/managers.py:TypeManager def _register_types(self): for ext in self: network_type = ext.obj.get_type() if network_type in self.drivers: LOG.error(_LE("Type driver '%(new_driver)s' ignored because" " type driver '%(old_driver)s' is already" " registered for type '%(type)s'"), &#123;'new_driver': ext.name, 'old_driver': self.drivers[network_type].name, 'type': network_type&#125;) else: self.drivers[network_type] = ext LOG.info(_LI("Registered types: %s"), self.drivers.keys()) 在register typedriver后，check tenant的network type是否在我们所register的type driver中，如果没有，则raise异常。其中tenant的network type是由/etc/neutron/plugins/ml2/ml2_conf.ini配置文件中的tenant_network_types参数设置。我的OpenStack环境的tenant_network_types参数配置如下: tenant_network_types = vxlan 1234567891011# /neutron/plugins/ml2/managers.py:TypeManagerdef _check_tenant_network_types(self, types): self.tenant_network_types = [] for network_type in types: if network_type in self.drivers: self.tenant_network_types.append(network_type) else: LOG.error(_LE("No type driver for tenant network_type: %s. " "Service terminated!"), network_type) raise SystemExit(1) LOG.info(_LI("Tenant network_types: %s"), self.tenant_network_types) 所以执行_check_tenant_network_types函数时，tenant network type校验成功。 mechanism_manager的创建也是类似的，它管理的mechanism driver。其根据/etc/neutron/plugins/ml2/ml2_conf.ini配置文件中的mechanism_drivers参数去构造mechanism driver对象。我的OpenStack环境mechanism_drivers配置参数如下: mechanism_drivers = openvswitch,l2population extension_manager的创建也类似。 extension_drivers = port_security 在type_manager，extension_manager和mechanism_manager创建完成后，执行initialize函数对所创建的driver进行初始化。 12345def initialize(self): # Initialize each driver in the list. for driver in self.ordered_ext_drivers: LOG.info(_LI("Initializing extension driver '%s'"), driver.name) driver.obj.initialize() 从上可以看出，最终会调用type_manager所管理的driver的initialize函数。 注意： PasteDeployment是一种机制或者说是一种设计模式，它用于在应用WSGI Application和Server提供一个联系的桥梁，并且为用户提供一个接口，当配置好PasteDeployment之后，用户只需调用loadapp方法就可以使用现有的WSGI Application，而保持了WSGIApplication对用户的透明性。 12345678910111213141516171819202122232425#/neutron/common/config.py def load_paste_app(app_name): """Builds and returns a WSGI app from a paste config file. :param app_name: Name of the application to load """ loader = wsgi.Loader(cfg.CONF) app = loader.load_app(app_name) return app#oslo_service/wsgi.py def load_app(self, name): """Return the paste URLMap wrapped WSGI application. :param name: Name of the application to load. :returns: Paste URLMap object wrapping the requested application. :raises: PasteAppNotFound """ try: LOG.debug("Loading app %(name)s from %(path)s", &#123;'name': name, 'path': self.config_path&#125;) return deploy.loadapp("config:%s" % self.config_path, name=name) except LookupError: LOG.exception(_LE("Couldn't lookup app: %s"), name) raise PasteAppNotFound(name=name, path=self.config_path) run_wsgi_app()运行刚创建的应用。它首先实例化一个Server对象，然后调用start()方法将其启动,也即是launch()方法。在传入的workers参数，通过get_api_workers()获取，如果neutron.conf的api_workers没有配置，它会传入cpu数目的workers，达到最佳性能。 12345678910111213141516171819202122232425#/neutron/service.py def run_wsgi_app(app): server = wsgi.Server("Neutron") server.start(app, cfg.CONF.bind_port, cfg.CONF.bind_host, workers=_get_api_workers()) LOG.info(_LI("Neutron service started, listening on %(host)s:%(port)s"), &#123;'host': cfg.CONF.bind_host, 'port': cfg.CONF.bind_port&#125;) return serverdef _get_api_workers(): workers = cfg.CONF.api_workers if workers is None: workers = processutils.get_worker_count() return workers#neutron/wsgi.py def start(self, application, port, host='0.0.0.0', workers=0): """Run a WSGI server with the given application.""" self._host = host self._port = port backlog = CONF.backlog self._socket = self._get_socket(self._host, self._port, backlog=backlog) self._launch(application, workers) _launch()方法 123456789101112131415161718192021def _launch(self, application, workers=0): service = WorkerService(self, application, self.disable_ssl) if workers &lt; 1: # The API service should run in the current process. # workers小于1直接运行在当前的进程 self._server = service # Dump the initial option values cfg.CONF.log_opt_values(LOG, logging.DEBUG) service.start() systemd.notify_once() else: # dispose the whole pool before os.fork, otherwise there will # be shared DB connections in child processes which may cause # DB errors. api.dispose() # The API service runs in a number of child processes. # Minimize the cost of checking for child exit by extending the # wait interval past the default of 0.01s. self._server = common_service.ProcessLauncher(cfg.CONF, wait_interval=1.0) self._server.launch_service(service, workers=workers)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron架构]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（1）]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%881%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 Neutron是OpenStack中用于管理网络的项目。neutron代码的入口配置文件neutron/setup.cfg，从[entry_points]可以看到整个项目服务的结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125[entry_points]console_scripts = neutron-bgp-dragent = neutron.cmd.eventlet.agents.bgp_dragent:main neutron-db-manage = neutron.db.migration.cli:main neutron-debug = neutron.debug.shell:main neutron-dhcp-agent = neutron.cmd.eventlet.agents.dhcp:main // neutron-keepalived-state-change = neutron.cmd.keepalived_state_change:main neutron-ipset-cleanup = neutron.cmd.ipset_cleanup:main neutron-l3-agent = neutron.cmd.eventlet.agents.l3:main // neutron-linuxbridge-agent = neutron.cmd.eventlet.plugins.linuxbridge_neutron_agent:main neutron-linuxbridge-cleanup = neutron.cmd.linuxbridge_cleanup:main neutron-macvtap-agent = neutron.cmd.eventlet.plugins.macvtap_neutron_agent:main neutron-metadata-agent = neutron.cmd.eventlet.agents.metadata:main neutron-netns-cleanup = neutron.cmd.netns_cleanup:main neutron-ns-metadata-proxy = neutron.cmd.eventlet.agents.metadata_proxy:main neutron-openvswitch-agent = neutron.cmd.eventlet.plugins.ovs_neutron_agent:main // neutron-ovs-cleanup = neutron.cmd.ovs_cleanup:main neutron-pd-notify = neutron.cmd.pd_notify:main neutron-server = neutron.cmd.eventlet.server:main // neutron-rpc-server = neutron.cmd.eventlet.server:main_rpc_eventlet // neutron-rootwrap = oslo_rootwrap.cmd:main neutron-rootwrap-daemon = oslo_rootwrap.cmd:daemon neutron-usage-audit = neutron.cmd.eventlet.usage_audit:main neutron-metering-agent = neutron.cmd.eventlet.services.metering_agent:main neutron-sriov-nic-agent = neutron.cmd.eventlet.plugins.sriov_nic_neutron_agent:main neutron-sanity-check = neutron.cmd.sanity_check:mainneutron.core_plugins = ml2 = neutron.plugins.ml2.plugin:Ml2Plugin //neutron.service_plugins = dummy = neutron.tests.unit.dummy_plugin:DummyServicePlugin router = neutron.services.l3_router.l3_router_plugin:L3RouterPlugin // firewall = neutron_fwaas.services.firewall.fwaas_plugin:FirewallPlugin // lbaas = neutron_lbaas.services.loadbalancer.plugin:LoadBalancerPlugin vpnaas = neutron_vpnaas.services.vpn.plugin:VPNDriverPlugin metering = neutron.services.metering.metering_plugin:MeteringPlugin neutron.services.firewall.fwaas_plugin.FirewallPlugin = neutron_fwaas.services.firewall.fwaas_plugin:FirewallPlugin neutron.services.loadbalancer.plugin.LoadBalancerPlugin = neutron_lbaas.services.loadbalancer.plugin:LoadBalancerPlugin neutron.services.vpn.plugin.VPNDriverPlugin = neutron_vpnaas.services.vpn.plugin:VPNDriverPlugin qos = neutron.services.qos.qos_plugin:QoSPlugin bgp = neutron.services.bgp.bgp_plugin:BgpPlugin tag = neutron.services.tag.tag_plugin:TagPlugin flavors = neutron.services.flavors.flavors_plugin:FlavorsPlugin auto_allocate = neutron.services.auto_allocate.plugin:Plugin network_ip_availability = neutron.services.network_ip_availability.plugin:NetworkIPAvailabilityPlugin timestamp_core = neutron.services.timestamp.timestamp_plugin:TimeStampPluginneutron.qos.notification_drivers = message_queue = neutron.services.qos.notification_drivers.message_queue:RpcQosServiceNotificationDriver //neutron.ml2.type_drivers = flat = neutron.plugins.ml2.drivers.type_flat:FlatTypeDriver local = neutron.plugins.ml2.drivers.type_local:LocalTypeDriver vlan = neutron.plugins.ml2.drivers.type_vlan:VlanTypeDriver geneve = neutron.plugins.ml2.drivers.type_geneve:GeneveTypeDriver gre = neutron.plugins.ml2.drivers.type_gre:GreTypeDriver vxlan = neutron.plugins.ml2.drivers.type_vxlan:VxlanTypeDriver //neutron.ml2.mechanism_drivers = logger = neutron.tests.unit.plugins.ml2.drivers.mechanism_logger:LoggerMechanismDriver test = neutron.tests.unit.plugins.ml2.drivers.mechanism_test:TestMechanismDriver linuxbridge = neutron.plugins.ml2.drivers.linuxbridge.mech_driver.mech_linuxbridge:LinuxbridgeMechanismDriver macvtap = neutron.plugins.ml2.drivers.macvtap.mech_driver.mech_macvtap:MacvtapMechanismDriver openvswitch = neutron.plugins.ml2.drivers.openvswitch.mech_driver.mech_openvswitch:OpenvswitchMechanismDriver l2population = neutron.plugins.ml2.drivers.l2pop.mech_driver:L2populationMechanismDriver sriovnicswitch = neutron.plugins.ml2.drivers.mech_sriov.mech_driver.mech_driver:SriovNicSwitchMechanismDriver fake_agent = neutron.tests.unit.plugins.ml2.drivers.mech_fake_agent:FakeAgentMechanismDriverneutron.ml2.extension_drivers = test = neutron.tests.unit.plugins.ml2.drivers.ext_test:TestExtensionDriver testdb = neutron.tests.unit.plugins.ml2.drivers.ext_test:TestDBExtensionDriver port_security = neutron.plugins.ml2.extensions.port_security:PortSecurityExtensionDriver qos = neutron.plugins.ml2.extensions.qos:QosExtensionDriver dns = neutron.plugins.ml2.extensions.dns_integration:DNSExtensionDriverML2neutron.openstack.common.cache.backends = memory = neutron.openstack.common.cache._backends.memory:MemoryBackendneutron.ipam_drivers = fake = neutron.tests.unit.ipam.fake_driver:FakeDriver internal = neutron.ipam.drivers.neutrondb_ipam.driver:NeutronDbPoolneutron.agent.l2.extensions = qos = neutron.agent.l2.extensions.qos:QosAgentExtensionneutron.qos.agent_drivers = ovs = neutron.plugins.ml2.drivers.openvswitch.agent.extension_drivers.qos_driver:QosOVSAgentDriver sriov = neutron.plugins.ml2.drivers.mech_sriov.agent.extension_drivers.qos_driver:QosSRIOVAgentDriver linuxbridge = neutron.plugins.ml2.drivers.linuxbridge.agent.extension_drivers.qos_driver:QosLinuxbridgeAgentDriverneutron.agent.linux.pd_drivers = dibbler = neutron.agent.linux.dibbler:PDDibblerneutron.services.external_dns_drivers = designate = neutron.services.externaldns.drivers.designate.driver:Designate# These are for backwards compat with Icehouse notification_driver configuration values# TODO(mriedem): Remove these once liberty-eol happens.oslo.messaging.notify.drivers = neutron.openstack.common.notifier.log_notifier = oslo_messaging.notify._impl_log:LogDriver neutron.openstack.common.notifier.no_op_notifier = oslo_messaging.notify._impl_noop:NoOpDriver neutron.openstack.common.notifier.test_notifier = oslo_messaging.notify._impl_test:TestDriver neutron.openstack.common.notifier.rpc_notifier2 = oslo_messaging.notify.messaging:MessagingV2Driver neutron.openstack.common.notifier.rpc_notifier = oslo_messaging.notify.messaging:MessagingDriveroslo.config.opts = neutron = neutron.opts:list_opts neutron.agent = neutron.opts:list_agent_opts neutron.base.agent = neutron.opts:list_base_agent_opts neutron.bgp.agent = neutron.services.bgp.common.opts:list_bgp_agent_opts neutron.db = neutron.opts:list_db_opts neutron.dhcp.agent = neutron.opts:list_dhcp_agent_opts neutron.extensions = neutron.opts:list_extension_opts neutron.l3.agent = neutron.opts:list_l3_agent_opts neutron.metadata.agent = neutron.opts:list_metadata_agent_opts neutron.metering.agent = neutron.opts:list_metering_agent_opts neutron.ml2 = neutron.opts:list_ml2_conf_opts neutron.ml2.linuxbridge.agent = neutron.opts:list_linux_bridge_opts neutron.ml2.macvtap.agent = neutron.opts:list_macvtap_opts neutron.ml2.ovs.agent = neutron.opts:list_ovs_opts neutron.ml2.sriov = neutron.opts:list_ml2_conf_sriov_opts neutron.ml2.sriov.agent = neutron.opts:list_sriov_agent_opts neutron.qos = neutron.opts:list_qos_opts nova.auth = neutron.opts:list_auth_optsoslo.config.opts.defaults = neutron = neutron.common.config:set_cors_middleware_defaultsneutron.db.alembic_migrations = neutron = neutron.db.migration:alembic_migrationsneutron.interface_drivers = ivs = neutron.agent.linux.interface:IVSInterfaceDriver linuxbridge = neutron.agent.linux.interface:BridgeInterfaceDriver null = neutron.agent.linux.interface:NullDriver openvswitch = neutron.agent.linux.interface:OVSInterfaceDriverneutron.agent.firewall_drivers = noop = neutron.agent.firewall:NoopFirewallDriver iptables = neutron.agent.linux.iptables_firewall:IptablesFirewallDriver iptables_hybrid = neutron.agent.linux.iptables_firewall:OVSHybridIptablesFirewallDriver openvswitch = neutron.agent.linux.openvswitch_firewall:OVSFirewallDriver 命名空间“neutron.core_plugins”和“neutron.service_plugins”分别指明各种CorePlugin与ServicePlugin实现的入口，而“console_scripts”指明了neutron-server服务以及各种Agent实现的入口，此外还包括一些辅助的命令或者工具。 我们按照以下顺序学习源码： 控制节点服务：neutron-server neutron-server 是Neutron启动neutron-server的api服务，负责接收用户的RESTful API请求根据setup.cfg文件可以看出neutron代码路径是neutron\cmd\eventlet\server:main neutron-rpc-server 是Neutron中启动neutron-server的rpc服务，将请求分发给各种agent。代码路径是neutron\cmd\eventlet\server:main_rpc_eventlet 前两个部分组成了neutron-server服务，即是控制节点要启动的服务。 计算节点服务：neutron-openvswitch-agent neutron-openvswitch-agent neutron-openvswitch-agent：Open vSwitch Agent部署在计算节点或者网络节点上，进行管理OVS虚拟交换机。根据setup.cfg文件可以看出neutron-openvswitch-agent的代码路径是neutron\cmd\eventlet\plugins\ovs_neutron_agent:main 网络节点服务：neutron-openvswitch-agent neutron-l3-agent neutron-dhcp-agent neutron-l3-agent l3 agent部署在计算节点或者网络节点上,负责3层虚拟网络的管理。根据setup.cfg文件可以看出neutron-l3-agent的代码路径是neutron\cmd\eventlet\agents\l3:main neutron-dhcp-agent ml2 router firewall message_queue]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线程同步工具CountDownLatch，CyclicBarrier和Semaphore的用法]]></title>
      <url>%2F2017%2F02%2F25%2F%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7CountDownLatch%EF%BC%8CCyclicBarrier%E5%92%8CSemaphore%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
      <content type="text"><![CDATA[CountDownLatch​ CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 伪代码为： ​ Main thread start​ Create CountDownLatch for N threads​ Create and start N threads​ Main thread wait on latch​ N threads completes there tasks are returns​ Main thread resume execution 主要方法： public CountDownLatch(int count); public void countDown(); public void await() throws InterruptedException CountDownLatch实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package Demo;import java.util.concurrent.CountDownLatch;public abstract class BaseHealthChecker implements Runnable&#123; private CountDownLatch latch; private String name; private boolean isServiceUp; public BaseHealthChecker(CountDownLatch latch, String name) &#123; super(); this.latch = latch; this.name = name; this.isServiceUp=false; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public boolean isServiceUp() &#123; return isServiceUp; &#125; public void setServiceUp(boolean isServiceUp) &#123; this.isServiceUp = isServiceUp; &#125; public abstract void checkService(); @Override public void run() &#123; // TODO Auto-generated method stub try &#123; checkService(); isServiceUp=true; &#125; catch (Throwable t) &#123; // TODO: handle exception t.printStackTrace(System.err); isServiceUp=false; &#125; finally&#123; if(latch!=null)&#123; latch.countDown(); &#125; &#125; &#125; &#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class CacheHealthChecker extends BaseHealthChecker &#123; public CacheHealthChecker(CountDownLatch latch) &#123; super(latch, "Cache Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class DatabaseHealthChecker extends BaseHealthChecker &#123; public DatabaseHealthChecker(CountDownLatch latch) &#123; super(latch, "Database Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class NetworkHealthChecker extends BaseHealthChecker &#123; public NetworkHealthChecker(CountDownLatch latch) &#123; super(latch, "Network Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+" is Up"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package Demo;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ApplicationStartupUtil &#123; private static List&lt;BaseHealthChecker&gt; services; private static CountDownLatch latch; private final static ApplicationStartupUtil app=new ApplicationStartupUtil(); public ApplicationStartupUtil()&#123; &#125; public static ApplicationStartupUtil getInstance()&#123; return app; &#125; public static boolean checkExternalService()&#123; boolean re=true; latch=new CountDownLatch(3); services=new ArrayList&lt;BaseHealthChecker&gt;(); services.add(new NetworkHealthChecker(latch)); services.add(new CacheHealthChecker(latch)); services.add(new DatabaseHealthChecker(latch)); ExecutorService executors=Executors.newFixedThreadPool(services.size()); for(final BaseHealthChecker v: services)&#123; executors.execute(v); &#125; executors.shutdown(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for(final BaseHealthChecker v:services)&#123; if(! v.isServiceUp())&#123; re=false; System.out.println("All services checked ,result is "+re); &#125; &#125; System.out.println("All services checked ,result is "+re); return re; &#125;&#125; 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; boolean re=false; ApplicationStartupUtil.checkExternalService(); &#125;&#125;//输出：Checking Network ServiceChecking Cache ServiceChecking Database ServiceNetwork Service is UpCache Serviceis UpDatabase Serviceis UpAll services checked ,result is true CyclicBarrier​ CyclicBarrier 类有一个整数初始值，此值表示将在同一点同步的线程数量。当其中一个线程到达确定点，它会调用await() 方法来等待其他线程。此时CyclicBarrier阻塞该线程进入休眠等待其他线程的到达。当最后一个线程调用CyclicBarrier 类的await() 方法，它唤醒所有等待的线程并继续执行它们的任务。 ​ CountDownLatch和CyclicBarrier的区别在于：CountDownLatch 适用于一组线程和另一个主线程之间的工作协作。一个主线程等待一组工作线程的任务完毕才继续它的执行是使用 CountDownLatch 的主要场景；CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。CyclicBarrier 的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的； CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 CyclicBarrier实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.Random;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class DemoCyclicBarrier &#123; public static void main(String[] args) &#123; int thread_num=5; CyclicBarrier cyclicBarrier=new CyclicBarrier(thread_num, new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("Internal Barrier"); &#125; &#125;); ExecutorService executor=Executors.newFixedThreadPool(thread_num); for (int i=0;i&lt;5;i++)&#123; executor.execute(new worker("worker "+i, cyclicBarrier)); &#125; executor.shutdown(); &#125;&#125;class worker implements Runnable&#123; private String name; private CyclicBarrier cyclicbarrier; public worker(String name, CyclicBarrier cyclicBarrier)&#123; this.name=name; this.cyclicbarrier=cyclicBarrier; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; Thread.sleep(1000 * (new Random()).nextInt(8)); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker "+this.getName()+" is waiting"); try &#123; cyclicbarrier.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker"+this.getName()+" is working"); &#125; &#125; Semaphore​ Semaphore 直译是信号量，可能称它是许可量更容易理解。当然，因为在计算机科学中这个名字由来已久，所以不能乱改。它的功能比较好理解，就是通过构造函数设定一个数量的许可，然后通过 acquire 方法获得许可，release 方法释放许可。它还有 tryAcquire 和 acquireUninterruptibly 方法，可以根据自己的需要选择。 Semaphore实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); Semaphore semp=new Semaphore(5); for(int i=0;i&lt;10;i++)&#123; exec.execute(new workerThread(i,semp)); &#125; exec.shutdown(); &#125;&#125;class workerThread implements Runnable&#123; private int id ; private Semaphore semp; public workerThread(int id, Semaphore semp) &#123; super(); this.id = id; this.semp = semp; &#125; public int getId() &#123; return id; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; semp.acquire(); System.out.println("workerThread id "+this.getId()+" get Access"); Thread.sleep((long) (Math.random() * 10000)); System.out.println("workerThread id "+this.getId()+" finish the work"); semp.release();//注销该语句后，只会执行5个线程，其他处在阻塞中 &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;//输出(未注销semp.release())workerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 4 get AccessworkerThread id 1 get AccessworkerThread id 1 finish the workworkerThread id 5 get AccessworkerThread id 2 finish the workworkerThread id 6 get AccessworkerThread id 4 finish the workworkerThread id 7 get AccessworkerThread id 6 finish the workworkerThread id 8 get AccessworkerThread id 7 finish the workworkerThread id 9 get AccessworkerThread id 8 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 9 finish the workworkerThread id 5 finish the work//输出(注销semp.release())workerThread id 1 get AccessworkerThread id 4 get AccessworkerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 2 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 4 finish the workworkerThread id 1 finish the work 参考：1.http://www.importnew.com/15731.html 2.http://blog.csdn.net/junshuaizhang/article/details/39580751 3.http://blog.csdn.net/junshuaizhang/article/details/39667289 4.http://developer.51cto.com/art/201403/432095.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之Executor框架和线程池]]></title>
      <url>%2F2017%2F02%2F23%2FJava%E5%B9%B6%E5%8F%91%E4%B9%8BExecutor%E6%A1%86%E6%9E%B6%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[1.基础简介：​ 在Java 5之后，并发编程引入了一堆新的启动、调度和管理线程的API。Executor框架便是Java 5中引入的，其内部使用了线程池机制，它在java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。 ​ Executor框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable等。 Executor接口中之定义了一个方法execute（Runnable command），该方法接收一个Runable实例，它用来执行一个任务，任务即一个实现了Runnable接口的类。 2.ExecutorService接口：​ ExecutorService接口继承自Executor接口，它提供了更丰富的实现多线程的方法，比如，ExecutorService提供了关闭自己的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以调用ExecutorService的shutdown（）方法来平滑地关闭 。在调用该方法之后，它会停止接受任何新的任务且等待已经提交的任务执行完成(已经提交的任务会分两类：一类是已经在执行的，另一类是还没有开始执行的)，当所有已经提交的任务执行完毕后将会关闭ExecutorService。因此我们一般用该接口来实现和管理多线程。 ​ ExecutorService的生命周期包括三种状态：运行、关闭、终止。创建后便进入运行状态，当调用了shutdown（）方法时，便进入关闭状态，此时意味着ExecutorService不再接受新的任务，但它还在执行已经提交了的任务，当素有已经提交了的任务执行完后，便到达终止状态。如果不调用shutdown（）方法，ExecutorService会一直处在运行状态，不断接收新的任务，执行新的任务，服务器端一般不需要关闭它，保持一直运行即可。 3.ExecutorService中submit和execute的区别：接收的参数不一样 submit有返回值，而execute没有 ​ Method submit extends base method Executor.execute by creating and returning a Future that can be used to cancel execution and/or wait for completion. ​ 用到返回值的例子，比如说我有很多个做validation的task，我希望所有的task执行完，然后每个task告诉我它的执行结果，是成功还是失败，如果是失败，原因是什么。然后我就可以把所有失败的原因综合起来发给调用者。 submit方便Exception处理 ​ There is a difference when looking at exception handling. If your tasks throws an exception and if it was submitted with execute this exception will go to the uncaught exception handler (when you don’t have provided one explicitly, the default one will just print the stack trace to System.err). If you submitted the task with submit any thrown exception, checked or not, is then part of the task’s return status. For a task that was submitted with submit and that terminates with an exception, the Future.get will rethrow this exception, wrapped in an ExecutionException. ​ 意思就是如果你在你的task里会抛出checked或者unchecked exception，而你又希望外面的调用者能够感知这些exception并做出及时的处理，那么就需要用到submit，通过捕获Future.get抛出的异常。 ​ 比如说，我有很多更新各种数据的task，我希望如果其中一个task失败，其它的task就不需要执行了。那我就需要catch Future.get抛出的异常，然后终止其它task的执行 下面的Executor执行Runnable任务和Executor执行Callable任务便是execute和submit的例子。 4.Executors（线程池管理类）：​ Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 public static ExecutorService newCachedThreadPool() 创建一个可缓存的线程池，调用execute将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 ​ 缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse.如果没有，就建一个新的线程加入池中，缓存型池子通常用于执行一些生存期很短的异步型任务。因此在一些面向连接的daemon型SERVER中用得不多。但对于生存期短的异步任务，它是Executor的首选。能reuse的线程，必须是timeout IDLE内的池中线程，缺省 timeout是60s,超过这个IDLE时长，线程实例将被终止及移出池。注意，放入CachedThreadPool的线程不必担心其结束，超过TIMEOUT不活动，其会自动被终止。 public static ExecutorService newFixedThreadPool(int nThreads) 创建固定数目线程的线程池 ​ newFixedThreadPool与cacheThreadPool差不多，也是能reuse就用，但不能随时建新的线程。其独特之处:任意时间点，最多只能有固定数目的活动线程存在，此时如果有新的线程要建立，只能放在另外的队列中等待，直到当前的线程中某个线程终止直接被移出池子。和cacheThreadPool不同，FixedThreadPool没有IDLE机制（可能也有，但既然文档没提，肯定非常长，类似依赖上层的TCP或UDP IDLE机制之类的），所以FixedThreadPool多数针对一些很稳定很固定的正规并发线程，多用于服务器。从方法的源代码看，cache池和fixed 池调用的是同一个底层池，只不过参数不同:fixed池线程数固定，并且是0秒IDLE（无IDLE）cache池线程数支持0-Integer.MAX_VALUE(显然完全没考虑主机的资源承受能力），60秒IDLE 。 public static ExecutorService newSingleThreadExecutor() 创建一个单线程化的Executor。 ​ 单例线程，任意时间池中只能有一个线程，用的是和cache池和fixed池相同的底层池，但线程数目是1-1,0秒IDLE（无IDLE）。 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) 创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。 ​ 调度型线程池，这个池子里的线程可以按schedule依次delay执行，或周期执行。 一般来说，CachedTheadPool在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的Executor的首选，只有当这种方式会引发问题时（比如需要大量长时间面向连接的线程时），才需要考虑用FixedThreadPool。（该段话摘自《Thinking in Java》第四版） 5.Executor接口执行任务：Executor执行Runnable任务 ​ 通过Executors的以上四个静态工厂方法获得 ExecutorService实例，而后调用该实例的execute（Runnable command）方法即可。一旦Runnable任务传递到execute（）方法，该方法便会自动在一个线程上执行。下面是是Executor执行Runnable任务的示例代码： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TestCachedThreadPool&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); //ExecutorService executorService = Executors.newFixedThreadPool(3); //ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 5; i++)&#123; executorService.execute(new TestRunnable(i)); &#125; executorService.shutdown(); &#125; &#125; class TestRunnable implements Runnable&#123; private int count ; public TestRunnable(int count)&#123; this.count=count; System.out.println("Create Thread-"+count); &#125; public void run()&#123; System.out.println("线程池中的"+Thread.currentThread().getName() + "被调用来处理Thread-"+count); &#125; &#125; //输出：Create Thread-0Create Thread-1Create Thread-2线程池中的pool-1-thread-1被调用来处理Thread-0Create Thread-3线程池中的pool-1-thread-2被调用来处理Thread-1Create Thread-4线程池中的pool-1-thread-2被调用来处理Thread-4线程池中的pool-1-thread-3被调用来处理Thread-2线程池中的pool-1-thread-4被调用来处理Thread-3 ​ 从结果中可以看出，pool-1-thread-2被调用了两次，这是随机的，execute会首先在线程池中选择一个已有空闲线程来执行任务，如果线程池中没有空闲线程，它便会创建一个新的线程来执行任务 同时也可以配合ThreadFactory接口的使用 123456789101112131415161718192021222324252627282930313233343536ExecutorService daemonThreadFactory = Executors.newCachedThreadPool(new DaemonThreadFactory()); ExecutorService maxPriorityThreadFactory = Executors.newCachedThreadPool(new MaxPriorityThreadFactory()); ExecutorService minPriorityThreadFactory = Executors.newCachedThreadPool(new MinPriorityThreadFactory());//设置后台线程属性class DaemonThreadFactory implements ThreadFactory&#123; @Override public Thread newThread(Runnable arg0) &#123; // TODO Auto-generated method stub Thread t=new Thread(arg0); t.setDaemon(true); return t; &#125; &#125;//设置最高优先级属性class MaxPriorityThreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setPriority(Thread.MAX_PRIORITY); return t; &#125;&#125;//设置最低优先级属性class MinPriorityThreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setPriority(Thread.MIN_PRIORITY); return t; &#125;&#125; Executor执行Callable任务 ​ 在Java 5之后，任务分两类：一类是实现了Runnable接口的类，一类是实现了Callable接口的类。两者都可以被ExecutorService执行，但是Runnable任务没有返回值，而Callable任务有返回值。并且Callable的call()方法只能通过ExecutorService的submit(Callable task) 方法来执行，并且返回一个 Future，是表示任务等待完成的 Future。 ​ Callable接口类似于Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常而Callable又返回结果，而且当获取返回结果时可能会抛出异常。Callable中的call()方法类似Runnable的run()方法，区别同样是有返回值，后者没有。 ​ 当将一个Callable的对象传递给ExecutorService的submit方法，则该call方法自动在一个线程上执行，并且会返回执行结果Future对象。同样，将Runnable的对象传递给ExecutorService的submit方法，则该run方法自动在一个线程上执行，并且会返回执行结果Future对象，但是在该Future对象上调用get方法，将返回null。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import java.util.ArrayList; import java.util.List; import java.util.concurrent.*; public class CallableDemo&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;(); //创建10个任务并执行 for (int i = 0; i &lt; 10; i++)&#123; //使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中 Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i)); //将任务执行结果存储到List中 resultList.add(future); &#125; //遍历任务的结果 for (Future&lt;String&gt; fs : resultList)&#123; try&#123; while(!fs.isDone());//Future返回如果没有完成，则一直循环等待，直到Future返回完成 System.out.println(fs.get()); //打印各个线程（任务）执行的结果 &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125;catch(ExecutionException e)&#123; e.printStackTrace(); &#125;finally&#123; //启动一次顺序关闭，执行以前提交的任务，但不接受新任务 executorService.shutdown(); &#125; &#125; &#125; &#125; class TaskWithResult implements Callable&lt;String&gt;&#123; private int id; public TaskWithResult(int id)&#123; this.id = id; &#125; /** * 任务的具体过程，一旦任务传给ExecutorService的submit方法， * 则该方法自动在一个线程上执行 */ public String call() throws Exception &#123; System.out.println("Task id="+id+" 的call()方法被" + Thread.currentThread().getName()+"自动调用！！"); //该返回结果将被Future的get方法得到 return "Task id="+id+" 的call()方法被自动调用，任务返回的结果是：" + id + ""; &#125; &#125; //输出：Task id=0 的call()方法被pool-1-thread-1自动调用！！Task id=2 的call()方法被pool-1-thread-3自动调用！！Task id=1 的call()方法被pool-1-thread-2自动调用！！Task id=3 的call()方法被pool-1-thread-4自动调用！！Task id=4 的call()方法被pool-1-thread-5自动调用！！Task id=0 的call()方法被自动调用，任务返回的结果是：0Task id=9 的call()方法被pool-1-thread-1自动调用！！Task id=6 的call()方法被pool-1-thread-7自动调用！！Task id=5 的call()方法被pool-1-thread-6自动调用！！Task id=7 的call()方法被pool-1-thread-8自动调用！！Task id=1 的call()方法被自动调用，任务返回的结果是：1Task id=2 的call()方法被自动调用，任务返回的结果是：2Task id=8 的call()方法被pool-1-thread-9自动调用！！Task id=3 的call()方法被自动调用，任务返回的结果是：3Task id=4 的call()方法被自动调用，任务返回的结果是：4Task id=5 的call()方法被自动调用，任务返回的结果是：5Task id=6 的call()方法被自动调用，任务返回的结果是：6Task id=7 的call()方法被自动调用，任务返回的结果是：7Task id=8 的call()方法被自动调用，任务返回的结果是：8Task id=9 的call()方法被自动调用，任务返回的结果是：9 ​ 从结果中可以同样可以看出，pool-1-thread-1被调用2次处理id=0和id=9的任务，submit也是首先选择空闲线程来执行任务，如果没有，才会创建新的线程来执行任务。另外，需要注意：如果Future的返回尚未完成，则get（）方法会阻塞等待，直到Future完成返回，可以通过调用isDone（）方法判断Future是否完成了返回。 Executor执行inVokeAny任务 ​ 方法 invokeAny() 接收一個包含 Callable 对象的集合作为参数。调用该方法不会返回 Future 对象，而是返回集合中某一個 Callable 对象的结果，而且无法保证调用之后返回的结果是哪一個 Callable，只知道它是这些 Callable 中一個执行结束的 Callable 对象。如果一个任务运行完毕或者抛出异常，方法会取消其它的 Callable 的执行。 Executor执行invokeAll任务 ​ 方法 invokeAll() 会调用存在于参数集合中的所有 Callable 对象，并且返回壹個包含 Future 对象的集合，你可以通过这個返回的集合来管理每個 Callable 的执行结果。需要注意的是，任务有可能因为异常而导致运行结束，所以它可能并不是真的成功运行了。但是我们没有办法通过 Future 对象来了解到这個差异。 自定义线程池ThreadPoolExecutor ​ 自定义线程池，可以用ThreadPoolExecutor类创建，它有多个构造方法来创建线程池，用该类很容易实现自定义的线程池，这里先贴上示例程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class ThreadPoolTest&#123; public static void main(String[] args)&#123; //创建等待队列 BlockingQueue&lt;Runnable&gt; bqueue = new ArrayBlockingQueue&lt;Runnable&gt;(20); //创建线程池，池中保存的线程数为3，允许的最大线程数为5 ThreadPoolExecutor pool = new ThreadPoolExecutor(3,5,50,TimeUnit.MILLISECONDS,bqueue); //创建七个任务 Runnable t1 = new MyThreads("t1"); Runnable t2 = new MyThreads("t2"); Runnable t3 = new MyThreads("t3"); Runnable t4 = new MyThreads("t4"); Runnable t5 = new MyThreads("t5"); Runnable t6 = new MyThreads("t6"); Runnable t7 = new MyThreads("t7"); //每个任务会在一个线程上执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); pool.execute(t6); pool.execute(t7); //关闭线程池 pool.shutdown(); &#125; &#125; class MyThreads implements Runnable&#123; private String name; public String getName() &#123; return name; &#125; public MyThreads(String name) &#123; // TODO Auto-generated constructor stub this.name=name; &#125; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + "正在执行 "+this.getName()); try&#123; Thread.sleep(100); &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; //输出pool-1-thread-2正在执行 t2pool-1-thread-3正在执行 t3pool-1-thread-1正在执行 t1pool-1-thread-1正在执行 t4pool-1-thread-3正在执行 t6pool-1-thread-2正在执行 t5pool-1-thread-3正在执行 t7 ​ 从结果中可以看出，七个任务是在线程池的三个线程上执行的。这里简要说明下用到的ThreadPoolExecuror类的构造方法中各个参数的含义。 1public ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue) corePoolSize：线程池中所保存的核心线程数，包括空闲线程。 maximumPoolSize：池中允许的最大线程数。 keepAliveTime：线程池中的空闲线程所能持续的最长时间。 unit：持续时间的单位。 workQueue：任务执行前保存任务的队列，仅保存由execute方法提交的Runnable任务。 根据ThreadPoolExecutor源码前面大段的注释，我们可以看出，当试图通过excute方法讲一个Runnable任务添加到线程池中时，按照如下顺序来处理： 1、如果线程池中的线程数量少于corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务； 2、如果线程池中的线程数量大于等于corePoolSize，但缓冲队列workQueue未满，则将新添加的任务放到workQueue中，按照FIFO的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）； 3、如果线程池中的线程数量大于等于corePoolSize，且缓冲队列workQueue已满，但线程池中的线程数量小于maximumPoolSize，则会创建新的线程来处理被添加的任务； 4、如果线程池中的线程数量等于了maximumPoolSize，有4种才处理方式（该构造方法调用了含有5个参数的构造方法，并将最后一个构造方法为RejectedExecutionHandler类型，它在处理线程溢出时有4种方式，这里不再细说，要了解的，自己可以阅读下源码）。 ​ 另外，当线程池中的线程数量大于corePoolSize时，如果里面有线程的空闲时间超过了keepAliveTime，就将其移除线程池，这样，可以动态地调整线程池中线程的数量。我们大致来看下Executors的源码，newCachedThreadPool的不带RejectedExecutionHandler参数（即第五个参数，线程数量超过maximumPoolSize时，指定处理方式）的构造方法如下： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 它将corePoolSize设定为0，而将maximumPoolSize设定为了Integer的最大值，线程空闲超过60秒，将会从线程池中移除。由于核心线程数为0，因此每次添加任务，都会先从线程池中找空闲线程，如果没有就会创建一个线程（SynchronousQueue决定的，后面会说）来执行新的任务，并将该线程加入到线程池中，而最大允许的线程数为Integer的最大值，因此这个线程池理论上可以不断扩大。 再来看newFixedThreadPool的不带RejectedExecutionHandler参数的构造方法，如下： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 它将corePoolSize和maximumPoolSize都设定为了nThreads，这样便实现了线程池的大小的固定，不会动态地扩大，另外，keepAliveTime设定为了0，也就是说线程只要空闲下来，就会被移除线程池，敢于LinkedBlockingQueue下面会说。 6.ExecuteService 服务的关闭​ shutdown()方法在终止前允许执行以前提交的任务，而 shutdownNow() 方法阻止等待任务的启动并试图停止当前正在执行的任务。在终止后，执行程序没有任务在执行，也没有任务在等待执行，并且无法提交新任务。应该关闭未使用的 ExecutorService以允许回收其资源。 7.排队的策略:1、直接提交。缓冲队列采用 SynchronousQueue，它将任务直接交给线程处理而不保持它们。如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中。直接提交通常要求无界 maximumPoolSizes（Integer.MAX_VALUE） 以避免拒绝新提交的任务。newCachedThreadPool采用的便是这种策略。 2、无界队列。使用无界队列（典型的便是采用预定义容量的 LinkedBlockingQueue，理论上是该缓冲队列可以对无限多的任务排队）将导致在所有 corePoolSize 线程都工作的情况下将新任务加入到缓冲队列中。这样，创建的线程就不会超过 corePoolSize，也因此，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列。newFixedThreadPool采用的便是这种策略。 3、有界队列。当使用有限的 maximumPoolSizes 时，有界队列（一般缓冲队列使用ArrayBlockingQueue，并制定队列的最大长度）有助于防止资源耗尽，但是可能较难调整和控制，队列大小和最大池大小需要相互折衷，需要设定合理的参数。 8.参考：http://blog.csdn.net/ns_code/article/details/17465497 http://blog.csdn.net/linghu_java/article/details/17123057 http://blog.csdn.net/bairrfhoinn/article/details/16848785 http://zhangjunhd.blog.51cto.com/113473/70068/ http://www.cnblogs.com/wanqieddy/p/3853863.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HttpClient工具类]]></title>
      <url>%2F2017%2F02%2F15%2FHttpClient%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E5%B0%81%E8%A3%85%2F</url>
      <content type="text"><![CDATA[一.HttpClient 介绍：​ HttpClient相比传统JDK自带的URLConnection，增加了易用性和灵活性，它不仅是客户端发送Http请求变得容易，而且也方便了开发人员测试接口（基于Http协议的），即提高了开发的效率，也方便提高代码的健壮性。它支持在HTTP/1.1规范中定义的所有的HTTP方法：GET, HEAD, POST, PUT, DELETE, TRACE 和 OPTIONS。每有一个方法都有一个对应的类：HttpGet，HttpHead，HttpPost，HttpPut，HttpDelete，HttpTrace和HttpOptions。所有的这些类均实现了HttpUriRequest接口，故可以作为execute的执行参数使用。 HTTP请求的URI包含一个协议计划protocol scheme，主机名host name,，可选的端口optional port，资源的路径resource path，可选的查询optional query和可选的片段optional fragment。 二. 特性：​ 基于标准、纯净的Java语言。实现了Http1.0和Http1.1 ​ 以可扩展的面向对象的结构实现了Http全部的方法（GET, POST, PUT, DELETE, HEAD, OPTIONS, and TRACE）。 ​ 支持HTTPS协议。 ​ 通过Http代理建立透明的连接。 ​ 利用CONNECT方法通过Http代理建立隧道的https连接。 ​ Basic, Digest, NTLMv1, NTLMv2, NTLM2 Session, SNPNEGO/Kerberos认证方案。 ​ 插件式的自定义认证方案。 ​ 便携可靠的套接字工厂使它更容易的使用第三方解决方案。 ​ 连接管理器支持多线程应用。支持设置最大连接数，同时支持设置每个主机的最大连接数，发现并关闭过期的连接。 ​ 自动处理Set-Cookie中的Cookie。 ​ 插件式的自定义Cookie策略。 ​ Request的输出流可以避免流中内容直接缓冲到socket服务器。 ​ Response的输入流可以有效的从socket服务器直接读取相应内容。 ​ 在http1.0和http1.1中利用KeepAlive保持持久连接。 ​ 直接获取服务器发送的response code和 headers。 ​ 设置连接超时的能力。 ​ 实验性的支持http1.1 response caching。 ​ 源代码基于Apache License 可免费获取。 三. 使用方法​ 创建HttpClient对象。 ​ 创建请求方法的实例，并指定请求URL。如果需要发送GET请求，创建HttpGet对象；如果需要发送POST请求，创建HttpPost对象。 ​ 如果需要发送请求参数，可调用HttpGet、HttpPost共同的setParams(HetpParams params)方法来添加请求参数；对于HttpPost对象而言，也可调用setEntity(HttpEntity entity)方法来设置请求参数。 ​ 调用HttpClient对象的execute(HttpUriRequest request)发送请求，该方法返回一个HttpResponse。 ​ 调用HttpResponse的getAllHeaders()、getHeaders(String name)等方法可获取服务器的响应头；调用HttpResponse的getEntity()方法可获取HttpEntity对象，该对象包装了服务器的响应内容。程序可通过该对象获取服务器的响应内容。 ​ 释放连接。无论执行方法是否成功，都必须释放连接 四.封装工具类 ​ 1.HttpHeader封装 ​ 2.SSL封装 ​ 3.HttpClientBuilder封装 ​ 链接：https://github.com/Luckylau/UsefulTools 五.参考资料http://blog.csdn.net/xiaoxian8023/article/category/5968067 http://blog.csdn.net/wangpeng047/article/details/19624529]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BeanUtils.copyProperties 与 PropertyUtils.copyProperties]]></title>
      <url>%2F2017%2F02%2F06%2FBeanUtils-copyProperties-%E4%B8%8E-PropertyUtils-copyProperties%2F</url>
      <content type="text"><![CDATA[首先明确一点是BeanUtils.copyProperties 存在于spring和apache commons-beanutils，PropertyUtils.copyProperties存在于apache commons-PropertyUtils。 org.springframework.beans.BeanUtils; org.apache.commons.beanutils.BeanUtils; org.apache.commons.beanutils.PropertyUtils; 1.org.springframework.beans.BeanUtils使用：首先看一下源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void copyProperties(Object source, Object target) throws BeansException &#123; copyProperties(source, target, (Class)null, (String[])null); &#125; public static void copyProperties(Object source, Object target, Class&lt;?&gt; editable) throws BeansException &#123; copyProperties(source, target, editable, (String[])null); &#125; public static void copyProperties(Object source, Object target, String... ignoreProperties) throws BeansException &#123; copyProperties(source, target, (Class)null, ignoreProperties); &#125; private static void copyProperties(Object source, Object target, Class&lt;?&gt; editable, String... ignoreProperties) throws BeansException &#123; Assert.notNull(source, "Source must not be null"); Assert.notNull(target, "Target must not be null"); Class actualEditable = target.getClass(); if(editable != null) &#123; if(!editable.isInstance(target)) &#123; throw new IllegalArgumentException("Target class [" + target.getClass().getName() + "] not assignable to Editable class [" + editable.getName() + "]"); &#125; actualEditable = editable; &#125; PropertyDescriptor[] targetPds = getPropertyDescriptors(actualEditable); List ignoreList = ignoreProperties != null?Arrays.asList(ignoreProperties):null; PropertyDescriptor[] var7 = targetPds; int var8 = targetPds.length; for(int var9 = 0; var9 &lt; var8; ++var9) &#123; PropertyDescriptor targetPd = var7[var9]; Method writeMethod = targetPd.getWriteMethod(); if(writeMethod != null &amp;&amp; (ignoreList == null || !ignoreList.contains(targetPd.getName()))) &#123; PropertyDescriptor sourcePd = getPropertyDescriptor(source.getClass(), targetPd.getName()); if(sourcePd != null) &#123; Method readMethod = sourcePd.getReadMethod(); if(readMethod != null &amp;&amp; ClassUtils.isAssignable(writeMethod.getParameterTypes()[0], readMethod.getReturnType())) &#123; try &#123; if(!Modifier.isPublic(readMethod.getDeclaringClass().getModifiers())) &#123; readMethod.setAccessible(true); &#125; Object ex = readMethod.invoke(source, new Object[0]); if(!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers())) &#123; writeMethod.setAccessible(true); &#125; writeMethod.invoke(target, new Object[]&#123;ex&#125;); &#125; catch (Throwable var15) &#123; throw new FatalBeanException("Could not copy property \'" + targetPd.getName() + "\' from source to target", var15); &#125; &#125; &#125; &#125; &#125; &#125; 成员变量赋值是基于目标对象的成员列表, 并且会跳过ignore的以及在源对象中不存在的属性, 所以这个方法是安全的, 不会因为两个对象之间的结构差异导致错误, 但是必须保证同名的两个成员变量类型相同. 1BeanUtils.copyProperties(source, target); 2.org.apache.commons.beanutils.BeanUtils使用：2.1 对于类型为Boolean/Short/Integer/Float/Double的属性，它会转换为0: 1234567891011121314151617181920212223242526public class User &#123; private Integer intVal; private Double doubleVal; private Short shortVal; private Long longVal; private Float floatVal; private Byte byteVal; private Boolean booleanVal; &#125; User src = new User(); User dest = new User(); BeanUtils.copyProperties(dest, src); System.out.println(src); System.out.println(dest); //输出 User [intVal=null, doubleVal=null, shortVal=null, longVal=null, floatVal=null, byteVal=null, booleanVal=null] User [intVal=0, doubleVal=0.0, shortVal=0, longVal=0, floatVal=0.0, byteVal=0, booleanVal=false] 在stackoverflow上有人解释说是因为这几个类型都有对应的基本类型，在进行类型转换时，有可能遇到类似Integer -&gt; int的转换，此时显然不能对int类型的属性赋值为null，因此统一转换为0。 如何让它不要转为0呢？可以这样： 1234import org.apache.commons.beanutils.converters.IntegerConverter; IntegerConverter converter = new IntegerConverter(null); //默认为null，而不是0 BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); beanUtilsBean.getConvertUtils().register(converter, Integer.class); 2.2 对于java.util.Date/BigDecimal/java.sql.Date/java.sql.Timestamp/java.sql.Time这几个类，如果值为null，则在copy时会抛异常，需要使用对应的Conveter： 12345678910111213141516171819202122232425262728293031public class User2 &#123; private java.util.Date javaUtilDateVal; private java.sql.Date javaSqlDateVal; private java.sql.Timestamp javaSqlTimeStampVal; private BigDecimal bigDecimalVal; private java.sql.Time javaSqlTime; &#125; User2 src = new User2(); User2 dest = new User2(); BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); //如果没有下面几行，则在转换null时会抛异常，例如：org.apache.commons.beanutils.ConversionException: No value specified for 'BigDecimal' //在org.apache.commons.beanutils.converters这个包下面有很多的Converter，可以按需要使用 beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.BigDecimalConverter(null), BigDecimal.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.DateConverter(null), java.util.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimestampConverter(null), java.sql.Timestamp.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlDateConverter(null), java.sql.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimeConverter(null), java.sql.Time.class); beanUtilsBean.copyProperties(dest, src); System.out.println(src); System.out.println(dest); 2.3使用BeanUtils还会经常碰到这样变态的需求： 假设是从A复制到B：需求1：如果B中某字段有值（不为null），则该字段不复制；也就是B中该字段没值时，才进行复制，适合于对B进行补充值的情况。需求2：如果A中某字段没值（为null），则该字段不复制，也就是不要把null复制到B当中。 对于需求1，可以这样： 12345678910111213141516171819import org.apache.commons.beanutils.BeanUtilsBean; import org.apache.commons.beanutils.PropertyUtils; public class CopyWhenNullBeanUtilsBean extends BeanUtilsBean&#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; try &#123; Object destValue = PropertyUtils.getSimpleProperty(bean, name); if (destValue == null) &#123; super.copyProperty(bean, name, value); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; 对于需求2，可以这样： 123456789101112import org.apache.commons.beanutils.BeanUtilsBean; public class CopyFromNotNullBeanUtilsBean extends BeanUtilsBean &#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; if (value == null) &#123; return; &#125; super.copyProperty(bean, name, value); &#125; &#125; 2.4 使用BeanUtils时，遇到日期类型的空值时会抛错的解决办法 新建一个转换器类，该类实现Converter接口，在convert方法中实现日期类型值的转换逻辑，然后注册。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class DateConverter implements Converter&#123; public Object convert(Class type, Object value)&#123; if(value == null)&#123; return null; &#125;else if(type == Timestamp.class)&#123; return convertToDate(type, value, "yyyy-MM-dd HH:mm:ss"); &#125;else if(type == Date.class)&#123; return convertToDate(type, value, "yyyy-MM-dd"); &#125;else if(type == String.class)&#123; return convertToString(type, value); &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToDate(Class type, Object value, String pattern) &#123; SimpleDateFormat sdf = new SimpleDateFormat(pattern); if(value instanceof String)&#123; try&#123; if(CommonUtils.isEmpty(value.toString()))&#123; return null; &#125; Date date = sdf.parse((String) value); if(type.equals(Timestamp.class))&#123; return new Timestamp(date.getTime()); &#125; return date; &#125;catch(Exception pe)&#123; return null; &#125; &#125;else if(value instanceof Date)&#123; return value; &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToString(Class type, Object value) &#123; if(value instanceof Date)&#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); if (value instanceof Timestamp) &#123; sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); &#125; try&#123; return sdf.format(value); &#125;catch(Exception e)&#123; throw new ConversionException("日期转换为字符串时出错！"); &#125; &#125;else&#123; return value.toString(); &#125; &#125; &#125; 1ConvertUtils.register(new DateConverter(), java.util.Date.class); 使用： 1BeanUtils.copyProperties(target, source); 3.org.apache.commons.beanutils.PropertyUtils使用：​ 使用PropertyUtils.copyProperties()拷贝一个bean中的属性到另一个bean中,第一个参数是目标bean,第二个参数是源bean，只是拷贝具有相同的 1PropertyUtils.copyProperties(target, source); 4.三者之间的区别：4.1 org.apache.commons.beanutils.BeanUtils 与org.apache.commons.beanutils.PropertyUtils ​ 从大范围讲，两个工具类都是对两个bean之前存在name相同的属性进行处理，无论是源bean或者目标bean多出的属性均不处理。具体到BeanUtils是相同name并且类型之间支持转换的属性可以处理，而PropertyUtils不支持类型转换必须是类型和name一样才处理。 ​ 对null的处理：PropertyUtils支持为null的场景；BeanUtils对部分属性不支持null的情况，具体为：date类型不支持，异常 date为org.apache.commons.beanutils.ConversionException: No value；specified for ‘Date’；Ineger、Boolean、Long等不支持， 转为0；string支持，保持null； ​ 源bean有属性：private Long dateVal;目标bean有属性：private Date dateVal;​ 使用 PropertyUtils，会报错：Caused by: java.lang.IllegalArgumentException: argument type mismatch​ 使用BeanUtils，则相当于new date（dateVal） ​ BeanUtils的高级功能org.apache.commons.beanutils.Converter接口可以自定义类型之间的转化，PropertyUtils没有 4.2 org.apache.commons.beanutils.BeanUtils与org.springframework.beans.BeanUtils org.springframework.beans.BeanUtils中实现的方式很简单，就是对两个对象中相同名字的属性进行简单get/set，仅检查属性的可访问性。 而org.springframework.beans.BeanUtils则施加了很多的检验，包括类型的转换，甚至于还会检验对象所属的类的可访问性。 5.参考：http://www.cnblogs.com/milton/p/5830942.html http://bylijinnan.iteye.com/blog/2224808 http://caoyaojun1988-163-com.iteye.com/blog/1871316 http://chenjumin.iteye.com/blog/701190 http://www.cnblogs.com/gaojing/archive/2011/08/23/2413616.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[历史金融危机一览表]]></title>
      <url>%2F2017%2F01%2F27%2F%E5%8E%86%E5%8F%B2%E9%87%91%E8%9E%8D%E5%8D%B1%E6%9C%BA%E4%B8%80%E8%A7%88%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[历史金融危机一览表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是vxlan网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFvxlan%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[前言：​ 处在年末工作的最后一天，其实也没有心情学习了，要不就总结和整理一下之前看的vxlan网络，大部分的内容还是复制拷贝的，只是按照自己的分明别类梳理梳理。vxlan网络是云计算网络的基础，openstack本身也是一种基础性简单使用，但还是有必要从理论上来学习vxlan网络。 云计算虚拟化对传统网络带来的挑战​ 云计算、虚拟化相关技术的发展，传统的网络无法满足于规模大、灵活性要求高的云数据中心的要求，于是便有了overlay网络的概念。overlay网络中被广泛应用的就是vxlan技术。首先我们了解一下随着云计算的发展，传统网络面临哪些挑战。 1.虚拟机迁移范围受到网络架构限制 ​ 虚拟机迁移，顾名思义，就是将虚拟机从一个物理机迁移到另一个物理机，但是要求在迁移过程中业务不能中断。要做到这一点，需要保证虚拟机迁移前后，其IP地址、MAC地址等参数维持不变。这就决定了，虚拟机迁移必须发生在一个二层域中。对于传统网络就要求网络本身具备多路径多链路的冗余和可靠性。传统的网络生成树(STPSpaning Tree Protocol)技术不仅部署繁琐荣，且协议复杂，网络规模不宜过大，限制了虚拟化的网络扩展性。基于各厂家私有的的IRF/vPC等设备级的(网络N:1)虚拟化技术，虽然可以简化拓扑简化、具备高可靠性的能力，但是对于网络有强制的拓扑形状限制，在网络的规模和灵活性上有所欠缺，只适合小规模网络构建，且一般适用于数据中心内部网络。而为了大规模网络扩展的TRILL/SPB/FabricPath/VPLS等技术，虽然解决了上述技术的不足，但对网络有特殊要求，即网络中的设备均要软硬件升级而支持此类新技术，带来部署成本的上升。 2.虚拟机规模受网络设备表项规格的限制 ​ 在大二层网络环境下，数据流均需要通过明确的网络寻址以保证准确到达目的地，因此网络设备的二层地址表项大小(即MAC地址表)，成为决定了云计算环境下虚拟机的规模的上限，并且因为表项并非百分之百的有效性，使得可用的虚机数量进一步降低，特别是对于低成本的接入设备而言，因其表项一般规格较小，限制了整个云计算数据中心的虚拟机数量，但如果其地址表项设计为与核心或网关设备在同一档次，则会提升网络建设成本。虽然核心或网关设备的MAC与ARP规格会随着虚拟机增长也面临挑战，但对于此层次设备能力而言，大规格是不可避免的业务支撑要求。减小接入设备规格压力的做法可以是分离网关能力，如采用多个网关来分担虚机的终结和承载，但如此也会带来成本的上升。 3.网络隔离/分离能力限制 ​ VLAN作为当前主流的网络隔离技术，在标准定义中只有12比特，也就是说可用的VLAN数量只有4000个左右。对于公有云或其它大型虚拟化云计算服务这种动辄上万甚至更多租户的场景而言，VLAN的隔离能力显然已经力不从心。 VLAXN网络的初相识1.VXLAN网络模型 从上图可以看到，VXLAN网络中出现了以下传统数据中心网络中没有的新元素： VTEP（VXLAN Tunnel Endpoints，VXLAN隧道端点）VXLAN网络的边缘设备，是VXLAN隧道的起点和终点，VXLAN报文的相关处理均在这上面进行。总之，它是VXLAN网络中绝对的主角。VTEP既可以是独立的网络设备（比如华为的CE系列交换机），也可以是虚拟机所在的服务器。那它究竟是如何发挥作用的呢？答案稍候揭晓。 VNI（VXLAN Network Identifier，VXLAN 网络标识符）前文提到，以太网数据帧中VLAN只占了12比特的空间，这使得VLAN的隔离能力在数据中心网络中力不从心。而VNI的出现，就是专门解决这个问题的。VNI是一种类似于VLAN ID的用户标示，一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VXLAN报文封装时，给VNI分配了足够的空间使其可以支持海量租户的隔离。详细的实现，我们将在后文中介绍。 VXLAN隧道“隧道”是一个逻辑上的概念，它并不新鲜，比如大家熟悉的GRE。说白了就是将原始报文“变身”下，加以“包装”，好让它可以在承载网络（比如IP网络）上传输。从主机的角度看，就好像原始报文的起点和终点之间，有一条直通的链路一样。而这个看起来直通的链路，就是“隧道”。顾名思义，“VXLAN隧道”便是用来传输经过VXLAN封装的报文的，它是建立在两个VTEP之间的一条虚拟通道。 2.VXLAN是如何解决以上挑战 2.1解决虚拟机迁移范围受到网络架构限制问题 ​ overlay网络的本质是在三层网络中实现二层网络的扩展。三层网络可以通过路由的方式在网络中分发，而路由网络本身并无特殊网络结构限制，具备良性大规模扩展能力，并且对设备本身无特殊要求，以高性能路由转发为佳，且路由网络本身具备很强的的故障自愈能力、负载均衡能力。前面提到，为了保证业务不中断，VM的迁移就必须发生在同一个二层域内。有了VTEP的封装机制和VXLAN隧道后，所谓的 “二层域”就可以轻而易举的突破物理上的界限？也就是说，在IP网络中， “明”里传输的是跨越三层网络的UDP报文，“暗”里却已经悄悄将源VM的原始报文送达目的VM。就好像在三层的网络之上，构建出了一个虚拟的二层网络，而且只要IP网络路由可达，这个虚拟的二层网络想做多大就做多大。 2.2解决虚拟机规模受网络设备表项规格的限制问题 ​ 既然无法提升设备表项规格，那就只能限制设备上的MAC表项，将大量VM的MAC地址“隐形”。VTEP会将VM发出的原始报文封装成一个新的UDP报文，并使用物理网络的IP和MAC地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就是说，网络中的其他设备看不到VM发送的原始报文。 ​ 如果服务器作为VTEP，那从服务器发送到接入设备的报文便是经过封装后的报文，这样，接入设备就不需要学习VM的MAC地址了，它只需要根据外层封装的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表项规格的限制了。 ​ 当然，如果网络设备作为VTEP，它还是需要学习VM的MAC地址。但是，从对报文进行封装的角度来说，网络设备的性能还是要比服务器强很多。 2.3解决网络隔离/分离能力限制 ​ 一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VTEP在对报文进行VXLAN封装时，给VNI分配了24比特的空间，这就意味着VXLAN网络理论上支持多达16M（即：2^24-1）的租户隔离。相比VLAN，VNI的隔离能力得到了巨大的提升，有效得解决了云计算中海量租户隔离的问题。 3.VXLAN报文格式 VTEP对VM发送的原始以太帧（Original L2 Frame）进行了以下“包装”： VXLAN Header: ​ 增加VXLAN头（8字节），其中包含24比特的VNI字段，用来定义VXLAN网络中不同的租户。此外，还包含VXLAN Flags（8比特，取值为00001000）和两个保留字段（分别为24比特和8比特）。 UDP Header: ​ VXLAN头和原始以太帧一起作为UDP的数据。UDP头中，目的端口号（VXLAN Port）固定为4789，源端口号（UDP Src. Port）是原始以太帧通过哈希算法计算后的值。 Outer IP Header: ​ 封装外层IP头。其中，源IP地址（Outer Src. IP）为源VM所属VTEP的IP地址，目的IP地址（Outer Dst. IP）为目的VM所属VTEP的IP地址。 Outer MAC Header: ​ 封装外层以太头。其中，源MAC地址（Src. MAC Addr.）为源VM所属VTEP的MAC地址，目的MAC地址（Dst. MAC Addr.）为到达目的VTEP的路径上下一跳设备的MAC地址。 VXLAN报文转发机制以CE系列交换机的实现为例 1.建立VXLAN隧道 前面提到的“同一大二层域”，就类似于传统网络中VLAN（虚拟局域网）的概念，只不过在VXLAN网络中，它有另外一个名字，叫做Bridge-Domain，简称BD。 ​ 我们知道，不同的VLAN是通过VLAN ID来进行区分的，那不同的BD是如何进行区分的呢？其实前面已经提到了，就是通过VNI来区分的。对于CE系列交换机而言，BD与VNI是1：1的映射关系，这种映射关系是通过在VTEP上配置命令行建立起来的。配置如下： 12bridge-domain 10 //表示创建一个“大二层广播域”BD，其编号为10 vxlan vni 5000 //表示在BD 10下，指定与之关联的VNI为5000 VTEP会根据以上配置生成BD与VNI的映射关系表，该映射表可以通过命令行查看，如下所示： 12345&lt;HUAWEI&gt; display vxlan vniNumber of vxlan vni : 1VNI BD-ID State ----------------------------------5000 10 up 有了映射表后，进入VTEP的报文就可以根据自己所属的BD来确定报文封装时该添加哪个VNI。那么，报文根据什么来确定自己属于哪个BD呢？ 在回答“如何确定报文属于哪个BD”之前，必须先要回答“哪些报文要进入VXLAN隧道”。 ​ 在VXLAN网络中，VTEP上有一个叫做“二层子接口”的逻辑接口，主要做两件事：一是根据配置来检查哪些报文需要进入VXLAN隧道；二是判断对检查通过的报文做怎样的处理。在二层子接口上，可以根据需要定义不同的流封装类型（类似于传统网络中不同的接口类型）。CE系列交换机目前支持三种不同的流封装类型，分别是dot1q、untag和default，它们各自对报文的处理方式如表3-1所示。有了这张表，你就能明白哪些报文要进VXLAN隧道了。 流封装类型 允许进入VXLAN隧道的报文类型 报文进行封装前的处理 收到VXLAN报文并解封装后的处理 dot1q 只允许携带指定VLAN Tag的报文进入VXLAN隧道。（这里的“指定VLAN Tag”是通过命令进行配置的） 进行VXLAN封装前，先剥掉原始报文的外层VLAN Tag 进行VXLAN解封装后：若内层原始报文带有VLAN Tag，则先将该VLAN Tag替换为指定的VLAN Tag，再转发；若内层原始报文不带VLAN Tag，则先将其添加指定的VLAN Tag，再转发。 untag 只允许不携带VLAN Tag的报文进入VXLAN隧道。 进行VXLAN封装前，不对原始报文做处理，即不添加任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 default 允许所有报文进入VXLAN隧道，不论报文是否携带VLAN Tag。 进行VXLAN封装前，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 说明：VXLAN隧道两端二层子接口的配置并不一定是完全对等的。正因为这样，才可能实现属于同一网段但是不同VLAN的两个VM通过VXLAN隧道进行通信。 看了上面的描述，再来回答“如何确定报文属于哪个BD”就非常简单了。其实，只要将二层子接口加入指定的BD，然后根据二层子接口上的配置，就可以确定报文属于哪个BD啦！ 比如下图所示的组网，我们可以分别在VTEP的两个物理接口10GE 1/0/1和10GE 1/0/2上配置不同流封装类型的二层子接口并将其分别加入不同的BD。 基于二层物理接口10GE 1/0/1，分别创建二层子接口10GE 1/0/1.1和10GE 1/0/1.2，且分别配置其流封装类型为dot1q和untag。配置如下： 123interface 10GE1/0/1.1 mode l2 //创建二层子接口10GE1/0/1.1 encapsulation dot1q vid 10 //只允许携带VLAN Tag 10的报文进入VXLAN隧道 bridge-domain 10 //报文进入的是BD 10 123interface 10GE1/0/1.2 mode l2 //创建二层子接口10GE1/0/1.2 encapsulation untag //只允许不携带VLAN Tag的报文进入VXLAN隧道 bridge-domain 20 //报文进入的是BD 20 基于二层物理接口10GE 1/0/2，创建二层子接口10GE 1/0/2.1，且流封装类型为default。配置如下： 123interface 10GE1/0/2.1 mode l2 //创建二层子接口10GE1/0/2.1 encapsulation default //允许所有报文进入VXLAN隧道 bridge-domain 30 //报文进入的是BD 30 此时你可能会有这样的疑问，为什么要在10GE 1/0/1上创建两个不同类型的子接口？是否还可以继续在10GE 1/0/1上创建一个default类型的二层子接口？换句话说，用户应该如何选择配置哪种类型的二层子接口？三种类型的二层子接口之间，是否存在配置约束关系？ 答案是不可以。其实根据上表的描述，这一点很容易理解。因为default类型的二层子接口允许所有报文进入VXLAN隧道，而dot1q和untag类型的二层子接口只允许某一类报文进入VXLAN隧道。这就决定了，default类型的二层子接口跟其他两种类型的二层子接口是不可以在同一物理接口上共存的。否则，报文到了接口之后如何判断要进入哪个二层子接口呢。所以，default类型的子接口，一般应用在经过此接口的报文均需要走同一条VXLAN隧道的场景，即下挂的VM全部属于同一BD。例如，图3-3中VM3和VM4均属于BD 30，则10GE 1/0/2上就可以创建default类型的二层子接口。 再来看下为什么可以在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。如图上所示，VM1和VM2分别属于VLAN 10和VLAN 20，且分别属于不同的大二层域BD 10和BD 20，显然他们发出的报文要进入不同的VXLAN隧道。如果VM1和VM2发出的报文在到达VTEP的10GE 1/0/1接口时，一个是携带VLAN 10的Tag的，一个是不携带VLAN Tag的（比如二层交换机上行连接VTEP的接口上配置的接口类型是Trunk，允许通过的VLAN为10和20，PVID为VLAN 20），则为了区分两种报文，就必须要在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。所以，当经过同一物理接口的报文既有带VLAN Tag的，又有不带VLAN Tag的，并且他们各自要进入不同的VXLAN隧道，则可以在该物理接口上同时创建dot1q和untag类型的二层子接口。 现在，我们可以来看下VXLAN隧道是怎么建立起来的了。一般而言，隧道的建立不外乎手工方式和自动方式两种。 手工方式这种方式需要用户手动指定VXLAN隧道的源和目的IP地址分别为本端和对端VTEP的IP地址，也就是人为的在本端VTEP和对端VTEP之间建立静态VXLAN隧道。对于CE系列交换机，以上配置是在NVE（Network Virtualization Edge）接口下完成的。配置过程如下： 1234interface Nve1 //创建逻辑接口NVE 1 source 1.1.1.1 //配置源VTEP的IP地址（推荐使用Loopback接口的IP地址） vni 5000 head-end peer-list 2.2.2.2 vni 5000 head-end peer-list 2.2.2.3 其中，vni 5000 head-end peer-list 2.2.2.2和vni 5000 head-end peer-list 2.2.2.3的配置，表示属于VNI 5000的对端VTEP有两个，IP地址分别为2.2.2.2和2.2.2.3。根据这两条配置，VTEP上会生成如下所示的一张表： 123456789&lt;HUAWEI&gt; display vxlan vni 5000 verbose BD ID : 10 State : up NVE : 288 Source : 1.1.1.1 UDP Port : 4789 BUM Mode : head-end Group Address : - Peer List : 2.2.2.2 2.2.2.3 根据上表中的Peer List，本端VTEP就可以知道属于同一BD（或同一VNI）的对端VTEP都有哪些，这也就决定了同一大二层广播域的范围。当VTEP收到BUM（Broadcast&amp;Unknown-unicast&amp;Multicast，广播&amp;未知单播&amp;组播）报文时，会将报文复制并发送给Peer List中所列的所有对端VTEP（这就好比广播报文在VLAN内广播）。因此，这张表也被称为“头端复制列表”。当VTEP收到已知单播报文时，会根据VTEP上的MAC表来确定报文要从哪条VXLAN隧道走。而此时Peer List中所列的对端，则充当了MAC表中“出接口”的角色。在后面的报文转发流程中，你将会看到头端复制列表是如何在VXLAN网络中指导报文进行转发的。 自动方式自动方式下VXLAN隧道的建立需要借助于其他的协议，例如BGP。CE系列交换机中，自动方式建立VXLAN隧道主要应用在EVN（Ethernet Virtual Network）和VXLAN的分布式网关场景中。本文不对该方式进行详细讲述，具体实现可参考EVN的相关资料。 从前面的描述我们知道，属于同一BD的VXLAN隧道可能不止一条，比如前面的头端复制列表中，同一个源端VTEP（1.1.1.1）对应了两个对端VTEP（2.2.2.2和2.2.2.3）。那就带来了另一个问题，报文到底应该走哪一条隧道呢？我们知道，基本的二三层转发中，二层转发依赖的是MAC表，如果没有对应的MAC表，则主机发送ARP广播报文请求对端的MAC地址；三层转发依赖的是FIB表。在VXLAN中，其实也是同样的道理。下面就让我们来看下，VXLAN网络中报文的转发流程。相信看完下面的内容，关于“如何确定报文要进哪条隧道”的疑惑也就迎刃而解了。 2.VXLAN网络中报文的转发流程 同子网互通 VM_A、VM_B和VM_C同属于10.1.1.0/24网段，且同属于VNI 5000。此时，VM_A想与VM_C进行通信。 ​ 由于是首次进行通信，VM_A上没有VM_C的MAC地址，所以会发送ARP广播报文请求VM_C的MAC地址。下面就让我们根据ARP请求报文及ARP应答报文的转发流程，来看下MAC地址是如何进行学习的。 ARP请求报文转发流程 ARP请求报文的转发流程如下： VM_A发送源MAC为MAC_A、目的MAC为全F、源IP为IP_A、目的IP为IP_C的ARP广播报文，请求VM_C的MAC地址。 VTEP_1收到ARP请求后，根据二层子接口上的配置判断报文需要进入VXLAN隧道。确定了报文所属BD后，也就确定了报文所属的VNI。同时，VTEP_1学习MAC_A、VNI和报文入接口（Port_1，即二层子接口对应的物理接口）的对应关系，并记录在本地MAC表中。之后，VTEP_1会根据头端复制列表对报文进行复制，并分别进行封装。 可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_1）的IP地址，外层目的IP地址为对端VTEP（VTEP_2和VTEP_3）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2和VTEP_3后，VTEP对报文进行解封装，得到VM_A发送的原始报文。同时，VTEP_2和VTEP_3学习VM_A的MAC地址、VNI和远端VTEP的IP地址（IP_1）的对应关系，并记录在本地MAC表中。之后，VTEP_2和VTEP_3根据二层子接口上的配置对报文进行相应的处理并在对应的二层域内广播。VM_B和VM_C接收到ARP请求后，比较报文中的目的IP地址是否为本机的IP地址。VM_B发现目的IP不是本机IP，故将报文丢弃；VM_C发现目的IP是本机IP，则对ARP请求做出应答。下面，让我们看下ARP应答报文是如何进行转发的。 ARP应答报文转发流程 ARP应答报文的转发流程如下： 由于此时VM_C上已经学习到了VM_A的MAC地址，所以ARP应答报文为单播报文。报文源MAC为MAC_C，目的MAC为MAC_A，源IP为IP_C、目的IP为IP_A。 VTEP_3接收到VM_C发送的ARP应答报文后，识别报文所属的VNI（识别过程与步骤2类似）。同时，VTEP_3学习MAC_C、VNI和报文入接口（Port_3）的对应关系，并记录在本地MAC表中。之后，VTEP_3对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_3）的IP地址，外层目的IP地址为对端VTEP（VTEP_1）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_1后，VTEP_1对报文进行解封装，得到VM_C发送的原始报文。同时，VTEP_1学习VM_C的MAC地址、VNI和远端VTEP的IP地址（IP_3）的对应关系，并记录在本地MAC表中。之后，VTEP_1将解封装后的报文发送给VM_A。至此，VM_A和VM_C均已学习到了对方的MAC地址。之后，VM_A和VM_C将采用单播方式进行通信。 不同子网互通 ​ VM_A和VM_B分别属于10.1.10.0/24网段和10.1.20.0/24网段，且分别属于VNI 5000和VNI 6000。VM_A和VM_B对应的三层网关分别是VTEP_3上BDIF 10和BDIF 20的IP地址。VTEP_3上存在到10.1.10.0/24网段和10.1.20.0/24网段的路由。此时，VM_A想与VM_B进行通信。 ​ BDIF接口的功能与VLANIF接口类似，是基于BD创建的三层逻辑接口，用以实现不同子网VM之间或VXLAN网络与非VXLAN网络之间的通信。 由于是首次进行通信，且VM_A和VM_B处于不同网段，VM_A需要先发送ARP广播报文请求网关（BDIF 10）的MAC，获得网关的MAC后，VM_A先将数据报文发送给网关；之后网关也将发送ARP广播报文请求VM_B的MAC，获得VM_B的MAC后，网关再将数据报文发送给VM_B。以上MAC地址学习的过程与同子网互通中MAC地址学习的流程一致，不再赘述。现在假设VM_A和VM_B均已学到网关的MAC、网关也已经学到VM_A和VM_B的MAC，下面就让我们看下数据报文是如何从VM_A发送到VM_B的。 不同子网VM互通报文转发流程 数据报文从VM_A发送到VM_B的流程如下： VM_A先将数据报文发送给网关。报文的源MAC为MAC_A，目的MAC为网关BDIF 10的MAC_10，源IP地址为IP_A，目的IP为IP_B。 VTEP_1收到数据报文后，识别此报文所属的VNI（VNI 5000），并根据MAC表项对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP的IP地址（IP_1），外层目的IP地址为对端VTEP的IP地址（IP_3）；外层源MAC地址为本地VTEP的MAC地址（MAC_1），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文进入VTEP_3，VTEP_3对报文进行解封装，得到VM_A发送的原始报文。然后，VTEP_3会对报文做如下处理： VTEP_3发现该报文的目的MAC为本机BDIF 10接口的MAC，而目的IP地址为IP_B（10.1.20.1），所以会根据路由表查找到IP_B的下一跳。 发现下一跳为10.1.20.10，出接口为BDIF 20。此时VTEP_3查询ARP表项，并将原始报文的源MAC修改为BDIF 20接口的MAC（MAC_20），将目的MAC修改为VM_B的MAC（MAC_B）。 报文到BDIF 20接口时，识别到需要进入VXLAN隧道（VNI 6000），所以根据MAC表对报文进行封装。这里封装的外层源IP地址为本地VTEP的IP地址（IP_3），外层目的IP地址为对端VTEP的IP地址（IP_2）；外层源MAC地址为本地VTEP的MAC地址（MAC_3），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2后，VTEP_2对报文进行解封装，得到内层的数据报文，并将其发送给VM_B。 说明：VXLAN网络与非VXLAN网络之间的互通，也需要借助于三层网关。 VXLAN应用部署方式我们以下图所示的典型的“Spine-Leaf”数据中心组网为例，给大家介绍一下CE系列交换机VXLAN的应用场景和部署方案。 ​ 在上图所示的数据中心里，企业用户拥有多个部门（部门1和部门2），每个部门中拥有多个VM（VM1和VM3，VM2和VM4）。同部门的VM属于同一个网段，不同部门的VM属于不同的网段。用户希望同一部门VM之间、不同部门VM之间，VM与Internet之间均可相互访问。 VXLAN网络的子网互通 相同子网互通 部署方案如图所示，Leaf1和Leaf2作为VXLAN网络的VTEP，两个Leaf之间搭建VXLAN隧道，并在每个Leaf上部署VXLAN二层网关，即可实现同一部门VM之间的相互通信。此时Spine只作为VXLAN报文的转发节点，不感知VXLAN隧道的存在，可以是任意的三层网络设备。 不同子网互通（集中式网关） 部署方案如图4-2所示，Leaf1、Leaf2和Spine作为VXLAN网络的VTEP，Leaf1和Spine之间、Leaf2和Spine之间分别搭建VXLAN隧道，并在Spine上部署VXLAN三层网关，即可实现不同部门VM之间的相互通信。 不同子网互通（分布式网关） 出现背景细心的读者可能已经发现，在不同子网互通（集中式网关）中，同一Leaf（Leaf1）下挂的不同网段VM（VM1和VM2）之间的通信，都需要在Spine上进行绕行，这样就导致Leaf与Spine之间的链路上，存在冗余的报文，额外占用了大量的带宽。同时，Spine作为VXLAN三层网关时，所有通过三层转发的终端租户的表项都需要在该设备上生成。但是，Spine的表项规格有限，当终端租户的数量越来越多时，容易成为网络瓶颈。分布式网关的出现，很好的解决了这两个问题。 部署方案 同Leaf节点下不同部门VM之间的通信如图4-3所示，Leaf1作为VXLAN网络的VTEP，在Leaf1上部署VXLAN三层网关，即可实现同Leaf下不同部门VM之间的相互通信。此时，VM1和VM2互访时，流量只需要在Leaf1节点进行转发，不再需要经过Spine节点，从而节约了大量的带宽资源。 跨Leaf节点不同部门VM之间的通信如图4-3所示，Leaf1和Leaf2作为VXLAN网络的VTEP，在Leaf1和Leaf2上部署VXLAN三层网关。两个VXLAN三层网关之间通过BGP动态建立VXLAN隧道，并通过BGP的remote-nexthop属性发布本网关下挂的主机路由信息给其他BGP邻居，从而实现跨Leaf节点不同部门VM之间的相互通信。 说明：Leaf作为VXLAN三层网关时，只学习其下挂终端租户的表项，而不必像集中式三层网关一样，需要学习网络中所有终端租户的表项，从而解决了集中式三层网关带来表项瓶颈问题。 VXLAN网络的可靠性 随着网络的快速普及和应用的日益深入，基础网络的可靠性日益成为用户关注的焦点，如何能够保证网络传输不中断对于终端用户而言非常重要。在VXLAN网络的子网互通中，VM与Leaf之间，Leaf与Spine之间都是通过单归方式接入的。这种组网接入方式，显然已经不能满足用户对VXLAN网络可靠性的需求。这时，可以按照如下图所示方式，提升VXLAN网络的可靠性。 接入层的可靠性 通常采用堆叠（CSS）方式提升接入层的可靠性。这是因为，接入层的设备数量繁多，堆叠方式可以将多台交换机设备组合在一起，虚拟化成一台交换设备，所有配置均在这一台虚拟交换机上进行，从而简化了接入层设备的运维复杂度。此外，堆叠系统内成员交换机之间在进行冗余备份的同时，能够利用跨设备的Eth-Trunk实现设备间链路的负载分担。 参考： http://support.huawei.com/huaweiconnect/enterprise/forum.php?mod=viewthread&amp;tid=334207&amp;extra=page%3D&amp;page=1 http://blog.csdn.net/sinat_31828101/article/details/50504656]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是overlay网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFoverllay%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[​ Overlay在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于IP的基础网络技术为主。 ​ 随着云计算虚拟化的驱动，基于主机虚拟化的Overlay技术出现，在服务器的Hypervisor内vSwitch上支持了基于IP的二层Overlay技术，通过更靠近应用的边缘来提供网络虚拟化服务，其目的是使虚拟机的部署与业务活动脱离物理网络及其限制，使得云计算的网络形态不断完善。主机的vSwitch支持基于IP的Overlay之后，虚机的二层访问直接构建在Overlay之上，物理网不再感知虚机的诸多特性。 存在三种不同的构建模式: Network Overlay 方案: ​ 所有终端均采用物理交换机作为VTEP节点,所有的物理接入交换机支持VXLAN，物理服务器支持SR-IOV功能，使虚拟机通过SR-IOV技术直接与物理交换机相连，虚拟机的流量在接入交换机上进行VXLAN报文的封装和卸载，对于非虚拟化服务器，直接连接支持VXLAN的接入交换机，服务器流量在接入交换机上进行VXLAN报文封装和卸载；当VXLAN网络需要与VLAN网络通信时，采用物理交换机做VXLAN GW，实现VXLAN网络主机与VLAN网络主机的通信；采用高端交换机做VXLAN IP GW，实现VXLAN网络与WAN以及Internet的互连。 Host Overlay 方案: ​ 所有终端均采用虚拟交换机作为VTEP节点，VTEP、VXLAN GW、VXLAN IP GW均通过安装在服务器上的软件实现，vSwitch实现VTEP功能，完成VXLAN报文的封装解封装；vFW等实现VXLAN GW功能，实现VXLAN网络与VLAN网络、物理服务器的互通；vRouter作为VXLAN IP GW，实现VXLAN网络与Internet和WAN的互联。在本组网中，由于所有VXLAN报文的封装卸载都通过软件实现，会占用部分服务器资源，当访问量大时，vRouter会成为系统瓶颈。 Hybrid Overlay 方案: ​ 既有物理交换机接入，又有虚拟交换机接入，且软件VTEP和硬件VTEP之间可以基于标准协议互通。上述两种组网方案中，网络Overlay方案与虚拟机相连，需要通过一些特殊的要求或技术实现虚拟机与VTEP的对接，组网不够灵活，但是主机Overlay方案与传统网络互通时，连接也比较复杂，且通过软件实现VXLAN IP GW也会成为整个网络的瓶颈，所以最理想的组网方案应该是一个结合了网络Overlay与主机Overlay两种方案优势的混合Overlay方案。如上图所示它通过vSwitch实现虚拟机的VTEP，通过物理交换机实现物理服务器的VTEP，通过物理交换机实现VXALN GW和VXLAN IP GW；混合式Overlay组网方案对虚拟机和物理服务器都能够很好的兼容，同时通过专业的硬件交换机实现VXLAN IP GW从而承载超大规模的流量转发，是目前应用比较广泛的组网方案。 PS: OpenStack 采用的是第二种方案 ​ 另外IETF在Overlay技术领域有如下三大技术路线正在讨论，为简单起见，只讨论基于IPv4的Overlay相关内容。 1 . VXLAN。 VXLAN是将以太网报文封装在UDP传输层上的一种隧道转发模式，目的UDP端口号为4798；为了使VXLAN充分利用承载网络路由的均衡性，VXLAN通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为UDP的号；采用24比特标识二层网络分段，称为VNI(VXLAN Network Identifier)，类似于VLAN ID作用；未知目的、广播、组播等网络流量均被封装为组播转发，物理网络要求支持任意源组播(ASM)。 2. GRE/NVGRE（Generic Routing Encapsulation，通用路由协议封装）是一种 IP-over-IP 的隧道。 NVGRE是将以太网报文封装在GRE内的一种隧道转发模式；采用24比特标识二层网络分段，称为VSI(Virtual Subnet Identifier)，类似于VLAN ID作用；为了使NVGRE利用承载网络路由的均衡性，NVGRE在GRE扩展字段flow ID，这就要求物理网络能够识别到GRE隧道的扩展信息，并以flow ID进行流量分担；未知目的、广播、组播等网络流量均被封装为组播转发。 3.STT（Stateless Transport Tunneling）。 STT利用了TCP的数据封装形式，但改造了TCP的传输机制，数据传输不遵循TCP状态机，而是全新定义的无状态机制，将TCP各字段意义重新定义，无需三次握手建立TCP连接，因此称为无状态TCP；以太网数据封装在无状态TCP；采用64比特Context ID标识二层网络分段；为了使STT充分利用承载网络路由的均衡性，通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为无状态TCP的源端口号；未知目的、广播、组播等网络流量均被封装为组播转发。 参考: http://www.h3c.com.cn/About_H3C/Company_Publication/IP_Lh/2013/04/Home/Catalog/201309/796466_30008_0.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[pyinstaller使用技巧]]></title>
      <url>%2F2017%2F01%2F22%2Fpyinstaller%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[​ 不经意间发现了这个工具pyinstaller2.0。它的功能是把python脚本打包成windows的可执行文件，这样就可以方便使用程序了。为了玩一下，于是写了一个图片分类的脚本，按照jpg, gif, png后缀将图片分别存储在各自文件夹中。脚本放在github上了。https://github.com/Luckylau/Useful-Python-Sample/blob/master/useful-tools/classify_Pic.py pythoninstall2.0运行前需要安装pywin32，假如你使用的是python 2.7(64位)，需要在官网 https://sourceforge.net/projects/pywin32/files/pywin32找到对应的版本 我的环境：win 10 python 2.7 (64位) ,pywin32-220.win-amd64-py2.7 打开pyinstall-2.0文件夹 如下图，shift+右键鼠标打开cmd,注意的是文件的路径不能有中文，我之前用的路径是D:\日常资料\日常资料\图片\大雪，会出现编码问题 在cmd上执行,不用理会error报错。 pyinstaller参数有如下选项，我们用的是-F, 后面跟的是要打包的python脚本的位置。 可选的opts有： -F, –onefile 打包成一个exe文件。 -D, –onedir 创建一个目录，包含exe文件，但会依赖很多文件（默认选项）。 -c, –console, –nowindowed 使用控制台，无界面(默认) -w, –windowed, –noconsole 使用窗口，无控制台 完毕之后，会在下图所示位置生成exe文件。 我们在该目录下取得exe文件，执行效果和python脚本是一样的。大功告成~~~~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo备份小技巧]]></title>
      <url>%2F2017%2F01%2F21%2Fhexo%E5%A4%87%E4%BB%BD%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[提交到github上备份: 12345678910111213cd blog/hexo# 初始化仓库git initgit add .git commit -m &quot;init&quot;# 建一个分支git checkout -b hexo# 删除本地的master分支git branch -d master# 添加远程git remote add origin https://github.com/用户名/用户名.github.io.git# 保存git push -u origin hexo 更换环境时: 123456789101112131415#1.安装git(配置git),nodejs;#2.克隆到本地git clone https://github.com/用户名/用户名.github.io.git hexocd hexo git checkout hexo#3.安装各种npm包npm install -g hexo-clinpm installnpm install hexo-deployer-git --save#用于markdown插入图片,首先确认 _config.yml 中有 post_asset_folder:truenpm install https://github.com/CodeFalling/hexo-asset-image --save#4 部署hexo cleanhexo generatehexo deploy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python中的struct模块]]></title>
      <url>%2F2017%2F01%2F19%2FPython%E4%B8%AD%E7%9A%84struct%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[​ python的struct模块，是在查看RYU控制器Openflow协议的实现源码接触到的。RYU控制器解包和封包就是用struct模块实现的。 ​ 在C语言中，struct结构体里面可以包含不同数据类型，比如int ,char,bool等。但是一旦涉及到网络通信时，传递的是二进制数据流（binary data）。对于二进制字符串，不必担心，但是对于如int，char等基本数据类型，需要有一种机制将这些特定的结构体类型打包成二进制流的字符串然后再在网络传输，同时接收端也需要通过某种机制进行解包还原出原始的结构体数据。 ​ python中的struct模块就提供了这样的机制，该模块的主要作用就是对python基本类型值与用python字符串格式表示的C struct类型间的转化，如下图: 1.简单演示 12345678910111213141516171819import structimport binasciivalues=(2017,'luckylau0',1.19)s=struct.Struct('I9sf')packed_data = s.pack(*values)#打包unpacked_data = s.unpack(packed_data)#解包print 'Original values:', valuesprint 'Format string :', s.formatprint 'Uses :', s.size, 'bytes'print struct.calcsize('I9sf')print 'Packed Value :', binascii.hexlify(packed_data)print 'Unpacked Type :', type(unpacked_data), ' Value:', unpacked_data#输出Original values: (2017, 'luckylau0', 1.19)Format string : I9sfUses : 20 bytes20Packed Value : e10700006c75636b796c617530000000ec51983fUnpacked Type : &lt;type 'tuple'&gt; Value: (2017, 'luckylau0', 1.190000057220459) ​ 代码中，首先定义了一个元组数据，包含int、string、float三种数据类型，然后定义了struct对象，并制定了format‘I8sf’，I 表示int ,8s表示八个字符长度的字符串，f 表示 float。最后通过struct的pack和unpack进行打包和解包。通过输出结果可以发现，value被pack之后，转化为了一段二进制字节串，而unpack可以把该字节串再转换回一个元组，但是值得注意的是对于float的精度发生了改变，这是由一些比如操作系统等客观因素所决定的。 2.字节顺序 ​ 打包的后的字节顺序默认上是由操作系统的决定的，当然struct模块也提供了自定义字节顺序的功能 ​ 例如采用小端存储 s = struct.Struct(‘&lt;I3sf’) 3.利用buffer，使用pack_into和unpack_from方法 12345678910111213141516171819202122import structimport binasciiimport ctypes values1 = (1, 'abc', 2.7)values2 = ('defg',101)s1 = struct.Struct('I3sf')s2 = struct.Struct('4sI') prebuffer = ctypes.create_string_buffer(s1.size+s2.size)print 'Before :',binascii.hexlify(prebuffer)s1.pack_into(prebuffer,0,*values1)s2.pack_into(prebuffer,s1.size,*values2)print 'After pack:',binascii.hexlify(prebuffer)print s1.unpack_from(prebuffer,0)print s2.unpack_from(prebuffer,s1.size)#输出Before : 0000000000000000000000000000000000000000After pack: 0100000061626300cdcc2c406465666765000000(1, 'abc', 2.700000047683716)('defg', 101) ​ 使用二进制打包数据的场景大部分都是对性能要求比较高的使用环境，所以上面提到的pack方法都是对输入数据进行操作后重新创建了一个内存空间用于返回，也就是说我们每次pack都会在内存中分配出相应的内存资源，这有时是一种很大的性能浪费。pack_into() 和 unpack_from()的方法就是对一个已经提前分配好的buffer进行字节的填充，而不会每次都产生一个新对象对字节进行存储。在RYU控制器中就是使用这两种方法。 4.总结： struct 模块 Python的struct库是一个简单的,高效的数据封装\解封装的库。主要包含5个函数: struct.pack(fmt, v1, v2, …): 将V1,V2等值按照对应的fmt(format)进行封装。 struct.unpack(fmt, string): 将string按照fmt的格式解封。 struct.pack_into(fmt, buffer, offset, v1, v2, …): 将V1,V2等值按照对应的fmt(format)封装到buffer中，从初始位置offset开始。 struct.unpack_from(fmt, buffer[offset=0，]): 按照fmt的格式，从offset开始将buffer解封。 struct.calcsize(fmt)： 计算对应的fmt的长度。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(3)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-3%2F</url>
      <content type="text"><![CDATA[2015年-2016年（35本书）2015年（4本书） 63.《黑客与画家》-Paul Graham 64.《文明之光》-吴军 65.《向死而生》-李开复 66.《大学之路（上）》-吴军 2016年（31本书） 67.《硅谷之谜》-吴军 68.《时间的针脚》-玛利亚杜埃尼亚斯 69.《动物庄园》-奥威尔 70.《绝望锻炼了我：朴槿惠自传》-朴槿惠 71.《解忧杂货店》-东野圭吾 72.《激荡三十年上》-吴晓波 73.《疑问集》-聂鲁达 74.《硅谷钢铁侠：埃隆·马斯克的冒险人生》-阿什利·范斯 75.《鱼羊野史第一卷》-高晓松 76.《你一定爱读的极简欧洲史》-约翰·赫斯特 77.《这么慢,那么美》-罗敷 78.《一个人的朝圣》-蕾秋·乔伊斯 79.《野火集：三十周年纪念版》-龙应台 80.《我们仨》-杨绛 81.《人间失格》-太宰治 82.《在绝望中寻找希望》-俞敏洪 83.《当尼采哭泣》-欧文 D.亚隆 84.《念完哈佛念阿弥陀佛》-陈宇廷 85.《你今天真好看》-莉兹克里莫 86.《我们生活在巨大差异里》-余华 87.《梦里花落知多少》-三毛 88.《纯真博物馆》-奥尔罕帕慕克 89.《岛上书店》-加布瑞埃拉泽文 90.《我与地坛》-史铁生 91.《史玉柱自述：我的营销心得》-史玉柱 92.《飞鸟集》-泰戈尔 93.《我可以咬你一口吗？》-利兹克利莫 94.《末日巨塔-基地组织与911之路》-劳伦斯赖特 95.《菊与刀:日本文化类型》-鲁思本尼迪克特 96.《小王子》-安托万德圣埃克苏佩里 97.《爱你就像爱生命》-王小波]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(2)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-2%2F</url>
      <content type="text"><![CDATA[2012年-2014年（37本书）2012年（7本书） 26.《爱的艺术》-艾弗洛姆 27.《平凡的世界》-路遥 28.《人生课》-张岱年 29.《世间最美丽的情郎：仓央嘉措的情与诗》-王臣 30.《追风筝的人》-(美国）胡赛尼 31.《纳兰词》-纳兰性德 32.《阿德勒谈灵魂与情感》-阿尔弗雷德阿德勒 2013年（13本书） 33.《促销的本质》-山姆沃尔顿 34.《历史是个什么玩意》-袁腾飞 35.《世界如此险恶，你要内心强大2》-石勇 36.《少有人走的路1》-M·斯科特·派克 37.《世界如此险恶，你要内心强大1》-石勇 38.《明朝那些事儿》-当年明月 39.《天才在左疯子在右》-高铭 40.《哲学与人生I》-傅佩荣 41.《哲学与人生II》-傅佩荣 42.《乌合之众》（法译本）-[法]古斯塔夫·勒庞 43.《万历十五年（增订纪念本）》-[美]黄仁宇 44.《沉默的大多数》-王小波 45.《自控力》-凯利·麦格尼格尔 2014年（17本书） 46.《七里香》，《无怨的青春》，《时光九篇》，《边缘光影》，《迷途诗册》，《我折叠着我的爱》-席慕容 47.《蒙田随笔》-蒙田（上海书店出版社） 48.《读书与做人》-季羡林 49.《男人来自火星，女人来自金星1》-约翰格雷 50.《男人来自火星，女人来自金星2》-约翰格雷 51.《超越自卑》-阿尔弗雷德阿德勒 52.《苏菲的世界》-乔斯坦贾德 53.《德意志的另一行泪》-朱维毅 54.《浪潮之巅》-吴军 55.《如果在冬夜，一个旅人》-[意大利] 伊塔洛·卡尔维诺 56.《审美与人的自由》-刘晓波 57.《撒哈拉的故事》-三毛 58.《文明之光》-吴军 59.《悉达多》-[德]赫尔曼黑塞 60.《呼兰河传》-萧红 61.《月亮与六便士》-毛姆 62.《人类的群星闪耀时》-斯蒂芬茨威格]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95%2F</url>
      <content type="text"><![CDATA[2009年-2011年（25本书）1.《谈美》-朱光潜 2.《安娜·卡列尼娜》（上下册）-（俄罗斯）托尔斯泰 3.《遇见未知的自己》- 张德芬 4.《人生若只如初见古典诗词的美丽与哀愁》- 安意如 5.《宋词三百首》- 上疆村民选编 6.《世界因你不同——李开复自传》- 李开复 范海涛 7.《思无邪：追绎前生的记忆》-安意如 8.《看张·爱玲画语》-安意如 9.《林肯传 》-戴尔·卡耐基 10.《富豪发家史》-子志编著 11.《水知道答案》-〔日〕江本胜 12.《彼得大帝》-帕甫连科 13.《活着就是为了改变世界》-杰弗里·扬,威廉西蒙 14.《我是沃兹：一段硅谷和苹果的悲情罗曼史》-斯蒂夫沃兹尼亚 15.《美国通史(上)》 16.《美国通史(下)》 17.《爱情诗集》- 文爱艺 18.《麦田里的守望者》-J.D塞林格 19.《批评官员的尺度：《纽约时报》诉警察局长沙利文案》-安东尼 20.《你是那人间的四月天》-林徽因 21.《汪国真经典诗文》-汪国真 22.《中国人的品格》-罗家伦 23.《蒙田随笔》-蒙田 24.《汪国真精选集》 25.《巨流河》-齐邦媛]]></content>
    </entry>

    
  
  
</search>
