<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[你懂网络吗(2)]]></title>
      <url>%2F2017%2F03%2F23%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： 以太网 以太网数据封装 以太网回顾？包括以下内容： 冲突域，广播域，CSMNCD，半双工，全双工，以太网编址 ,以太网帧，以太网物理层，以太网布线 ​ 冲突域是一个以太网术语，指的是这样一种网络情形，即网段上的一台设备发送分组时，该物理网段上的其他所有设备都必须债昕它。这很糟糕，因为如果同一个物理网段中的两台设备同时传输数据，将发生冲突(即两台设备的数字信号将在线路上相互干扰)，导致设备必须在以后重传数据。冲突对网络性能有严重的负面影响，因此绝对要避免冲突。 **广播域**指的是网段中的一组设备，它们侦昕在该网段上发送的所有广播。广播域的边界通常为诸如交换机和路由器等物理介质，但广播域也可能是一个逻辑网段，其中每台主机都可通过数据链路层(硬件地址)广播访问其他所有主机。 ​ CSMNCD (Carrier Sense Multiple Access with Collision Detection ，载波侦听多路访问/冲突检测)这是一种帮助设备均衡地共享带宽的协议，可避免两台设备同时在网络介质上传输数据。 帮助最大限度地减少冲突，从而提高数据传输效率。主机想通过网络传输数据时，它首先检查线路上是否有数字信号。如果没有其他主机传输数据，该主机将开始传输数据。但到这里并非万事大吉，传输主机将持续地监视线路，确保没有其他主机开始传输。如果该主机在线路上检测到其他信号，它将发送一个扩展的拥堵信号 (jam signal)，使网段上的所有节点都不再发送数据(想想电话忙音吧)。检测到拥堵信号后，其他节点将等待一段时间再尝试传输。后退算法决定了发生冲突的工作站多长时间后可重新传输，如果连续 15 次尝试都导致冲突，尝试传输的节点将超时。 以太网 LAN 中发生冲突后，将出现如下’情况: 拥堵信号告诉所有设备发生了冲突； 冲突激活随机后退算法； 以太网网段中的每台设备都暂停传输，直到其后退定时器到期； 定时器到期后，所有主机的传输优先级都相同。 CSMAlCD 网络持续发生严重冲突时，将导致如下结果: 延迟; 低吞吐量; 拥塞; 半双工以太网使用 CSMA/CD 协议，以帮助防范冲突，并在发生冲突时支持重传。如果集线器与交换机相连，它必须运行在半双工模式下，因为终端必须能够检测冲突。半双工以太网的效率只有30%-40% ，因为在大型 100BaseT 网络中，通常最大传输速度只有 30 - 40 Mbitls。 全双工以太网同时使用两对导线,与半双工以太网只使用一对导线不同 。在传输设备的发射器和接收设备的接收器之间，全双工使用一条点到点连接，这意味着使用全双工时，数据传输速度比半双工时快。你元需担心冲突，因为全双工提供了一条”多车道高速公路”，而不像半双工那样提供一条”单车道公路”。全双工以太网在两个方向的效率都为 100% 。全双工以太网可用于下面 6 种情形: 交换机到主机的连接; 交换机到交换机的连接; 主机到主机的连接(使用交叉电缆); 交换机到路由器的连接(使用交叉电缆); 路由器到路由器的连接(使用交叉电缆); 路由器到主机的连接(使用交叉电缆)。 基本上除集线器外，其他所有设备都可在全双工模式下运行。 以太网编址 MAC (硬件)地址长 48 位 (6 B)，采用十六进制格式。 I/G (Individual/Group) 位： 值为 0 ，我们就可认为相应的地址为某台设备的 MAC 地址，很可能出现在 MAC 报头的源地址部分;值为 1 ，我们就可认为相应的地址为以太网中的广播地址或组播地址或者令牌环和FDDI 中的广播地址或功能地址 。 G/L位(全局/本地位，也称为 U/L位): 值为 0 ，则表示相应的地址为全局管理地址，由 IEEE 分配; 值为 1， 则表示相应的地址为本地管理地址 ; OUI ( Organizationally Unique Identifier，组织唯一标识符)： 由 IEEE 分配给组织的，它包含 24位 (3 B)，而组织给其生产的每个网卡都分配一个唯一的( 据说如此，但不保证 ) 全局管理地址，该地址长 24 位 (3 B)。 右边 24 位为本地管理(制造商分配)的编码，特定制造商生产第一个网卡时，通常将这部分设置为 24 个 0 ，然后依次递增，直到将其生产的第 1677 216 个网卡设置为 24 个 1 。 数据链路层负责将比特合并成字节，再将字节封装成帧。在数据链路层，我们使用帧封装来自网络层的分组，以便通过特定类型的介质进行传输。 以太网帧 数据链路层负责将比特合并成字节，再将字节封装成帧。在数据链路层，我们使用帧封装来自网络层的分组，以便通过特定类型的介质进行传输。下图是以太网帧和802.3帧。 前导码交替的 0 和 1 ，在每个分组的开头提供 5 MHz 的时钟信号，让接收设备能够跟踪到来的比特流。 帧起始位置分隔符 (SFD) I同步前导码为 7B，而 SFD (同步)为 lBo SFD 的值为 10101011 ,其中最后两个 l 让接收方能够识别中间的 0 和 1 交替模式，进而同步并检测到数据开头。 目标地址 (DA) 包含一个 48 位的值，且 LSB (Least Significant Bit，最低有效位)优先。接收方根据 DA 判断到来的分组是否是发送给特定节点的。 目标地址可以是单播地址、广播地址或组播 MAC 地址。 别忘了， 广播地址全为 1 (在十六进制格式下全为 F) ， 广播发送给所有设备，而组播只发送给网络中一组类似的节点。 源地址 (SA) SA 是一个 48 位的 MAC 地址 ， 用于标识传输设备，也使用 LSB 优先格式。在 SA 字段中，不能包含广播地址或组播地址。 长度或类型 802.3 帧使用长度字段，而 Etbemet_II 帧使用类型字段标识网络层协议。 802.3不能标识上层协议，只能用于专用 LAN，如 IPX。 数据这是网络层传递给数据链路层的帧，其长度为 46-1500 B。 帧校验序列 (FCS) FCS 字段位子，用于存储 CRC (Cyclic Redundancy Check ，循环冗余校验 ) 结果的帧的帧尾 。 CRC 是一种数学算法，创建每个帧时都将运行它 。 作为接收方的主机收到帧并运行 CRC 时，其结果必须相同，否则，接收方将认为发生了错误，进而将帧丢弃。 以太网物理层 ，IEEE 对 802.3进行了扩展，制定了两个新标准: 802.3u ( 快速以太网)和 802 .3ab (使用 5 类电缆的吉比特以太网)，然后又制定了标准 802.3ae (使用光纤和同轴电缆，速度为 10 Gbitls )。 IEEE 802.3 标准： 以太网布线 有三种，直通电缆 交叉电缆 反转电缆。 (1)主机到主机。交叉电缆(2) 主机到交换机或集线器。直通电缆(3) 路由器到主机。交叉电缆(4) 交换机到交换机。交叉电缆(5) 路由器到交换机或集线器。直通电缆(6) 集线器到集线器。交叉电缆(7) 集线器到交换机。交叉电缆(8) 主机到路由器的控制台串行通信 (COM) 端口。 反转电缆 二进制和十进制和十六进制转换？ 半字节（4位） 字节（8位） 8 4 2 1 128 64 32 16 8 4 2 1 二进制转十进制 10010110: 128+16+4+2=150 十六进制转二进制 0x6A : 6 =0110 A=1010 即为01101010 二进制转十六进制 11001101 : 1100=12 1101=13 即为0xCD 数据封装？​ 为通信和交换信息，每层都使用 PDU ( Protocol Data Unit，协议数据单元 )0 PDU包含在模型每一层给数据添加的控制信息。这些控制信息通常被添加在数据字段前面的报头中，但也可能被添加在报尾中。 ​ OSI 模型每一层都对数据进行封装来形成 PDU ， PDU 的名称随报头提供的信息而异。这些 PDU信息仅在接收设备的对等层被读取，然后被剥离，然后数据被交给下一层。 封装过程如下： (1) 用户信息被转换为数据，以便通过网络传输；(2) 数据被转换为数据段，并在发送主机和接收主机之间建立一条可靠的连接；(3) 数据段被转换为分组或数据报，并在报头中加入逻辑地址，使得能够在互联网络中路由分组；(4) 分组或数据报被转换为帧，以便在本地网络中传输。使用硬件(以太网)地址来唯一地标识本地网络中的主机；(5) 帧被转换为比特，并使用数字编码和时钟同步方案 ； 解释上述过程如下： ​ 事实上由上层将数据流交给传输层。作为技术人员，我们并不关心数据流来自何方。我们的职责是，在接收设备处可靠地重建数据流，并将其交给上层。 使用面向连接的协议(即 TCP) 时，传输层将数据流转换为数据段，并创建一条虚电路以建立可靠的会话。 接下来，它对每个数据段进行编号，并使用确认和流量控制。如果你使用的是 TCP，虚电路将由源端口号和目标端口号以及源 IP 地址和目标 P 地址(称为套接字)标识。别忘了，主机只能使用不小于 1024 的端口号( 0-1023 为知名端口号)。目标端口号标识了上层进程(应用程序)，在接收主机可靠地重建数据流后，数据流将被交给该进程(应用程序)。 问与答？以太网帧包含哪些字段？ 源 MAC 地址、目标 MAC 地址、标识网络层协议的以太类型( Ether-Type )、数据以及存储 CRC 结果的 FCS]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(7)]]></title>
      <url>%2F2017%2F03%2F21%2F%E4%BD%A0%E6%87%82python%E5%90%97-7%2F</url>
      <content type="text"><![CDATA[python的新式类和旧式类​ python的新式类是2.2版本引进来的，我们可以将之前的类叫做经典类或者旧式类。为什么要在2.2中引进new style class呢？官方给的解释是：为了统一类(class)和类型(type)。 使用环境是python 2.7 新式类与旧式类的区别 12345678910111213141516171819202122class C(object): passclass B: passif __name__ == '__main__': c = C() b = B() print type(c) print c.__class__ print type(b) print b.__class__ print "**********************" print dir(C) print dir(B)#output&lt;class '__main__.C'&gt;&lt;class '__main__.C'&gt;&lt;type 'instance'&gt;__main__.B**********************['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']['__doc__', '__module__'] ​ 如上所示b是旧式类的一个实例，c是新式类的一个实例。c的class与type返回的结果是一样的，得到统一。而b的class与type返回的结果并不相同。同时我们还发现新式类有更多的属性和方法，旧式类只有区区的2个方法。 ​ 我们也发现为了向前兼容，默认情况下用户定义的类为经典类，新类需要继承自所有类的基类 object 或者继承自object的新类。那么为了确保自己使用的是新式类，有两种以下方法： 元类，在类模块代码的最前面加入如下代码 metaclass = classname(自定义的某个新式类)。 类都从内建类object直接或者间接地继承。 新式类的属性和方法内置的object对象是所有内置，object对象定义了一系列特殊的方法实现所有对象的默认行为。 1.new，init方法这两个方法是用来创建object的子类对象，静态方法new()用来创建类的实例，然后再调用init()来初始化实例。 123456789101112class C(object): passclass B: passif __name__ == '__main__': c = C("ooo") b = B("ooo")#outputTypeError: object() takes no parameters #新式类TypeError: this constructor takes no arguments #旧式类 新式类都有一个new的静态方法，它的原型是object.new(cls[, …])cls是一个类对象，如上面代码，当你调用C(args, **kargs)来创建一个类C的实例时，python的内部调用是C.new(C, args, kargs)，然后返回值是类C的实例c，在确认c是C的实例后，python再调用C.init(c, *args, kargs)来初始化实例c。所以调用一个实例c = C(”ooo“)，实际执行的代码为： 123c = C.__new__(C, "ooo")if isinstance(c, C): C.__init__(c, "ooo") 可以使用new来实现Singleton单例模式： 12345678910111213141516171819202122class Singleton(object): _singleton=&#123;&#125; def __new__(cls, *args, **kwargs): if not cls._singleton.has_key(cls): cls._singleton[cls]=object.__new__(cls) return cls._singleton[cls]class B(object): #做对比 passif __name__ == '__main__': a=Singleton() print id(a) b=Singleton() print id(b) c=B() print id(c) d=B() print id(d)#output140573118190288140573118190288140573118190352140573118190416 使用id()操作，可以看到两个实例指向同一个内存地址。Singleton的所有子类也有这一特性，只有一个实例对象，如果它的子类定义了init()方法，那么必须保证它的init方法能够安全的同一个实例进行多次调用。 2.delattr, getattribute, setattr方法对象使用这些方法来处理属性的访问 getattribute 对新式类的实例来说，所有属性和方法的访问操作都是通过getattribute完成，这是由object基类实现的。如果有特殊的要求，可以重载getattribute方法，下面实现一个不能使用append方法的list： 12345678910111213141516class listNoappend(list): def __getattribute__(self, item): if item == 'append': raise AttributeError(item) return list.__getattribute__(self, item)if __name__ == '__main__': a = listNoappend() print type(a) print dir(a) a.append("abc")#output&lt;class '__main__.listNoappend'&gt;['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__dict__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']a.append("abc")raise AttributeError(item)AttributeError: append 3.hash, repr, str方法print(someobj)会调用someobj.str()， 如果str没有定义，则会调用someobj.repr()， str()和repr()的区别： 默认的实现是没有任何作用的，repr的目标是对象信息唯一性，str的目标是对象信息的可读性 容器对象的str一般使用的是对象元素的repr，如果重新定义了repr，而没有定义str，则默认调用str时，调用的是repr，也就是说好的编程习惯是每一个类都需要重写一个repr方法，用于提供对象的可读信息，而重写str方法是可选的。实现str方法，一般是需要更加好看的打印效果，比如你要制作一个报表的时候等。可以允许object的子类重载这些方法，或者添加新的方法。 4.slots属性​ 通常每一个实例x都会有一个dict属性，用来记录实例中所有的属性和方法，也是通过这个字典，可以让实例绑定任意的属性。而slots属性作用就是，当类C有比较少的变量，而且拥有slots属性时，类C的实例 就没有dict属性，而是把变量的值存在一个固定的地方。如果试图访问一个slots中没有的属性，实例就会报错。这样操作有什么好处呢？slots属性虽然令实例失去了绑定任意属性的便利，但是因为每一个实例没有dict属性，却能有效节省每一个实例的内存消耗，有利于生成小而精干的实例。 ​ 在一个实际的企业级应用中，当一个类生成上百万个实例时，即使一个实例节省几十个字节都可以节省一大笔内存，这种情况就值得使用slots属性。 slots是一个类变量，slots属性可以赋值一个包含类属性名的字符串元组，或者是可迭代变量，或者是一个字符串。 只有在新式类中生效，如下对比： 1234567891011121314151617181920212223242526272829class A: #做对比 def __init__(self,x,y): self.x=x self.y=y __slots__='x','y'class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__='x','y'if __name__ == '__main__': a=A(3,6) print a.x print a.y a.z=7 print a.z b = B(3, 6) print b.x print b.y b.z=6 print b.z#output36736AttributeError: 'B' object has no attribute 'z' 需要注意的几点： 当一个类的父类没有定义slots属性，父类中的dict属性总是可以访问到的，所以只在子类中定义slots属性，而不在父类中定义是没有意义的。 如果定义了slots属性，还是想在之后添加新的变量，就需要把dict字符串添加到__slots__的元组里。 12345class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__=('x','y',"__dict__") 定义了slots属性，还会消失的一个属性是weakref，这样就不支持实例的weak reference，如果还是想用这个功能，同样，可以把’weakref‘字符串添加到元组里。 slots功能是通过descriptor实现的，会为每一个变量创建一个descriptor。 slots的功能只影响定义它的类，因此，子类需要重新定义slots才能有它的功能。 12345678910111213141516171819class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__=('x','y')class C(B): passif __name__ == '__main__': b = B(3, 6) c=C(3,6) c.z=9 print c.z b.z=9 print b.z# output9'B' object has no attribute 'z' 5.getitem方法​ 在python中，隐式调用实例的私有特殊方法时，新的对象模型和经典对象模型表现上不太一样。在经典对象模型中，无论是显示调用还是隐式调用特殊方法，都会调用实例中后绑定的特殊方法。而在新的对象模型中，除非显式地调用实例的特殊方法，否则python总是会去调用类中定义的特殊方法，如果没有定义的话，就报错。 123456789101112131415161718def getItem(index): return index + 1class OldStyle: passclass NewStyle(object): passif __name__ == '__main__': old = OldStyle() old.__getitem__=getItem print old[2] new =NewStyle() new.__getitem__=getItem print new.__getitem__(2) #显示调用 print new[2]# output33TypeError: 'NewStyle' object does not support indexing 调用old[1]，将产生一个隐式的getitem方法的调用，在新式类中，因为类中没有定义这个方法，也不是object基类有的方法，所以报错。需要显示地调用才可以运行。 新式类的继承​ 新式类同样支持多继承，但是如果新式类想要从多个内置类型中继承生成一个新类的话，则这些内置类必须是经过精心设计，能够互相兼容的。显然，python也没会让你随意的从多个内置类中进行多继承，想创建一个超级类不是那么容易的。。。通常情况下，至多可以继承一个内置类，比如list, set, dict等。 下图是MRO(Method Resolution Order ,方法解析顺序)，分别是旧式类和新式类的方法顺序。旧式类深度优先的方式进行查找，新式类广度优先的方式查找 1234567891011121314151617class D: def __init__(self): self.x = "d"class B(D): passclass C(D): def __init__(self): self.x = "c"class A(B,C): passif __name__ == '__main__': a=A() print a.x print A.__mro__#output dAttributeError: class A has no attribute '__mro__' 1234567891011121314151617class D(object): def __init__(self): self.x = "d"class B(D): passclass C(D): def __init__(self): self.x = "c"class A(B,C): #当B,C变成C，B时候 A.__mro__的输出顺序也会变 passif __name__ == '__main__': a=A() print a.x print A.__mro__#outputc(&lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;type 'object'&gt;) 另一个注意的是协作式调用父类方法使用： 1234567891011121314151617181920212223242526272829303132class A(object): def foo(self): print "AAAAA"class B(A): def foo(self): print "BBBBB" A.foo(self)class C(A): def foo(self): print "CCCCC" A.foo(self)class D(B,C): def foo(self): print "DDDDD" B.foo(self) C.foo(self)if __name__ == '__main__': d=D() print d.foo() print D.__mro__#outputDDDDDBBBBBAAAAACCCCCAAAAANone(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;) ​ 可以看到，基类A的方法重复运行了两次。怎样才能确保父类中的方法只被顺序的调用一次呢？在新的对象系统中，有一种特殊的方法super(aclass, obj)，可以返回obj实例的一个特殊类型superobject(超对象， 不是简单的父类的对象)，当我们使用超对象调用父类的方法时，就能保证只被运行一次： 12345678910111213141516171819202122232425262728class A(object): def foo(self): print "AAAAA"class B(A): def foo(self): print "BBBBB" super(B,self).foo()class C(A): def foo(self): print "CCCCC" super(C, self).foo()class D(B,C): def foo(self): print "DDDDD" super(D, self).foo()if __name__ == '__main__': d=D() print d.foo()#outputDDDDDBBBBBCCCCCAAAAANone ​ 可以看到，D的父类中所有的foo方法都得到执行，并且基类A的foo方法只执行了一次。如果养成了使用super去调用父类方法的习惯，那么你的类就可以适应无论多么复杂的继承调用结构。super()可以看成是更加安全调用父类方法的一种新方式。 新式类的Descriptor​ descriptor可以说是一个绑定了特定访问方法的类属性，这些访问方法是重写了descriptor protocol中的三个方法，分别是get, set, del方法。如果三个中任一一个方法在对象中定义了，就说这个对象是一个descriptor对象，可以把这个对象赋值给其它属性。descriptor protocol可以看成是一个有三个方法的接口。 ​ 通常对一个实例的属性的访问操作，如get, set, delete是通过实例的dict字典属性进行的，例如下面代码: 123456789class Person(object): name="lucky"if __name__ == '__main__': person=Person() person.name="Lau" print person.name#outputLau ​ 对于操作person.name，会一个查找链，首先通过实例对象的dict属性访问，即person.dict[‘x’]（实例的字典），再通过类型对象的dict属性访问，即type(person).dict[‘x’]，等价于Person.dict[‘name’]（类的字典），再通过父类对象的dict属性访问，person.class.base.dict[‘name’],等价于Parent.dict[‘name’]，type(a)的父类的字典。 ​ 如果这个需要被查找的属性是一个定义了descriptor协议方法的对象，那么python就不会按照默认的查找方式，而是调用descriptor协议中定义的方法get方法获取，同样的道理，给name赋值的时候是通过调用set方法实现而不是通过dict属性。 12345678910111213141516171819class DescriptorName(object): def __init__(self,name): self.name=name def __get__(self, instance, owner): print '__get__' , instance,owner return self.name def __set__(self, instance, value): print '__set__',instance,value self.name=valueclass Person(object): name=DescriptorName("Lucky")if __name__ == '__main__': person=Person() person.name="Lau" print person.name#output__set__ &lt;__main__.Person object at 0x7f9b2458c490&gt; Lau__get__ &lt;__main__.Person object at 0x7f9b2458c490&gt; &lt;class '__main__.Person'&gt;Lau 上面的例子是基于类的方式来创建描述符，你还可以通过property()函数来创建描述符 123456789101112131415161718192021222324252627282930class Person(object): def __init__(self, name): self.name = name self._email=None def get_email(self): print ' get_email is invoked' return self._email def set_email(self, value): print ' set_email is invoked' self._email = value def del_email(self): print 'del_email is invoked' del self._email email = property(get_email, set_email, del_email, 'this is email property')if __name__ == '__main__': person = Person("Luckylau") person.email="laujunbupt0913@163.com" # set_email is invoked print person.email # get_email is invoked del person.email # del_email is invoked#outputset_email is invokedget_email is invokedlaujunbupt0913@163.comdel_email is invoked property()函数返回的是一个描述符对象，它可接收四个参数property(fget=None, fset=None, fdel=None, doc=None) fget：属性获取方法 fset：属性设置方法 fdel：属性删除方法 doc： docstring 使用纯python的方式来实现property函数如下： 1234567891011121314151617181920212223242526272829303132333435363738class Property(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, instance, owner): if instance is None: return self if self.fget is None: raise AttributeError("unreadable attribute") return self.fget(instance) def __set__(self, instance, value): if self.fset is None: raise AttributeError("can't set attribute") self.fset(instance, value) def __delete__(self, instance): if self.fdel is None: raise AttributeError("can't del attribute") self.fdel(instance) def getter(self, fget): print "Property getter is invoked " return type(self)(fget, self.fset, self.fdel, self.__doc__) def setter(self, fset): print "Property setter is invoked " return type(self)(self.fget, fset, self.fdel, self.__doc__) def deleter(self, fdel): print "Property deleter is invoked " return type(self)(self.fget, self.fset, fdel, self.__doc__) 同时你还可以用property装饰器创建描述符 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Property(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, instance, owner): if instance is None: return self if self.fget is None: raise AttributeError("unreadable attribute") return self.fget(instance) def __set__(self, instance, value): if self.fset is None: raise AttributeError("can't set attribute") self.fset(instance, value) def __delete__(self, instance): if self.fdel is None: raise AttributeError("can't del attribute") self.fdel(instance) def getter(self, fget): print "Property getter is invoked " return type(self)(fget, self.fset, self.fdel, self.__doc__) def setter(self, fset): print "Property setter is invoked " return type(self)(self.fget, fset, self.fdel, self.__doc__) def deleter(self, fdel): print "Property deleter is invoked " return type(self)(self.fget, self.fset, fdel, self.__doc__)class Person(object): def __init__(self,name): self.name=name self._email = None @Property def email(self): pass @email.getter def email(self): print " get_email is invoked " return self._email @email.setter def email(self, value): print " set_email is invoked " self._email = value @email.deleter def email(self): print " del_email is invoked " del self._emailif __name__ == '__main__': p = Person("Luckylau") print "**************" p.email = "laujunbupt0913@163.com" print "**************" print p.email#outputProperty getter is invoked Property setter is invoked Property deleter is invoked ********** set_email is invoked ********** get_email is invoked laujunbupt0913@163.com 参考：http://www.pythontab.com/html/2015/pythonjichu_1113/982.html http://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html http://blog.csdn.net/imzoer/article/details/8737642]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(6)]]></title>
      <url>%2F2017%2F03%2F20%2F%E4%BD%A0%E6%87%82python%E5%90%97-6%2F</url>
      <content type="text"><![CDATA[*args和 **kwargs用args和*kwargs只是为了方便并没有强制使用它们。 当你不确定你的函数里将要传递多少参数时你可以用*args.例如,它可以传递任意数量的参数: 123456789def print_everything(*args): for count, thing in enumerate(args): print '&#123;0&#125;. &#123;1&#125;'.format(count, thing)if __name__ == '__main__': print_everything('apple', 'banana', 'cabbage')#output0. apple1. banana2. cabbage 相似的,**kwargs允许你使用没有事先定义的参数名: 12345678def table_things(**kwargs): for name, value in kwargs.items(): print '&#123;0&#125; = &#123;1&#125;'.format(name, value)if __name__ == '__main__': table_things(apple='fruit', cabbage='vegetable')#outputcabbage = vegetableapple = fruit 你也可以混着用.命名参数首先获得参数值然后所有的其他参数都传递给*args和**kwargs.命名参数在列表的最前端.*args和**kwargs可以同时在函数的定义中,但是*args必须在**kwargs前面. 当调用函数时你也可以用*和**语法.例如: 12345678def print_three_things(a, b, c): print 'a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;'.format(a,b,c)if __name__ == '__main__': mylist = ['aardvark', 'baboon', 'cat'] print_three_things(*mylist)#outputa = aardvark, b = baboon, c = cat 就像你看到的一样,它可以传递列表(或者元组)的每一项并把它们解包.注意必须与它们在函数里的参数相吻合.当然,你也可以在函数定义或者函数调用时用* 参考：http://stackoverflow.com/questions/3394835/args-and-kwargs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(1)]]></title>
      <url>%2F2017%2F03%2F17%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： OSI模型 OSI模型：​ OSI 模型包含 7 层，它们分为两组:上 3 层指定了终端中的应用程序如何彼此通信以及如何与用户交流;下 4 层指定了如何进行端到端的数据传输。 请记住，这3 层都对联网和网络地址一无所知，那是下 4 层的职责 。 ISO的功能如下： ​ 应用层是实际应用程序之间的接口。这意味着诸如 MicrosoftWord 等应用程序并不位于应用层中，而是与应用层协议交互。 ​ 表示层向应用层提供数据，并负责数据转换和代码格式化。 ​ 会话层负责在表示层实体之间建立、管理和终止会话，还X才设备或节点之间的对话进行控制。 为此提供了 3 种不同的模式:单工、半双工和全双工。 ​ 传输层将数据进行分段并重组为数据流。位于传输层的服务将来自上层应用的数据进行分段和重组，并将它们合并到同一个数据流中。它们提供了端到端的数据传输服务，并可在互联网络上的发送主机和目标主机之间建立逻辑连接。另外，对上层应用程序进行多路复用、建立会话以及拆除虚电路，并提供透明的数据传输，从而对高层隐藏随网络而异的信息。 ​ 网络层(第 3 层)管理设备编址、跟踪设备在网络中的位置并确定最佳的数据传输路径，这意味着网络层必须在位于不同网络中的设备之间传输数据流。 ​ 数据链路层将报文封装成数据帧，并添加定制的报头，其中包含目标硬件地址和源硬件地址 。路由器运行在网络层，根本不关心主机位于什么地方，而只关心网络(包括远程网络)位于什么地方以及前往这些网络(包括远程网络)的最佳路径。路由器只关心网络，这是好事!对本地网络中每台设备进行唯一标识的工作由数据链路层负责。数据链路层使用硬件地址，让主机能够给本地网络中的其他主机发送分组以及穿越路由器发送分组。每当在路由器之间传输分组时，分组都将被使用数据链路层控制信息封装成帧，但接收路由器会将这些信息剥离，只保留完整的原始分组。在每一跳都将重复这种将分组封装成帧的过程，直到分组最终到达正确的接收主机。在整个传输过程中，分组本身从未被修改过，而只是被必要的控制信息封装，以便能够通过不同的介质进行传输，明白这一点至关重要。 IEEE 以太网数据链路层包含两个子层，如下：介质访问控制 (MAC) 子层 (802.3)和逻辑链路控制 (LLC) 子层 (802.2) 。介质访问控制 (MAC) 子层 (802.3)，它采用”先到先服务”的访问方式，带宽由大家共享，因此称为竟用介质访问( contention media access )。 逻辑链路控制 (LLC) 子层 (802.2)负责识别网络层协议并对其进行封装。 ​ 物理层有两项功能:发送和接收比特。比特的取值只能为 0 或 1一一使用数字值的摩尔斯码。物理层直接与各种通信介质交流。 总结: 应用层、表示层和会话层属于上层，负责用户界面和应用程序之间的通信。传输层提供分段、排序和虚电路。网络层提供逻辑网络编址以及在互联网络中路由的功能。数据链路层提供了将数据封装成帧并将其放到网络介质上的功能。物理层负责将收到的 0 和 1 编码成数字信号，以便在网段中传输。 问与答：1.对数据流进行分段发生在 OSI模型的哪一层? 传输层 解释：传输层从上层接收大型数据，将其分割成较小的片段，这些片段称为数据段。 2.下面哪 4 项描述了路由器的主要功能?A. 分组交换 B. 冲突防范 C. 分组过滤D. 增大广播域 E. 互联网络通信 F. 广播转发G. 路径选择 A 、 C 、 E 、 G。路由器提供分组交换、分组过滤、互联网络通信以及路径选择功能。虽然路由器确实分割或终止冲突域，但这不是路由器的主要功能，因此选项 B 不正确。 3.路由器运行在第？层; LAN 交换机运行在第？层;以太网集线器运行在第？层;字处理程序运行在第？层。A. 3 , 3 ， 1 、 7 B.3 、 2 、 1 、无C.3 、 2 、 1 、 7 D.2 、 3 、 1 、 7E.3 , 3, 2 、无 路由器运行在第 3 层， LAN 交换机运行在第 2 层，以太网集线器运行在第 1 层。字处理程序与应用层接口通信，但并非运行在第 7 层，因此答案为”无”。 4.下面哪 3 种有关全双工以太网运行方式的说法是正确的?A.在全双工模式下不会发生冲突B. 每个全双工节点都必须有一个专用的交换机端口C. 以太网集线器端口被预先配置为全双工模式D. 在全双工环境中，在传输数据前，主机的网卡必须检查网络介质是否可用E 主机的网卡和交换机端口必须能够以全双工模式运行 A 、 B 、 E。全双工意味着可使用两对导线同时发送和接收数据。每个节点都必须有专用的交换机端口，这意味着不会发送冲突。主机的网卡和交换机端口都必须支持全双工模式，并设置为这种模式。 5. (1) 哪一层选择通信伙伴并判断其可用性、判断建立连接所需资掘的可用性、协调参与通信的应用程序，并就控制数据完整性和错误恢复的流程达成一致?(2) 哪一层负责将来自数据链路层的数据分组转换为电信号?(3) 哪一层实现路由选择，在终端系统之间建立连接并选择路径?(4) 哪一层定义了如何对数据进行格式化、表示、编码和转换，以便在网络中使用?(5) 哪一层负责在应用程序之间建立、管理和终止会话?(6) 哪一层确保通过物理链路可靠地传输数据，且主要与物理地址、线路管理、网络拓扑、错误通知、按顺序传输帧以及流量控制有关?(7) 哪一层用于让终端节点能够通过网络进行可靠的通信，提供建立、维护、拆除虚电路的机制，提供传输错误检测和恢复的机制，并提供流量控制机制?(8) 哪一层提供逻辑地址，供路由器用来决定传输路径?(9) 哪一层指定了电平、线路速度和电缆针脚，并在设备之间传输比特?(10) 哪一层将比特合并成字节，再将字节封装成帧，使用 MAC 地址，并提供错误检测功能?(11) 哪一层负责在网络中将来自不同应用程序的数据分开。(12) 哪一层的数据表示为帧?(13) 哪一层的数据表示为数据段?(14) 哪一层的数据表示为分组?(15) 哪一层的数据表示为比特?(16) 按封装顺序排列下列各项:分组帧比特数据段(17) 哪一层对数据进行分段和重组?(1 8) 哪一层实际传输数据，并处理错误通知、网络拓扑和流量控制?(19) 哪一层管理设备编址、跟踪设备在网络中的位置并决定传输数据的最佳路径?(20) MAC 地址长多少位?以什么方式表示? (1) 应用层负责寻找服务器提供的网络资源，并提供流量控制和错误控制功能(如果应用程序开发人员选择这样做)(2) 物理层接收来自数据链路层的帧，将 0 和 1 编码成数字信号，以便在网络介质上传输(3) 网络层提供了在互联网络中进行路由选择的功能，还提供了逻辑地址(4) 表示层确保数据为应用层能够理解的格式(5) 会话层在应用程序之间建立、维护并终止会话 (6) 数据链路层的 PDU 称为帧，该层还提供物理编址以及将分组放到网络介质上的其他选项(7) 传输层使用虚电路在主机之间建立可靠的连接(8)网络层提供了逻辑地址(这通常是 IP 地址)和路由选择功能(9) 物理层负责在设备之间建立电气和机械连接(10) 数据链路层负责将数据分组封装成帧(11) 会话层在不同主机的应用程序之间建立会话(12) 数据链路层将从网络层收到的分组封装成帧(13) 传输层将用户数据分段(14) 网络层将来自传输层的数据段封装成分组(15) 物理层负责以数字信号的形式传输 l 和 o (比特)(16) 数据段、分组、帧、比特(17) 传输层(18) 数据链路层(19) 网络层(20) 长 48 位 (6B) 表示为一个十六进制数 6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(5)]]></title>
      <url>%2F2017%2F03%2F17%2F%E4%BD%A0%E6%87%82python%E5%90%97-5%2F</url>
      <content type="text"><![CDATA[python的format函数使用语法 它通过{}和:来代替%。 用法 ^、&lt;、&gt;分别是居中、左对齐、右对齐，后面带宽度:号后面带填充的字符，只能是一个字符，不指定的话默认是用空格填充 精度常跟类型f一起使用 b、d、o、x分别是二进制、十进制、八进制、十六进制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Person(): def __init__(self, name, age): self.name = name self.age = age def __str__(self): return 'This guy is &#123;self.name&#125;,&#123;self.age&#125; old'.format(self=self)if __name__ == '__main__': # 元组表达 info = ("luckylau", 23) print "info : %s" % (info,) #对于元组，后面的逗号不能少，会报错 print '&#123;1&#125;,&#123;0&#125;'.format(*info) #对于元组，星号不能少，会报错 # 通过位置映射 print '&#123;0&#125;,&#123;1&#125;'.format('test', '123') print '&#123;0&#125;,&#123;1&#125;,&#123;0&#125;'.format('test', '123') # 通过关键字映射 print "&#123;name&#125;,&#123;age&#125;".format(name="luckylau", age=23) # 通过对象属性 print str(Person("luckylau",23)) # 数组表达 info=["luckylau",23] print "info : %s" % (info,) print 'info :&#123;1&#125;,&#123;0&#125;'.format(*info) #星号不能少 print "info : %s" % (info) print 'info :&#123;0[1]&#125;,&#123;0[0]&#125;'.format(info) # 字典的表达 info=&#123;"name":"luckylau","age":23&#125; print "info : %s " %(info) print "info : %s" % (info,) print 'info : &#123;name&#125;,&#123;age&#125;'.format(**info) #两个星号一个不能少 # 对齐 print '&#123;:&gt;8&#125;'.format('189') print '&#123;:0&gt;8&#125;'.format('189') # 精度 print '&#123;:.2f&#125;'.format(321.33345) # 转二进制 print '&#123;:b&#125;'.format(17)#outputinfo : ('luckylau', 23)23,luckylautest,123test,123,testluckylau,23This guy is luckylau,23 oldinfo : ['luckylau', 23]info :23,luckylauinfo : ['luckylau', 23]info :23,luckylauinfo : &#123;'age': 23, 'name': 'luckylau'&#125; info : &#123;'age': 23, 'name': 'luckylau'&#125;info : luckylau,23 18900000189321.3310001]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(4)]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BD%A0%E6%87%82python%E5%90%97-4%2F</url>
      <content type="text"><![CDATA[Python 的类的下划线命名_xxx 单下划线开头的变量，标明是一个受保护(protected)的变量，原则上不允许直接访问，但外部类还是可以访问到这个变量，这只是程序员之间的一个约定，用于警告说明这是一个私有变量，外部类不要去访问它。 1234567891011121314class Person(object): def __init__(self, name): self._name = nameclass Student(Person): def __init__(self, age): super(Student,self).__init__("luckylau") self._age = ageif __name__ == '__main__': stu = Student(20) print stu._age print stu._name # 约定不能出现这样的代码来访问name属性,但实际是可以访问的。#output20luckylau __xxx 双下划线开头的，表示的是私有类型(private)的变量。只能是允许这个类本身进行访问了, 连子类也不可以,用于命名一个类属性（类变量），调用时名字被改变，双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。 12345678910111213141516class Person(object): def __init__(self, name): self.__name = nameclass Student(Person): def __init__(self, age): super(Student,self).__init__("luckylau") self._age = ageif __name__ == '__main__': stu = Student(20) print stu.__name #AttributeError: 'Student' object has no attribute '__name' 子类不能访问 print stu._Person__name #这样可以访问 person=Person("luckylau") #AttributeError: 'Person' object has no attribute '__name' 实例不能访问 print person.__name #AttributeError: 'Person' object has no attribute '__name' 实例不能访问 print person._Person__name #这样可以访问 print person.__dict__ #&#123;'_Person__name': 'luckylau'&#125; xxx 以双下划线开头，并且以双下划线结尾的，是内置变量，内置变量是可以直接访问的，不是 private 变量，所以，不要自己定义这类变量。 123456__init____file____dirt__...]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(3)]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BD%A0%E6%87%82python%E5%90%97-3%2F</url>
      <content type="text"><![CDATA[@staticmethod和@classmethod的区别什么是python的修饰符Decorators？​ 装饰器模式可以在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责，也能够处理那些可以撤销的职责。经常用于日志记录、性能测试等场合。 ​ 想象一下这个很常见的场景，你写了一个方法： 1234567891011121314151617181920def A(n): if n &gt; 2: print n print "aaaaaa" else: print A.__name__def B(n): if n &gt;2: print n print "bbbbbb" else: print B.__name__if __name__ == '__main__': A(3) B(3)#ouptput3aaaaaa3bbbbbb 用修饰符优美的表达式 12345678910111213141516171819202122def decorator(fn): def inner(n): if n&gt;2: print n else: print fn.__name__ return inner@decoratordef A(n): print "aaaaaa"@decoratordef B(n): print "bbbbbb"if __name__ == '__main__': A(3) B(3)# output3aaaaaa3bbbbbb 当有多个修饰符时候，由远及近影响，如下： 123456789101112131415def tag_wrap(tag): def decorator(fn): def inner(s): return '&lt;%s&gt;%s&lt;%s&gt;' % (tag, fn(s), tag) return inner return decorator@tag_wrap('a')@tag_wrap('b')@tag_wrap('c')def greet(name): return 'Hello, %s!' % nameif __name__ == '__main__': print(greet('world'))#output&lt;a&gt;&lt;b&gt;&lt;c&gt;Hello, world!&lt;c&gt;&lt;b&gt;&lt;a&gt; 我们再举一个日志的例子 12345678910111213141516171819202122232425262728293031323334def log_calls(fn): def inner(*args, **kwargs): out = apply(fn, args, kwargs) with open('logfile.log', 'a') as logfile: logfile.write('%s called with args %s and kwargs %s, returning %s\n' % (fn.__name__, args, kwargs, out)) return out return inner@log_callsdef fizz_buzz_or_number(i): if i % 15 == 0: return 'fizzbuzz' elif i % 3 == 0: return 'fizz' elif i % 5 == 0: return 'buzz' else: return iif __name__ == '__main__': for i in range(1, 31): print(fizz_buzz_or_number(i))#outputfizz_buzz_or_number called with args (1,) and kwargs &#123;&#125;, returning 1fizz_buzz_or_number called with args (2,) and kwargs &#123;&#125;, returning 2fizz_buzz_or_number called with args (3,) and kwargs &#123;&#125;, returning fizzfizz_buzz_or_number called with args (4,) and kwargs &#123;&#125;, returning 4fizz_buzz_or_number called with args (5,) and kwargs &#123;&#125;, returning buzzfizz_buzz_or_number called with args (6,) and kwargs &#123;&#125;, returning fizzfizz_buzz_or_number called with args (7,) and kwargs &#123;&#125;, returning 7... @staticmethod和@classmethodPython其实有3个方法,即静态方法(staticmethod),类方法(classmethod)和实例方法 @staticmethod和@classmethod本身也是装饰器的一种特例。先看下面的例子： 12345678910111213141516171819202122232425262728293031def foo(x): print "executing foo(%s)"%(x)class A(object): def foo(self,x): print "executing foo(%s,%s)"%(self,x) @classmethod def class_foo(cls,x): #不需要self参数，但第一个参数需要是表示自身类的cls参数 print "executing class_foo(%s,%s)"%(cls,x) @staticmethod def static_foo(x): #不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样 print "executing static_foo(%s)"%xif __name__ == '__main__': a=A() a.class_foo(3) a.foo(3) a.static_foo(3) A.class_foo(3) A.static_foo(3) A.foo(3) #outputexecuting class_foo(&lt;class '__main__.A'&gt;,3)executing foo(&lt;__main__.A object at 0x7f79857c9350&gt;,3)executing static_foo(3)executing class_foo(&lt;class '__main__.A'&gt;,3)executing static_foo(3)A.foo(3)TypeError: unbound method foo() must be called with A instance as first argument (got int instance instead) \ 实例方法 类方法 静态方法 a = A() a.foo(x) a.class_foo(x) a.static_foo(x) A 不可用 A.class_foo(x) A.static_foo(x 参考：http://pythoncentral.io/difference-between-staticmethod-and-classmethod-in-python/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[云计算中的IAAS，PASS，SAAS的区别]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84IAAS%EF%BC%8CSAAS-PASS%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[什么是云计算？​ “云”其实是互联网的一个隐喻，“云计算”其实就是使用互联网来接入存储或者运行在远程服务器端的应用，数据，或者服务。任何一个使用基于互联网的方法来计算，存储和开发的公司，都可以从技术上叫做从事云的公司。 IAAS,SAAS,PASS的通俗解释？ IAAS,SAAS,PASS的概念？Iaas（基础设施即服务Infrastructure as a Service） ​ IaaS就是专门提供基础设施服务，IaaS公司会提供场外服务器，存储和网络硬件，你可以租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。一些大的IaaS公司包括Amazon, Microsoft, VMWare, Rackspace和Red Hat.不过这些公司又都有自己的专长，比如Amazon和微软给你提供的不只是IaaS，他们还会将其计算能力出租给你来host你的网站。 Paas（平台即服务Platform-as-a-Service） ​ 第二层就是所谓的PaaS，某些时候也叫做中间件。你公司所有的开发都可以在这一层进行，节省了时间和资源。PaaS公司在网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统。这节省了你在硬件上的费用，也让分散的工作室之间的合作变得更加容易。网页应用管理，应用设计，应用虚拟主机，存储，安全以及应用开发协作工具等。一些大的PaaS提供者有Google App Engine,Microsoft Azure，Force.com,Heroku，Engine Yard。最近兴起的公司有AppFog,Mendix和Standing Cloud. Saas（软件即服务Software-as-a-Service） ​ 第三层也就是所谓SaaS。这一层是和你的生活每天接触的一层，大多是通过网页浏览器来接入。任何一个远程服务器上的应用都可以通过网络来运行，就是SaaS了。你消费的服务完全是从网页如Netflix,MOG,Google Apps,Box.net,Dropbox或者苹果的iCloud那里进入这些分类。尽管这些网页服务是用作商务和娱乐或者两者都有，但这也算是云技术的一部分。一些用作商务的SaaS应用包括Citrix的Go To Meeting，Cisco的WebEx，Salesforce的CRM，ADP，Workday和SuccessFactors。 参考:https://www.zhihu.com/question/21641778]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂java吗(1)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82java%E5%90%97-1%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(2)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82python%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[深刻理解Python中的元类(metaclass)问题 ：什么是metaclass？在哪些情况会使用？ 类也是对象​ 在理解元类之前，你需要先掌握Python中的类。Python中类的概念借鉴于Smalltalk，这显得有些奇特。在大多数编程语言中，类就是一组用来描述如何生成一个对象的代码段。在Python中这一点仍然成立： 1234567class ObjectCreator(object): passif __name__ == '__main__': my_object=ObjectCreator() print my_object#output&lt;__main__.ObjectCreator object at 0x7f8fd686d450&gt; ​ 但是，Python中的类还远不止如此。类同样也是一种对象。是的，没错，就是对象。只要你使用关键字class，Python解释器在执行的时候就会创建一个对象。将在内存中创建一个对象，名字就是ObjectCreator。这个对象（类）自身拥有创建对象（类实例）的能力，而这就是为什么它是一个类的原因。但是，它的本质仍然是一个对象，于是乎你可以对它做如下的操作： 1) 你可以将它赋值给一个变量 2) 你可以拷贝它 3) 你可以为它增加属性 4) 你可以将它作为函数参数进行传递 下面的代码段： 1234567891011121314151617181920class ObjectCreator(object): passdef echo(o): print oif __name__ == '__main__': echo(ObjectCreator) #作为函数参数进行传递 echo(ObjectCreator()) print hasattr(ObjectCreator, 'new_attribute') ObjectCreator.new_attribute = 'foo' #增加属性 print hasattr(ObjectCreator, 'new_attribute') print ObjectCreator.new_attribute ObjectCreatorMirror = ObjectCreator #赋值给一个变量 print ObjectCreatorMirror()#output&lt;class '__main__.ObjectCreator'&gt;&lt;__main__.ObjectCreator object at 0x7f94fa648450&gt;FalseTruefoo&lt;__main__.ObjectCreator object at 0x7f94fa558e10&gt; 动态地创建类​ 因为类也是对象，你可以在运行时动态的创建它们，就像其他任何对象一样。首先，你可以在函数中创建类，使用class关键字即可。 1234567891011121314151617def choose_class(name): if name == 'foo': class Foo(object): pass return Foo # 返回的是类，不是类的实例 else: class Bar(object): pass return Barif __name__ == '__main__': MyClass = choose_class('foo') print MyClass # 函数返回的是类，不是类的实例 print MyClass() # 你可以通过这个类创建类实例，也就是对象#output&lt;class '__main__.Foo'&gt;&lt;__main__.Foo object at 0x7f401385a450&gt; ​ 但这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是通过什么东西来生成的才对。当你使用class关键字时，Python解释器自动创建这个对象。但就和Python中的大多数事情一样，Python仍然提供给你手动处理的方法。还记得内建函数type吗？这个古老但强大的函数能够让你知道一个对象的类型是什么，就像这样： 12345678910111213class ObjectCreator(object): passif __name__ == '__main__': print type(1) print type("1") print type(ObjectCreator) print type(ObjectCreator()) # output&lt;type 'int'&gt;&lt;type 'str'&gt;&lt;type 'type'&gt;&lt;class '__main__.ObjectCreator'&gt; 这里，type有一种完全不同的能力，它也能动态的创建类。type可以接受一个类的描述作为参数，然后返回一个类。（我知道，根据传入参数的不同，同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后兼容性） type可以像这样工作： 1type(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）) 可以手动像这样创建： 1234567891011if __name__ == '__main__': MyShinyClass = type('MyShinyClass', (), &#123;&#125;) # 返回一个类对象 等价于 # class MyShinyClass(object): # pass # print MyShinyClass print MyShinyClass() # 创建一个该类的实例#output&lt;class '__main__.MyShinyClass'&gt;&lt;__main__.MyShinyClass object at 0x7fc8bb86a450&gt; ​ 你会发现我们使用“MyShinyClass”作为类名，并且也可以把它当做一个变量来作为类的引用。类和变量是不同的，这里没有任何理由把事情弄的复杂。 1234567891011121314if __name__ == '__main__': foo = type('Foo', (), &#123;'bar': False&#125;) #等价于class Foo(object): # bar = False print foo print foo.bar f = foo() #将foo当成一个普通的类一样使用 print f print f.bar #output &lt;class '__main__.Foo'&gt; False &lt;__main__.Foo object at 0x7f9868844450&gt; False type 接受一个字典来为类定义属性，并且可以将foo当成一个普通的类一样使用 12345678910if __name__ == '__main__': foo = type('Foo', (), &#123;'bar': False&#125;) class foochild(foo): pass FooChild = type('foochild', (foo,), &#123;&#125;) print FooChild print FooChild.bar # bar属性是由foo继承而来#output &lt;class '__main__.foochild'&gt; False 你可以看到，在Python中，类也是对象，你可以动态的创建类。这就是当你使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的。 到底什么是元类​ 元类就是用来创建类的“东西”。你创建类就是为了创建类的实例对象，不是吗？但是我们已经学习到了Python中的类也是对象。好吧，元类就是用来创建这些类（对象）的，元类就是类的类。 你已经看到了type可以让你像这样做： 1MyClass = type('MyClass', (), &#123;&#125;) ​ 这是因为函数type实际上是一个元类。type就是Python在背后用来创建所有类的元类。现在你想知道那为什么type会全部采用小写形式而不是Type呢？好吧，我猜这是为了和str保持一致性，str是用来创建字符串对象的类，而int是用来创建整数对象的类。type就是创建类对象的类。你可以通过检查class属性来看到这一点。Python中所有的东西，注意，我是指所有的东西——都是对象。这包括整数、字符串、函数以及类。它们全部都是对象，而且它们都是从一个类创建而来。 1234567891011121314151617181920212223242526def foo(): passclass Bar(object): passif __name__ == '__main__': age=35 name="lucky" b = Bar() print age.__class__ print name.__class__ print foo.__class__ print b.__class__ print Bar.__class__ print age.__class__.__class__ print name.__class__.__class__ print b.__class__.__class__# output&lt;type 'int'&gt;&lt;type 'str'&gt;&lt;type 'function'&gt;&lt;class '__main__.Bar'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt; 因此，元类就是创建类这种对象的东西。如果你喜欢的话，可以把元类称为“类工厂”（不要和工厂类搞混了:D） type就是Python的内建元类，当然了，你也可以创建自己的元类。 创建自己的元类首先了解metaclass**属性** 12class Foo(object): __metaclass__ = something 你可以在写一个类的时候为其添加metaclass属性,如果你这么做了，Python就会用元类来创建类Foo。小心点，这里面有些技巧。你首先写下class Foo(object)，但是类对象Foo还没有在内存中创建。Python会在类的定义中寻找metaclass属性，如果找到了，Python就会用它来创建类Foo，如果没有找到，就会用内建的type来创建这个类。把下面这段话反复读几次。当你写如下代码时 : 12class Foo(Bar): pass Python做了如下的操作： Foo中有metaclass这个属性吗？如果是，Python会在内存中通过metaclass创建一个名字为Foo的类对象（我说的是类对象，请紧跟我的思路）。如果Python没有找到metaclass，它会继续在Bar（父类）中寻找metaclass属性，并尝试做和前面同样的操作。如果Python在任何父类中都找不到metaclass，它就会在模块层次中去寻找metaclass，并尝试做同样的操作。如果还是找不到metaclass,Python就会用内置的type来创建这个类对象。 现在的问题就是，你可以在metaclass中放置些什么代码呢？答案就是：可以创建一个类的东西。那么什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东东都可以。 ​ 元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。假想一个很傻的例子，你决定在你的模块里所有的类的属性都应该是大写形式。有好几种方法可以办到，但其中一种就是通过在模块级别设定metaclass。采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改成大写形式就万事大吉了。 ​ 幸运的是，metaclass实际上可以被任意调用，它并不需要是一个正式的类（我知道，某些名字里带有‘class’的东西并不需要是一个class，画画图理解下，这很有帮助）。所以，我们这里就先以一个简单的函数作为例子开始。 123456789101112131415161718192021222324252627282930313233343536373839404142import six# 元类会自动将你通常传给‘type’的参数作为自己的参数传入def upper_attr(future_class_name, future_class_parents, future_class_attr): ''' 返回一个类对象，将属性都转为大写形式 :param future_class_name: :param future_class_parents: :param future_class_attr: :return: ''' # 选择所有不以'__'开头的属性 attrs = ((name, value)for name, value in future_class_attr.items() if not name.startswith('__')) # 将它们转为大写形式 uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 通过'type'来做类对象的创建 return type(future_class_name, future_class_parents, uppercase_attr)#__metaclass__ = upper_attr #这会作用到这个模块中的所有类class Foo(object): # 我们也可以只在这里定义__metaclass__，这样就只会作用于这个类中 __metaclass__ = upper_attr bar = 'bar'@six.add_metaclass(upper_attr) #还可以这么设置metaclassclass Doo(object): doo = "doo" if __name__ == '__main__': print hasattr(Foo, 'bar') print hasattr(Foo, 'BAR') if hasattr(Foo, 'BAR'): f = Foo() print f.BAR print hasattr(Doo, 'DOO')#outputFalseTruebarTrue 现在让我们再做一次，这一次用一个真正的class来当做元类: 1234567891011121314# 请记住，'type'实际上是一个类，就像'str'和'int'一样# 所以，你可以从type继承class UpperAttrMetaClass(type): # __new__ 是在__init__之前被调用的特殊方法 # __new__是用来创建对象并返回之的方法 # 而__init__只是用来将传入的参数初始化给对象 # 你很少用到__new__，除非你希望能够控制对象的创建 # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情 # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用 def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type(future_class_name, future_class_parents, uppercase_attr) 但是，这种方式其实不是OOP。我们直接调用了type，而且我们没有改写父类的new方法。现在让我们这样去处理: 12345678class UpperAttrMetaclass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 复用type.__new__方法 # 这就是基本的OOP编程，没什么魔法 return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr) 你可能已经注意到了有个额外的参数upperattr_metaclass，这并没有什么特别的。类方法的第一个参数总是表示当前的实例，就像在普通的类方法中的self参数一样。当然了，为了清晰起见，这里的名字我起的比较长。但是就像self一样，所有的参数都有它们的传统名称。因此，在真实的产品代码中一个元类应该是像这样的： 12345class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__') uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type.__new__(cls, name, bases, uppercase_attr) 如果使用super方法的话，我们还可以使它变得更清晰一些，这会缓解继承（是的，你可以拥有元类，从元类继承，从type继承） 123456789101112131415class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return super(UpperAttrMetaclass, cls).__new__(cls, name, bases, uppercase_attr)class doo(): __metaclass__ = UpperAttrMetaclass doo="doo"if __name__ == '__main__': foo=UpperAttrMetaclass("Foo",(),&#123;'bar' :"foo"&#125;) print hasattr(foo, 'bar') print hasattr(doo, 'DOO')#outputFalseTrue 就是这样，除此之外，关于元类真的没有别的可说的了。使用到元类的代码比较复杂，这背后的原因倒并不是因为元类本身，而是因为你通常会使用元类去做一些晦涩的事情，依赖于自省，控制继承等等。确实，用元类来搞些“黑暗魔法”是特别有用的，因而会搞出些复杂的东西来。但就元类本身而言，它们其实是很简单的： 1) 拦截类的创建 2) 修改类 3) 返回修改之后的类 为什么要用metaclass类而不是函数?由于metaclass可以接受任何可调用的对象，那为何还要使用类呢，因为很显然使用类会更加复杂啊？这里有好几个原因： 1） 意图会更加清晰。当你读到UpperAttrMetaclass(type)时，你知道接下来要发生什么。 2） 你可以使用OOP编程。元类可以从元类中继承而来，改写父类的方法。元类甚至还可以使用元类。 3） 你可以把代码组织的更好。当你使用元类的时候肯定不会是像我上面举的这种简单场景，通常都是针对比较复杂的问题。将多个方法归总到一个类中会很有帮助，也会使得代码更容易阅读。 4） 你可以使用new, init以及call这样的特殊方法。它们能帮你处理不同的任务。就算通常你可以把所有的东西都在new里处理掉，有些人还是觉得用init更舒服些。 5） 哇哦，这东西的名字是metaclass，肯定非善类，我要小心！ 现在回到我们的大主题上来，究竟是为什么你会去使用这样一种容易出错且晦涩的特性？好吧，一般来说，你根本就用不上它： 12Metaclasses are deeper magic that 99% of users should never worry about. If you wonder whether you need them, you don&apos;t (the people who actually need them know with certainty that they need them, and don&apos;t need an explanation about why).Python Guru Tim Peters “元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类。” —— Python界的领袖 Tim Peters 元类的主要用途是创建API。一个典型的例子是Django ORM。它允许你像这样定义： 123class Person(models.Model): name = models.CharField(max_length=30) age = models.IntegerField() 但是如果你像这样做的话： 12guy = Person(name='bob', age='35')print guy.age 这并不会返回一个IntegerField对象，而是会返回一个int，甚至可以直接从数据库中取出数据。这是有可能的，因为models.Model定义了metaclass， 并且使用了一些魔法能够将你刚刚定义的简单的Person类转变成对数据库的一个复杂hook。Django框架将这些看起来很复杂的东西通过暴露出一个简单的使用元类的API将其化简，通过这个API重新创建代码，在背后完成真正的工作。 结语：首先，你知道了类其实是能够创建出类实例的对象。好吧，事实上，类本身也是实例，当然，它们是元类的实例。Python中的一切都是对象，它们要么是类的实例，要么是元类的实例，除了type。type实际上是它自己的元类，在纯Python环境中这可不是你能够做到的，这是通过在实现层面耍一些小手段做到的。其次，元类是很复杂的。对于非常简单的类，你可能不希望通过使用元类来对类做修改。你可以通过其他两种技术来修改类： 1） Monkey patching 2) class decorators 当你需要动态修改类时，99%的时间里你最好使用上面这两种技术。当然了，其实在99%的时间里你根本就不需要动态修改类 :D 参考：http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python http://blog.jobbole.com/21351/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(1)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82python%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[Python的函数参数传递示例一： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c=2 print "test after" print id(c) return cif __name__ == '__main__': a=1 print "main before" print id(a) test(a) print "main after" print id(a) print a# outputmain before12460376test before12460376test after12460352main after124603761 示例二： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c.append(1) print "test after" print id(c) return cif __name__ == '__main__': a=[] print "main before" print id(a) test(a) print "main after" print id(a) print a #output main before139625132046312test before139625132046312test after139625132046312main after139625132046312[1] 示例三： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c=[2,3] print "test after" print id(c) return cif __name__ == '__main__': a=[1] print "main before" print id(a) test(a) print "main after" print id(a) print a# outputmain before139900695660520test before139900695660520test after139900695661672main after139900695660520[1] 总结： ​ 对象有两种,“可更改”（mutable）与“不可更改”（immutable）对象。在python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。对于不可更改对象而言一定是“值传递”引用，如示例一；对于可更改对象也可以“值传递”，如示例三；对于示例二，传入的是可变对象，并且函数对其进行操作，属于“引用传递”。 函数参数的定义有四种形式： F(arg1,arg2,…) F(arg2=,arg3=…) F(*arg1) F(**arg1) 12345678910111213141516171819202122232425262728293031323334def test(x,y=5,*a,**b): print x,y,a,bif __name__ == '__main__': test(1) test(1, 2) test(1, 2, 3) test(1, 2, 3, 4) test(1, 2, (3, 4),5) test(1, 2, 3, 4, 5,a=2) test(x=1) test(x=1,y=2) test(x=1,y=2,a=3) test(x=1,y=2,a=3,b=4) test(x=1, y=2, a=3, b=4,c=5) test(1, 2, z=1) test(1, 2, 3, a=1) test(1, 2, 3, 4, a=1) test(1, 2, 3, 4, a=1, b=2, c=3) #output 1 5 () &#123;&#125; 1 2 () &#123;&#125; 1 2 (3,) &#123;&#125; 1 2 (3, 4) &#123;&#125; 1 2 ((3, 4), 5) &#123;&#125; 1 2 (3, 4, 5) &#123;'a': 2&#125; 1 5 () &#123;&#125; 1 2 () &#123;&#125; 1 2 () &#123;'a': 3&#125; 1 2 () &#123;'a': 3, 'b': 4&#125; 1 2 () &#123;'a': 3, 'c': 5, 'b': 4&#125; 1 2 () &#123;'z': 1&#125; 1 2 (3,) &#123;'a': 1&#125; 1 2 (3, 4) &#123;'a': 1&#125; 1 2 (3, 4) &#123;'a': 1, 'c': 3, 'b': 2&#125; 首先按顺序把“arg”这种形式的实参给对应的形参； 第二，把“arg=”这种形式的实参赋值给形参； 第三，把多出来的“arg”这种形式的实参组成一个tuple给带一个星号的形参； 第四，把多出来的“key=value”这种形式的实参转为一个dictionary给带两个星号的形参。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LoadBalancerv2的原理分析]]></title>
      <url>%2F2017%2F03%2F10%2FLoadBalancerv2%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[​ OpenStack 是直接采用各种开源可用的负载均衡项目来完成负载均衡的任务，默认使用 HAProxy。LBaaSv2 本质来说，其实也是根据用户提出的负载均衡要求，生成符合的HAProxy配置文件并启动 HAProxy，然后由 HAProxy 进行负载均衡。 High Availability Proxy（HAProxy）？​ HAProxy 是个著名的开源的软件 TCP（四层）/HTTP（七层） 负载均衡器和代理（proxy）软件，可以运行在 Linux，Solaris 和 FreeBSD 等系统上。目前，它已经被许多大公司采用，包括GitHub, Imgur, Instagram, and Twitter 等。它类似 Nginx 的，采用了单进程和事件驱动模型；它使用的内存量低而且稳定，能够处理大量并发请求。 在这里我简单罗列HAProxy配置。 haproxy 配置中分成五部分内容，分别如下：​ global：参数是进程级的，通常是和操作系统相关。这些参数一般只设置一次，如果配置无误，就不需要再次进行修改。​ defaults：配置默认参数，这些参数可以被用到frontend，backend，Listen组件。​ frontend：接收请求的前端虚拟节点，Frontend可以更加规则直接指定具体使用后端的backend。​ backend：后端服务集群的配置，是真实服务器，一个Backend对应一个或者多个实体服务器。​ Listen Fronted和backend的组合体。 neutron的LoadBalancerv2配置文件在 /etc/haproxy/haproxy.cfg中 12345678910111213141516171819202122232425262728293031323334353637###########全局配置######### global log /dev/log local0 #[日志输出配置，所有日志都记录在本机，通过local0输出] log /dev/log local1 notice #定义haproxy 日志级别[error warringinfo debug] chroot /var/lib/haproxy stats socket /run/haproxy/admin.sock mode 660 level admin stats timeout 30s user haproxy group haproxy #可以由配置项 user_group 指定，默认为 nogroup daemon #以后台形式运行harpoxy # Default SSL material locations ca-base /etc/ssl/certs crt-base /etc/ssl/private # Default ciphers to use on SSL-enabled listening sockets. # For more information, see ciphers(1SSL). This list is from: # https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS ssl-default-bind-options no-sslv3 ########默认配置############ defaults log global mode http option httplog option dontlognull timeout connect 5000 timeout client 50000 timeout server 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.http 我们事先创建了qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2，我们看看它的配置文件 12root@netagent:~# ip netns listqlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 该负载均衡是1个LoadBalance对应1个listener,1个pool。 在/var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy.conf 中 12345678910111213141516171819202122232425262728293031323334# Configuration for loadbalance1global daemon user nobody group haproxy log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy_stats.sock mode 0666 level userdefaults log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 62ac018e-f6fc-4d60-80df-13b1e4cdc6f6 option tcplog maxconn 100 option forwardfor bind 2.2.2.20:80 mode http default_backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 mode http balance roundrobin timeout check 1 option httpchk GET /index.html http-check expect rstatus 201|200|202 server d56fc582-33cd-4fc7-b95f-16534c8a4860 2.2.2.5:80 weight 1 check inter 1s fall 5 server cc2230bf-f3b8-4beb-8584-71b0f3a0ba5c 2.2.2.4:80 weight 1 check inter 1s fall 5 server b490cadb-cff1-4e7a-92c7-a134c0f8b321 2.2.2.6:80 weight 1 check inter 1s fall 5 LBaasv2 可以看做 OpenStack Neutron 对各种物理负载均衡器的虚拟化。它的概念可以和 HAProxy 中的概念进行类比： HAProxy 的概念 LBaasv2 的概念 说明 Driver LBaas v2也是采取 driver 模型来支持多种物理的负载均衡器。LBaasv2 默认实现了 HAProxy driver，同时，它也支持多个其他 Vendor driver。 Frontend Listener LBaasv2采用Listener方式将流量转移到不同的pool中的member。 Backend Pool 代表Listener所监听的负载后端的虚拟机池。 Backend server Member Member 对应的是 pool 里面处理网络请求的一个 OpenStack Nova 虚机 Health check Health monitor 它用来监测 pool 里面 member 的状态，支持 HTTP, TCP, 和 ping 等多种检测方法。在 Nuetron 中这是可选的，如果没有 Health monitor，pool 会一直认为所有的 member 都是 ACTIVE 状态，这样所有的 member 会一直出现在 VIP 的分发列表中，哪怕 member 对应的实例不能响应网络请求。这在实际应用中会造成负载均衡的响应异常。 LoadBalancerv2的使用场景？ ​ 由上图可知道，一个LoadBalancerv2可以对应多个Pool,我们另外又建立一个pool如下所示： 在/var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy.conf 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# Configuration for loadbalance1global daemon user nobody group haproxy #可以由配置项 user_group 指定，默认为 nogroup log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy_stats.sock mode 0666 level user defaults #不用管 log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 62ac018e-f6fc-4d60-80df-13b1e4cdc6f6 option tcplog maxconn 100 option forwardfor # 当 mode 为 ”http“时，设置 forwardfor，使得通过 X-Forward-For 头来保存原始的源 IP 地址 bind 2.2.2.20:80 #监听Listener的vip:port mode http #监听Protocol default_backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 #对应的监听池frontend bf144f31-cdbb-4426-b90b-4bdbc67501f1 option tcplog maxconn 100 option forwardfor bind 2.2.2.20:100 mode http default_backend 8b50ed30-5290-421c-9d31-fb3751a26be2backend 8b50ed30-5290-421c-9d31-fb3751a26be2 mode http balance roundrobin server bef852d0-9164-46ee-ace5-92462e8d89ef 2.2.2.14:100 weight 1 server 8aeb5cc2-7301-4931-ac3b-e0d0ca891e88 2.2.2.15:100 weight 1 server 250a919f-dfc1-41b6-8378-2b4015f1acd0 2.2.2.16:100 weight 1backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 mode http balance roundrobin timeout check 1 option httpchk GET /index.html http-check expect rstatus 201|200|202 server cc2230bf-f3b8-4beb-8584-71b0f3a0ba5c 2.2.2.4:80 weight 1 check inter 1s fall 5 #member1 的配置，包括 ip，port（member 提供服务的端口，此时没有指定check port，因此也是健康检查的 TCP端口），weight；check 指定做健康检查；inter 指定两次连续检查之间的间隔，默认2s (1s）；fall 指定 Max Retries 或者连续几次检查失败即认为member 是 DOWN 的次数 （5） server d56fc582-33cd-4fc7-b95f-16534c8a4860 2.2.2.5:80 weight 1 check inter 1s fall 5 server b490cadb-cff1-4e7a-92c7-a134c0f8b321 2.2.2.6:80 weight 1 check inter 1s fall 5 访问wget -O - http://2.2.2.2:80 和wget -O - http://2.2.2.2:100都成功。 以上是vip与pool的members同在一个subnet下，下面我们验证一下vip与pool的members不在同一个subnet。 我们创建一个新的Loadbalance和一个listener,vip地址为7.7.7.7,然后创建一个pool,注意一个虚拟机可以加入多个pool,所以我们还把上面的虚拟机加入这个新建的pool中。然后通过路由器subnet7.7.7.0/24和subnet2.2.2.0/24连通。也就是说vip7.7.7.7能与member2.2.2.4,2.2.2.5,2.2.2.6是联通的。 配置如下/var/lib/neutron/lbaas/v2/5081116f-8928-40d7-8aaa-e30c336ca713/haproxy.conf 12345678910111213141516171819202122232425262728293031# Configuration for loadbalance3global daemon user nobody group haproxy log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/5081116f-8928-40d7-8aaa-e30c336ca713/haproxy_stats.sock mode 0666 level userdefaults log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 84800dd3-0507-4628-b54b-a23226bec4f8 option tcplog maxconn 100 option forwardfor bind 7.7.7.7:80 mode http default_backend 3583deda-e9ca-40bb-ba23-0fec204c099fbackend 3583deda-e9ca-40bb-ba23-0fec204c099f mode http balance roundrobin server 48b36860-8e4d-476e-9196-ad052c317f44 2.2.2.5:80 weight 1 server f8732b2a-bfaa-4e5f-b8bb-f88c9fed899b 2.2.2.4:80 weight 1 server 004f7950-4031-4de3-98b2-ca30e39c4e4e 2.2.2.6:80 weight 1 也就是说只要vip与member可通信即可，不一定要在同一个subnet中。 另外，如果要从外网访问的话，则还需要创建一个 floating ip 并且把它关联到 lb 的vip 上。 haproxy 所在的namespace 其实只有一个IP地址，分别接收外部连接以及和成员之间的连接。 LoadBalancerv2的多agent模式？​ LoadBalancerv2服务可以独立部署在服务器上，包括2个服务，neutron-openvswitch-agent 和neutron-lbassv2-agent。假设有2个节点都部署了LoadBalancerv2服务，当neutron-server发出创建请求时，会在这两个节点选择一个创建对应得namespace空间。 LoadBalancerv2的流程分析？​ 我们以qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2为例子来分析这个过程。 12345678910111213ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever9: tap83f82fcf-d1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:d1:c8:b1 brd ff:ff:ff:ff:ff:ff inet 2.2.2.20/24 brd 2.2.2.255 scope global tap83f82fcf-d1 #vip的地址 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fed1:c8b1/64 scope link valid_lft forever preferred_lft forever ​ 该接口tap83f82fcf-d1挂在ovs上，并被打上它所在network的vlan_id的: 12345678910111213Bridge br-int fail_mode: secure Port patch-tun Interface patch-tun type: patch options: &#123;peer=patch-int&#125; Port br-int Interface br-int type: internal Port &quot;tap83f82fcf-d1&quot; tag: 1 Interface &quot;tap83f82fcf-d1&quot; type: internal ​ 对于LoadBalancerv2创建过程（在v2中指Create a load balancer和Create listener完成，我们发现当只是完成Create a load balancer时候，并没有出现namespace，当Create listener完成时才会有namespace出现）我们对等如下操作： 12345678910111213141516171819202122232425ovs-vsctl --if-exists del-port tap83f82fcf-d1 --add-port br-int tap83f82fcf-d1 --set Interface tap83f82fcf-d1 type=internal --set Interface tap83f82fcf-d1 external-ids:iface-id=83f82fcf-d141-4774-87a0-ace79196bc88 --set Interface tap83f82fcf-d1 external-ids:iface-status=active --set Interface tap83f82fcf-d1 external-ids:attached-mac=fa:16:3e:d1:c8:b1#iface-id 和 attached-mac可以在数据库中查到ip link set tap83f82fcf-d1 address fa:16:3e:d1:c8:b1ip netns add qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 sysctl -w net.ipv4.conf.all.promote_secondaries=1ip link set tap83f82fcf-d1 netns qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip link set lo upip link set tap83f82fcf-d1 netns qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip link set tap83f82fcf-d1 upip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip addr show tap83f82fcf-d1 permanent scope globalip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip -4 addr add 2.2.2.20/24 brd 255.255.255.0 scope global dev tap83f82fcf-d1ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip route list dev tap83f82fcf-d1 scope linkip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 route add default gw 2.2.2.1ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 arping -U -I tap83f82fcf-d1 -c 3 2.2.2.20 LoadBalancerv2的源码解读？​ LoadBalancerv2的代码结构如下： 1.Create a load balancer 2.Create a listener 3.Create a pool 4.Add member 5.Create a health monitor 参考：http://blog.csdn.net/zhu_tianwei/article/details/41117323]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IO的同步与异步，阻塞与非阻塞]]></title>
      <url>%2F2017%2F03%2F08%2FIO%E7%9A%84%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5%EF%BC%8C%E9%98%BB%E5%A1%9E%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
      <content type="text"><![CDATA[​ 同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？我们以Linux环境下的network IO来讨论。 ​ 对于一个network IO (以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 1 等待数据准备 (Waiting for the data to be ready) 2 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I/O Models ”有以下5种： blocking IO nonblocking IO IO multiplexing signal driven IO asynchronous IO。其中signal driven IO不常见，以下分析4中模型。然后再区分IO的同步与异步，阻塞与非阻塞。 I/O Models1.阻塞式I/O模型 blocking IO 在linux中，默认情况下所有的socket都是blocking ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据；对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。这时在用户进程这边，整个进程挂起，被阻塞。kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。​ 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 2.非阻塞I/O模型 non-blocking IO linux下，可以通过设置socket使其变为non-blocking。 ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据；对于network io来说，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程没有被挂起，可以干些别的，但是需要不断的主动询问kernel数据好了没有，直到准备好，发起一个系统调用。但是在第二个阶段仍然是block的。 3.I/O复用模型 IO multiplexing ​ I/O复用最常见的就是select和epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 ​ 当用户进程调用了select，那么整个进程会被block，不能干别的，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。这个和阻塞式I/O模型 blocking IO的区别在于这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 4.异步I/O模型 Asynchronous I/O ​ 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 四者的区别：blocking vs non-blocking：调用blocking IO会一直block住对应的进程直到操作完成，准备阶段和拷贝阶段都被blocking，而non-blocking IO在kernel还准备数据的情况下会立刻返回，只是在拷贝阶段blocking。 synchronous IO和asynchronous IO： 首先看定义：（简单来说：同步I/O：导致请求进程阻塞，直到I/O操作完成；异步I/O: 不导致请求进程阻塞。） A synchronous I/O operation causes the requesting process to be blocked until that I/O operationcompletes; An asynchronous I/O operation does not cause the requesting process to be blocked; blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 ​ 有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 通俗的例子： 3个人排队去买包子，甲买肉馅馒头，乙买素馅馒头，丙买白馒头。 如果是阻塞式I/O模型，按照先后到来顺序处理甲乙丙，甲到来时候，店铺老板说我在做啊，你就在这等着我做完，哪里也不要去，肉馅馒头做好后给甲，甲可以走了，接着处理乙，乙处理完，再处理丙。 如果是非阻塞式I/O模型，假设还是甲乙丙顺序来，甲询问说我要肉馅馒头，老板说还没有做好，这时侯甲就离开搞其他的事情了，乙到了，询问说我要素馅馒头，老板说还没有做好，这时侯乙就离开搞其他的事情了，丙到了，询问说我要白馒头，老板说还没有做好，这时侯丙就离开搞其他的事情了。只不过甲乙丙还会时不时来询问我要的好了没有，假设白馒头非常好做，某个时刻老板做好了，正巧碰到丙又来询问，老板此刻说你的好了，此时丙哪里也不要去了，什么也不要做了，等着老板把白馒头返回给他。此后甲和乙时不时还来询问我要的好了没有。。可见这时候甲乙丙并不需要一直等待，可以做其他事情，同时并不一定是甲先来一定会被先处理。 如果是I/O复用模型，假设还是甲乙丙顺序来，然后甲乙丙会把自己的需求告诉店小二，然后店小二负责去询问老板肉馅馒头，素馅馒头，白馒头做好了没有。如果在I/O复用模型中，socket没有non-blocking时候，甲乙丙不能走，其他事情也不能做，干等着。店小二通知说素馅馒头好了，这时候乙去见老板拿自己所需要的。我们看到这时候并不是按甲乙丙顺序处理的，虽然甲乙丙被店小二阻塞了，但给人感觉是“并发”，哪个先准备好，先处理哪个。 如果是异步I/O模型，假设还是甲乙丙顺序来，店老板立即给甲乙丙返回一个纸条“好的”，甲乙丙各自散去了，该干嘛就干嘛，这时候店老板做馒头，无论是先做好了甲还是乙丙，就通知他们并把相应的馒头交给他们。甲乙丙也不需要时不时的来询问，更不需要去等待啦。 参考：http://blog.csdn.net/historyasamirror/article/details/5778378 https://www.zhihu.com/question/19732473]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Openstack 负载均衡 LoadBalancerv2]]></title>
      <url>%2F2017%2F03%2F07%2FOpenstack%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1LoadBalancerv2%2F</url>
      <content type="text"><![CDATA[​ 最近研究了一下Openstack负载均衡，yum源和源码级别的安装都尝试成功了。网上有很多文章都是LoadBalancerv1，这个已经被放弃了。所以写一下自己是如何使用LoadBalancerv2。当然在介绍之前还是从负载均衡基础知识开始吧。（Mitaka版本的LoadBalancerv2） 负载均衡的概念和分类？​ 负载均衡（Load Balancing）是将来访的网络流量在运行相同应用的多个服务器之间进行分发的一种核心网络服务。它的功能由负载均衡器（load balancer）提供。负载均衡器可以是一个硬件设备，也可以由软件实现。它充当反向代理，在多个服务器之间分发网络或者应用流量。它常用来增加应用的访问容量（并发用户数）和可靠性，它也会通过降低服务器的负载来提高应用的总体性能。 负载均衡器的分类 负载均衡器一般可以分为两类：第4层负载均衡器和第7层负载均衡器。 第 4 层负载平衡器：基于网络和传输层协议（IP，TCP，FTP，UDP等）来均衡负载。 第7层的负载均衡器：基于应用层协议比如 HTTP, SMTP, SNMP, FTP, Telnet 等均衡负载。比如对 HTTP 来说，第七层的负载均衡器能根据应用的特定数据比如 HTTP 头，cookies 或者应用消息中的数据来做进一步的请求分发。 负载分发算法 ​ 两种类型的负载均衡器都能接收请求，然后根据特定的算法将请求分发到特定的服务器。一些行业标准的算法是： ​ 轮询 (Round robin)：轮流分发到各个（活动）服务器​ 加权轮循 (Weighted round robin)：每个服务器有一定的加权（weight），轮询时考虑加权。​ 最少连接 (Least connections)：转发到有最少连接数的服务器​ 最少响应时间 (Least response time)：转发到响应时间最短的服务器 可靠性和可用性 ​ 负载均衡器通过监控应用的健康状态来确保可靠性和可用性，并且只转发请求到能及时做出响应的服务和应用。 Session persistence （会话保持） ​ 用户(浏览器)在和服务端交互的时候，通常会在本地保存一些信息，而整个过程叫做一个会话(Session)并用唯一的Session ID进行标识。会话的概念不仅用于购物车这种常见情况，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制，此外HTTP客户端也会额外缓存一些数据在本地，这样就可以减少请求提高性能了。如果负载均衡可能将这个会话的请求分配到不同的后台服务端上，这肯定是不合适的，必须通过多个backend共享这些数据，效率肯定会很低下，最简单的情况是保证会话一致性——相同的会话每次请求都会被分配到同一个backend上去。 ​ 会话保持表示在一个会话期间，转发一个用户的请求到同一个后端服务器。这对购物车或者付款类的请求非常重要。 常用的方法包括： ​ Source IP：相同来源的请求转发到同一个服务器​ HTTP Cookie：该模式下，loadbalancer 为客户端的第一次连接生成 cookie，后续携带该 cookie 的请求会被某个 member 处理​ APP Cookie：该模式下，依靠后端应用服务器生成的 cookie 决定被某个 member 处理 负载均衡的实现方式？http重定向 ​ 当http代理（比如浏览器）向web服务器请求某个URL后，web服务器可以通过http响应头信息中的Location标记来返回一个新的URL。这意味着HTTP代理需要继续请求这个新的URL，完成自动跳转。 缺陷：1、吞吐率限制​ 主站点服务器的吞吐率平均分配到了被转移的服务器。现假设使用RR（Round Robin）调度策略，子服务器的最大吞吐率为1000reqs/s，那么主服务器的吞吐率要达到3000reqs/s才能完全发挥三台子服务器的作用，那么如果有100台子服务器，那么主服务器的吞吐率可想而知得有大？相反，如果主服务的最大吞吐率为6000reqs/s，那么平均分配到子服务器的吞吐率为2000reqs/s，而现子服务器的最大吞吐率为1000reqs/s，因此就得增加子服务器的数量，增加到6个才能满足。 2、重定向访问深度不同​ 有的重定向一个静态页面，有的重定向相比复杂的动态页面，那么实际服务器的负载差异是不可预料的，而主站服务器却一无所知。因此整站使用重定向方法做负载均衡不太好。 ​ 我们需要权衡转移请求的开销和处理实际请求的开销，前者相对于后者越小，那么重定向的意义就越大，例如下载。你可以去很多镜像下载网站试下，会发现基本下载都使用了Location做了重定向。 DNS负载均衡 ​ DNS负责提供域名解析服务，当访问某个站点时，实际上首先需要通过该站点域名的DNS服务器来获取域名指向的IP地址，在这一过程中，DNS服务器完成了域名到IP地址的映射，同样，这样映射也可以是一对多的，这时候，DNS服务器便充当了负载均衡调度器，它就像http重定向转换策略一样，将用户的请求分散到多台服务器上，但是它的实现机制完全不同。 ​ 相比http重定向，基于DNS的负载均衡完全节省了所谓的主站点，或者说DNS服务器已经充当了主站点的职能。但不同的是，作为调度器，DNS服务器本身的性能几乎不用担心。因为DNS记录可以被用户浏览器或者互联网接入服务商的各级DNS服务器缓存，只有当缓存过期后才会重新向域名的DNS服务器请求解析。也说是DNS不存在http的吞吐率限制，理论上可以无限增加实际服务器的数量。 缺陷：1、没有用户能直接看到DNS解析到了哪一台实际服务器，加服务器运维人员的调试带来了不便。2、策略的局限性。例如你无法将HTTP请求的上下文引入到调度策略中，而在前面介绍的基于HTTP重定向的负载均衡系统中，调度器工作在HTTP层面，它可以充分理解HTTP请求后根据站点的应用逻辑来设计调度策略，比如根据请求不同的URL来进行合理的过滤和转移。3、如果要根据实际服务器的实时负载差异来调整调度策略，这需要DNS服务器在每次解析操作时分析各服务器的健康状态，对于DNS服务器来说，这种自定义开发存在较高的门槛，更何况大多数站点只是使用第三方DNS服务。4、DNS记录缓存，各级节点的DNS服务器不同程序的缓存会让你晕头转向。5、基于以上几点，DNS服务器并不能很好地完成工作量均衡分配，最后，是否选择基于DNS的负载均衡方式完全取决于你的需要。 反向代理负载均衡 ​ 几乎所有主流的Web服务器都热衷于支持基于反向代理的负载均衡。它的核心工作就是转发HTTP请求。相比前面的HTTP重定向和DNS解析，反向代理的调度器扮演的是用户和实际服务器中间人的角色：1、任何对于实际服务器的HTTP请求都必须经过调度器2、调度器必须等待实际服务器的HTTP响应，并将它反馈给用户（前两种方式不需要经过调度反馈，是实际服务器直接发送给用户） 特性：1、调度策略丰富。例如可以为不同的实际服务器设置不同的权重，以达到能者多劳的效果。2、对反向代理服务器的并发处理能力要求高，因为它工作在HTTP层面。3、反向代理服务器进行转发操作本身是需要一定开销的，比如创建线程、与后端服务器建立TCP连接、接收后端服务器返回的处理结果、分析HTTP头部信息、用户空间和内核空间的频繁切换等，虽然这部分时间并不长，但是当后端服务器处理请求的时间非常短时，转发的开销就显得尤为突出。例如请求静态文件，更适合使用前面介绍的基于DNS的负载均衡方式。4、反向代理服务器可以监控后端服务器，比如系统负载、响应时间、是否可用、TCP连接数、流量等，从而根据这些数据调整负载均衡的策略。5、反射代理服务器可以让用户在一次会话周期内的所有请求始终转发到一台特定的后端服务器上（粘滞会话），这样的好处一是保持session的本地访问，二是防止后端服务器的动态内存缓存的资源浪费。 IP层负载均衡LVS-NAT ​ 我们需要在HTTP层面以下实现负载均衡，这些负载均衡调度器的工作必须由Linux内核来完成，因为我们希望网络数据包在从内核缓冲区进入进程用户地址空间之前，尽早地被转发到其他实际服务器上。而且正因为可以将调度器工作在应用层之下，这些负载均衡系统可以支持更多的网络服务协议，比如ftp，smtp，dns，以及流媒体和VoIP等应用。 ​ DNAT： 反向NAT，将实际服务器放置在内部网络，而作为网关的NAT服务器将来自用户端的数据包转发给内部网络的实际服务器(需要修改的是数据包的目标地址和端口)。比较著名的例子是LVS。NAT调度器的吞吐率很高是因为其在内核中进行请求转发的较低开销。 但是NAT服务器的带宽却成为了瓶颈。幸运的是，LVS提供了另一种负载均衡的方式，那就是直接路由。 直接路由LVS-DR ​ 不同于NAT机制，直接路由的负载均衡调度器工作在数据链路层上，简单地说，它通过修改数据包的目标mac地址，将数据包转发到实际服务器上，并且重要的是，实际服务器的响应数据包将直接发送给客户端，不经过调度器。适用于视频网站（响应的数据包远远超过请求的数据包）。对于LVS-DR，一旦调度器失效，你可以马上将LVS-DR切换到DNS-RR模式 常见的开源软件负载均衡器？​ 负载均衡器 目前有2种，一种是通过硬件来进行进行，常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；另外一种就是类似于LVS/HAProxy、Nginx的基于Linux的开源免费的负载均衡软件策略,这些都是通过软件级别来实现，所以费用非常低廉。 Nginx、LVS及HAProxy是目前最常用的开源软件负载均衡器。 LVS LVS：使用集群技术和Linux操作系统实现一个高性能、高可用的服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。 LVS的特点是： 1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的； 2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； 3、工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived； 4、无流量，保证了均衡器IO的性能不会收到大流量的影响； 5、应用范围比较广，可以对所有应用做负载均衡； 6、软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了；其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。 7、如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。 Nginx Nginx的特点是： 1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是许多朋友喜欢它的原因之一； 2、Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在； 3、Nginx安装和配置比较简单，测试起来比较方便； 4、也可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； 5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测； 6、Nginx仅能支持http和Email，这样就在适用范围上面小很多，这个它的弱势； 7、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web架构，大有和以前最流行的LAMP架构分庭抗争之势，在高流量的环境中也有很好的效果。 8、Nginx现在作为Web反向加速缓存越来越成熟了，很多朋友都已在生产环境下投入生产了，而且反映效果不错，速度比传统的Squid服务器更快，有兴趣的朋友可以考虑用其作为反向代理加速器。 HAProxy HAProxy的特点是： 1、HAProxy是支持虚拟主机的，以前有朋友说这个不支持虚拟主机，我这里特此更正一下。 2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作 3、支持url检测后端的服务器出问题的检测会有很好的帮助。 4、它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。 5、HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。 6、HAProxy的算法现在也越来越多了，具体有如下8种： roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的； static-rr，表示根据权重，建议关注； leastconn，表示最少连接者先处理，建议关注； source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注； ri，表示根据请求的URI； rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name； hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求； rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 负载均衡部署模式？基本的负载均衡场景有3种： Two-Arm (or sometimes called In-Line)（双臂）模式One-Arm（单臂）模式Direct Server Response模式 Two-Arm (or sometimes called In-Line)（双臂）模式 双臂模式有 switched mode（“bridge mode” or “transparent mode”） 和routed mode两种，routed mode要优于switched mode，实际生产环境也没有switched mode方式。 ​ 对于routed mode模式来说，As you can agree, the Load-Balancer is also a router between the “Front End” and “Back End” networks. As such, he can simply do destination IP NAT in client request coming to the load-balanced virtual IP and forward the packet to one of the servers in server farm. During this proces, the destination physical server is chosen by the load-balancing algorithm.Return traffic is going back via the Load-Balancer and the source IP is again changed to the virtual load-balanced IP in the response to the Client. One-Arm（单臂）模式 ​ the Load-Balancer is using only one interface and this interface is on the same L2 network with all the servers. ​ The traffic that the client initializes will get to the Load-Balancer that has the virtual load-balanced IP. The load-sharing algorithm will pick a physical server to which the Load-Balancer will forward the traffic with destination IP NATed to the physical IP of the server and forward it out the same interface towards the physical server.BUT the Load-balancer also needs to do source IP nat so that the server reply will go back from the server to the Load-Balancer and not directly back to the Client, who is not expecting a reply directly from physical server IP. From the physical servers perspective, all the traffic is coming from Load-Balancer Direct Server Response (or sometimes called Direct Server Return) ​ As we hopefully all know, switches learn about MAC addresses as they see frames coming on ports with source MACs. Also imagine that we have a router that has to know the MAC address of the Load-Balanced IP on the last L3 hop. With the picture below, you can already spot the “trick” this scenario tries to present here once you notice the disabled ARP on physical servers ​ In this scenario, Load-balancer only sees the incoming part of client-server traffic and all the returning traffic from physical servers is coming directly back to the client IP. The biggest advantages of this solution is that there is no NAT and the Load-Balancer throughput is only used in one way, so less performance impact for the Load-Balancer system. Disabling ARP on a physical server is not a difficult task. ​ Disadvantages however are that you have to manually configure the Load-Balancer with all the server MAC addresses and might be more difficult to troubleshoot with only one way traffic seen by the Load-Balancer on the whole L2 segment. LoadBalancerv2初体验？1.部署 我们假设LoadBalancerv2服务在网络节点启动，以yum源的方式安装。源码是： https://github.com/openstack/neutron-lbaas/tree/stable/mitaka 在控制节点(neutron-server)操作如下: 12345678910111213141516171819202122232425262728293031yum install openstack-neutron-lbaascd /etc/neutron/#1.3编辑neutron.conf文件service_plugins =router, neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2#1.4 编辑lbaas_agent.ini 文件[DEFAULT]interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverovs_use_veth = Truedevice_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver[haproxy]user_group =haproxy#1.5 编辑neutron_lbaas.conf文件service_provider =LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default#然后执行neutron-db-manage --subproject neutron-lbaas upgrade headsystemctl restart neutron-server 在网络节点操作如下： 12345678910111213141516171819202122232425262728293031yum install haproxyyum install openstack-neutron-lbaascd /etc/neutron/#1.4 编辑neutron.conf文件service_plugins =router, neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2#1.5 编辑lbaas_agent.ini 文件[DEFAULT]interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverovs_use_veth = Truedevice_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver[haproxy]user_group =haproxy#1.6 编辑neutron_lbaas.conf文件service_provider =LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default#1.7启动服务systemctl start neutron-lbaasv2-agent.service 另外可以安装前端界面 1.8安装neutron-lbaas-dashboard这个是在openstack_dashboard安装的节点，一般是controller节点 123456789git clone https://git.openstack.org/openstack/neutron-lbaas-dashboardcd neutron-lbaas-dashboardpython setup.py installcp neutron_lbaas_dashboard/enabled/1480project_loadbalancersv2_panel.py /usr/share/openstack-dashboard/openstack_dashboard/local/enabled/systemctl restart httpd.service memcached.service 2.创建负载均衡 Load balancerThe load balancer occupies a neutron network port and has an IP address assigned from a subnet.ListenerLoad balancers can listen for requests on multiple ports. Each one of those ports is specified by a listener.PoolA pool holds a list of members that serve content through the load balancer.MemberMembers are servers that serve traffic behind a load balancer. Each member is specified by the IP address and port that it uses to serve traffic.Health monitorMembers may go offline from time to time and health monitors divert traffic away from members that are not responding properly. Health monitors are associated with pools.由于lbaas dashboard有些问题，所以在后台用命令行创建， dashboard可显示，但不能任何操作 [root@controller ~]# source admin-openrc.sh [root@controller ~]# neutron subnet-list 创建loadbalancer[root@controller ~]# neutron lbaas-loadbalancer-create –name lb1 96f0db98-45fb-48ef-afae-808425fbb2bc添加lbaas-listener[root@controller ~]# neutron lbaas-listener-create –loadbalancer lb1 –protocol HTTP –protocol-port 80 –name listener1创建pool[root@controller ~]# neutron lbaas-pool-create –lb-algorithm ROUND_ROBIN –listener listener1 –protocol HTTP –name pool1添加member[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.4 –protocol-port 80 pool1[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.5 –protocol-port 80 pool1[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.6 –protocol-port 80 pool1添加监控[root@controller ~]# neutron lbaas-healthmonitor-create –delay 3 –type HTTP –max-retries 3 –timeout 3 –pool pool1 [root@controller ~]# neutron lbaas-loadbalancer-show lb1 3.简单验证： 我们对member成员进行模拟http服务，即172.16.1.4,172.16.1.5,172.16.1.6分别运行 172.16.1.4while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver1’ | sudo nc -l -p 80 ; done172.16.1.5while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver2’ | sudo nc -l -p 80 ; done172.16.1.6while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver3’ | sudo nc -l -p 80 ; done 然后创建一个客户端访问负载均衡的vip 172.16.1.9 ,多次执行,如下图wget -O - http:// 172.16.1.9 （第一次）wget -O - http:// 172.16.1.9 （第二次）wget -O - http:// 172.16.1.9 （第三次）wget -O - http:// 172.16.1.9（第四次） 我们发现第一次是server1响应 第二次是server2响应 第三次是server3响应 第四次是server1响应 参考：http://networkgeekstuff.com/networking/basic-load-balancer-scenarios-explained/ https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html http://www.cnblogs.com/sammyliu/p/4656176.html http://blog.csdn.net/u013628152/article/details/51318414]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python yield 使用浅析]]></title>
      <url>%2F2017%2F03%2F06%2FPython-yield-%E4%BD%BF%E7%94%A8%E6%B5%85%E6%9E%90%2F</url>
      <content type="text"><![CDATA[yield的概念？1.简单的斐波那契數列第一版： 12345678def fab(max): n, a, b = 0, 0, 1 while n &lt; max: print b a, b = b, a + b n = n + 1if __name__ == '__main__': fab(5) 缺点：直接在 fab 函数中用 print 打印数字会导致该函数可复用性较差，因为 fab 函数返回 None，其他函数无法获得该函数生成的数列。 2.简单的斐波那契數列第二版： 1234567891011def fab(max): n, a, b = 0, 0, 1 L = [] while n &lt; max: L.append(b) a, b = b, a + b n = n + 1 return Lif __name__ == '__main__': for n in fab(5): print n 缺点：该函数在运行中占用的内存会随着参数 max 的增大而增大，如果要控制内存占用，最好不要用 List。 3.简单的斐波那契數列第三版： 根据range与xrange的思想设计： 123456789101112131415161718class Fab(object): def __init__(self,max): self.max=max self.n,self.a,self.b=0,0,1 def __iter__(self): return self def next(self): if self.n&lt;self.max: r=self.b self.a, self.b = self.b, self.a + self.b self.n=self.n+1 return r raise StopIterationif __name__ == '__main__': for n in Fab(5): print n 缺点：代码远远没有第一版的 fab 函数来得简洁。 如果我们想要保持第一版 fab 函数的简洁性，同时又要获得 iterable 的效果，yield 就派上用场了。 123456789def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': for n in fab(5): print n ​ yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator，调用 fab(5) 不会执行 fab 函数，而是返回一个 iterable 对象！在 for 循环执行时，每次循环都会执行 fab 函数内部的代码，执行到 yield b 时，fab 函数就返回一个迭代值，下次迭代时，代码从 yield b 的下一条语句继续执行，而函数的本地变量看起来和上次中断执行前是完全一样的，于是函数继续执行，直到再次遇到 yield。 12345678910111213def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': f=fab(5) print (f.next()) print (f.next()) print (f.next()) print (f.next()) print (f.next()) 一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。比如在读取文件时候很好使用的。 123456789def read_file(fpath): BLOCK_SIZE = 1024 with open(fpath, 'rb') as f: while True: block = f.read(BLOCK_SIZE) if block: yield block else: return Iterables，Generators，Yield？​ 当你创建了一个列表,你可以一个一个的读取它的每一项,这叫做iteration。所有你可以用在for...in...语句中的都是可迭代的:比如lists,strings,files…因为这些可迭代的对象你可以随意的读取所以非常方便易用,但是你必须把它们的值放到内存里,当它们有很多值时就会消耗太多的内存. 1234if __name__ == '__main__': mylist = [x * x for x in range(3)] for i in mylist: print i ​ 生成器也是迭代器的一种,但是你只能迭代它们一次.原因很简单,因为它们不是全部存在内存里,它们只在要调用的时候在内存里生成。 1234if __name__ == '__main__': mygenerator = (x * x for x in range(3)) for i in mygenerator: print i ​ 生成器和迭代器的区别就是用()代替[],还有你不能用for i in mygenerator第二次调用生成器:首先计算0,然后会在内存里丢掉0去计算1,直到计算完4. 1234567891011121314def createGenerator(): mylist = range(3) for i in mylist: yield i * iif __name__ == '__main__': mygenerator = createGenerator() print(mygenerator) for i in mygenerator: print i#output&lt;generator object createGenerator at 0x7f5930639730&gt;014 ​ 在这里这个例子好像没什么用,不过当你的函数要返回一个非常大的集合并且你希望只读一次的话,那么它就非常的方便了.要理解Yield你必须先理解当你调用函数的时候,函数里的代码并没有运行.函数仅仅返回生成器对象,这就是它最微妙的地方:-)然后呢,每当for语句迭代生成器的时候你的代码才会运转.一旦函数运行并没有碰到yeild语句就认为生成器已经为空了.原因有可能是循环结束或者没有满足if/else之类的. 1234567891011121314151617181920212223242526272829303132class Bank(): # 让我们建个银行,生产许多ATM crisis = False def create_atm(self): while not self.crisis: yield "$100"if __name__ == '__main__': hsbc = Bank() # 当一切就绪了你想要多少ATM就给你多少 corner_street_atm = hsbc.create_atm() print(corner_street_atm.next()) print(corner_street_atm.next()) print([corner_street_atm.next() for cash in range(5)]) hsbc.crisis = True # cao,经济危机来了没有钱了! print(corner_street_atm.next()) wall_street_atm = hsbc.create_atm() # 对于其他ATM,它还是True print(wall_street_atm.next()) hsbc.crisis = False # 麻烦的是,尽管危机过去了,ATM还是空的 print(corner_street_atm.next()) brand_new_atm = hsbc.create_atm() # 只能重新新建一个atm了 for cash in brand_new_atm: print cash#output$100$100['$100', '$100', '$100', '$100', '$100']&lt;type 'exceptions.StopIteration'&gt;&lt;type 'exceptions.StopIteration'&gt;&lt;type 'exceptions.StopIteration'&gt;$100$100... yield的源码分析？在解释生成器之前，需要讲解一下Python虚拟机的调用原理。 1234567891011121314151617181920212223242526272829303132333435typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* code segment */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* points after the last local */ /* Next free slot in f_valuestack. Frame creation sets to f_valuestack. Frame evaluation usually NULLs it, but a frame that yields sets it to the current stack top. */ PyObject **f_stacktop; PyObject *f_trace; /* Trace function */ /* If an exception is raised in this frame, the next there are used to * record the exception info (if any) originally in the thread state. See * comments before set_exc_info() -- it's not obvious. * Invariant: if _type is NULL, then so are _value and _traceback. * Desired invariant: all three are NULL, or all three are non-NULL. That * one isn't currently true, but "should be". */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; PyThreadState *f_tstate; int f_lasti; /* Last instruction if called */ /* Call PyFrame_GetLineNumber() instead of reading this field directly. As of 2.3 f_lineno is only valid when tracing is active (i.e. when f_trace is set). At other times we use PyCode_Addr2Line to calculate the line from the current bytecode index. */ int f_lineno; /* Current line number */ int f_iblock; /* index in f_blockstack */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */&#125; PyFrameObject; 生成器的源码在Objects/genobject.c 12345678910111213141516PyObject *PyGen_New(PyFrameObject *f)&#123; PyGenObject *gen = PyObject_GC_New(PyGenObject, &amp;PyGen_Type); # 创建生成器对象 if (gen == NULL) &#123; Py_DECREF(f); return NULL; &#125; gen-&gt;gi_frame = f; # 赋予代码块 Py_INCREF(f-&gt;f_code); # 引用计数+1 gen-&gt;gi_code = (PyObject *)(f-&gt;f_code); gen-&gt;gi_running = 0; # 0表示为执行，也就是生成器的初始状态 gen-&gt;gi_weakreflist = NULL; _PyObject_GC_TRACK(gen); # GC跟踪 return (PyObject *)gen;&#125; send与next 123456789101112static PyObject *gen_iternext(PyGenObject *gen)&#123; return gen_send_ex(gen, NULL, 0);&#125;static PyObject *gen_send(PyGenObject *gen, PyObject *arg)&#123; return gen_send_ex(gen, arg, 0);&#125; 从上面的代码中可以看到，send和next都是调用的同一函数gen_send_ex，区别在于是否带有参数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static PyObject *gen_send_ex(PyGenObject *gen, PyObject *arg, int exc)&#123; PyThreadState *tstate = PyThreadState_GET(); PyFrameObject *f = gen-&gt;gi_frame; PyObject *result; if (gen-&gt;gi_running) &#123; # 判断生成器是否已经运行 PyErr_SetString(PyExc_ValueError, "generator already executing"); return NULL; &#125; if (f==NULL || f-&gt;f_stacktop == NULL) &#123; # 如果代码块为空或调用栈为空，则抛出StopIteration异常 /* Only set exception if called from send() */ if (arg &amp;&amp; !exc) PyErr_SetNone(PyExc_StopIteration); return NULL; &#125; if (f-&gt;f_lasti == -1) &#123; # f_lasti=1 代表首次执行 if (arg &amp;&amp; arg != Py_None) &#123; # 首次执行不允许带有参数 PyErr_SetString(PyExc_TypeError, "can't send non-None value to a " "just-started generator"); return NULL; &#125; &#125; else &#123; /* Push arg onto the frame's value stack */ result = arg ? arg : Py_None; Py_INCREF(result); # 该参数引用计数+1 *(f-&gt;f_stacktop++) = result; # 参数压栈 &#125; /* Generators always return to their most recent caller, not * necessarily their creator. */ f-&gt;f_tstate = tstate; Py_XINCREF(tstate-&gt;frame); assert(f-&gt;f_back == NULL); f-&gt;f_back = tstate-&gt;frame; gen-&gt;gi_running = 1; # 修改生成器执行状态 result = PyEval_EvalFrameEx(f, exc); # 执行字节码 gen-&gt;gi_running = 0; # 恢复为未执行状态 /* Don't keep the reference to f_back any longer than necessary. It * may keep a chain of frames alive or it could create a reference * cycle. */ assert(f-&gt;f_back == tstate-&gt;frame); Py_CLEAR(f-&gt;f_back); /* Clear the borrowed reference to the thread state */ f-&gt;f_tstate = NULL; /* If the generator just returned (as opposed to yielding), signal * that the generator is exhausted. */ if (result == Py_None &amp;&amp; f-&gt;f_stacktop == NULL) &#123; Py_DECREF(result); result = NULL; /* Set exception if not called by gen_iternext() */ if (arg) PyErr_SetNone(PyExc_StopIteration); &#125; if (!result || f-&gt;f_stacktop == NULL) &#123; /* generator can't be rerun, so release the frame */ Py_DECREF(f); gen-&gt;gi_frame = NULL; &#125; return result;&#125; 参考：http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/ http://www.cnblogs.com/coder2012/p/4990834.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的eventlet使用与理解]]></title>
      <url>%2F2017%2F03%2F06%2FPython%E7%9A%84eventlet%E4%BD%BF%E7%94%A8%E4%B8%8E%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Eventlet eventlet在openstack，还有ryu控制器中使用频率很高，有必要总结一下用法。 什么是协程？​ 说到Coroutine，我们必须提到两个更远的东西。在操作系统（os）级别，有进程（process）和线程（thread）两个（仅从我们常见的讲）实际的“东西”（不说概念是因为这两个家伙的确不仅仅是概念，而是实际存在的，os的代码管理的资源）。这两个东西都是用来模拟“并行”的，写操作系统的程序员通过用一定的策略给不同的进程和线程分配CPU计算资源，来让用户“以为”几个不同的事情在“同时”进行“。在单CPU上，是os代码强制把一个进程或者线程挂起，换成另外一个来计算，所以，实际上是串行的，只是“概念上的并行”。在现在的多核的cpu上，线程可能是“真正并行的”。 ​ Coroutine，翻译成”协程“，初始碰到的人马上就会跟上面两个概念联系起来。直接先说区别，Coroutine是编译器级的，Process和Thread是操作系统级的。Coroutine的实现，通常是对某个语言做相应的提议，然后通过后成编译器标准，然后编译器厂商来实现该机制。Process和Thread看起来也在语言层次，但是内生原理却是操作系统先有这个东西，然后通过一定的API暴露给用户使用，两者在这里有不同。Process和Thread是os通过调度算法，保存当前的上下文，然后从上次暂停的地方再次开始计算，重新开始的地方不可预期，每次CPU计算的指令数量和代码跑过的CPU时间是相关的，跑到os分配的cpu时间到达后就会被os强制挂起。Coroutine是编译器的魔术，通过插入相关的代码使得代码段能够实现分段式的执行，重新开始的地方是yield关键字指定的，一次一定会跑到一个yield对应的地方。 总之，对于Coroutine，是编译器帮助做了很多的事情，来让代码不是一次性的跑到底，而不是操作系统强制的挂起。代码每次跑多少，是可预期的。但是，Process和Thread，在这个层面上完全不同，这两个东西是操作系统管理的。 python-eventlet又是什么?官方网站对eventlet的描述是： ​ Eventlet is built around the concept of green threads (i.e. coroutines, we use the terms interchangeably) that are launched to do network-related work. Green threads differ from normal threads in two main ways: ​ Green threads are so cheap they are nearly free. You do not have to conserve green threads like you would normal threads. In general, there will be at least one green thread per network connection.Green threads cooperatively yield to each other instead of preemptively being scheduled. The major advantage from this behavior is that shared data structures don’t need locks, because only if a yield is explicitly called can​ another green thread have access to the data structure. It is also possible to inspect primitives such as queues to see if they have any pending data. ​ 大概意思是Eventlet是以绿色线程（协同线程）的概念建立起来的网络库，绿色线程和普通线程的区别是：1.绿色线程的开销小 2.绿色线程共享数据，无需锁，同一时刻只有一个线程能访问数据，通过类似队列的去查找等待的数据。 ​ eventlet是一个用来处理和网络相关的python库函数，而且可以通过协程来实现并发，在eventlet里，把“协程”叫做 greenthread(绿色线程)。所谓并发，就是开启了多个greenthread，并且对这些greenthread进行管理，以实现非阻塞式的 I/O。比如说用eventlet可以很方便的写一个性能很好的web服务器，或者是一个效率很高的网页爬虫，这都归功于eventlet的“绿色线程”，以及对“绿色线程”的管理机制。更让人不可思议的是，eventlet为了实现“绿色线程”，竟然对python的和网络相关的几个标准库函数进行了改写，并且可以以补丁（patch）的方式导入到程序中，因为python的库函数只支持普通的线程，而不支持协程，eventlet称之为“绿化”。​ 它通过greenlet提供的协程功能，让开发者可以不用将以往的多线程等并发程序的开发方式转变成异步状态机模型，就能直接使用select/epoll/kqueue等操作系统提供的支持高并发IO接口，并且能尽可能地发挥它们在并发上的优势。 eventlet的结构如下图所示,eventlet实现的”并发” 更准确的讲, 是 IO多路复用。 python-eventlet API?Greenthread Spawn (spawn，孵化的意思，即如何产生greenthread) 主要有3个函数可以创建绿色线程： 1)eventlet.spawn(func, args, *kwargs)： ​ 创建一个绿色线程去运行func这个函数，后面的参数是传递给这个函数的参数。返回值是一个eventlet.GreenThread对象，这个对象可以用来接受func函数运行的返回值。在绿色线程池还没有满的情况下，这个绿色线程一被创建就立刻被执行。其实，用这种方法去创建线程也是可以理解的，线程被创建出来，肯定是有一定的任务要去执行，这里直接把函数当作参数传递进去，去执行一定的任务，就好像标准库中的线程用run()方法去执行任务一样。 2)eventlet.spawn_n(func, args, *kwargs)： 这个函数和spawn()类似，不同的就是它没有返回值，因而更加高效，这种特性，使它也有存在的价值。 3)eventlet.spawn_after(seconds, func, args, *kwargs)： 这个函数和spawn()基本上一样，都有一样的返回值，不同的是它可以限定在什么时候执行这个绿色线程，即在seconds秒之后，启动这个绿色线程。 Greenthread Control 1）eventlet.sleep(seconds=0) 悬挂当前的绿色线程，以允许其它的绿色线程执行 2）class eventlet.GreenPool ​ 这是一个类，在这个类中用set集合来容纳所创建的绿色线程，并且可以指定容纳线程的最大数量（默认是1000个），它的内部是用Semaphore和Event这两个类来对池进行控制的，这样就构成了线程池。其中，有几个比较重要的方法： ​ free() ​ imap(function, *iterables) ​ resize(new_size) ​ running() ​ spawn(function, args, *kwargs) ​ spawn_n(function, args, *kwargs) ​ starmap(function, iterable) ​ waitall() ​ waiting() 3）class eventlet.GreenPile 这也是一个类，而且是一个很有用的类，在它内部维护了一个GreenPool对象和一个Queue对象。这个GreenPool对象可以是从外部传递进来的，也可以是在类内部创建的，GreenPool对象主要是用来创建绿色线程的，即在GreenPile内部调用了GreenPool.spawn()方法。而Queue对象则是用来保存spawn()方法的返回值的，即Queue中保存的是GreenThread对象。并且它还实现了next()方法，也就意味着GreenPile对象具有了迭代器的性质。所以如果我们要对绿色线程的返回值进行操作的话，用这个类是再好不过的了。 next()Wait for the next result, suspending the current greenthread until it is available. Raises StopIteration when there are no more results. spawn(func, args, *kw)Runs func in its own green thread, with the result available by iterating over the GreenPile object 4）class eventlet.Queue ​ 基类是LightQueue，它实现了大部分的队列的常用方法。它是用collections做为实现队列的基本数据结构的。而且这个LightQueue的实现，不单单实现了存取操作，在本质上它实现了一个生产者和消费者问题，定义了两个set()类型的成员变量putters和getters，前者用来存放在队列满时，被阻塞的绿色线程，后者用来存放当队列空时，被阻塞的绿色线程。类中的putting()和getting()方法就是分别得到被阻塞的绿色线程的数量。Queue继承了LightQueue，并且又增加了它自己的两个方法：task_done()和join()。task_done()是被消费者的绿色线程所调用的，表示在这个项上的所有工作都做完了，join()是阻塞，直到队列中所有的任务都完成。LifoQueue和PriorityQueue是存放数据的两种不同的方式。 5）class eventlet.Timeout This class is a way to add timeouts to anything. It raises exception in the current greenthread after timeout seconds. When exception is omitted or None, the Timeout instance itself is raised. Patching Functions 这里就是之前所说的“绿化”，经过eventlet“绿化”过的模块都在eventlet.green中，导入他们主要有两种方法： 1) eventlet.import_patched(modulename, additional_modules, *kw_additional_modules) 1234567from eventlet.green import socketfrom eventlet.green import SocketServerBaseHTTPServer = eventlet.import_patched('BaseHTTPServer', ('socket', socket), ('SocketServer', SocketServer))BaseHTTPServer = eventlet.import_patched('BaseHTTPServer', socket=socket, SocketServer=SocketServer) 2）eventlet.monkey_patch(all=True, os=False, select=False, socket=False, thread=False, time=False) 12import eventleteventlet.monkey_patch(socket=True, select=True) Network Convenience Functions（和网络相关的函数） eventlet.connect(addr, family=, bind=None) 主要执行了以下几个步骤：新建了一个TCP类型的socket，绑定本地的ip和端口，和远程的地址进行连接 123456def connect(addr, family=socket.AF_INET, bind=None): sock = socket.socket(family, socket.SOCK_STREAM) if bind is not None: sock.bind(bind) sock.connect(addr) return sock eventlet.listen(addr, family=, backlog=50) 和connect()类似，只是把connect()换成了listen()，backlog指定了最大的连接数量 1234567def listen(addr, family=socket.AF_INET, backlog=50): sock = socket.socket(family, socket.SOCK_STREAM) if sys.platform[:3]=="win": sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #这段不知道具体是做什么的 sock.bind(addr) sock.listen(backlog) return sock eventlet.wrap_ssl(sock, a, *kw) 给socket加上ssl(安全套接层)，对数据进行加密 eventlet.serve(sock, handle, concurrency=1000) 这个函数直接创建了一个socket服务器，在它内部创建了一个GreenPool对象，默认的最大绿色线程数是1000，然后是一个循环来接受连接 123456789101112def serve(sock, handle, concurrency=1000): pool = greenpool.GreenPool(concurrency) server_gt = greenthread.getcurrent() while True: try: conn, addr = sock.accept() gt = pool.spawn(handle, conn, addr) gt.link(_stop_checker, server_gt, conn) conn, addr, gt = None, None, None except StopServe: return eventlet 中的wsgi？流程描述： 服务器开一个socket等待客户端连接；请求来了，服务器会读出传来的数据，然后根据HTTP协议做一些初步的封装，接着就可以调用事先注册的应用程序了，并将请求的数据塞进去；等响应处理完毕了再把数据通过socket发出去。 123456789101112131415161718192021222324server参数介绍：def server(sock, # Server socket, must be already bound to a port and listening(IP和端口并开启监听). site, # WSGI application function(事件处理函数，发送start_response响应头然后返回响应内容) log=None, # File-like object that logs should be written to.If not specified, sys.stderr is used.(日志处理，默认为sys.stderr用来重定向标准错误信息的) environ=None, # Additional parameters that go into the environ dictionary of every request(每次请求的参数，写入一个字典中) max_size=None, #Maximum number of client connections opened at any time by this server.(默认为1024) max_http_version=DEFAULT_MAX_HTTP_VERSION, # Set to "HTTP/1.0" to make the server pretend it only supports HTTP 1.0. # This can help with applications or clients that don't behave properly using HTTP 1.1.(HTTP协议版本,默认为HTTP/1.1) protocol=HttpProtocol, # Protocol class.（协议类，默认为HttpProtocol） server_event=None, # Used to collect the Server object(搜集服务器对象信息) minimum_chunk_size=None, # Minimum size in bytes for http chunks. This can be used to improve performance of applications which yield many small strings, though # using it technically violates the WSGI spec. This can be overridden on a per request basis by setting environ['eventlet.minimum_write_chunk_size']. # 设置最小的Chunk大小，可以通过设置environ['eventlet.minimum_write_chunk_size']来覆盖.Chunk表示服务器发送给客户端的分块传输编码（Chunked transfer encoding） log_x_forwarded_for=True, # If True (the default), logs the contents of the x-forwarded-for header in addition to the actual client ip address in the 'client_ip' field of the log line. # 默认为True,记录客户端IP日志,X-Forwarded-For(XFF)是用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段。 custom_pool=None, # A custom GreenPool instance which is used to spawn client green threads.If this is supplied, max_size is ignored.(协程池，如果启用则可以忽略前面的max_size参数) keepalive=True, # If set to False, disables keepalives on the server; all connections will be closed after serving one request.（控制客户端连接数是否保持alive） log_output=True, # A Boolean indicating if the server will log data or not.(确定服务端是否输出日志) log_format=DEFAULT_LOG_FORMAT, # A python format string that is used as the template to generate log lines.(日志输出格式) url_length_limit=MAX_REQUEST_LINE, # A maximum allowed length of the request url. If exceeded, 414 error is returned.（最大的url长度限制，默认为8192） debug=True, # True if the server should send exception tracebacks to the clients on 500 errors.If False, the server will respond with empty bodies.(是否发送调式信息给客户端) socket_timeout=None, # Timeout for client connections' socket operations. Default None means wait forever.(Socket超时时间设置，单位是秒) capitalize_response_headers=True) # Normalize response headers' names to Foo-Bar(是否标准化相应头) Client端： 12345678#客户端代码：import eventletc=eventlet.connect(('127.0.0.1', 6000))while True: data=raw_input('Enter data:') c.sendall(data) rc=c.recv(1024) print rc Server端： 123456789101112#服务端代码：import eventletdef handle(client): while True: c = client.recv(1024) print c client.sendall(c)server = eventlet.listen(('127.0.0.1', 6000))pool = eventlet.GreenPool(10000)while True: new_sock, address = server.accept() pool.spawn_n(handle, new_sock) python-eventlet 的Demo?官方上引以为傲的“网页爬虫”，用到了绿色线程池和imap()函数 123456789101112131415urls = [ "http://www.google.com/intl/en_ALL/images/logo.gif", "http://python.org/images/python-logo.gif", "http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif",]import eventletfrom eventlet.green import urllib2def fetch(url): return urllib2.urlopen(url).read()pool = eventlet.GreenPool()for body in pool.imap(fetch, urls): print("got body", len(body)) 源码级别的分析？eventlet主要依赖另外2个python package: greenletpython-epoll (或其他类似的异步IO库, 如poll/select等) 主要做了3个工作: 封装greenlet封装epoll改写python标准库中相关的module, 以便支持epoll 什么是epoll？ epoll是linux实现的一个基于事件的异步IO库, 在之前类似的异步IO库poll上改进而来。 下面两个例子会演示如何用epoll将阻塞的IO操作用epoll改写为异步非阻塞： blocking IO import socket 12345678910111213141516171819202122EOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)try: while True: connectiontoclient, address = serversocket.accept() request = b'' while EOL1 not in request and EOL2 not in request: request += connectiontoclient.recv(1024) print('-'*40 + '\n' + request.decode()[:-2]) connectiontoclient.send(response) connectiontoclient.close()finally: serversocket.close() ​ 需要注意的是程序会在connectiontoclient, address = serversocket.accept()这一行block住, 直到获取到新的连接, 程序才会继续往下运行.同时, 这个程序同一个时间内只能处理一个连接, 如果有很多用户同时访问8080端口, 必须要按先后 顺序依次处理这些连接, 前面一个连接成功返回后, 才会处理后面的连接. non-blocking IO by using epoll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import socket, selectEOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)serversocket.setblocking(0)epoll = select.epoll()epoll.register(serversocket.fileno(), select.EPOLLIN)try: connections = &#123;&#125;; requests = &#123;&#125;; responses = &#123;&#125; while True: events = epoll.poll(1) for fileno, event in events: if fileno == serversocket.fileno(): connection, address = serversocket.accept() connection.setblocking(0) epoll.register(connection.fileno(), select.EPOLLIN) connections[connection.fileno()] = connection requests[connection.fileno()] = b'' responses[connection.fileno()] = response elif event &amp; select.EPOLLIN: requests[fileno] += connections[fileno].recv(1024) if EOL1 in requests[fileno] or EOL2 in requests[fileno]: epoll.modify(fileno, select.EPOLLOUT) print('-'*40 + '\n' + requests[fileno].decode()[:-2]) elif event &amp; select.EPOLLOUT: byteswritten = connections[fileno].send(responses[fileno]) responses[fileno] = responses[fileno][byteswritten:] if len(responses[fileno]) == 0: epoll.modify(fileno, 0) connections[fileno].shutdown(socket.SHUT_RDWR) elif event &amp; select.EPOLLHUP: epoll.unregister(fileno) connections[fileno].close() del connections[fileno]finally: epoll.unregister(serversocket.fileno()) epoll.close() serversocket.close() 可以看到, 例子中首先使用serversocket.setblocking(0)将socket设为异步的模式,然后 用select.epoll()新建了一个epoll, 接着用epoll.register(serversocket.fileno(),select.EPOLLIN)将该socket上的IO输入事件(select.EPOLLIN)注册到epoll里.这样做了以后, 就可以将 上面例子中会在socket.accept()这步阻塞的MainLoop改写为基于异步IO事件的epoll循环了.events = epoll.poll(1) ​ 简单的说, 如果有很多用户同时连接到8080端口, 这个程序会同时accept()所有的socket连接, 然后通过这行代码将发生IO事件socket放到events中, 并在后面循环中处理. 没有发生IO事件的 socket不会在loop中做处理. 这样使用epoll就实现了一个简单的并发web服务器. 注意, 这里提到的并发, 和我们通常所理解线程/进程的并发并不太一样, 更准确的说, 是 IO多路复用 . 什么是greenlet？ greentlet是python中实现我们所谓的”Coroutine(协程)”的一个基础库. 12345678910111213141516from greenlet import greenletdef test1(): print 12 gr2.switch() print 34def test2(): print 56 gr1.switch() print 78 gr1 = greenlet(test1) gr2 = greenlet(test2) gr1.switch()#输出125634 ​ 程序先分别为两个函数定义了2个greenlet: gr1和gr2.gr1.switch()显式切换到gr1上执行, gr1中输出”12”后gr2.switch()显式切换到gr2上执行输出56, 又gr1.switch()显式切换到gr1上, 输出34. test1()执行结束,gr1 die. 于是 test2()里的78不会输出.可以发现greenlet仅仅是实现了一个最简单的”coroutine”, 而eventlet中的greenthread是在 greenlet的基础上封装了一些更high-level的功能, 比如greenlet的调度等. 什么是eventlet.green？ 从epoll的运行机制可以看出, 要使用异步IO, 必须要将相关IO操作改写成non-blocking的方式. 但是我们用eventlet.spawn()的函数,并没有针对epoll做任何改写, 那eventlet是怎么实现 异步IO的呢?这也是eventlet这个package最凶残的地方, 它自己重写了python标准库中IO相关的操作, 将它们 改写成支持epoll的模式, 放在eventlet.green中.比如说, socket.accept()被改成了这样 123456789101112def accept(self): if self.act_non_blocking: return self.fd.accept() fd = self.fd while True: res = socket_accept(fd) if res is not None: client, addr = res set_nonblocking(client) return type(self)(client), addr trampoline(fd, read=True, timeout=self.gettimeout(), timeout_exc=socket.timeout("timed out")) ​ 然后在eventlet.spawn()的时候, 通过 一些高阶魔法和”huge hack”, 将这些改写过得模块”patch”到spawn出的greenthread上, 从而 实现epoll的IO多路复用, 相当凶残.其中的hub和greenthread分别对应eventlet.hubs.hub和eventlet.greenthread, 本质都是 一个greenlet的实例.hub中封装前面提到的epoll, epoll的事件循环是由hub.run()这个方法里实现.每当用户调用 eventlet.spawn(), 就会在当前python线程的pool里产生一个新的greenthread. 由于greenthread 里的IO相关的python标准库被改写成non-blocking的模式(参考上面的socket.accept()).每当greenthread里做IO相关的操作时, 最终都会返回到hub中的epoll循环, 然后根据epoll中的 IO事件, 调用响应的函数. 具体如下面所示.greenthread.sleep(), 实际上也是将CPU控制权交给hub,然后由hub调度下一个需要运行的 greenthread. 123456789101112131415161718192021222324252627282930313233def wait(self, seconds=None): readers = self.listeners[READ] writers = self.listeners[WRITE] if not readers and not writers: if seconds: sleep(seconds) return try: presult = self.poll.poll(int(seconds * self.WAIT_MULTIPLIER)) except select.error, e: if get_errno(e) == errno.EINTR: return raise SYSTEM_EXCEPTIONS = self.SYSTEM_EXCEPTIONS for fileno, event in presult: try: if event &amp; READ_MASK: readers.get(fileno, noop).cb(fileno) if event &amp; WRITE_MASK: writers.get(fileno, noop).cb(fileno) if event &amp; select.POLLNVAL: self.remove_descriptor(fileno) continue if event &amp; EXC_MASK: readers.get(fileno, noop).cb(fileno) writers.get(fileno, noop).cb(fileno) except SYSTEM_EXCEPTIONS: raise except: self.squelch_exception(fileno, sys.exc_info()) clear_sys_exc_info() 参考:http://blog.csdn.net/xiangmin2587/article/details/8182775 http://blog.csdn.net/qq910894904/article/details/41699541 http://www.cnblogs.com/wonderKK/p/4062591.html http://eventlet.net/doc/ http://eventlet.net/doc/modules/wsgi.html http://www.xuebuyuan.com/1379840.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java框架之SpringBoot]]></title>
      <url>%2F2017%2F03%2F03%2Fjava%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBoot%2F</url>
      <content type="text"><![CDATA[SpringBoot非常受欢迎，在github我也用SpringBoot封装neutron-api，地址为： https://github.com/Luckylau/SpringBoot-NeutronApi 总觉得应该普及一下基本知识。 什么是SpringBoot？​ Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式，Boot致力于在蓬勃发展的快速应用开发领域（rapid application development）成为领导者。 ​ Boot的目标不在于为已解决的问题域提供新的解决方案，而是为平台带来另一种开发体验，从而简化对这些已有技术的使用。对于已经熟悉Spring生态系统的开发人员来说，Boot是一个很理想的选择，不过对于采用Spring技术的新人来说，Boot提供一种更简洁的方式来使用这些技术。 ​ Boot提供了许多的“starter”模块，它们定义了一组依赖，这些依赖能够添加到构建系统之中，从而解析框架及其父平台所需的特定类库。例如，spring-boot-starter-actuator依赖会引入一组基本的Spring项目，从而实现应用的快速配置和即时可用。关于这种依赖，值得强调的一点就是当开发Web应用，尤其是RESTful Web服务的时候，如果包含了spring-boot-starter-web依赖，它就会为你提供启动嵌入式Tomcat容器的自动化配置，并且提供对微服务应用有价值的端点信息，如服务器信息、应用指标（metrics）以及环境详情。除此之外，如果引入spring-boot-starter-security模块的话，actuator会自动配置Spring Security，从而为应用提供基本的认证以及其他高级的安全特性。它还会为应用结构引入一个内部的审计框架，这个框架可以用来生成报告或其他的用途，比如开发认证失败的锁定策略。 ​ Boot对Spring应用的开发进行了简化，提供了模块化方式导入依赖的能力，强调了开发RESTful Web服务的功能并提供了生成可运行jar的能力，这一切都清晰地表明在开发可部署的微服务方面Boot框架是一个强大的工具。正如前面的例子所示，借助于Boot，让一个RESTful Web工程运行起来是一件很容易的事情；在企业级基础设施领域，微服务是一种越来越流行的应用架构，因为它能够实现快速开发、更小的代码库、企业级集成以及模块化部署。 实战Domo?以SpringBoot-neutron-api项目为例，这也是一个RESTFUL项目。 1.创建一个Maven项目 我们在eclipse下创建两个maven项目，一个选择maven-archtype-quickstart，一个选择maven-archtype-webapp。将maven-archtype-webapp下的webapp目录拷贝到基于maven-archtype-quickstart创建的maven项目，然后将其删除。 如果没有src/main/resources可以按照如下方式创建 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 其余根据开发需要补充即可。下面是一些配置数据库的，主要别人的一些操作，我也看了一下公司产品的代码，大同小异，简单的贴出来。 12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!--数据库操作--&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在src/main/resources这个文件夹下面新建一个application.properties 123456789101112131415#DB Configuration:spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/testdbspring.datasource.username = rootspring.datasource.password = 123456#JPA Configuration: spring.jpa.database=MySQLspring.jpa.show-sql=true spring.jpa.generate-ddl=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernate.dialect.MySQL5Dialect spring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy #spring.jpa.database=org.hibernate.dialect.MySQL5InnoDBDialect #spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MYSQL5Dialect 待续。。。。。 参考：http://www.infoq.com/cn/articles/microframeworks1-spring-boot http://blog.csdn.net/cool__wang/article/details/49466609 http://www.cnblogs.com/dreamroute/p/5173896.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的sqlalchemy库使用]]></title>
      <url>%2F2017%2F03%2F02%2FPython%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Sqlalchemy库 本文主要参考官方文档和一些网上资料，并结合之前python-web-frame项目使用来详细说明Sqlalchemy的使用，版本号为SQLAlchemy 1.1。 Sqlalchemy的架构？ Object Relational Mapper &amp;&amp; SQL Expression Language ?下面是截取python-web-frame项目代码 12345678910111213141516171819202122232425262728293031323334#api.pydef get_engine(): global _ENGINE if _ENGINE is not None: return _ENGINE _ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) db_models.int_dbs(_ENGINE) return _ENGINE# db_models.pyBase = declarative.declarative_base()def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE)class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) def __init__(self, user_id, name, gender, age, email): self.user_id = user_id self.name = name self.gender = gender self.age = age self.email = email Connecting 123_ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) echo flag is a shortcut to setting up SQLAlchemy logging, which is accomplished via Python’s standard logging module. With it enabled, we’ll see all the generated SQL produced. echo意思说开启日志，你可以看到整个SQL是如何产生的，方便调试。 _ENGINE is an instance of Engine, and it represents the core interface to the database, adapted through a dialect that handles the details of the database and DBAPI in use. _ENGINE 意思说与数据库打交道的核心接口 Declare a Mapping 123456789101112131415Base = declarative.declarative_base()class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) 生成一个映射使用的Base. Create a Schema 12def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE) db_User类继承了Base类，它具有metadata属性，通过create_all()方法，注入与数据库打交道的核心接口_ENGINE，我们发现有一系列的命令完成数据库中user表是否存在的检测和生成。 Creating a Session 1234567891011def get_session_maker(engine): global _SESSION_MAKER if _SESSION_MAKER is not None: return _SESSION_MAKER _SESSION_MAKER = sqlalchemy.orm.sessionmaker(bind=engine) return _SESSION_MAKERdef get_session(): engine = get_engine() maker = get_session_maker(engine) session = maker() return session This custom-made Session class will create new Session objects which are bound to our database. Querying http://docs.sqlalchemy.org/en/rel_1_1/orm/query.html#sqlalchemy.orm.query.Query query()和 aliased() Common Filter Operators filter() 12345678910111213141516171819202122232425262728293031equals:query.filter(User.name == 'ed')not equals:query.filter(User.name != 'ed')LIKE:query.filter(User.name.like('%ed%'))IN:query.filter(User.name.in_(['ed', 'wendy', 'jack']))# works with query objects too:query.filter(User.name.in_( session.query(User.name).filter(User.name.like('%ed%'))))NOT IN:query.filter(~User.name.in_(['ed', 'wendy', 'jack']))IS NULL:query.filter(User.name == None)# alternatively, if pep8/linters are a concernquery.filter(User.name.is_(None))AND:# use and_()from sqlalchemy import and_query.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))# or send multiple expressions to .filter()query.filter(User.name == 'ed', User.fullname == 'Ed Jones')# or chain multiple filter()/filter_by() callsquery.filter(User.name == 'ed').filter(User.fullname == 'Ed Jones'OR:from sqlalchemy import or_query.filter(or_(User.name == 'ed', User.name == 'wendy'))MATCH:query.filter(User.name.match('wendy') Returning Lists and Scalars all() returns a list first() applies a limit of one and returns the first result as a scalar one() fully fetches all rows, and if not exactly one object identity or composite row is present in the result, raises an error 注意：The one() method is great for systems that expect to handle “no items found” versus “multiple items found” differently; such as a RESTful web service, which may want to raise a “404 not found” when no results are found, but raise an application error when multiple results are found. one_or_none() is like one(), except that if no results are found, it doesn’t raise an error; it just returns None. Like one(), however, it does raise an error if multiple results are found scalar() invokes the one() method, and upon success returns the first column of the row Using Textual SQL text() Counting count() Building a Relationship 一对多 12345678class db_User(Base): .... telephone = relationship("db_Telephone",order_by="db_Telephone.id",back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 即：一个db_user对应多个db_Telephone 一对一 12345678class db_User(Base): .... telephone = relationship("db_Telephone",uselist=False,back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 多对多 Many to Many adds an association table between two classes.多对多关系会在两个类之间增加一个关联的表。The association table is indicated by the secondary argument to relationship().这个关联的表在 relationship() 方法中通过 secondary 参数来表示。Usually, the Table uses the MetaData object associated with the declarative base class,通常的，这个表会通过 MetaData 对象来与声明基类关联，so that the ForeignKey directives can locate the remote tables with which to link:所以这个 ForeignKey 指令会使用链接来定位到远程的表： 123456789101112131415161718192021#多对多关系中的两个表之间的一个关联表post_keywords = Table('post_keywords', Base.metadata, Column('post_id', ForeignKey('posts.id'), primary_key=True), Column('keyword_id', ForeignKey('keywords.id'), primary_key=True) class Parent(Base): __tablename__ = 'left' id = Column(Integer, primary_key=True) children = relationship( "Child", secondary=association_table, back_populates="parents")class Child(Base): __tablename__ = 'right' id = Column(Integer, primary_key=True) parents = relationship( "Parent", secondary=association_table, back_populates="children") Querying with Joins Using Aliases Using EXISTS Common Relationship Operators eq() (many-to-one “equals” comparison) ne() (many-to-one “not equals” comparison) IS NULL (many-to-one comparison, also uses eq()) contains() (used for one-to-many collections) any() (used for collections) has() (used for scalar references) Query.with_parent() (used for any relationship) Eager Loading Query.options() subqueryload()第一种 Joined Load()第二种 contains_eager()第三种 Deleting db_user与db_Telephone是一对多关系，下面操作解决了删除db_user，会自动删除关联的表数据 12345678910111213141516171819202122def delete_user(self, user_id): logger.info("user.user_id: %s" % (user_id)) try: session = get_session() user=session.query( db_models.db_User).filter_by( user_id=user_id).first() session.delete(user) session.flush() session.commit() except exc.NoResultFound: logger.error("delete user occur error ...")class db_User(Base): ... telephone = relationship( "db_Telephone", order_by="db_Telephone.id", back_populates="user" , cascade="save-update, merge, delete")class db_Telephone(Base): ... user = relationship("db_User", back_populates="telephone") 参考：http://docs.sqlalchemy.org/en/rel_1_0/orm/tutorial.html http://docs.sqlalchemy.org/en/rel_1_0/core/tutorial.html http://blog.csdn.net/zd0303/article/details/50261347 http://blog.csdn.net/Jmilk/article/details/52445093#one-to-many]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python的pecan框架使用]]></title>
      <url>%2F2017%2F03%2F01%2Fpython%E7%9A%84pecan%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Pecan web框架 什么是Pecan?​ 创造Pecan是为了填补Python web框架世界的一个空缺——一个提供object-dispatch（对象分发）方式路由的超轻量级的框架。Pecan的目标并不是要成为一个“全栈”框架，因此没有支持一些额外的功能，比如session或是数据库 。相反，Pecan专注于HTTP本身。 功能包括： Object-dispatch for easy routingFull support for REST-style controllersExtensible security frameworkExtensible template language supportExtensible JSON supportEasy Python-based configuration 所以对于OpenStack来说，Pecan是一个很好的选择，因为OpenStack项目中统一使用sqlalchemy来实现ORM，API的实现也不需要模板功能，安全控制则基于Keystone体系。使用Pecan来开发REST服务，代码量很少，代码结构也清晰。 创建简单的Pecan应用？首先在linux新建一个virtualenv环境（本文是在ubantu16.04），我们首先看一下自动生成的工程目录结构。 12345678910111213141516171819202122232425262728293031323334353637383940luckylau@luckylau-Ubuntu:~$virtualenv pecan-envluckylau@luckylau-Ubuntu:~$cd pecan-env/luckylau@luckylau-Ubuntu:~/pecan-env$ source bin/activate(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pip install pecan(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pecan create test_project(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ tree test_project/test_project/├── config.py├── MANIFEST.in├── public #一些静态文件包括CSS,JS,images,为你的开发服务│ ├── css│ │ └── style.css│ └── images│ └── logo.png├── setup.cfg├── setup.py└── test_project #基于MVC模型生成的结构 ├── app.py #决定应用是如何创造的，这个文件必须包含set_app()并返回WSGI应用对象，一般情况下就用原生的，除非不能满足你定制的应用。 ├── controllers #控制层实现 │ ├── __init__.py │ ├── __init__.pyc │ ├── root.py │ └── root.pyc ├── __init__.py ├── __init__.pyc ├── model #模型实现 │ ├── __init__.py #在这里可以加入与database交互，定义表和ORM等 │ └── __init__.pyc ├── templates #模板实现 │ ├── error.html │ ├── index.html │ └── layout.html └── tests #单元测试 ├── config.py ├── __init__.py ├── test_functional.py ├── test_units.py └── test_units.pyc8 directories, 23 files 实战Demo?我们通过实际操作中补充pecan相关知识点。项目托管到github: https://github.com/Luckylau/python-web-frame 该项目用到pecan和wsme(Web Services Made Easy),首先解释一下WSME吧 WSME的全称是Web Service Made Easy，是专门用于实现REST服务的typing库，让你不需要直接操作请求和响应，而且刚好和Pecan结合得非常好，所以，OpenStack的很多项目都使用了Pecan + WSME的组合来实现API。 WSME的理念是：在大部分情况下，Web服务的输入和输出对数据类型的要求都是严格的。所以它就专门解决了这个事情，然后把其他事情都交给其他框架去实现。 WSME会自动帮你检查HTTP请求和响应中的数据是否符合预先设定好的要求。WSME的主要方式是通过装饰器来控制controller方法的输入和输出。WSME中主要使用两个控制器： ● @signature: 这个装饰器用来描述一个函数的输入和输出。 ● @wsexpose: 这个装饰器包含@signature的功能，同时会把函数的路由信息暴露给Web框架，效果就像Pecan的expose装饰器。 123456789101112131415luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── config.py│ ├── controllers│ │ ├── __init__.py│ │ └── root.py│ ├── expose.py│ ├── hooks.py│ └── __init__.py├── cmd│ ├── api.py│ └── __init__.py└── __init__.py 首先参考openstack我们人工的建立如上目录。首先我们实现config.py 代码 https://pecan.readthedocs.io/en/latest/configuration.html#application-configuration 该链接解释配置的含义。 config.py 123456789101112131415161718192021222324app = &#123; 'root': 'webdemo.api.controllers.root.RootController', 'modules': ['webdemo.api'], 'debug': True,&#125;logging = &#123; 'root': &#123;'level': 'INFO', 'handlers': ['console']&#125;, 'loggers': &#123; 'webdemo': &#123;'level': 'INFO', 'handlers': ['console']&#125; &#125;, 'handlers': &#123; 'console': &#123; 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'simple' &#125; &#125;, 'formatters': &#123; 'simple': &#123; 'format': ('%(asctime)s %(levelname)-5.5s [%(name)s]' '[%(threadName)s] %(message)s') &#125; &#125;&#125; modules At least one of the listed modules must contain an app.setup_app function which is called to create the WSGI app. In other words, this package should be where your app.py file is located, and this file should contain a setup_app function. 简单来说，modules是app.py(同时包含setup_pp功能)所在的包，pecan会扫描的。 root The root controller of your application. Remember to provide a string representing a Python path to some callable (e.g.”yourapp.controllers.root.RootController”). 简单来说，RootController所在路径 debugEnables the ability to display tracebacks in the browser and interactively debug during development. 简单来说，是否开启debug模式 app.py 123456789101112import pecanfrom webdemo.api import config as api_configdef get_pecan_config(): filename=api_config.__file__.replace('.pyc','.py') return pecan.configuration.conf_from_file(filename)def setup_app(): config=get_pecan_config() app_conf=dict(config.app) app=pecan.make_app(app_conf.pop('root'), logging=getattr(config,'logging',&#123;&#125;), **app_conf) return app expose.py 123456#让API返回JSON格式的数据import wsmeext.pecan as wsme_pecandef expose(*args, **kwargs): if 'rest_content_types' not in kwargs: kwargs['rest_content_types'] = ('json',) return wsme_pecan.wsexpose(*args, **kwargs) root.py 12345678910from pecan import restfrom wsme import types as wtypesfrom webdemo.api import exposeimport logginglogger = logging.getLogger(__name__)class RootController(rest.RestController): @expose.expose(wtypes.text) def get(self): logger.info("Method is called ...") return "python-web-frame: pecan &amp; wsme " api.py 123456789from wsgiref import simple_serverfrom webdemo.api import appdef main(): application = app.setup_app() httpd = simple_server.make_server('', 8080, application) print ("Server on port 8080 ,listening ...") httpd.serve_forever()if __name__ == '__main__': main() 我们进一步扩展该Demo，源码更新看日志： https://github.com/Luckylau/python-web-frame/commits/master 需求：设计一个管理用户的API，实现如下 GET /v1/users 获取所有用户的列表。POST /v1/users 创建一个用户。GET /v1/users/ 获取一个特定用户的详细信息。PUT /v1/users/ 修改一个用户的详细信息。DELETE /v1/users/ 删除一个用户。 1234567891011121314151617181920212223242526luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── __init__.py│ │ ├── controller.py #用户管理控制器│ │ └── users.py #用户模型│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── __init__.py└── __init__.pyc 然后我们在加入sqlalchemy库来实现数据库操作 我们可以看一个脚本预热一下 https://github.com/Luckylau/oslo.modules.sample/blob/lucky-branch/sqlalchemy.orm/db_query_ports.py 然后开始我们这个Demo的扩展 由于OpenStack项目在单元测试中使用的是sqlite的内存数据库，这样开发者运行单元测试的时候不需要安装和配置复杂的MySQL数据库，只要安装好sqlite3就可以了。而且，数据库是保存在内存中的，会提高单元测试的速度，我们的Demo也是用sqlite，sqlalchemy库的使用参考： https://luckylau.github.io/2017/03/02/Python%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3/ 12345678910111213141516171819202122232425262728293031323334webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── controller.py│ │ ├── controller.pyc│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── users.py│ │ └── users.pyc│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── db│ ├── api.py #sqlalchemy 增删改查功能│ ├── __init__.py #│ └── models.py # sqlalchemy ORM的定义├── __init__.py└── __init__.pyc5 directories, 26 files 具体的分析在源码有标注。 参考：https://pecan.readthedocs.io/en/latest/ http://www.infoq.com/cn/articles/OpenStack-demo-API3 https://pythonhosted.org/WSME/ http://www.sqlalchemy.org/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单（4）]]></title>
      <url>%2F2017%2F02%2F28%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95%EF%BC%884%EF%BC%89%2F</url>
      <content type="text"><![CDATA[2017年-至今98.《你一年的8760小时》-艾力 99.《牛棚杂忆》-季羡林 100.《愚人的坚持》-稻盛和夫，山中伸弥 101.《异类》-马尔柯姆-格拉德威尔 102.《人类动物园》-德斯蒙德莫里斯 103.《美学漫话》-宗白华 104.《逃不开的经济周期》-拉斯特维德 105.《明治维新六十年》-樱雪丸 106.《武士道》-新渡户稻造 107.《我所理解的生活》-韩寒 108.《呀，原来如此》-知乎 109《宋朝原来是这样》-醉罢君山]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的wsgi理解]]></title>
      <url>%2F2017%2F02%2F28%2Fpython%E7%9A%84wsgi%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之WSGI ​ WSGI的全称是Web Server Gateway Interface，翻译过来就是Web服务器网关接口。具体的来说，WSGI是一个规范，定义了Web服务器如何与Python应用程序进行交互，使得使用Python写的Web应用程序可以和Web服务器对接起来。WSGI一开始是在PEP-0333中定义的，最新版本是在Python的PEP-3333定义的。 为什么需要WSGI规范？在Web部署的方案上，有一个方案是目前应用最广泛的： ​ 首先，部署一个Web服务器专门用来处理HTTP协议层面相关的事情，比如如何在一个物理机上提供多个不同的Web服务（单IP多域名，单IP多端口等）这种事情。 ​ 然后，部署一个用各种语言编写（Java, PHP, Python, Ruby等）的应用程序，这个应用程序会从Web服务器上接收客户端的请求，处理完成后，再返回响应给Web服务器，最后由Web服务器返回给客户端。 ​ 要采用这种方案，Web服务器和应用程序之间就要知道如何进行交互。为了定义Web服务器和应用程序之间的交互过程，就形成了很多不同的规范。比如改进CGI性能的FasgCGI，Java专用的Servlet规范，还有Python专用的WSGI规范等。提出这些规范的目的就是为了定义统一的标准，提升程序的可移植性。在WSGI规范的最开始的PEP-333中一开始就描述了为什么需要WSGI规范。 ​ WSGI存在的目的有两个： 让Web服务器知道如何调用Python应用程序，并且把用户的请求告诉应用程序。 让Python应用程序知道用户的具体请求是什么，以及如何返回结果给Web服务器。 WSGI中的角色？​ 在WSGI中定义了两个角色，Web服务器端称为server或者gateway，应用程序端称为application或者framework（因为WSGI的应用程序端的规范一般都是由具体的框架来实现的）。我们下面统一使用server和application这两个术语。 ​ server端会先收到用户的请求，然后会根据规范的要求调用application端，如下图所示： 调用的结果会被封装成HTTP响应后再发送给客户端。 WSGI中间件 ?​ WSGI Middleware（中间件）也是WSGI规范的一部分。上一章我们已经说明了WSGI的两个角色：server和application。那么middleware是一种运行在server和application中间的应用（一般都是Python应用）。middleware同时具备server和application角色，对于server来说，它是一个application；对于application来说，它是一个server。middleware并不修改server端和application端的规范，只是同时实现了这两个角色的功能而已。 1.Server收到客户端的HTTP请求后，生成了environ_s，并且已经定义了start_response_s。 2.Server调用Middleware的application对象，传递的参数是environ_s和start_response_s。 3.Middleware会根据environ执行业务逻辑，生成environ_m，并且已经定义了start_response_m。 4.Middleware决定调用Application的application对象，传递参数是environ_m和start_response_m。Application的application对象处理完成后，会调用start_response_m并且返回结果给Middleware，存放在result_m中。 5.Middleware处理result_m，然后生成result_s，接着调用start_response_s，并返回结果result_s给Server端。Server端获取到result_s后就可以发送结果给客户端了。 从上面的流程可以看出middleware应用的几个特点： Server认为middleware是一个application。 Application认为middleware是一个server。 Middleware可以有多层。 WSGi示例代码？​ 在给出示例代码前我们需要了解wsgiref，它是官方给出的一个实现了WSGI标准用于演示用的简单Python内置库，实现了一个简单的WSGI Server和WSGI Application（在simple_server模块中），主要分为五个模块：simple_server， util， headers， handlers， validate。 注意：simple_server只支持单线程，做测试 WSGI对于应用程序有以下标准规定： 应用程序必须是一个可调用的对象，因此，应用程序可以是一个函数，一个类，或者一个重载了call的类的实例。 应用程序必须接受两个参数并且要按照位置顺序，分别是environ（环境变量），以及start_response函数（负责将响应的status code，headers写进缓冲区但不返回给客户端）。 应用程序返回的结果必须是一个可迭代的对象 由简入繁 123456789from wsgiref.simple_server import make_serverdef simple_app(environ,start_response): status="200 OK" response_headers=[('Content-type', 'text/plain')] start_response(status,response_headers) return [u"This is simple app demo".encode('utf-8')]http=make_server('',8080,simple_app)print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011from wsgiref.simple_server import make_serverclass App(): def __call__(self, environ, start_response): status = "200 OK" response_headers = [('Content-type', 'text/plain')] start_response(status, response_headers) return [u"This is App".encode('utf-8')]simple_app = App()http = make_server('', 8080, simple_app) #只要是实现了__call__方法的实例也可以的print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011121314from wsgiref.simple_server import make_serverclass class_app: def __init__(self, environ, start_response): self.env = environ self.start = start_response def __iter__(self): status = "200 OK" response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield "Class : My Own Hello World!"app = class_apphttpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 1234567891011121314151617181920212223242526272829303132from wsgiref.simple_server import make_serverURL_PATTERNS = ( ('tags', 'tag_app'), ('about', 'about_app'))class Dispatcher(object): def _match(self, path): path = path.split("/")[1] for url, app in URL_PATTERNS: print("path:%s url:%s" % (path, url)) if path == url: return app def __call__(self, environ, start_response): path = environ.get('PATH_INFO') app = self._match(path) if app: app = globals()[app] return app(environ, start_response) else: start_response("404 not found ", [('Content-type', 'text/plain')]) return ["Page dose not exists!"]def tag_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is tag page!"]def about_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is about me page!"]app = Dispatcher()httpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 源码wsgiref解析?wsgiref.simple_server 中make_server函数 12345678# wsgiref/simple_server.pydef make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): """Create a new WSGI server listening on `host` and `port` for `app`""" server = server_class((host, port), handler_class) server.set_app(app) return server make_server函数默认使用的服务器类为WSGI Server，调用了构造函数（但是它的构造函数到底藏在哪一层服务器上呢？），相对应的使用WSGIRequestHandler 类作为请求的处理类（这两个类都定义在wsgiref.simple_server模块中），在实例化一个WSGI Server后设置它的application后返回该实例。 server_class=WSGIServer WSGI Server作为一个服务器，自然免不了要调用socket来建立TCP连接，因此这里的WSGI Server是基于Python的内置网络库BaseHTTPServer.py以及SocketServer.py实现的。 WSGI Server继承了HTTPServer,HTTPServer继承了TCPServer,TCPServer继承了BaseServer，在 BaseServerr中有handle_request函数 12345678910111213141516171819#SocketServer.pydef handle_request(self): """Handle one request, possibly blocking. Respects self.timeout. """ # Support people who used socket.settimeout() to escape # handle_request before self.timeout was available. timeout = self.socket.gettimeout() if timeout is None: timeout = self.timeout #self.timeout是BaseServer类的属性，默认是None elif self.timeout is not None: timeout = min(timeout, self.timeout) fd_sets = _eintr_retry(select.select, [self], [], [], timeout) #处理EINTR，当捕获到某个信号且相应信号处理函数返回时，这个系统调用被中断，调用返回错误，设置errno为EINTR。 if not fd_sets[0]: self.handle_timeout() return self._handle_request_noblock() 12345678def _eintr_retry(func, *args): """restart a system call interrupted by EINTR""" while True: try: return func(*args) except (OSError, select.error) as e: if e.args[0] != errno.EINTR: rais 1234567891011121314151617181920#SocketServer.pydef _handle_request_noblock(self): """Handle one request, without blocking. I assume that select.select has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). """ try: request, client_address = self.get_request() except socket.error: return if self.verify_request(request, client_address): try: self.process_request(request, client_address) except: self.handle_error(request, client_address) self.shutdown_request(request) else: self.shutdown_request(request) 关于使用select解决EINTR错误请参考这里：PEP 475 – Retry system calls failing with EINTR 因为我们把timeout设置为None，导致select.select永远不会超时，因此如果一直没有客户端连接服务器，服务器就会阻塞在select函数。当一个EINTR错误提出时，select可以重复调用。 通过select函数当我们确认已经收到了来自客户端的请求连接，此时调用accept函数不会阻塞时，于是调用handle_request_noblock函数,在函数中再依次调用了verify_request, process_request, finish_request。 1234567891011121314151617181920212223242526#SocketServer.py def get_request(self): """Get the request and client address from the socket. May be overridden. """ return self.socket.accept() #定义在TCPServerdef verify_request(self, request, client_address): """Verify the request. May be overridden. Return True if we should proceed with this request. """ return Truedef process_request(self, request, client_address): """Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. """ self.finish_request(request, client_address) self.shutdown_request(request)def finish_request(self, request, client_address): """Finish one request by instantiating RequestHandlerClass.""" self.RequestHandlerClass(request, client_address, self)def shutdown_request(self, request): """Called to shutdown and close an individual request.""" self.close_request(request)def close_request(self, request): """Called to clean up an individual request.""" pass handle_request——-&gt;handle_request_noblock——–&gt;get_request——–&gt;verify_request——-&gt; process_request———&gt;finish_request———&gt;RequestHandlerClass RequestHandlerClass在simple_server 传入的是WSGIRequestHandler handler_class=WSGIRequestHandler RequestHandlerClass主要用于处理请求，生成一些必要的环境参数之后才传给负责发送响应请求的ServerHandler WSGIRequestHandler的handle()继承如下，最后追踪到wsgiref/handles.py:BaseHandler 123456789101112131415161718192021222324252627282930313233def run(self, application): """Invoke the application""" # Note to self: don't move the close()! Asynchronous servers shouldn't # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you'll break asynchronous servers by # prematurely closing. Async servers must return from 'run()' without # closing if there might still be output to iterate over. try: self.setup_environ() self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out. def finish_response(self): """Send any iterable data, then close self and the iterable Subclasses intended for use in asynchronous servers will want to redefine this method, such that it sets up callbacks in the event loop to iterate over the data, and to call 'self.close()' once the response is finished. """ try: if not self.result_is_file() or not self.sendfile(): for data in self.result: self.write(data) self.finish_content() finally: self.close() ServerHandler函数主要功能集中在run函数上，同时start_response函数也定义在同一文件中，start_response函数（在application中调用）也必须要按照PEP-333标准定义 最终所有的数据都在finish_response()中写回给客户端。finish_response函数调用了write函数，write函数每次调用时都会检查headers是否已发送，否则先发送headers在发送data。 start_response函数源码 12345678910111213141516171819202122232425def start_response(self, status, headers,exc_info=None): """'start_response()' callable as specified by PEP 333""" if exc_info: try: if self.headers_sent: # Re-raise original exception if headers sent raise exc_info[0], exc_info[1], exc_info[2] finally: exc_info = None # avoid dangling circular ref elif self.headers is not None: raise AssertionError("Headers already set!") assert type(status) is StringType,"Status must be a string" assert len(status)&gt;=4,"Status must be at least 4 characters" assert int(status[:3]),"Status message must begin w/3-digit code" assert status[3]==" ", "Status message must have a space after code" if __debug__: for name,val in headers: assert type(name) is StringType,"Header names must be strings" assert type(val) is StringType,"Header values must be strings" assert not is_hop_by_hop(name),"Hop-by-hop headers not allowed" self.status = status self.headers = self.headers_class(headers) return self.write start_response函数主要用于检测headers是不是已经发送了，如果发送了必须提出异常，同时检测headers是否有不规范的地方，最后返回一个write函数（用于向套接字相关文件写入数据，PEP要求）。 参考：https://segmentfault.com/a/1190000003069785 http://blog.csdn.net/laughing2333/article/details/51288660 http://blog.csdn.net/sraing/article/details/8455242 https://www.python.org/dev/peps/pep-3333/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（2）]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%882%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 首先从控制节点入手，neutron-server包括 neutron-server：neutron\cmd\eventlet\server:main neutron-rpc-server：neutron\cmd\eventlet\server:main_rpc_eventlet两部分 本文主要描述Paste + PasteDeploy + Routes + WebOb实现neutron-server的api服务过程。 123456789101112131415#/neutron/cmd/eventlet/server/__init__.pyfrom oslo_config import cfgfrom neutron import serverfrom neutron.server import rpc_eventletfrom neutron.server import wsgi_eventletfrom neutron.server import wsgi_pecandef main(): server.boot_server(_main_neutron_server)def _main_neutron_server(): if cfg.CONF.web_framework == 'legacy': wsgi_eventlet.eventlet_wsgi_server()# 使用原先实现 eventlet_wsgi_server 启动服务 else: wsgi_pecan.pecan_wsgi_server()#使用新实现 Pecan WSGI server启动服务def main_rpc_eventlet(): server.boot_server(rpc_eventlet.eventlet_rpc_server) 这段代码是控制节点的核心，包含了neutron-server和neutron-rpc-server，其任务也即：api服务和rpc服务，包括RPC-server的创建，RPC-client的创建，WSGI server的创建。 server.boot_server()代码如下： 1234567891011121314151617181920#/neutron/server/__init__.pyimport sysfrom oslo_config import cfgfrom neutron._i18n import _from neutron.common import configdef boot_server(server_func): # the configuration will be read into the cfg.CONF global data structure config.init(sys.argv[1:]) config.setup_logging() config.set_config_defaults() if not cfg.CONF.config_file: sys.exit(_("ERROR: Unable to find configuration file via the default" " search paths (~/.neutron/, ~/, /etc/neutron/, /etc/) and" " the '--config-file' option!")) try: server_func() except KeyboardInterrupt: pass except RuntimeError as e: sys.exit(_("ERROR: %s") % e) ​ boot_server做的事情就是读取neutron\common\config配置文件，做初始化，包括日志，配置等，然后 server_func()，也即_main_neutron_server()启动。因为在api服务实现上目前有两种方式，”legacy”和”pecan”,根据读取的neutron\common\config中的配置来启动api服务。我们看”legacy”模式，也即 Paste + PasteDeploy + Routes + WebOb，这几个不同的模块分别负责应用的WSGI化、URL路由和请求处理等功能。 wsgi_eventlet.eventlet_wsgi_server() 123456789#/neutron/server/wsgi_eventlet.pyimport eventletfrom oslo_log import logfrom neutron._i18n import _LIfrom neutron import serviceLOG = log.getLogger(__name__)def eventlet_wsgi_server(): neutron_api = service.serve_wsgi(service.NeutronApiService) start_api_and_rpc_workers(neutron_api) neutron_api = service.serve_wsgi(service.NeutronApiService)，主要是创建服务，并启动。关键在于NeutronApiService，NeutronApiService继承了WsgiService类，调用了它的start方法，即_run_wsgi(app_name) 1234567891011121314151617181920212223242526272829303132333435363738394041424344#/neutron/service.pydef serve_wsgi(cls): try: service = cls.create() # create(cls, app_name='neutron') service.start() # _run_wsgi(self.app_name) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_LE('Unrecoverable error: please check log ' 'for details.')) return service#/neutron/service.py：NeutronApiServiceclass NeutronApiService(WsgiService): """Class for neutron-api service.""" @classmethod def create(cls, app_name='neutron'): # Setup logging early, supplying both the CLI options and the # configuration mapping from the config file # We only update the conf dict for the verbose and debug # flags. Everything else must be set up in the conf file... # Log the options used when starting if we're in debug mode... config.setup_logging() service = cls(app_name) return service #/neutron/service.py：WsgiServiceclass WsgiService(object): """Base class for WSGI based services. For each api you define, you must also define these flags: :&lt;api&gt;_listen: The address on which to listen :&lt;api&gt;_listen_port: The port on which to listen """ def __init__(self, app_name): self.app_name = app_name self.wsgi_app = None def start(self): self.wsgi_app = _run_wsgi(self.app_name) def wait(self): self.wsgi_app.wait() #/neutron/service.py def _run_wsgi(app_name): app = config.load_paste_app(app_name) if not app: LOG.error(_LE('No known API applications configured.')) return return run_wsgi_app(app) _run_wsgi(app_name)包括load_paste_app()和run_wsgi_app()。load_paste_app()从api-paste.ini文件加载composite为neutron的相关信息，生成一个应用。这个很关键，我们看看api-paste.ini文件 12345678910111213141516171819202122232425262728293031323334[composite:neutron]use = egg:Paste#urlmap/: neutronversions/v2.0: neutronapi_v2_0[composite:neutronapi_v2_0]use = call:neutron.auth:pipeline_factorynoauth = cors request_id catch_errors extensions neutronapiapp_v2_0keystone = cors request_id catch_errors authtoken keystonecontext extensions neutronapiapp_v2_0[filter:request_id]paste.filter_factory = oslo_middleware:RequestId.factory[filter:catch_errors]paste.filter_factory = oslo_middleware:CatchErrors.factory[filter:cors]paste.filter_factory = oslo_middleware.cors:filter_factoryoslo_config_project = neutron[filter:keystonecontext]paste.filter_factory = neutron.auth:NeutronKeystoneContext.factory[filter:authtoken]paste.filter_factory = keystonemiddleware.auth_token:filter_factory[filter:extensions]paste.filter_factory = neutron.api.extensions:plugin_aware_extension_middleware_factory[app:neutronversions]paste.app_factory = neutron.api.versions:Versions.factory[app:neutronapiapp_v2_0]paste.app_factory = neutron.api.v2.router:APIRouter.factory 最终调用了/v2.0: neutronapi_v2_0，具体是neutron.api.v2.router:APIRouter.factory，v2版api的实现是在neutron.api.v2.router:APIRouter，位于neutron\neutron\api\v2\router.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class APIRouter(base_wsgi.Router): @classmethod def factory(cls, global_config, **local_config): return cls(**local_config) def __init__(self, **local_config): mapper = routes_mapper.Mapper() #获取NeutornManage的core_plugin，这个定义在/etc/neutron/neutron.conf, #比如我的是core_plugin = ml2,service_plugins = router plugin = manager.NeutronManager.get_plugin() #扫描特定路径下的extensions ext_mgr = extensions.PluginAwareExtensionManager.get_instance() #扩展资源，包括networks，subnets,ports,subnetpools ext_mgr.extend_resources("2.0", attributes.RESOURCE_ATTRIBUTE_MAP) col_kwargs = dict(collection_actions=COLLECTION_ACTIONS, member_actions=MEMBER_ACTIONS) #定义的局部方法 def _map_resource(collection, resource, params, parent=None): allow_bulk = cfg.CONF.allow_bulk allow_pagination = cfg.CONF.allow_pagination allow_sorting = cfg.CONF.allow_sorting controller = base.create_resource( collection, resource, plugin, params, allow_bulk=allow_bulk, parent=parent, allow_pagination=allow_pagination, allow_sorting=allow_sorting) path_prefix = None if parent: path_prefix = "/%s/&#123;%s_id&#125;/%s" % (parent['collection_name'], parent['member_name'], collection) mapper_kwargs = dict(controller=controller, requirements=REQUIREMENTS, path_prefix=path_prefix, **col_kwargs) return mapper.collection(collection, resource, **mapper_kwargs) mapper.connect('index', '/', controller=Index(RESOURCES)) for resource in RESOURCES: _map_resource(RESOURCES[resource], resource, attributes.RESOURCE_ATTRIBUTE_MAP.get( RESOURCES[resource], dict())) resource_registry.register_resource_by_name(resource) for resource in SUB_RESOURCES: _map_resource(SUB_RESOURCES[resource]['collection_name'], resource, attributes.RESOURCE_ATTRIBUTE_MAP.get( SUB_RESOURCES[resource]['collection_name'], dict()), SUB_RESOURCES[resource]['parent']) # Certain policy checks require that the extensions are loaded # and the RESOURCE_ATTRIBUTE_MAP populated before they can be # properly initialized. This can only be claimed with certainty # once this point in the code has been reached. In the event # that the policies have been initialized before this point, # calling reset will cause the next policy check to # re-initialize with all of the required data in place. policy.reset() super(APIRouter, self).__init__(mapper) 我们好好分析上述代码做了什么，这是很关键的部分。 创建plugin(包括core plugin和service plugin) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#/neutron/api/v2/router.py:APIRouter plugin = manager.NeutronManager.get_plugin()#/neutron/manager.py:NeutronManager @classmethod def get_plugin(cls): # Return a weakref to minimize gc-preventing references. return weakref.proxy(cls.get_instance().plugin)#/neutron/manager.py:NeutronManager @classmethod def get_instance(cls): # double checked locking if not cls.has_instance(): cls._create_instance() return cls._instance#/neutron/manager.py:NeutronManager @classmethod @utils.synchronized("manager") def _create_instance(cls): if not cls.has_instance(): cls._instance = cls()#/neutron/manager.py:NeutronManagerclass NeutronManager(object): """Neutron's Manager class. Neutron's Manager class is responsible for parsing a config file and instantiating the correct plugin that concretely implements neutron_plugin_base class. The caller should make sure that NeutronManager is a singleton. """ _instance = None def __init__(self, options=None, config_file=None): # If no options have been provided, create an empty dict if not options: options = &#123;&#125; msg = validate_pre_plugin_load() if msg: LOG.critical(msg) raise Exception(msg) # NOTE(jkoelker) Testing for the subclass with the __subclasshook__ # breaks tach monitoring. It has been removed # intentionally to allow v2 plugins to be monitored # for performance metrics. plugin_provider = cfg.CONF.core_plugin LOG.info(_LI("Loading core plugin: %s"), plugin_provider) self.plugin = self._get_plugin_instance(CORE_PLUGINS_NAMESPACE, plugin_provider) msg = validate_post_plugin_load() if msg: LOG.critical(msg) raise Exception(msg) # core plugin as a part of plugin collection simplifies # checking extensions # TODO(enikanorov): make core plugin the same as # the rest of service plugins self.service_plugins = &#123;constants.CORE: self.plugin&#125; self._load_service_plugins() # Used by pecan WSGI self.resource_plugin_mappings = &#123;&#125; self.resource_controller_mappings = &#123;&#125; ​ get_plugin函数返回NeutronManager的plugin(core plugin)的弱引用，那么core plugin是什么对象呢?core plugin和service plugin在NeutronManager的init函数创建的。其中core plugin和service plugin分别根据neutron.conf配置文件中的core_plugin参数和service_plugins参数进行创建。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#/neutron/manager.py:NeutronManager def _get_plugin_instance(self, namespace, plugin_provider): plugin_class = self.load_class_for_provider(namespace, plugin_provider) return plugin_class() @staticmethod#/neutron/manager.py:NeutronManager def load_class_for_provider(namespace, plugin_provider): """Loads plugin using alias or class name :param namespace: namespace where alias is defined :param plugin_provider: plugin alias or class name :returns plugin that is loaded :raises ImportError if fails to load plugin """ try: return utils.load_class_by_alias_or_classname(namespace, plugin_provider) except ImportError: raise ImportError(_("Plugin '%s' not found.") % plugin_provider)#/neutron/common/utils.py def load_class_by_alias_or_classname(namespace, name):"""Load class using stevedore alias or the class name:param namespace: namespace where the alias is defined:param name: alias or class name of the class to be loaded:returns class if calls can be loaded:raises ImportError if class cannot be loaded"""if not name: LOG.error(_LE("Alias or class name is not set")) raise ImportError(_("Class not found."))try: # Try to resolve class by alias mgr = driver.DriverManager(namespace, name) # 利用stevedore模块创建core_plugin class_to_load = mgr.driverexcept RuntimeError: e1_info = sys.exc_info() # Fallback to class name try: class_to_load = importutils.import_class(name) except (ImportError, ValueError): LOG.error(_LE("Error loading class by alias"), exc_info=e1_info) LOG.error(_LE("Error loading class by class name"), exc_info=True) raise ImportError(_("Class not found."))return class_to_load 在def load_class_by_alias_or_classname(namespace, name)中我们调用mgr = driver.DriverManager(namespace, name)加载core_plugin，即ml2。 在配置文件setup.cfg中ml2 = neutron.plugins.ml2.plugin:Ml2Plugin，我们查看它的源码，如下： 123456789101112131415#/neutron/plugins/ml2/plugin.py:Ml2Plugin def __init__(self): # First load drivers, then initialize DB, then initialize drivers self.type_manager = managers.TypeManager() self.extension_manager = managers.ExtensionManager() self.mechanism_manager = managers.MechanismManager() super(Ml2Plugin, self).__init__() self.type_manager.initialize() self.extension_manager.initialize() self.mechanism_manager.initialize() self._setup_dhcp() self._start_rpc_notifiers() self.add_agent_status_check(self.agent_health_check) self._verify_service_plugins_requirements() LOG.info(_LI("Modular L2 Plugin initialization complete")) 注意： PasteDeployment是一种机制或者说是一种设计模式，它用于在应用WSGI Application和Server提供一个联系的桥梁，并且为用户提供一个接口，当配置好PasteDeployment之后，用户只需调用loadapp方法就可以使用现有的WSGI Application，而保持了WSGIApplication对用户的透明性。 12345678910111213141516171819202122232425#/neutron/common/config.py def load_paste_app(app_name): """Builds and returns a WSGI app from a paste config file. :param app_name: Name of the application to load """ loader = wsgi.Loader(cfg.CONF) app = loader.load_app(app_name) return app#oslo_service/wsgi.py def load_app(self, name): """Return the paste URLMap wrapped WSGI application. :param name: Name of the application to load. :returns: Paste URLMap object wrapping the requested application. :raises: PasteAppNotFound """ try: LOG.debug("Loading app %(name)s from %(path)s", &#123;'name': name, 'path': self.config_path&#125;) return deploy.loadapp("config:%s" % self.config_path, name=name) except LookupError: LOG.exception(_LE("Couldn't lookup app: %s"), name) raise PasteAppNotFound(name=name, path=self.config_path) run_wsgi_app()运行刚创建的应用。它首先实例化一个Server对象，然后调用start()方法将其启动,也即是launch()方法。在传入的workers参数，通过get_api_workers()获取，如果neutron.conf的api_workers没有配置，它会传入cpu数目的workers，达到最佳性能。 12345678910111213141516171819202122232425#/neutron/service.py def run_wsgi_app(app): server = wsgi.Server("Neutron") server.start(app, cfg.CONF.bind_port, cfg.CONF.bind_host, workers=_get_api_workers()) LOG.info(_LI("Neutron service started, listening on %(host)s:%(port)s"), &#123;'host': cfg.CONF.bind_host, 'port': cfg.CONF.bind_port&#125;) return serverdef _get_api_workers(): workers = cfg.CONF.api_workers if workers is None: workers = processutils.get_worker_count() return workers#neutron/wsgi.py def start(self, application, port, host='0.0.0.0', workers=0): """Run a WSGI server with the given application.""" self._host = host self._port = port backlog = CONF.backlog self._socket = self._get_socket(self._host, self._port, backlog=backlog) self._launch(application, workers) _launch()方法 123456789101112131415161718192021def _launch(self, application, workers=0): service = WorkerService(self, application, self.disable_ssl) if workers &lt; 1: # The API service should run in the current process. # workers小于1直接运行在当前的进程 self._server = service # Dump the initial option values cfg.CONF.log_opt_values(LOG, logging.DEBUG) service.start() systemd.notify_once() else: # dispose the whole pool before os.fork, otherwise there will # be shared DB connections in child processes which may cause # DB errors. api.dispose() # The API service runs in a number of child processes. # Minimize the cost of checking for child exit by extending the # wait interval past the default of 0.01s. self._server = common_service.ProcessLauncher(cfg.CONF, wait_interval=1.0) self._server.launch_service(service, workers=workers)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron架构]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[neutron源码解读（1）]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%881%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文是基于Mitaka版本（20170227最新的代码）学习。 Neutron是OpenStack中用于管理网络的项目。neutron代码的入口配置文件neutron/setup.cfg，从[entry_points]可以看到整个项目服务的结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125[entry_points]console_scripts = neutron-bgp-dragent = neutron.cmd.eventlet.agents.bgp_dragent:main neutron-db-manage = neutron.db.migration.cli:main neutron-debug = neutron.debug.shell:main neutron-dhcp-agent = neutron.cmd.eventlet.agents.dhcp:main // neutron-keepalived-state-change = neutron.cmd.keepalived_state_change:main neutron-ipset-cleanup = neutron.cmd.ipset_cleanup:main neutron-l3-agent = neutron.cmd.eventlet.agents.l3:main // neutron-linuxbridge-agent = neutron.cmd.eventlet.plugins.linuxbridge_neutron_agent:main neutron-linuxbridge-cleanup = neutron.cmd.linuxbridge_cleanup:main neutron-macvtap-agent = neutron.cmd.eventlet.plugins.macvtap_neutron_agent:main neutron-metadata-agent = neutron.cmd.eventlet.agents.metadata:main neutron-netns-cleanup = neutron.cmd.netns_cleanup:main neutron-ns-metadata-proxy = neutron.cmd.eventlet.agents.metadata_proxy:main neutron-openvswitch-agent = neutron.cmd.eventlet.plugins.ovs_neutron_agent:main // neutron-ovs-cleanup = neutron.cmd.ovs_cleanup:main neutron-pd-notify = neutron.cmd.pd_notify:main neutron-server = neutron.cmd.eventlet.server:main // neutron-rpc-server = neutron.cmd.eventlet.server:main_rpc_eventlet // neutron-rootwrap = oslo_rootwrap.cmd:main neutron-rootwrap-daemon = oslo_rootwrap.cmd:daemon neutron-usage-audit = neutron.cmd.eventlet.usage_audit:main neutron-metering-agent = neutron.cmd.eventlet.services.metering_agent:main neutron-sriov-nic-agent = neutron.cmd.eventlet.plugins.sriov_nic_neutron_agent:main neutron-sanity-check = neutron.cmd.sanity_check:mainneutron.core_plugins = ml2 = neutron.plugins.ml2.plugin:Ml2Plugin //neutron.service_plugins = dummy = neutron.tests.unit.dummy_plugin:DummyServicePlugin router = neutron.services.l3_router.l3_router_plugin:L3RouterPlugin // firewall = neutron_fwaas.services.firewall.fwaas_plugin:FirewallPlugin // lbaas = neutron_lbaas.services.loadbalancer.plugin:LoadBalancerPlugin vpnaas = neutron_vpnaas.services.vpn.plugin:VPNDriverPlugin metering = neutron.services.metering.metering_plugin:MeteringPlugin neutron.services.firewall.fwaas_plugin.FirewallPlugin = neutron_fwaas.services.firewall.fwaas_plugin:FirewallPlugin neutron.services.loadbalancer.plugin.LoadBalancerPlugin = neutron_lbaas.services.loadbalancer.plugin:LoadBalancerPlugin neutron.services.vpn.plugin.VPNDriverPlugin = neutron_vpnaas.services.vpn.plugin:VPNDriverPlugin qos = neutron.services.qos.qos_plugin:QoSPlugin bgp = neutron.services.bgp.bgp_plugin:BgpPlugin tag = neutron.services.tag.tag_plugin:TagPlugin flavors = neutron.services.flavors.flavors_plugin:FlavorsPlugin auto_allocate = neutron.services.auto_allocate.plugin:Plugin network_ip_availability = neutron.services.network_ip_availability.plugin:NetworkIPAvailabilityPlugin timestamp_core = neutron.services.timestamp.timestamp_plugin:TimeStampPluginneutron.qos.notification_drivers = message_queue = neutron.services.qos.notification_drivers.message_queue:RpcQosServiceNotificationDriver //neutron.ml2.type_drivers = flat = neutron.plugins.ml2.drivers.type_flat:FlatTypeDriver local = neutron.plugins.ml2.drivers.type_local:LocalTypeDriver vlan = neutron.plugins.ml2.drivers.type_vlan:VlanTypeDriver geneve = neutron.plugins.ml2.drivers.type_geneve:GeneveTypeDriver gre = neutron.plugins.ml2.drivers.type_gre:GreTypeDriver vxlan = neutron.plugins.ml2.drivers.type_vxlan:VxlanTypeDriver //neutron.ml2.mechanism_drivers = logger = neutron.tests.unit.plugins.ml2.drivers.mechanism_logger:LoggerMechanismDriver test = neutron.tests.unit.plugins.ml2.drivers.mechanism_test:TestMechanismDriver linuxbridge = neutron.plugins.ml2.drivers.linuxbridge.mech_driver.mech_linuxbridge:LinuxbridgeMechanismDriver macvtap = neutron.plugins.ml2.drivers.macvtap.mech_driver.mech_macvtap:MacvtapMechanismDriver openvswitch = neutron.plugins.ml2.drivers.openvswitch.mech_driver.mech_openvswitch:OpenvswitchMechanismDriver l2population = neutron.plugins.ml2.drivers.l2pop.mech_driver:L2populationMechanismDriver sriovnicswitch = neutron.plugins.ml2.drivers.mech_sriov.mech_driver.mech_driver:SriovNicSwitchMechanismDriver fake_agent = neutron.tests.unit.plugins.ml2.drivers.mech_fake_agent:FakeAgentMechanismDriverneutron.ml2.extension_drivers = test = neutron.tests.unit.plugins.ml2.drivers.ext_test:TestExtensionDriver testdb = neutron.tests.unit.plugins.ml2.drivers.ext_test:TestDBExtensionDriver port_security = neutron.plugins.ml2.extensions.port_security:PortSecurityExtensionDriver qos = neutron.plugins.ml2.extensions.qos:QosExtensionDriver dns = neutron.plugins.ml2.extensions.dns_integration:DNSExtensionDriverML2neutron.openstack.common.cache.backends = memory = neutron.openstack.common.cache._backends.memory:MemoryBackendneutron.ipam_drivers = fake = neutron.tests.unit.ipam.fake_driver:FakeDriver internal = neutron.ipam.drivers.neutrondb_ipam.driver:NeutronDbPoolneutron.agent.l2.extensions = qos = neutron.agent.l2.extensions.qos:QosAgentExtensionneutron.qos.agent_drivers = ovs = neutron.plugins.ml2.drivers.openvswitch.agent.extension_drivers.qos_driver:QosOVSAgentDriver sriov = neutron.plugins.ml2.drivers.mech_sriov.agent.extension_drivers.qos_driver:QosSRIOVAgentDriver linuxbridge = neutron.plugins.ml2.drivers.linuxbridge.agent.extension_drivers.qos_driver:QosLinuxbridgeAgentDriverneutron.agent.linux.pd_drivers = dibbler = neutron.agent.linux.dibbler:PDDibblerneutron.services.external_dns_drivers = designate = neutron.services.externaldns.drivers.designate.driver:Designate# These are for backwards compat with Icehouse notification_driver configuration values# TODO(mriedem): Remove these once liberty-eol happens.oslo.messaging.notify.drivers = neutron.openstack.common.notifier.log_notifier = oslo_messaging.notify._impl_log:LogDriver neutron.openstack.common.notifier.no_op_notifier = oslo_messaging.notify._impl_noop:NoOpDriver neutron.openstack.common.notifier.test_notifier = oslo_messaging.notify._impl_test:TestDriver neutron.openstack.common.notifier.rpc_notifier2 = oslo_messaging.notify.messaging:MessagingV2Driver neutron.openstack.common.notifier.rpc_notifier = oslo_messaging.notify.messaging:MessagingDriveroslo.config.opts = neutron = neutron.opts:list_opts neutron.agent = neutron.opts:list_agent_opts neutron.base.agent = neutron.opts:list_base_agent_opts neutron.bgp.agent = neutron.services.bgp.common.opts:list_bgp_agent_opts neutron.db = neutron.opts:list_db_opts neutron.dhcp.agent = neutron.opts:list_dhcp_agent_opts neutron.extensions = neutron.opts:list_extension_opts neutron.l3.agent = neutron.opts:list_l3_agent_opts neutron.metadata.agent = neutron.opts:list_metadata_agent_opts neutron.metering.agent = neutron.opts:list_metering_agent_opts neutron.ml2 = neutron.opts:list_ml2_conf_opts neutron.ml2.linuxbridge.agent = neutron.opts:list_linux_bridge_opts neutron.ml2.macvtap.agent = neutron.opts:list_macvtap_opts neutron.ml2.ovs.agent = neutron.opts:list_ovs_opts neutron.ml2.sriov = neutron.opts:list_ml2_conf_sriov_opts neutron.ml2.sriov.agent = neutron.opts:list_sriov_agent_opts neutron.qos = neutron.opts:list_qos_opts nova.auth = neutron.opts:list_auth_optsoslo.config.opts.defaults = neutron = neutron.common.config:set_cors_middleware_defaultsneutron.db.alembic_migrations = neutron = neutron.db.migration:alembic_migrationsneutron.interface_drivers = ivs = neutron.agent.linux.interface:IVSInterfaceDriver linuxbridge = neutron.agent.linux.interface:BridgeInterfaceDriver null = neutron.agent.linux.interface:NullDriver openvswitch = neutron.agent.linux.interface:OVSInterfaceDriverneutron.agent.firewall_drivers = noop = neutron.agent.firewall:NoopFirewallDriver iptables = neutron.agent.linux.iptables_firewall:IptablesFirewallDriver iptables_hybrid = neutron.agent.linux.iptables_firewall:OVSHybridIptablesFirewallDriver openvswitch = neutron.agent.linux.openvswitch_firewall:OVSFirewallDriver 我们按照以下顺序学习源码： 控制节点服务：neutron-server neutron-server 是Neutron启动neutron-server的api服务，负责接收用户的RESTful API请求根据setup.cfg文件可以看出neutron代码路径是neutron\cmd\eventlet\server:main neutron-rpc-server 是Neutron中启动neutron-server的rpc服务，将请求分发给各种agent。代码路径是neutron\cmd\eventlet\server:main_rpc_eventlet 前两个部分组成了neutron-server服务，即是控制节点要启动的服务。 计算节点服务：neutron-openvswitch-agent neutron-openvswitch-agent neutron-openvswitch-agent：Open vSwitch Agent部署在计算节点或者网络节点上，进行管理OVS虚拟交换机。根据setup.cfg文件可以看出neutron-openvswitch-agent的代码路径是neutron\cmd\eventlet\plugins\ovs_neutron_agent:main 网络节点服务：neutron-openvswitch-agent neutron-l3-agent neutron-dhcp-agent neutron-l3-agent l3 agent部署在计算节点或者网络节点上,负责3层虚拟网络的管理。根据setup.cfg文件可以看出neutron-l3-agent的代码路径是neutron\cmd\eventlet\agents\l3:main neutron-dhcp-agent ml2 router firewall message_queue]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线程同步工具CountDownLatch，CyclicBarrier和Semaphore的用法]]></title>
      <url>%2F2017%2F02%2F25%2F%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7CountDownLatch%EF%BC%8CCyclicBarrier%E5%92%8CSemaphore%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
      <content type="text"><![CDATA[CountDownLatch​ CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 伪代码为： ​ Main thread start​ Create CountDownLatch for N threads​ Create and start N threads​ Main thread wait on latch​ N threads completes there tasks are returns​ Main thread resume execution 主要方法： public CountDownLatch(int count); public void countDown(); public void await() throws InterruptedException CountDownLatch实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package Demo;import java.util.concurrent.CountDownLatch;public abstract class BaseHealthChecker implements Runnable&#123; private CountDownLatch latch; private String name; private boolean isServiceUp; public BaseHealthChecker(CountDownLatch latch, String name) &#123; super(); this.latch = latch; this.name = name; this.isServiceUp=false; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public boolean isServiceUp() &#123; return isServiceUp; &#125; public void setServiceUp(boolean isServiceUp) &#123; this.isServiceUp = isServiceUp; &#125; public abstract void checkService(); @Override public void run() &#123; // TODO Auto-generated method stub try &#123; checkService(); isServiceUp=true; &#125; catch (Throwable t) &#123; // TODO: handle exception t.printStackTrace(System.err); isServiceUp=false; &#125; finally&#123; if(latch!=null)&#123; latch.countDown(); &#125; &#125; &#125; &#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class CacheHealthChecker extends BaseHealthChecker &#123; public CacheHealthChecker(CountDownLatch latch) &#123; super(latch, "Cache Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class DatabaseHealthChecker extends BaseHealthChecker &#123; public DatabaseHealthChecker(CountDownLatch latch) &#123; super(latch, "Database Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class NetworkHealthChecker extends BaseHealthChecker &#123; public NetworkHealthChecker(CountDownLatch latch) &#123; super(latch, "Network Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+" is Up"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package Demo;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ApplicationStartupUtil &#123; private static List&lt;BaseHealthChecker&gt; services; private static CountDownLatch latch; private final static ApplicationStartupUtil app=new ApplicationStartupUtil(); public ApplicationStartupUtil()&#123; &#125; public static ApplicationStartupUtil getInstance()&#123; return app; &#125; public static boolean checkExternalService()&#123; boolean re=true; latch=new CountDownLatch(3); services=new ArrayList&lt;BaseHealthChecker&gt;(); services.add(new NetworkHealthChecker(latch)); services.add(new CacheHealthChecker(latch)); services.add(new DatabaseHealthChecker(latch)); ExecutorService executors=Executors.newFixedThreadPool(services.size()); for(final BaseHealthChecker v: services)&#123; executors.execute(v); &#125; executors.shutdown(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for(final BaseHealthChecker v:services)&#123; if(! v.isServiceUp())&#123; re=false; System.out.println("All services checked ,result is "+re); &#125; &#125; System.out.println("All services checked ,result is "+re); return re; &#125;&#125; 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; boolean re=false; ApplicationStartupUtil.checkExternalService(); &#125;&#125;//输出：Checking Network ServiceChecking Cache ServiceChecking Database ServiceNetwork Service is UpCache Serviceis UpDatabase Serviceis UpAll services checked ,result is true CyclicBarrier​ CyclicBarrier 类有一个整数初始值，此值表示将在同一点同步的线程数量。当其中一个线程到达确定点，它会调用await() 方法来等待其他线程。此时CyclicBarrier阻塞该线程进入休眠等待其他线程的到达。当最后一个线程调用CyclicBarrier 类的await() 方法，它唤醒所有等待的线程并继续执行它们的任务。 ​ CountDownLatch和CyclicBarrier的区别在于：CountDownLatch 适用于一组线程和另一个主线程之间的工作协作。一个主线程等待一组工作线程的任务完毕才继续它的执行是使用 CountDownLatch 的主要场景；CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。CyclicBarrier 的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的； CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 CyclicBarrier实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.Random;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class DemoCyclicBarrier &#123; public static void main(String[] args) &#123; int thread_num=5; CyclicBarrier cyclicBarrier=new CyclicBarrier(thread_num, new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("Internal Barrier"); &#125; &#125;); ExecutorService executor=Executors.newFixedThreadPool(thread_num); for (int i=0;i&lt;5;i++)&#123; executor.execute(new worker("worker "+i, cyclicBarrier)); &#125; executor.shutdown(); &#125;&#125;class worker implements Runnable&#123; private String name; private CyclicBarrier cyclicbarrier; public worker(String name, CyclicBarrier cyclicBarrier)&#123; this.name=name; this.cyclicbarrier=cyclicBarrier; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; Thread.sleep(1000 * (new Random()).nextInt(8)); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker "+this.getName()+" is waiting"); try &#123; cyclicbarrier.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker"+this.getName()+" is working"); &#125; &#125; Semaphore​ Semaphore 直译是信号量，可能称它是许可量更容易理解。当然，因为在计算机科学中这个名字由来已久，所以不能乱改。它的功能比较好理解，就是通过构造函数设定一个数量的许可，然后通过 acquire 方法获得许可，release 方法释放许可。它还有 tryAcquire 和 acquireUninterruptibly 方法，可以根据自己的需要选择。 Semaphore实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); Semaphore semp=new Semaphore(5); for(int i=0;i&lt;10;i++)&#123; exec.execute(new workerThread(i,semp)); &#125; exec.shutdown(); &#125;&#125;class workerThread implements Runnable&#123; private int id ; private Semaphore semp; public workerThread(int id, Semaphore semp) &#123; super(); this.id = id; this.semp = semp; &#125; public int getId() &#123; return id; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; semp.acquire(); System.out.println("workerThread id "+this.getId()+" get Access"); Thread.sleep((long) (Math.random() * 10000)); System.out.println("workerThread id "+this.getId()+" finish the work"); semp.release();//注销该语句后，只会执行5个线程，其他处在阻塞中 &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;//输出(未注销semp.release())workerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 4 get AccessworkerThread id 1 get AccessworkerThread id 1 finish the workworkerThread id 5 get AccessworkerThread id 2 finish the workworkerThread id 6 get AccessworkerThread id 4 finish the workworkerThread id 7 get AccessworkerThread id 6 finish the workworkerThread id 8 get AccessworkerThread id 7 finish the workworkerThread id 9 get AccessworkerThread id 8 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 9 finish the workworkerThread id 5 finish the work//输出(注销semp.release())workerThread id 1 get AccessworkerThread id 4 get AccessworkerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 2 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 4 finish the workworkerThread id 1 finish the work 参考：1.http://www.importnew.com/15731.html 2.http://blog.csdn.net/junshuaizhang/article/details/39580751 3.http://blog.csdn.net/junshuaizhang/article/details/39667289 4.http://developer.51cto.com/art/201403/432095.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之Executor框架和线程池]]></title>
      <url>%2F2017%2F02%2F23%2FJava%E5%B9%B6%E5%8F%91%E4%B9%8BExecutor%E6%A1%86%E6%9E%B6%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[1.基础简介：​ 在Java 5之后，并发编程引入了一堆新的启动、调度和管理线程的API。Executor框架便是Java 5中引入的，其内部使用了线程池机制，它在java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。 ​ Executor框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable等。 Executor接口中之定义了一个方法execute（Runnable command），该方法接收一个Runable实例，它用来执行一个任务，任务即一个实现了Runnable接口的类。 2.ExecutorService接口：​ ExecutorService接口继承自Executor接口，它提供了更丰富的实现多线程的方法，比如，ExecutorService提供了关闭自己的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以调用ExecutorService的shutdown（）方法来平滑地关闭 。在调用该方法之后，它会停止接受任何新的任务且等待已经提交的任务执行完成(已经提交的任务会分两类：一类是已经在执行的，另一类是还没有开始执行的)，当所有已经提交的任务执行完毕后将会关闭ExecutorService。因此我们一般用该接口来实现和管理多线程。 ​ ExecutorService的生命周期包括三种状态：运行、关闭、终止。创建后便进入运行状态，当调用了shutdown（）方法时，便进入关闭状态，此时意味着ExecutorService不再接受新的任务，但它还在执行已经提交了的任务，当素有已经提交了的任务执行完后，便到达终止状态。如果不调用shutdown（）方法，ExecutorService会一直处在运行状态，不断接收新的任务，执行新的任务，服务器端一般不需要关闭它，保持一直运行即可。 3.ExecutorService中submit和execute的区别：接收的参数不一样 submit有返回值，而execute没有 ​ Method submit extends base method Executor.execute by creating and returning a Future that can be used to cancel execution and/or wait for completion. ​ 用到返回值的例子，比如说我有很多个做validation的task，我希望所有的task执行完，然后每个task告诉我它的执行结果，是成功还是失败，如果是失败，原因是什么。然后我就可以把所有失败的原因综合起来发给调用者。 submit方便Exception处理 ​ There is a difference when looking at exception handling. If your tasks throws an exception and if it was submitted with execute this exception will go to the uncaught exception handler (when you don’t have provided one explicitly, the default one will just print the stack trace to System.err). If you submitted the task with submit any thrown exception, checked or not, is then part of the task’s return status. For a task that was submitted with submit and that terminates with an exception, the Future.get will rethrow this exception, wrapped in an ExecutionException. ​ 意思就是如果你在你的task里会抛出checked或者unchecked exception，而你又希望外面的调用者能够感知这些exception并做出及时的处理，那么就需要用到submit，通过捕获Future.get抛出的异常。 ​ 比如说，我有很多更新各种数据的task，我希望如果其中一个task失败，其它的task就不需要执行了。那我就需要catch Future.get抛出的异常，然后终止其它task的执行 下面的Executor执行Runnable任务和Executor执行Callable任务便是execute和submit的例子。 4.Executors（线程池管理类）：​ Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了ExecutorService接口。 public static ExecutorService newCachedThreadPool() 创建一个可缓存的线程池，调用execute将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。 ​ 缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse.如果没有，就建一个新的线程加入池中，缓存型池子通常用于执行一些生存期很短的异步型任务。因此在一些面向连接的daemon型SERVER中用得不多。但对于生存期短的异步任务，它是Executor的首选。能reuse的线程，必须是timeout IDLE内的池中线程，缺省 timeout是60s,超过这个IDLE时长，线程实例将被终止及移出池。注意，放入CachedThreadPool的线程不必担心其结束，超过TIMEOUT不活动，其会自动被终止。 public static ExecutorService newFixedThreadPool(int nThreads) 创建固定数目线程的线程池 ​ newFixedThreadPool与cacheThreadPool差不多，也是能reuse就用，但不能随时建新的线程。其独特之处:任意时间点，最多只能有固定数目的活动线程存在，此时如果有新的线程要建立，只能放在另外的队列中等待，直到当前的线程中某个线程终止直接被移出池子。和cacheThreadPool不同，FixedThreadPool没有IDLE机制（可能也有，但既然文档没提，肯定非常长，类似依赖上层的TCP或UDP IDLE机制之类的），所以FixedThreadPool多数针对一些很稳定很固定的正规并发线程，多用于服务器。从方法的源代码看，cache池和fixed 池调用的是同一个底层池，只不过参数不同:fixed池线程数固定，并且是0秒IDLE（无IDLE）cache池线程数支持0-Integer.MAX_VALUE(显然完全没考虑主机的资源承受能力），60秒IDLE 。 public static ExecutorService newSingleThreadExecutor() 创建一个单线程化的Executor。 ​ 单例线程，任意时间池中只能有一个线程，用的是和cache池和fixed池相同的底层池，但线程数目是1-1,0秒IDLE（无IDLE）。 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) 创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。 ​ 调度型线程池，这个池子里的线程可以按schedule依次delay执行，或周期执行。 一般来说，CachedTheadPool在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的Executor的首选，只有当这种方式会引发问题时（比如需要大量长时间面向连接的线程时），才需要考虑用FixedThreadPool。（该段话摘自《Thinking in Java》第四版） 5.Executor接口执行任务：Executor执行Runnable任务 ​ 通过Executors的以上四个静态工厂方法获得 ExecutorService实例，而后调用该实例的execute（Runnable command）方法即可。一旦Runnable任务传递到execute（）方法，该方法便会自动在一个线程上执行。下面是是Executor执行Runnable任务的示例代码： 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TestCachedThreadPool&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); //ExecutorService executorService = Executors.newFixedThreadPool(3); //ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 5; i++)&#123; executorService.execute(new TestRunnable(i)); &#125; executorService.shutdown(); &#125; &#125; class TestRunnable implements Runnable&#123; private int count ; public TestRunnable(int count)&#123; this.count=count; System.out.println("Create Thread-"+count); &#125; public void run()&#123; System.out.println("线程池中的"+Thread.currentThread().getName() + "被调用来处理Thread-"+count); &#125; &#125; //输出：Create Thread-0Create Thread-1Create Thread-2线程池中的pool-1-thread-1被调用来处理Thread-0Create Thread-3线程池中的pool-1-thread-2被调用来处理Thread-1Create Thread-4线程池中的pool-1-thread-2被调用来处理Thread-4线程池中的pool-1-thread-3被调用来处理Thread-2线程池中的pool-1-thread-4被调用来处理Thread-3 ​ 从结果中可以看出，pool-1-thread-2被调用了两次，这是随机的，execute会首先在线程池中选择一个已有空闲线程来执行任务，如果线程池中没有空闲线程，它便会创建一个新的线程来执行任务 同时也可以配合ThreadFactory接口的使用 123456789101112131415161718192021222324252627282930313233343536ExecutorService daemonThreadFactory = Executors.newCachedThreadPool(new DaemonThreadFactory()); ExecutorService maxPriorityThreadFactory = Executors.newCachedThreadPool(new MaxPriorityThreadFactory()); ExecutorService minPriorityThreadFactory = Executors.newCachedThreadPool(new MinPriorityThreadFactory());//设置后台线程属性class DaemonThreadFactory implements ThreadFactory&#123; @Override public Thread newThread(Runnable arg0) &#123; // TODO Auto-generated method stub Thread t=new Thread(arg0); t.setDaemon(true); return t; &#125; &#125;//设置最高优先级属性class MaxPriorityThreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setPriority(Thread.MAX_PRIORITY); return t; &#125;&#125;//设置最低优先级属性class MinPriorityThreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setPriority(Thread.MIN_PRIORITY); return t; &#125;&#125; Executor执行Callable任务 ​ 在Java 5之后，任务分两类：一类是实现了Runnable接口的类，一类是实现了Callable接口的类。两者都可以被ExecutorService执行，但是Runnable任务没有返回值，而Callable任务有返回值。并且Callable的call()方法只能通过ExecutorService的submit(Callable task) 方法来执行，并且返回一个 Future，是表示任务等待完成的 Future。 ​ Callable接口类似于Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常而Callable又返回结果，而且当获取返回结果时可能会抛出异常。Callable中的call()方法类似Runnable的run()方法，区别同样是有返回值，后者没有。 ​ 当将一个Callable的对象传递给ExecutorService的submit方法，则该call方法自动在一个线程上执行，并且会返回执行结果Future对象。同样，将Runnable的对象传递给ExecutorService的submit方法，则该run方法自动在一个线程上执行，并且会返回执行结果Future对象，但是在该Future对象上调用get方法，将返回null。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import java.util.ArrayList; import java.util.List; import java.util.concurrent.*; public class CallableDemo&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;(); //创建10个任务并执行 for (int i = 0; i &lt; 10; i++)&#123; //使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中 Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i)); //将任务执行结果存储到List中 resultList.add(future); &#125; //遍历任务的结果 for (Future&lt;String&gt; fs : resultList)&#123; try&#123; while(!fs.isDone());//Future返回如果没有完成，则一直循环等待，直到Future返回完成 System.out.println(fs.get()); //打印各个线程（任务）执行的结果 &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125;catch(ExecutionException e)&#123; e.printStackTrace(); &#125;finally&#123; //启动一次顺序关闭，执行以前提交的任务，但不接受新任务 executorService.shutdown(); &#125; &#125; &#125; &#125; class TaskWithResult implements Callable&lt;String&gt;&#123; private int id; public TaskWithResult(int id)&#123; this.id = id; &#125; /** * 任务的具体过程，一旦任务传给ExecutorService的submit方法， * 则该方法自动在一个线程上执行 */ public String call() throws Exception &#123; System.out.println("Task id="+id+" 的call()方法被" + Thread.currentThread().getName()+"自动调用！！"); //该返回结果将被Future的get方法得到 return "Task id="+id+" 的call()方法被自动调用，任务返回的结果是：" + id + ""; &#125; &#125; //输出：Task id=0 的call()方法被pool-1-thread-1自动调用！！Task id=2 的call()方法被pool-1-thread-3自动调用！！Task id=1 的call()方法被pool-1-thread-2自动调用！！Task id=3 的call()方法被pool-1-thread-4自动调用！！Task id=4 的call()方法被pool-1-thread-5自动调用！！Task id=0 的call()方法被自动调用，任务返回的结果是：0Task id=9 的call()方法被pool-1-thread-1自动调用！！Task id=6 的call()方法被pool-1-thread-7自动调用！！Task id=5 的call()方法被pool-1-thread-6自动调用！！Task id=7 的call()方法被pool-1-thread-8自动调用！！Task id=1 的call()方法被自动调用，任务返回的结果是：1Task id=2 的call()方法被自动调用，任务返回的结果是：2Task id=8 的call()方法被pool-1-thread-9自动调用！！Task id=3 的call()方法被自动调用，任务返回的结果是：3Task id=4 的call()方法被自动调用，任务返回的结果是：4Task id=5 的call()方法被自动调用，任务返回的结果是：5Task id=6 的call()方法被自动调用，任务返回的结果是：6Task id=7 的call()方法被自动调用，任务返回的结果是：7Task id=8 的call()方法被自动调用，任务返回的结果是：8Task id=9 的call()方法被自动调用，任务返回的结果是：9 ​ 从结果中可以同样可以看出，pool-1-thread-1被调用2次处理id=0和id=9的任务，submit也是首先选择空闲线程来执行任务，如果没有，才会创建新的线程来执行任务。另外，需要注意：如果Future的返回尚未完成，则get（）方法会阻塞等待，直到Future完成返回，可以通过调用isDone（）方法判断Future是否完成了返回。 Executor执行inVokeAny任务 ​ 方法 invokeAny() 接收一個包含 Callable 对象的集合作为参数。调用该方法不会返回 Future 对象，而是返回集合中某一個 Callable 对象的结果，而且无法保证调用之后返回的结果是哪一個 Callable，只知道它是这些 Callable 中一個执行结束的 Callable 对象。如果一个任务运行完毕或者抛出异常，方法会取消其它的 Callable 的执行。 Executor执行invokeAll任务 ​ 方法 invokeAll() 会调用存在于参数集合中的所有 Callable 对象，并且返回壹個包含 Future 对象的集合，你可以通过这個返回的集合来管理每個 Callable 的执行结果。需要注意的是，任务有可能因为异常而导致运行结束，所以它可能并不是真的成功运行了。但是我们没有办法通过 Future 对象来了解到这個差异。 自定义线程池ThreadPoolExecutor ​ 自定义线程池，可以用ThreadPoolExecutor类创建，它有多个构造方法来创建线程池，用该类很容易实现自定义的线程池，这里先贴上示例程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class ThreadPoolTest&#123; public static void main(String[] args)&#123; //创建等待队列 BlockingQueue&lt;Runnable&gt; bqueue = new ArrayBlockingQueue&lt;Runnable&gt;(20); //创建线程池，池中保存的线程数为3，允许的最大线程数为5 ThreadPoolExecutor pool = new ThreadPoolExecutor(3,5,50,TimeUnit.MILLISECONDS,bqueue); //创建七个任务 Runnable t1 = new MyThreads("t1"); Runnable t2 = new MyThreads("t2"); Runnable t3 = new MyThreads("t3"); Runnable t4 = new MyThreads("t4"); Runnable t5 = new MyThreads("t5"); Runnable t6 = new MyThreads("t6"); Runnable t7 = new MyThreads("t7"); //每个任务会在一个线程上执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); pool.execute(t6); pool.execute(t7); //关闭线程池 pool.shutdown(); &#125; &#125; class MyThreads implements Runnable&#123; private String name; public String getName() &#123; return name; &#125; public MyThreads(String name) &#123; // TODO Auto-generated constructor stub this.name=name; &#125; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + "正在执行 "+this.getName()); try&#123; Thread.sleep(100); &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; //输出pool-1-thread-2正在执行 t2pool-1-thread-3正在执行 t3pool-1-thread-1正在执行 t1pool-1-thread-1正在执行 t4pool-1-thread-3正在执行 t6pool-1-thread-2正在执行 t5pool-1-thread-3正在执行 t7 ​ 从结果中可以看出，七个任务是在线程池的三个线程上执行的。这里简要说明下用到的ThreadPoolExecuror类的构造方法中各个参数的含义。 1public ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue) corePoolSize：线程池中所保存的核心线程数，包括空闲线程。 maximumPoolSize：池中允许的最大线程数。 keepAliveTime：线程池中的空闲线程所能持续的最长时间。 unit：持续时间的单位。 workQueue：任务执行前保存任务的队列，仅保存由execute方法提交的Runnable任务。 根据ThreadPoolExecutor源码前面大段的注释，我们可以看出，当试图通过excute方法讲一个Runnable任务添加到线程池中时，按照如下顺序来处理： 1、如果线程池中的线程数量少于corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务； 2、如果线程池中的线程数量大于等于corePoolSize，但缓冲队列workQueue未满，则将新添加的任务放到workQueue中，按照FIFO的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）； 3、如果线程池中的线程数量大于等于corePoolSize，且缓冲队列workQueue已满，但线程池中的线程数量小于maximumPoolSize，则会创建新的线程来处理被添加的任务； 4、如果线程池中的线程数量等于了maximumPoolSize，有4种才处理方式（该构造方法调用了含有5个参数的构造方法，并将最后一个构造方法为RejectedExecutionHandler类型，它在处理线程溢出时有4种方式，这里不再细说，要了解的，自己可以阅读下源码）。 ​ 另外，当线程池中的线程数量大于corePoolSize时，如果里面有线程的空闲时间超过了keepAliveTime，就将其移除线程池，这样，可以动态地调整线程池中线程的数量。我们大致来看下Executors的源码，newCachedThreadPool的不带RejectedExecutionHandler参数（即第五个参数，线程数量超过maximumPoolSize时，指定处理方式）的构造方法如下： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 它将corePoolSize设定为0，而将maximumPoolSize设定为了Integer的最大值，线程空闲超过60秒，将会从线程池中移除。由于核心线程数为0，因此每次添加任务，都会先从线程池中找空闲线程，如果没有就会创建一个线程（SynchronousQueue决定的，后面会说）来执行新的任务，并将该线程加入到线程池中，而最大允许的线程数为Integer的最大值，因此这个线程池理论上可以不断扩大。 再来看newFixedThreadPool的不带RejectedExecutionHandler参数的构造方法，如下： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 它将corePoolSize和maximumPoolSize都设定为了nThreads，这样便实现了线程池的大小的固定，不会动态地扩大，另外，keepAliveTime设定为了0，也就是说线程只要空闲下来，就会被移除线程池，敢于LinkedBlockingQueue下面会说。 6.ExecuteService 服务的关闭​ shutdown()方法在终止前允许执行以前提交的任务，而 shutdownNow() 方法阻止等待任务的启动并试图停止当前正在执行的任务。在终止后，执行程序没有任务在执行，也没有任务在等待执行，并且无法提交新任务。应该关闭未使用的 ExecutorService以允许回收其资源。 7.排队的策略:1、直接提交。缓冲队列采用 SynchronousQueue，它将任务直接交给线程处理而不保持它们。如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中。直接提交通常要求无界 maximumPoolSizes（Integer.MAX_VALUE） 以避免拒绝新提交的任务。newCachedThreadPool采用的便是这种策略。 2、无界队列。使用无界队列（典型的便是采用预定义容量的 LinkedBlockingQueue，理论上是该缓冲队列可以对无限多的任务排队）将导致在所有 corePoolSize 线程都工作的情况下将新任务加入到缓冲队列中。这样，创建的线程就不会超过 corePoolSize，也因此，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列。newFixedThreadPool采用的便是这种策略。 3、有界队列。当使用有限的 maximumPoolSizes 时，有界队列（一般缓冲队列使用ArrayBlockingQueue，并制定队列的最大长度）有助于防止资源耗尽，但是可能较难调整和控制，队列大小和最大池大小需要相互折衷，需要设定合理的参数。 8.参考：http://blog.csdn.net/ns_code/article/details/17465497 http://blog.csdn.net/linghu_java/article/details/17123057 http://blog.csdn.net/bairrfhoinn/article/details/16848785 http://zhangjunhd.blog.51cto.com/113473/70068/ http://www.cnblogs.com/wanqieddy/p/3853863.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HttpClient工具类]]></title>
      <url>%2F2017%2F02%2F15%2FHttpClient%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E5%B0%81%E8%A3%85%2F</url>
      <content type="text"><![CDATA[一.HttpClient 介绍：​ HttpClient相比传统JDK自带的URLConnection，增加了易用性和灵活性，它不仅是客户端发送Http请求变得容易，而且也方便了开发人员测试接口（基于Http协议的），即提高了开发的效率，也方便提高代码的健壮性。它支持在HTTP/1.1规范中定义的所有的HTTP方法：GET, HEAD, POST, PUT, DELETE, TRACE 和 OPTIONS。每有一个方法都有一个对应的类：HttpGet，HttpHead，HttpPost，HttpPut，HttpDelete，HttpTrace和HttpOptions。所有的这些类均实现了HttpUriRequest接口，故可以作为execute的执行参数使用。 HTTP请求的URI包含一个协议计划protocol scheme，主机名host name,，可选的端口optional port，资源的路径resource path，可选的查询optional query和可选的片段optional fragment。 二. 特性：​ 基于标准、纯净的Java语言。实现了Http1.0和Http1.1 ​ 以可扩展的面向对象的结构实现了Http全部的方法（GET, POST, PUT, DELETE, HEAD, OPTIONS, and TRACE）。 ​ 支持HTTPS协议。 ​ 通过Http代理建立透明的连接。 ​ 利用CONNECT方法通过Http代理建立隧道的https连接。 ​ Basic, Digest, NTLMv1, NTLMv2, NTLM2 Session, SNPNEGO/Kerberos认证方案。 ​ 插件式的自定义认证方案。 ​ 便携可靠的套接字工厂使它更容易的使用第三方解决方案。 ​ 连接管理器支持多线程应用。支持设置最大连接数，同时支持设置每个主机的最大连接数，发现并关闭过期的连接。 ​ 自动处理Set-Cookie中的Cookie。 ​ 插件式的自定义Cookie策略。 ​ Request的输出流可以避免流中内容直接缓冲到socket服务器。 ​ Response的输入流可以有效的从socket服务器直接读取相应内容。 ​ 在http1.0和http1.1中利用KeepAlive保持持久连接。 ​ 直接获取服务器发送的response code和 headers。 ​ 设置连接超时的能力。 ​ 实验性的支持http1.1 response caching。 ​ 源代码基于Apache License 可免费获取。 三. 使用方法​ 创建HttpClient对象。 ​ 创建请求方法的实例，并指定请求URL。如果需要发送GET请求，创建HttpGet对象；如果需要发送POST请求，创建HttpPost对象。 ​ 如果需要发送请求参数，可调用HttpGet、HttpPost共同的setParams(HetpParams params)方法来添加请求参数；对于HttpPost对象而言，也可调用setEntity(HttpEntity entity)方法来设置请求参数。 ​ 调用HttpClient对象的execute(HttpUriRequest request)发送请求，该方法返回一个HttpResponse。 ​ 调用HttpResponse的getAllHeaders()、getHeaders(String name)等方法可获取服务器的响应头；调用HttpResponse的getEntity()方法可获取HttpEntity对象，该对象包装了服务器的响应内容。程序可通过该对象获取服务器的响应内容。 ​ 释放连接。无论执行方法是否成功，都必须释放连接 四.封装工具类 ​ 1.HttpHeader封装 ​ 2.SSL封装 ​ 3.HttpClientBuilder封装 ​ 链接：https://github.com/Luckylau/UsefulTools 五.参考资料http://blog.csdn.net/xiaoxian8023/article/category/5968067 http://blog.csdn.net/wangpeng047/article/details/19624529]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BeanUtils.copyProperties 与 PropertyUtils.copyProperties]]></title>
      <url>%2F2017%2F02%2F06%2FBeanUtils-copyProperties-%E4%B8%8E-PropertyUtils-copyProperties%2F</url>
      <content type="text"><![CDATA[首先明确一点是BeanUtils.copyProperties 存在于spring和apache commons-beanutils，PropertyUtils.copyProperties存在于apache commons-PropertyUtils。 org.springframework.beans.BeanUtils; org.apache.commons.beanutils.BeanUtils; org.apache.commons.beanutils.PropertyUtils; 1.org.springframework.beans.BeanUtils使用：首先看一下源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void copyProperties(Object source, Object target) throws BeansException &#123; copyProperties(source, target, (Class)null, (String[])null); &#125; public static void copyProperties(Object source, Object target, Class&lt;?&gt; editable) throws BeansException &#123; copyProperties(source, target, editable, (String[])null); &#125; public static void copyProperties(Object source, Object target, String... ignoreProperties) throws BeansException &#123; copyProperties(source, target, (Class)null, ignoreProperties); &#125; private static void copyProperties(Object source, Object target, Class&lt;?&gt; editable, String... ignoreProperties) throws BeansException &#123; Assert.notNull(source, "Source must not be null"); Assert.notNull(target, "Target must not be null"); Class actualEditable = target.getClass(); if(editable != null) &#123; if(!editable.isInstance(target)) &#123; throw new IllegalArgumentException("Target class [" + target.getClass().getName() + "] not assignable to Editable class [" + editable.getName() + "]"); &#125; actualEditable = editable; &#125; PropertyDescriptor[] targetPds = getPropertyDescriptors(actualEditable); List ignoreList = ignoreProperties != null?Arrays.asList(ignoreProperties):null; PropertyDescriptor[] var7 = targetPds; int var8 = targetPds.length; for(int var9 = 0; var9 &lt; var8; ++var9) &#123; PropertyDescriptor targetPd = var7[var9]; Method writeMethod = targetPd.getWriteMethod(); if(writeMethod != null &amp;&amp; (ignoreList == null || !ignoreList.contains(targetPd.getName()))) &#123; PropertyDescriptor sourcePd = getPropertyDescriptor(source.getClass(), targetPd.getName()); if(sourcePd != null) &#123; Method readMethod = sourcePd.getReadMethod(); if(readMethod != null &amp;&amp; ClassUtils.isAssignable(writeMethod.getParameterTypes()[0], readMethod.getReturnType())) &#123; try &#123; if(!Modifier.isPublic(readMethod.getDeclaringClass().getModifiers())) &#123; readMethod.setAccessible(true); &#125; Object ex = readMethod.invoke(source, new Object[0]); if(!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers())) &#123; writeMethod.setAccessible(true); &#125; writeMethod.invoke(target, new Object[]&#123;ex&#125;); &#125; catch (Throwable var15) &#123; throw new FatalBeanException("Could not copy property \'" + targetPd.getName() + "\' from source to target", var15); &#125; &#125; &#125; &#125; &#125; &#125; 成员变量赋值是基于目标对象的成员列表, 并且会跳过ignore的以及在源对象中不存在的属性, 所以这个方法是安全的, 不会因为两个对象之间的结构差异导致错误, 但是必须保证同名的两个成员变量类型相同. 1BeanUtils.copyProperties(source, target); 2.org.apache.commons.beanutils.BeanUtils使用：2.1 对于类型为Boolean/Short/Integer/Float/Double的属性，它会转换为0: 1234567891011121314151617181920212223242526public class User &#123; private Integer intVal; private Double doubleVal; private Short shortVal; private Long longVal; private Float floatVal; private Byte byteVal; private Boolean booleanVal; &#125; User src = new User(); User dest = new User(); BeanUtils.copyProperties(dest, src); System.out.println(src); System.out.println(dest); //输出 User [intVal=null, doubleVal=null, shortVal=null, longVal=null, floatVal=null, byteVal=null, booleanVal=null] User [intVal=0, doubleVal=0.0, shortVal=0, longVal=0, floatVal=0.0, byteVal=0, booleanVal=false] 在stackoverflow上有人解释说是因为这几个类型都有对应的基本类型，在进行类型转换时，有可能遇到类似Integer -&gt; int的转换，此时显然不能对int类型的属性赋值为null，因此统一转换为0。 如何让它不要转为0呢？可以这样： 1234import org.apache.commons.beanutils.converters.IntegerConverter; IntegerConverter converter = new IntegerConverter(null); //默认为null，而不是0 BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); beanUtilsBean.getConvertUtils().register(converter, Integer.class); 2.2 对于java.util.Date/BigDecimal/java.sql.Date/java.sql.Timestamp/java.sql.Time这几个类，如果值为null，则在copy时会抛异常，需要使用对应的Conveter： 12345678910111213141516171819202122232425262728293031public class User2 &#123; private java.util.Date javaUtilDateVal; private java.sql.Date javaSqlDateVal; private java.sql.Timestamp javaSqlTimeStampVal; private BigDecimal bigDecimalVal; private java.sql.Time javaSqlTime; &#125; User2 src = new User2(); User2 dest = new User2(); BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); //如果没有下面几行，则在转换null时会抛异常，例如：org.apache.commons.beanutils.ConversionException: No value specified for 'BigDecimal' //在org.apache.commons.beanutils.converters这个包下面有很多的Converter，可以按需要使用 beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.BigDecimalConverter(null), BigDecimal.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.DateConverter(null), java.util.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimestampConverter(null), java.sql.Timestamp.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlDateConverter(null), java.sql.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimeConverter(null), java.sql.Time.class); beanUtilsBean.copyProperties(dest, src); System.out.println(src); System.out.println(dest); 2.3使用BeanUtils还会经常碰到这样变态的需求： 假设是从A复制到B：需求1：如果B中某字段有值（不为null），则该字段不复制；也就是B中该字段没值时，才进行复制，适合于对B进行补充值的情况。需求2：如果A中某字段没值（为null），则该字段不复制，也就是不要把null复制到B当中。 对于需求1，可以这样： 12345678910111213141516171819import org.apache.commons.beanutils.BeanUtilsBean; import org.apache.commons.beanutils.PropertyUtils; public class CopyWhenNullBeanUtilsBean extends BeanUtilsBean&#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; try &#123; Object destValue = PropertyUtils.getSimpleProperty(bean, name); if (destValue == null) &#123; super.copyProperty(bean, name, value); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; 对于需求2，可以这样： 123456789101112import org.apache.commons.beanutils.BeanUtilsBean; public class CopyFromNotNullBeanUtilsBean extends BeanUtilsBean &#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; if (value == null) &#123; return; &#125; super.copyProperty(bean, name, value); &#125; &#125; 2.4 使用BeanUtils时，遇到日期类型的空值时会抛错的解决办法 新建一个转换器类，该类实现Converter接口，在convert方法中实现日期类型值的转换逻辑，然后注册。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class DateConverter implements Converter&#123; public Object convert(Class type, Object value)&#123; if(value == null)&#123; return null; &#125;else if(type == Timestamp.class)&#123; return convertToDate(type, value, "yyyy-MM-dd HH:mm:ss"); &#125;else if(type == Date.class)&#123; return convertToDate(type, value, "yyyy-MM-dd"); &#125;else if(type == String.class)&#123; return convertToString(type, value); &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToDate(Class type, Object value, String pattern) &#123; SimpleDateFormat sdf = new SimpleDateFormat(pattern); if(value instanceof String)&#123; try&#123; if(CommonUtils.isEmpty(value.toString()))&#123; return null; &#125; Date date = sdf.parse((String) value); if(type.equals(Timestamp.class))&#123; return new Timestamp(date.getTime()); &#125; return date; &#125;catch(Exception pe)&#123; return null; &#125; &#125;else if(value instanceof Date)&#123; return value; &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToString(Class type, Object value) &#123; if(value instanceof Date)&#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); if (value instanceof Timestamp) &#123; sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); &#125; try&#123; return sdf.format(value); &#125;catch(Exception e)&#123; throw new ConversionException("日期转换为字符串时出错！"); &#125; &#125;else&#123; return value.toString(); &#125; &#125; &#125; 1ConvertUtils.register(new DateConverter(), java.util.Date.class); 使用： 1BeanUtils.copyProperties(target, source); 3.org.apache.commons.beanutils.PropertyUtils使用：​ 使用PropertyUtils.copyProperties()拷贝一个bean中的属性到另一个bean中,第一个参数是目标bean,第二个参数是源bean，只是拷贝具有相同的 1PropertyUtils.copyProperties(target, source); 4.三者之间的区别：4.1 org.apache.commons.beanutils.BeanUtils 与org.apache.commons.beanutils.PropertyUtils ​ 从大范围讲，两个工具类都是对两个bean之前存在name相同的属性进行处理，无论是源bean或者目标bean多出的属性均不处理。具体到BeanUtils是相同name并且类型之间支持转换的属性可以处理，而PropertyUtils不支持类型转换必须是类型和name一样才处理。 ​ 对null的处理：PropertyUtils支持为null的场景；BeanUtils对部分属性不支持null的情况，具体为：date类型不支持，异常 date为org.apache.commons.beanutils.ConversionException: No value；specified for ‘Date’；Ineger、Boolean、Long等不支持， 转为0；string支持，保持null； ​ 源bean有属性：private Long dateVal;目标bean有属性：private Date dateVal;​ 使用 PropertyUtils，会报错：Caused by: java.lang.IllegalArgumentException: argument type mismatch​ 使用BeanUtils，则相当于new date（dateVal） ​ BeanUtils的高级功能org.apache.commons.beanutils.Converter接口可以自定义类型之间的转化，PropertyUtils没有 4.2 org.apache.commons.beanutils.BeanUtils与org.springframework.beans.BeanUtils org.springframework.beans.BeanUtils中实现的方式很简单，就是对两个对象中相同名字的属性进行简单get/set，仅检查属性的可访问性。 而org.springframework.beans.BeanUtils则施加了很多的检验，包括类型的转换，甚至于还会检验对象所属的类的可访问性。 5.参考：http://www.cnblogs.com/milton/p/5830942.html http://bylijinnan.iteye.com/blog/2224808 http://caoyaojun1988-163-com.iteye.com/blog/1871316 http://chenjumin.iteye.com/blog/701190 http://www.cnblogs.com/gaojing/archive/2011/08/23/2413616.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[历史金融危机一览表]]></title>
      <url>%2F2017%2F01%2F27%2F%E5%8E%86%E5%8F%B2%E9%87%91%E8%9E%8D%E5%8D%B1%E6%9C%BA%E4%B8%80%E8%A7%88%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[历史金融危机一览表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是vxlan网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFvxlan%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[前言：​ 处在年末工作的最后一天，其实也没有心情学习了，要不就总结和整理一下之前看的vxlan网络，大部分的内容还是复制拷贝的，只是按照自己的分明别类梳理梳理。vxlan网络是云计算网络的基础，openstack本身也是一种基础性简单使用，但还是有必要从理论上来学习vxlan网络。 云计算虚拟化对传统网络带来的挑战​ 云计算、虚拟化相关技术的发展，传统的网络无法满足于规模大、灵活性要求高的云数据中心的要求，于是便有了overlay网络的概念。overlay网络中被广泛应用的就是vxlan技术。首先我们了解一下随着云计算的发展，传统网络面临哪些挑战。 1.虚拟机迁移范围受到网络架构限制 ​ 虚拟机迁移，顾名思义，就是将虚拟机从一个物理机迁移到另一个物理机，但是要求在迁移过程中业务不能中断。要做到这一点，需要保证虚拟机迁移前后，其IP地址、MAC地址等参数维持不变。这就决定了，虚拟机迁移必须发生在一个二层域中。对于传统网络就要求网络本身具备多路径多链路的冗余和可靠性。传统的网络生成树(STPSpaning Tree Protocol)技术不仅部署繁琐荣，且协议复杂，网络规模不宜过大，限制了虚拟化的网络扩展性。基于各厂家私有的的IRF/vPC等设备级的(网络N:1)虚拟化技术，虽然可以简化拓扑简化、具备高可靠性的能力，但是对于网络有强制的拓扑形状限制，在网络的规模和灵活性上有所欠缺，只适合小规模网络构建，且一般适用于数据中心内部网络。而为了大规模网络扩展的TRILL/SPB/FabricPath/VPLS等技术，虽然解决了上述技术的不足，但对网络有特殊要求，即网络中的设备均要软硬件升级而支持此类新技术，带来部署成本的上升。 2.虚拟机规模受网络设备表项规格的限制 ​ 在大二层网络环境下，数据流均需要通过明确的网络寻址以保证准确到达目的地，因此网络设备的二层地址表项大小(即MAC地址表)，成为决定了云计算环境下虚拟机的规模的上限，并且因为表项并非百分之百的有效性，使得可用的虚机数量进一步降低，特别是对于低成本的接入设备而言，因其表项一般规格较小，限制了整个云计算数据中心的虚拟机数量，但如果其地址表项设计为与核心或网关设备在同一档次，则会提升网络建设成本。虽然核心或网关设备的MAC与ARP规格会随着虚拟机增长也面临挑战，但对于此层次设备能力而言，大规格是不可避免的业务支撑要求。减小接入设备规格压力的做法可以是分离网关能力，如采用多个网关来分担虚机的终结和承载，但如此也会带来成本的上升。 3.网络隔离/分离能力限制 ​ VLAN作为当前主流的网络隔离技术，在标准定义中只有12比特，也就是说可用的VLAN数量只有4000个左右。对于公有云或其它大型虚拟化云计算服务这种动辄上万甚至更多租户的场景而言，VLAN的隔离能力显然已经力不从心。 VLAXN网络的初相识1.VXLAN网络模型 从上图可以看到，VXLAN网络中出现了以下传统数据中心网络中没有的新元素： VTEP（VXLAN Tunnel Endpoints，VXLAN隧道端点）VXLAN网络的边缘设备，是VXLAN隧道的起点和终点，VXLAN报文的相关处理均在这上面进行。总之，它是VXLAN网络中绝对的主角。VTEP既可以是独立的网络设备（比如华为的CE系列交换机），也可以是虚拟机所在的服务器。那它究竟是如何发挥作用的呢？答案稍候揭晓。 VNI（VXLAN Network Identifier，VXLAN 网络标识符）前文提到，以太网数据帧中VLAN只占了12比特的空间，这使得VLAN的隔离能力在数据中心网络中力不从心。而VNI的出现，就是专门解决这个问题的。VNI是一种类似于VLAN ID的用户标示，一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VXLAN报文封装时，给VNI分配了足够的空间使其可以支持海量租户的隔离。详细的实现，我们将在后文中介绍。 VXLAN隧道“隧道”是一个逻辑上的概念，它并不新鲜，比如大家熟悉的GRE。说白了就是将原始报文“变身”下，加以“包装”，好让它可以在承载网络（比如IP网络）上传输。从主机的角度看，就好像原始报文的起点和终点之间，有一条直通的链路一样。而这个看起来直通的链路，就是“隧道”。顾名思义，“VXLAN隧道”便是用来传输经过VXLAN封装的报文的，它是建立在两个VTEP之间的一条虚拟通道。 2.VXLAN是如何解决以上挑战 2.1解决虚拟机迁移范围受到网络架构限制问题 ​ overlay网络的本质是在三层网络中实现二层网络的扩展。三层网络可以通过路由的方式在网络中分发，而路由网络本身并无特殊网络结构限制，具备良性大规模扩展能力，并且对设备本身无特殊要求，以高性能路由转发为佳，且路由网络本身具备很强的的故障自愈能力、负载均衡能力。前面提到，为了保证业务不中断，VM的迁移就必须发生在同一个二层域内。有了VTEP的封装机制和VXLAN隧道后，所谓的 “二层域”就可以轻而易举的突破物理上的界限？也就是说，在IP网络中， “明”里传输的是跨越三层网络的UDP报文，“暗”里却已经悄悄将源VM的原始报文送达目的VM。就好像在三层的网络之上，构建出了一个虚拟的二层网络，而且只要IP网络路由可达，这个虚拟的二层网络想做多大就做多大。 2.2解决虚拟机规模受网络设备表项规格的限制问题 ​ 既然无法提升设备表项规格，那就只能限制设备上的MAC表项，将大量VM的MAC地址“隐形”。VTEP会将VM发出的原始报文封装成一个新的UDP报文，并使用物理网络的IP和MAC地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就是说，网络中的其他设备看不到VM发送的原始报文。 ​ 如果服务器作为VTEP，那从服务器发送到接入设备的报文便是经过封装后的报文，这样，接入设备就不需要学习VM的MAC地址了，它只需要根据外层封装的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表项规格的限制了。 ​ 当然，如果网络设备作为VTEP，它还是需要学习VM的MAC地址。但是，从对报文进行封装的角度来说，网络设备的性能还是要比服务器强很多。 2.3解决网络隔离/分离能力限制 ​ 一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VTEP在对报文进行VXLAN封装时，给VNI分配了24比特的空间，这就意味着VXLAN网络理论上支持多达16M（即：2^24-1）的租户隔离。相比VLAN，VNI的隔离能力得到了巨大的提升，有效得解决了云计算中海量租户隔离的问题。 3.VXLAN报文格式 VTEP对VM发送的原始以太帧（Original L2 Frame）进行了以下“包装”： VXLAN Header: ​ 增加VXLAN头（8字节），其中包含24比特的VNI字段，用来定义VXLAN网络中不同的租户。此外，还包含VXLAN Flags（8比特，取值为00001000）和两个保留字段（分别为24比特和8比特）。 UDP Header: ​ VXLAN头和原始以太帧一起作为UDP的数据。UDP头中，目的端口号（VXLAN Port）固定为4789，源端口号（UDP Src. Port）是原始以太帧通过哈希算法计算后的值。 Outer IP Header: ​ 封装外层IP头。其中，源IP地址（Outer Src. IP）为源VM所属VTEP的IP地址，目的IP地址（Outer Dst. IP）为目的VM所属VTEP的IP地址。 Outer MAC Header: ​ 封装外层以太头。其中，源MAC地址（Src. MAC Addr.）为源VM所属VTEP的MAC地址，目的MAC地址（Dst. MAC Addr.）为到达目的VTEP的路径上下一跳设备的MAC地址。 VXLAN报文转发机制以CE系列交换机的实现为例 1.建立VXLAN隧道 前面提到的“同一大二层域”，就类似于传统网络中VLAN（虚拟局域网）的概念，只不过在VXLAN网络中，它有另外一个名字，叫做Bridge-Domain，简称BD。 ​ 我们知道，不同的VLAN是通过VLAN ID来进行区分的，那不同的BD是如何进行区分的呢？其实前面已经提到了，就是通过VNI来区分的。对于CE系列交换机而言，BD与VNI是1：1的映射关系，这种映射关系是通过在VTEP上配置命令行建立起来的。配置如下： 12bridge-domain 10 //表示创建一个“大二层广播域”BD，其编号为10 vxlan vni 5000 //表示在BD 10下，指定与之关联的VNI为5000 VTEP会根据以上配置生成BD与VNI的映射关系表，该映射表可以通过命令行查看，如下所示： 12345&lt;HUAWEI&gt; display vxlan vniNumber of vxlan vni : 1VNI BD-ID State ----------------------------------5000 10 up 有了映射表后，进入VTEP的报文就可以根据自己所属的BD来确定报文封装时该添加哪个VNI。那么，报文根据什么来确定自己属于哪个BD呢？ 在回答“如何确定报文属于哪个BD”之前，必须先要回答“哪些报文要进入VXLAN隧道”。 ​ 在VXLAN网络中，VTEP上有一个叫做“二层子接口”的逻辑接口，主要做两件事：一是根据配置来检查哪些报文需要进入VXLAN隧道；二是判断对检查通过的报文做怎样的处理。在二层子接口上，可以根据需要定义不同的流封装类型（类似于传统网络中不同的接口类型）。CE系列交换机目前支持三种不同的流封装类型，分别是dot1q、untag和default，它们各自对报文的处理方式如表3-1所示。有了这张表，你就能明白哪些报文要进VXLAN隧道了。 流封装类型 允许进入VXLAN隧道的报文类型 报文进行封装前的处理 收到VXLAN报文并解封装后的处理 dot1q 只允许携带指定VLAN Tag的报文进入VXLAN隧道。（这里的“指定VLAN Tag”是通过命令进行配置的） 进行VXLAN封装前，先剥掉原始报文的外层VLAN Tag 进行VXLAN解封装后：若内层原始报文带有VLAN Tag，则先将该VLAN Tag替换为指定的VLAN Tag，再转发；若内层原始报文不带VLAN Tag，则先将其添加指定的VLAN Tag，再转发。 untag 只允许不携带VLAN Tag的报文进入VXLAN隧道。 进行VXLAN封装前，不对原始报文做处理，即不添加任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 default 允许所有报文进入VXLAN隧道，不论报文是否携带VLAN Tag。 进行VXLAN封装前，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 说明：VXLAN隧道两端二层子接口的配置并不一定是完全对等的。正因为这样，才可能实现属于同一网段但是不同VLAN的两个VM通过VXLAN隧道进行通信。 看了上面的描述，再来回答“如何确定报文属于哪个BD”就非常简单了。其实，只要将二层子接口加入指定的BD，然后根据二层子接口上的配置，就可以确定报文属于哪个BD啦！ 比如下图所示的组网，我们可以分别在VTEP的两个物理接口10GE 1/0/1和10GE 1/0/2上配置不同流封装类型的二层子接口并将其分别加入不同的BD。 基于二层物理接口10GE 1/0/1，分别创建二层子接口10GE 1/0/1.1和10GE 1/0/1.2，且分别配置其流封装类型为dot1q和untag。配置如下： 123interface 10GE1/0/1.1 mode l2 //创建二层子接口10GE1/0/1.1 encapsulation dot1q vid 10 //只允许携带VLAN Tag 10的报文进入VXLAN隧道 bridge-domain 10 //报文进入的是BD 10 123interface 10GE1/0/1.2 mode l2 //创建二层子接口10GE1/0/1.2 encapsulation untag //只允许不携带VLAN Tag的报文进入VXLAN隧道 bridge-domain 20 //报文进入的是BD 20 基于二层物理接口10GE 1/0/2，创建二层子接口10GE 1/0/2.1，且流封装类型为default。配置如下： 123interface 10GE1/0/2.1 mode l2 //创建二层子接口10GE1/0/2.1 encapsulation default //允许所有报文进入VXLAN隧道 bridge-domain 30 //报文进入的是BD 30 此时你可能会有这样的疑问，为什么要在10GE 1/0/1上创建两个不同类型的子接口？是否还可以继续在10GE 1/0/1上创建一个default类型的二层子接口？换句话说，用户应该如何选择配置哪种类型的二层子接口？三种类型的二层子接口之间，是否存在配置约束关系？ 答案是不可以。其实根据上表的描述，这一点很容易理解。因为default类型的二层子接口允许所有报文进入VXLAN隧道，而dot1q和untag类型的二层子接口只允许某一类报文进入VXLAN隧道。这就决定了，default类型的二层子接口跟其他两种类型的二层子接口是不可以在同一物理接口上共存的。否则，报文到了接口之后如何判断要进入哪个二层子接口呢。所以，default类型的子接口，一般应用在经过此接口的报文均需要走同一条VXLAN隧道的场景，即下挂的VM全部属于同一BD。例如，图3-3中VM3和VM4均属于BD 30，则10GE 1/0/2上就可以创建default类型的二层子接口。 再来看下为什么可以在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。如图上所示，VM1和VM2分别属于VLAN 10和VLAN 20，且分别属于不同的大二层域BD 10和BD 20，显然他们发出的报文要进入不同的VXLAN隧道。如果VM1和VM2发出的报文在到达VTEP的10GE 1/0/1接口时，一个是携带VLAN 10的Tag的，一个是不携带VLAN Tag的（比如二层交换机上行连接VTEP的接口上配置的接口类型是Trunk，允许通过的VLAN为10和20，PVID为VLAN 20），则为了区分两种报文，就必须要在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。所以，当经过同一物理接口的报文既有带VLAN Tag的，又有不带VLAN Tag的，并且他们各自要进入不同的VXLAN隧道，则可以在该物理接口上同时创建dot1q和untag类型的二层子接口。 现在，我们可以来看下VXLAN隧道是怎么建立起来的了。一般而言，隧道的建立不外乎手工方式和自动方式两种。 手工方式这种方式需要用户手动指定VXLAN隧道的源和目的IP地址分别为本端和对端VTEP的IP地址，也就是人为的在本端VTEP和对端VTEP之间建立静态VXLAN隧道。对于CE系列交换机，以上配置是在NVE（Network Virtualization Edge）接口下完成的。配置过程如下： 1234interface Nve1 //创建逻辑接口NVE 1 source 1.1.1.1 //配置源VTEP的IP地址（推荐使用Loopback接口的IP地址） vni 5000 head-end peer-list 2.2.2.2 vni 5000 head-end peer-list 2.2.2.3 其中，vni 5000 head-end peer-list 2.2.2.2和vni 5000 head-end peer-list 2.2.2.3的配置，表示属于VNI 5000的对端VTEP有两个，IP地址分别为2.2.2.2和2.2.2.3。根据这两条配置，VTEP上会生成如下所示的一张表： 123456789&lt;HUAWEI&gt; display vxlan vni 5000 verbose BD ID : 10 State : up NVE : 288 Source : 1.1.1.1 UDP Port : 4789 BUM Mode : head-end Group Address : - Peer List : 2.2.2.2 2.2.2.3 根据上表中的Peer List，本端VTEP就可以知道属于同一BD（或同一VNI）的对端VTEP都有哪些，这也就决定了同一大二层广播域的范围。当VTEP收到BUM（Broadcast&amp;Unknown-unicast&amp;Multicast，广播&amp;未知单播&amp;组播）报文时，会将报文复制并发送给Peer List中所列的所有对端VTEP（这就好比广播报文在VLAN内广播）。因此，这张表也被称为“头端复制列表”。当VTEP收到已知单播报文时，会根据VTEP上的MAC表来确定报文要从哪条VXLAN隧道走。而此时Peer List中所列的对端，则充当了MAC表中“出接口”的角色。在后面的报文转发流程中，你将会看到头端复制列表是如何在VXLAN网络中指导报文进行转发的。 自动方式自动方式下VXLAN隧道的建立需要借助于其他的协议，例如BGP。CE系列交换机中，自动方式建立VXLAN隧道主要应用在EVN（Ethernet Virtual Network）和VXLAN的分布式网关场景中。本文不对该方式进行详细讲述，具体实现可参考EVN的相关资料。 从前面的描述我们知道，属于同一BD的VXLAN隧道可能不止一条，比如前面的头端复制列表中，同一个源端VTEP（1.1.1.1）对应了两个对端VTEP（2.2.2.2和2.2.2.3）。那就带来了另一个问题，报文到底应该走哪一条隧道呢？我们知道，基本的二三层转发中，二层转发依赖的是MAC表，如果没有对应的MAC表，则主机发送ARP广播报文请求对端的MAC地址；三层转发依赖的是FIB表。在VXLAN中，其实也是同样的道理。下面就让我们来看下，VXLAN网络中报文的转发流程。相信看完下面的内容，关于“如何确定报文要进哪条隧道”的疑惑也就迎刃而解了。 2.VXLAN网络中报文的转发流程 同子网互通 VM_A、VM_B和VM_C同属于10.1.1.0/24网段，且同属于VNI 5000。此时，VM_A想与VM_C进行通信。 ​ 由于是首次进行通信，VM_A上没有VM_C的MAC地址，所以会发送ARP广播报文请求VM_C的MAC地址。下面就让我们根据ARP请求报文及ARP应答报文的转发流程，来看下MAC地址是如何进行学习的。 ARP请求报文转发流程 ARP请求报文的转发流程如下： VM_A发送源MAC为MAC_A、目的MAC为全F、源IP为IP_A、目的IP为IP_C的ARP广播报文，请求VM_C的MAC地址。 VTEP_1收到ARP请求后，根据二层子接口上的配置判断报文需要进入VXLAN隧道。确定了报文所属BD后，也就确定了报文所属的VNI。同时，VTEP_1学习MAC_A、VNI和报文入接口（Port_1，即二层子接口对应的物理接口）的对应关系，并记录在本地MAC表中。之后，VTEP_1会根据头端复制列表对报文进行复制，并分别进行封装。 可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_1）的IP地址，外层目的IP地址为对端VTEP（VTEP_2和VTEP_3）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2和VTEP_3后，VTEP对报文进行解封装，得到VM_A发送的原始报文。同时，VTEP_2和VTEP_3学习VM_A的MAC地址、VNI和远端VTEP的IP地址（IP_1）的对应关系，并记录在本地MAC表中。之后，VTEP_2和VTEP_3根据二层子接口上的配置对报文进行相应的处理并在对应的二层域内广播。VM_B和VM_C接收到ARP请求后，比较报文中的目的IP地址是否为本机的IP地址。VM_B发现目的IP不是本机IP，故将报文丢弃；VM_C发现目的IP是本机IP，则对ARP请求做出应答。下面，让我们看下ARP应答报文是如何进行转发的。 ARP应答报文转发流程 ARP应答报文的转发流程如下： 由于此时VM_C上已经学习到了VM_A的MAC地址，所以ARP应答报文为单播报文。报文源MAC为MAC_C，目的MAC为MAC_A，源IP为IP_C、目的IP为IP_A。 VTEP_3接收到VM_C发送的ARP应答报文后，识别报文所属的VNI（识别过程与步骤2类似）。同时，VTEP_3学习MAC_C、VNI和报文入接口（Port_3）的对应关系，并记录在本地MAC表中。之后，VTEP_3对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_3）的IP地址，外层目的IP地址为对端VTEP（VTEP_1）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_1后，VTEP_1对报文进行解封装，得到VM_C发送的原始报文。同时，VTEP_1学习VM_C的MAC地址、VNI和远端VTEP的IP地址（IP_3）的对应关系，并记录在本地MAC表中。之后，VTEP_1将解封装后的报文发送给VM_A。至此，VM_A和VM_C均已学习到了对方的MAC地址。之后，VM_A和VM_C将采用单播方式进行通信。 不同子网互通 ​ VM_A和VM_B分别属于10.1.10.0/24网段和10.1.20.0/24网段，且分别属于VNI 5000和VNI 6000。VM_A和VM_B对应的三层网关分别是VTEP_3上BDIF 10和BDIF 20的IP地址。VTEP_3上存在到10.1.10.0/24网段和10.1.20.0/24网段的路由。此时，VM_A想与VM_B进行通信。 ​ BDIF接口的功能与VLANIF接口类似，是基于BD创建的三层逻辑接口，用以实现不同子网VM之间或VXLAN网络与非VXLAN网络之间的通信。 由于是首次进行通信，且VM_A和VM_B处于不同网段，VM_A需要先发送ARP广播报文请求网关（BDIF 10）的MAC，获得网关的MAC后，VM_A先将数据报文发送给网关；之后网关也将发送ARP广播报文请求VM_B的MAC，获得VM_B的MAC后，网关再将数据报文发送给VM_B。以上MAC地址学习的过程与同子网互通中MAC地址学习的流程一致，不再赘述。现在假设VM_A和VM_B均已学到网关的MAC、网关也已经学到VM_A和VM_B的MAC，下面就让我们看下数据报文是如何从VM_A发送到VM_B的。 不同子网VM互通报文转发流程 数据报文从VM_A发送到VM_B的流程如下： VM_A先将数据报文发送给网关。报文的源MAC为MAC_A，目的MAC为网关BDIF 10的MAC_10，源IP地址为IP_A，目的IP为IP_B。 VTEP_1收到数据报文后，识别此报文所属的VNI（VNI 5000），并根据MAC表项对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP的IP地址（IP_1），外层目的IP地址为对端VTEP的IP地址（IP_3）；外层源MAC地址为本地VTEP的MAC地址（MAC_1），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文进入VTEP_3，VTEP_3对报文进行解封装，得到VM_A发送的原始报文。然后，VTEP_3会对报文做如下处理： VTEP_3发现该报文的目的MAC为本机BDIF 10接口的MAC，而目的IP地址为IP_B（10.1.20.1），所以会根据路由表查找到IP_B的下一跳。 发现下一跳为10.1.20.10，出接口为BDIF 20。此时VTEP_3查询ARP表项，并将原始报文的源MAC修改为BDIF 20接口的MAC（MAC_20），将目的MAC修改为VM_B的MAC（MAC_B）。 报文到BDIF 20接口时，识别到需要进入VXLAN隧道（VNI 6000），所以根据MAC表对报文进行封装。这里封装的外层源IP地址为本地VTEP的IP地址（IP_3），外层目的IP地址为对端VTEP的IP地址（IP_2）；外层源MAC地址为本地VTEP的MAC地址（MAC_3），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2后，VTEP_2对报文进行解封装，得到内层的数据报文，并将其发送给VM_B。 说明：VXLAN网络与非VXLAN网络之间的互通，也需要借助于三层网关。 VXLAN应用部署方式我们以下图所示的典型的“Spine-Leaf”数据中心组网为例，给大家介绍一下CE系列交换机VXLAN的应用场景和部署方案。 ​ 在上图所示的数据中心里，企业用户拥有多个部门（部门1和部门2），每个部门中拥有多个VM（VM1和VM3，VM2和VM4）。同部门的VM属于同一个网段，不同部门的VM属于不同的网段。用户希望同一部门VM之间、不同部门VM之间，VM与Internet之间均可相互访问。 VXLAN网络的子网互通 相同子网互通 部署方案如图所示，Leaf1和Leaf2作为VXLAN网络的VTEP，两个Leaf之间搭建VXLAN隧道，并在每个Leaf上部署VXLAN二层网关，即可实现同一部门VM之间的相互通信。此时Spine只作为VXLAN报文的转发节点，不感知VXLAN隧道的存在，可以是任意的三层网络设备。 不同子网互通（集中式网关） 部署方案如图4-2所示，Leaf1、Leaf2和Spine作为VXLAN网络的VTEP，Leaf1和Spine之间、Leaf2和Spine之间分别搭建VXLAN隧道，并在Spine上部署VXLAN三层网关，即可实现不同部门VM之间的相互通信。 不同子网互通（分布式网关） 出现背景细心的读者可能已经发现，在不同子网互通（集中式网关）中，同一Leaf（Leaf1）下挂的不同网段VM（VM1和VM2）之间的通信，都需要在Spine上进行绕行，这样就导致Leaf与Spine之间的链路上，存在冗余的报文，额外占用了大量的带宽。同时，Spine作为VXLAN三层网关时，所有通过三层转发的终端租户的表项都需要在该设备上生成。但是，Spine的表项规格有限，当终端租户的数量越来越多时，容易成为网络瓶颈。分布式网关的出现，很好的解决了这两个问题。 部署方案 同Leaf节点下不同部门VM之间的通信如图4-3所示，Leaf1作为VXLAN网络的VTEP，在Leaf1上部署VXLAN三层网关，即可实现同Leaf下不同部门VM之间的相互通信。此时，VM1和VM2互访时，流量只需要在Leaf1节点进行转发，不再需要经过Spine节点，从而节约了大量的带宽资源。 跨Leaf节点不同部门VM之间的通信如图4-3所示，Leaf1和Leaf2作为VXLAN网络的VTEP，在Leaf1和Leaf2上部署VXLAN三层网关。两个VXLAN三层网关之间通过BGP动态建立VXLAN隧道，并通过BGP的remote-nexthop属性发布本网关下挂的主机路由信息给其他BGP邻居，从而实现跨Leaf节点不同部门VM之间的相互通信。 说明：Leaf作为VXLAN三层网关时，只学习其下挂终端租户的表项，而不必像集中式三层网关一样，需要学习网络中所有终端租户的表项，从而解决了集中式三层网关带来表项瓶颈问题。 VXLAN网络的可靠性 随着网络的快速普及和应用的日益深入，基础网络的可靠性日益成为用户关注的焦点，如何能够保证网络传输不中断对于终端用户而言非常重要。在VXLAN网络的子网互通中，VM与Leaf之间，Leaf与Spine之间都是通过单归方式接入的。这种组网接入方式，显然已经不能满足用户对VXLAN网络可靠性的需求。这时，可以按照如下图所示方式，提升VXLAN网络的可靠性。 接入层的可靠性 通常采用堆叠（CSS）方式提升接入层的可靠性。这是因为，接入层的设备数量繁多，堆叠方式可以将多台交换机设备组合在一起，虚拟化成一台交换设备，所有配置均在这一台虚拟交换机上进行，从而简化了接入层设备的运维复杂度。此外，堆叠系统内成员交换机之间在进行冗余备份的同时，能够利用跨设备的Eth-Trunk实现设备间链路的负载分担。 参考： http://support.huawei.com/huaweiconnect/enterprise/forum.php?mod=viewthread&amp;tid=334207&amp;extra=page%3D&amp;page=1 http://blog.csdn.net/sinat_31828101/article/details/50504656]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是overlay网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFoverllay%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[​ Overlay在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于IP的基础网络技术为主。 ​ 随着云计算虚拟化的驱动，基于主机虚拟化的Overlay技术出现，在服务器的Hypervisor内vSwitch上支持了基于IP的二层Overlay技术，通过更靠近应用的边缘来提供网络虚拟化服务，其目的是使虚拟机的部署与业务活动脱离物理网络及其限制，使得云计算的网络形态不断完善。主机的vSwitch支持基于IP的Overlay之后，虚机的二层访问直接构建在Overlay之上，物理网不再感知虚机的诸多特性。 存在三种不同的构建模式: Network Overlay 方案: ​ 所有终端均采用物理交换机作为VTEP节点,所有的物理接入交换机支持VXLAN，物理服务器支持SR-IOV功能，使虚拟机通过SR-IOV技术直接与物理交换机相连，虚拟机的流量在接入交换机上进行VXLAN报文的封装和卸载，对于非虚拟化服务器，直接连接支持VXLAN的接入交换机，服务器流量在接入交换机上进行VXLAN报文封装和卸载；当VXLAN网络需要与VLAN网络通信时，采用物理交换机做VXLAN GW，实现VXLAN网络主机与VLAN网络主机的通信；采用高端交换机做VXLAN IP GW，实现VXLAN网络与WAN以及Internet的互连。 Host Overlay 方案: ​ 所有终端均采用虚拟交换机作为VTEP节点，VTEP、VXLAN GW、VXLAN IP GW均通过安装在服务器上的软件实现，vSwitch实现VTEP功能，完成VXLAN报文的封装解封装；vFW等实现VXLAN GW功能，实现VXLAN网络与VLAN网络、物理服务器的互通；vRouter作为VXLAN IP GW，实现VXLAN网络与Internet和WAN的互联。在本组网中，由于所有VXLAN报文的封装卸载都通过软件实现，会占用部分服务器资源，当访问量大时，vRouter会成为系统瓶颈。 Hybrid Overlay 方案: ​ 既有物理交换机接入，又有虚拟交换机接入，且软件VTEP和硬件VTEP之间可以基于标准协议互通。上述两种组网方案中，网络Overlay方案与虚拟机相连，需要通过一些特殊的要求或技术实现虚拟机与VTEP的对接，组网不够灵活，但是主机Overlay方案与传统网络互通时，连接也比较复杂，且通过软件实现VXLAN IP GW也会成为整个网络的瓶颈，所以最理想的组网方案应该是一个结合了网络Overlay与主机Overlay两种方案优势的混合Overlay方案。如上图所示它通过vSwitch实现虚拟机的VTEP，通过物理交换机实现物理服务器的VTEP，通过物理交换机实现VXALN GW和VXLAN IP GW；混合式Overlay组网方案对虚拟机和物理服务器都能够很好的兼容，同时通过专业的硬件交换机实现VXLAN IP GW从而承载超大规模的流量转发，是目前应用比较广泛的组网方案。 PS: OpenStack 采用的是第二种方案 ​ 另外IETF在Overlay技术领域有如下三大技术路线正在讨论，为简单起见，只讨论基于IPv4的Overlay相关内容。 1 . VXLAN。 VXLAN是将以太网报文封装在UDP传输层上的一种隧道转发模式，目的UDP端口号为4798；为了使VXLAN充分利用承载网络路由的均衡性，VXLAN通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为UDP的号；采用24比特标识二层网络分段，称为VNI(VXLAN Network Identifier)，类似于VLAN ID作用；未知目的、广播、组播等网络流量均被封装为组播转发，物理网络要求支持任意源组播(ASM)。 2. GRE/NVGRE（Generic Routing Encapsulation，通用路由协议封装）是一种 IP-over-IP 的隧道。 NVGRE是将以太网报文封装在GRE内的一种隧道转发模式；采用24比特标识二层网络分段，称为VSI(Virtual Subnet Identifier)，类似于VLAN ID作用；为了使NVGRE利用承载网络路由的均衡性，NVGRE在GRE扩展字段flow ID，这就要求物理网络能够识别到GRE隧道的扩展信息，并以flow ID进行流量分担；未知目的、广播、组播等网络流量均被封装为组播转发。 3.STT（Stateless Transport Tunneling）。 STT利用了TCP的数据封装形式，但改造了TCP的传输机制，数据传输不遵循TCP状态机，而是全新定义的无状态机制，将TCP各字段意义重新定义，无需三次握手建立TCP连接，因此称为无状态TCP；以太网数据封装在无状态TCP；采用64比特Context ID标识二层网络分段；为了使STT充分利用承载网络路由的均衡性，通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为无状态TCP的源端口号；未知目的、广播、组播等网络流量均被封装为组播转发。 参考: http://www.h3c.com.cn/About_H3C/Company_Publication/IP_Lh/2013/04/Home/Catalog/201309/796466_30008_0.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[pyinstaller使用技巧]]></title>
      <url>%2F2017%2F01%2F22%2Fpyinstaller%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[​ 不经意间发现了这个工具pyinstaller2.0。它的功能是把python脚本打包成windows的可执行文件，这样就可以方便使用程序了。为了玩一下，于是写了一个图片分类的脚本，按照jpg, gif, png后缀将图片分别存储在各自文件夹中。脚本放在github上了。https://github.com/Luckylau/Useful-Python-Sample/blob/master/useful-tools/classify_Pic.py pythoninstall2.0运行前需要安装pywin32，假如你使用的是python 2.7(64位)，需要在官网 https://sourceforge.net/projects/pywin32/files/pywin32找到对应的版本 我的环境：win 10 python 2.7 (64位) ,pywin32-220.win-amd64-py2.7 打开pyinstall-2.0文件夹 如下图，shift+右键鼠标打开cmd,注意的是文件的路径不能有中文，我之前用的路径是D:\日常资料\日常资料\图片\大雪，会出现编码问题 在cmd上执行,不用理会error报错。 pyinstaller参数有如下选项，我们用的是-F, 后面跟的是要打包的python脚本的位置。 可选的opts有： -F, –onefile 打包成一个exe文件。 -D, –onedir 创建一个目录，包含exe文件，但会依赖很多文件（默认选项）。 -c, –console, –nowindowed 使用控制台，无界面(默认) -w, –windowed, –noconsole 使用窗口，无控制台 完毕之后，会在下图所示位置生成exe文件。 我们在该目录下取得exe文件，执行效果和python脚本是一样的。大功告成~~~~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo备份小技巧]]></title>
      <url>%2F2017%2F01%2F21%2Fhexo%E5%A4%87%E4%BB%BD%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[提交到github上备份: 12345678910111213cd blog/hexo# 初始化仓库git initgit add .git commit -m &quot;init&quot;# 建一个分支git checkout -b hexo# 删除本地的master分支git branch -d master# 添加远程git remote add origin https://github.com/用户名/用户名.github.io.git# 保存git push -u origin hexo 更换环境时: 123456789101112131415#1.安装git(配置git),nodejs;#2.克隆到本地git clone https://github.com/用户名/用户名.github.io.git hexocd hexo git checkout hexo#3.安装各种npm包npm install -g hexo-clinpm installnpm install hexo-deployer-git --save#用于markdown插入图片,首先确认 _config.yml 中有 post_asset_folder:truenpm install https://github.com/CodeFalling/hexo-asset-image --save#4 部署hexo cleanhexo generatehexo deploy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python中的struct模块]]></title>
      <url>%2F2017%2F01%2F19%2FPython%E4%B8%AD%E7%9A%84struct%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[​ python的struct模块，是在查看RYU控制器Openflow协议的实现源码接触到的。RYU控制器解包和封包就是用struct模块实现的。 ​ 在C语言中，struct结构体里面可以包含不同数据类型，比如int ,char,bool等。但是一旦涉及到网络通信时，传递的是二进制数据流（binary data）。对于二进制字符串，不必担心，但是对于如int，char等基本数据类型，需要有一种机制将这些特定的结构体类型打包成二进制流的字符串然后再在网络传输，同时接收端也需要通过某种机制进行解包还原出原始的结构体数据。 ​ python中的struct模块就提供了这样的机制，该模块的主要作用就是对python基本类型值与用python字符串格式表示的C struct类型间的转化，如下图: 1.简单演示 12345678910111213141516171819import structimport binasciivalues=(2017,'luckylau0',1.19)s=struct.Struct('I9sf')packed_data = s.pack(*values)#打包unpacked_data = s.unpack(packed_data)#解包print 'Original values:', valuesprint 'Format string :', s.formatprint 'Uses :', s.size, 'bytes'print struct.calcsize('I9sf')print 'Packed Value :', binascii.hexlify(packed_data)print 'Unpacked Type :', type(unpacked_data), ' Value:', unpacked_data#输出Original values: (2017, 'luckylau0', 1.19)Format string : I9sfUses : 20 bytes20Packed Value : e10700006c75636b796c617530000000ec51983fUnpacked Type : &lt;type 'tuple'&gt; Value: (2017, 'luckylau0', 1.190000057220459) ​ 代码中，首先定义了一个元组数据，包含int、string、float三种数据类型，然后定义了struct对象，并制定了format‘I8sf’，I 表示int ,8s表示八个字符长度的字符串，f 表示 float。最后通过struct的pack和unpack进行打包和解包。通过输出结果可以发现，value被pack之后，转化为了一段二进制字节串，而unpack可以把该字节串再转换回一个元组，但是值得注意的是对于float的精度发生了改变，这是由一些比如操作系统等客观因素所决定的。 2.字节顺序 ​ 打包的后的字节顺序默认上是由操作系统的决定的，当然struct模块也提供了自定义字节顺序的功能 ​ 例如采用小端存储 s = struct.Struct(‘&lt;I3sf’) 3.利用buffer，使用pack_into和unpack_from方法 12345678910111213141516171819202122import structimport binasciiimport ctypes values1 = (1, 'abc', 2.7)values2 = ('defg',101)s1 = struct.Struct('I3sf')s2 = struct.Struct('4sI') prebuffer = ctypes.create_string_buffer(s1.size+s2.size)print 'Before :',binascii.hexlify(prebuffer)s1.pack_into(prebuffer,0,*values1)s2.pack_into(prebuffer,s1.size,*values2)print 'After pack:',binascii.hexlify(prebuffer)print s1.unpack_from(prebuffer,0)print s2.unpack_from(prebuffer,s1.size)#输出Before : 0000000000000000000000000000000000000000After pack: 0100000061626300cdcc2c406465666765000000(1, 'abc', 2.700000047683716)('defg', 101) ​ 使用二进制打包数据的场景大部分都是对性能要求比较高的使用环境，所以上面提到的pack方法都是对输入数据进行操作后重新创建了一个内存空间用于返回，也就是说我们每次pack都会在内存中分配出相应的内存资源，这有时是一种很大的性能浪费。pack_into() 和 unpack_from()的方法就是对一个已经提前分配好的buffer进行字节的填充，而不会每次都产生一个新对象对字节进行存储。在RYU控制器中就是使用这两种方法。 4.总结： struct 模块 Python的struct库是一个简单的,高效的数据封装\解封装的库。主要包含5个函数: struct.pack(fmt, v1, v2, …): 将V1,V2等值按照对应的fmt(format)进行封装。 struct.unpack(fmt, string): 将string按照fmt的格式解封。 struct.pack_into(fmt, buffer, offset, v1, v2, …): 将V1,V2等值按照对应的fmt(format)封装到buffer中，从初始位置offset开始。 struct.unpack_from(fmt, buffer[offset=0，]): 按照fmt的格式，从offset开始将buffer解封。 struct.calcsize(fmt)： 计算对应的fmt的长度。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(3)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-3%2F</url>
      <content type="text"><![CDATA[2015年-2016年（35本书）2015年（4本书） 63.《黑客与画家》-Paul Graham 64.《文明之光》-吴军 65.《向死而生》-李开复 66.《大学之路（上）》-吴军 2016年（31本书） 67.《硅谷之谜》-吴军 68.《时间的针脚》-玛利亚杜埃尼亚斯 69.《动物庄园》-奥威尔 70.《绝望锻炼了我：朴槿惠自传》-朴槿惠 71.《解忧杂货店》-东野圭吾 72.《激荡三十年上》-吴晓波 73.《疑问集》-聂鲁达 74.《硅谷钢铁侠：埃隆·马斯克的冒险人生》-阿什利·范斯 75.《鱼羊野史第一卷》-高晓松 76.《你一定爱读的极简欧洲史》-约翰·赫斯特 77.《这么慢,那么美》-罗敷 78.《一个人的朝圣》-蕾秋·乔伊斯 79.《野火集：三十周年纪念版》-龙应台 80.《我们仨》-杨绛 81.《人间失格》-太宰治 82.《在绝望中寻找希望》-俞敏洪 83.《当尼采哭泣》-欧文 D.亚隆 84.《念完哈佛念阿弥陀佛》-陈宇廷 85.《你今天真好看》-莉兹克里莫 86.《我们生活在巨大差异里》-余华 87.《梦里花落知多少》-三毛 88.《纯真博物馆》-奥尔罕帕慕克 89.《岛上书店》-加布瑞埃拉泽文 90.《我与地坛》-史铁生 91.《史玉柱自述：我的营销心得》-史玉柱 92.《飞鸟集》-泰戈尔 93.《我可以咬你一口吗？》-利兹克利莫 94.《末日巨塔-基地组织与911之路》-劳伦斯赖特 95.《菊与刀:日本文化类型》-鲁思本尼迪克特 96.《小王子》-安托万德圣埃克苏佩里 97.《爱你就像爱生命》-王小波]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(2)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-2%2F</url>
      <content type="text"><![CDATA[2012年-2014年（37本书）2012年（7本书） 26.《爱的艺术》-艾弗洛姆 27.《平凡的世界》-路遥 28.《人生课》-张岱年 29.《世间最美丽的情郎：仓央嘉措的情与诗》-王臣 30.《追风筝的人》-(美国）胡赛尼 31.《纳兰词》-纳兰性德 32.《阿德勒谈灵魂与情感》-阿尔弗雷德阿德勒 2013年（13本书） 33.《促销的本质》-山姆沃尔顿 34.《历史是个什么玩意》-袁腾飞 35.《世界如此险恶，你要内心强大2》-石勇 36.《少有人走的路1》-M·斯科特·派克 37.《世界如此险恶，你要内心强大1》-石勇 38.《明朝那些事儿》-当年明月 39.《天才在左疯子在右》-高铭 40.《哲学与人生I》-傅佩荣 41.《哲学与人生II》-傅佩荣 42.《乌合之众》（法译本）-[法]古斯塔夫·勒庞 43.《万历十五年（增订纪念本）》-[美]黄仁宇 44.《沉默的大多数》-王小波 45.《自控力》-凯利·麦格尼格尔 2014年（17本书） 46.《七里香》，《无怨的青春》，《时光九篇》，《边缘光影》，《迷途诗册》，《我折叠着我的爱》-席慕容 47.《蒙田随笔》-蒙田（上海书店出版社） 48.《读书与做人》-季羡林 49.《男人来自火星，女人来自金星1》-约翰格雷 50.《男人来自火星，女人来自金星2》-约翰格雷 51.《超越自卑》-阿尔弗雷德阿德勒 52.《苏菲的世界》-乔斯坦贾德 53.《德意志的另一行泪》-朱维毅 54.《浪潮之巅》-吴军 55.《如果在冬夜，一个旅人》-[意大利] 伊塔洛·卡尔维诺 56.《审美与人的自由》-刘晓波 57.《撒哈拉的故事》-三毛 58.《文明之光》-吴军 59.《悉达多》-[德]赫尔曼黑塞 60.《呼兰河传》-萧红 61.《月亮与六便士》-毛姆 62.《人类的群星闪耀时》-斯蒂芬茨威格]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95%2F</url>
      <content type="text"><![CDATA[2009年-2011年（25本书）1.《谈美》-朱光潜 2.《安娜·卡列尼娜》（上下册）-（俄罗斯）托尔斯泰 3.《遇见未知的自己》- 张德芬 4.《人生若只如初见古典诗词的美丽与哀愁》- 安意如 5.《宋词三百首》- 上疆村民选编 6.《世界因你不同——李开复自传》- 李开复 范海涛 7.《思无邪：追绎前生的记忆》-安意如 8.《看张·爱玲画语》-安意如 9.《林肯传 》-戴尔·卡耐基 10.《富豪发家史》-子志编著 11.《水知道答案》-〔日〕江本胜 12.《彼得大帝》-帕甫连科 13.《活着就是为了改变世界》-杰弗里·扬,威廉西蒙 14.《我是沃兹：一段硅谷和苹果的悲情罗曼史》-斯蒂夫沃兹尼亚 15.《美国通史(上)》 16.《美国通史(下)》 17.《爱情诗集》- 文爱艺 18.《麦田里的守望者》-J.D塞林格 19.《批评官员的尺度：《纽约时报》诉警察局长沙利文案》-安东尼 20.《你是那人间的四月天》-林徽因 21.《汪国真经典诗文》-汪国真 22.《中国人的品格》-罗家伦 23.《蒙田随笔》-蒙田 24.《汪国真精选集》 25.《巨流河》-齐邦媛]]></content>
    </entry>

    
  
  
</search>
