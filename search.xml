<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[java中的Unsafe类使用]]></title>
      <url>%2F2018%2F06%2F14%2Fjava%E4%B8%AD%E7%9A%84Unsafe%E7%B1%BB%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[Unsafe类存在sun.misc.Unsafe中可以直接读写内存、获得地址偏移值、锁定或释放线程。concurrentHashmap的1.7版本大量使用该类来提高提升Java运行效率。下面我们介绍一下其使用。 操作成员变量123456789101112131415161718192021222324252627282930313233343536373839public class test &#123; public static Unsafe getUnsafe() &#123; try &#123; final Field unsafeField = Unsafe.class.getDeclaredField("theUnsafe"); unsafeField.setAccessible(true); // the unsafe instance return (Unsafe) unsafeField.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] args)throws Exception &#123; Unsafe unsafe = getUnsafe(); Dog dog = new Dog(); // 获取name属性偏移量 long nameOffset = unsafe.objectFieldOffset(Dog.class.getDeclaredField("name")); unsafe.putObject(dog, nameOffset, "李富貴"); //获取age属性偏移量 long ageOffset = unsafe.objectFieldOffset(Dog.class.getDeclaredField("age")); unsafe.putInt(dog, ageOffset,5); System.out.println(dog.toString()); &#125;&#125;class Dog &#123; private String name; private int age; @Override public String toString() &#123; return "&#123;\"Dog\":&#123;" + " \"name\":\"" + name + "\"" + ", \"age\":\"" + age + "\"" + "&#125;&#125;"; &#125;&#125; 操作数组12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class test &#123; public static Unsafe getUnsafe() &#123; try &#123; final Field unsafeField = Unsafe.class.getDeclaredField("theUnsafe"); unsafeField.setAccessible(true); // the unsafe instance return (Unsafe) unsafeField.get(null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] args)throws Exception &#123; Unsafe unsafe = getUnsafe(); //帮助理解concurrentHashmap Dog[] dogs = new Dog[3]; long sbase = unsafe.arrayBaseOffset(Dog[].class); int ts = unsafe.arrayIndexScale(Dog[].class); int sshift = 31 - Integer.numberOfLeadingZeros(ts); unsafe.putOrderedObject(dogs, (long)(0 &lt;&lt; sshift) + sbase, new Dog("那傻狗",5)); unsafe.putOrderedObject(dogs, (long)(1 &lt;&lt; sshift) + sbase, new Dog("李富貴",5)); unsafe.putOrderedObject(dogs, ts*2 + sbase, new Dog("哈士奇", 5)); for(int i = 0 ; i &lt; dogs.length ; i++)&#123; System.out.println(dogs[i].toString()); &#125; &#125;&#125;class Dog &#123; private String name; private int age; public Dog(String name, int age)&#123; this.age = age; this.name = name; &#125; @Override public String toString() &#123; return "&#123;\"Dog\":&#123;" + " \"name\":\"" + name + "\"" + ", \"age\":\"" + age + "\"" + "&#125;&#125;"; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[concurrentHashmap的设计之美]]></title>
      <url>%2F2018%2F06%2F06%2FconcurrentHashmap%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B9%8B%E7%BE%8E%2F</url>
      <content type="text"><![CDATA[concurrentHashmap是Java工程师接触最多的关于并发和线程安全的类，本篇从jdk1.6, jdk1.7, jdk1.8三个版本的实现来详细分析其设计之美。 结构原型首先简单从整体把握concurrentHashmap的结构原理。 JDK1.6和JDK1.7版本 JDK1.8版本 构造函数名词解释initialCapacity：初始化容量，指的是所有Segment中的hash桶的数量和，默认16。 concurrencyLevel：最大并发级别，也是数组segments的最大长度，初始化之后就不会改变，实际扩容的是每个segment里的hash桶，默认16。 loadFactor：每个Segment的加载因子，当个数大于threshold=hash桶数量*loadFactor时候会扩容。 Unsafe：这是jdk1.7常用的机制，可以看这篇文章。 1234567891011121314151617181920212223242526272829303132333435363738394041private static final sun.misc.Unsafe UNSAFE; // Segment数组第一个元素的地址相对于该对象实例起始地址的偏移量private static final long SBASE; // Segment数组中元素element基本类型大小的移位量，比如我们要在i位置加入元素，//用unsafe.putOrderedObject(segments, (i &lt;&lt; SSHIFT) + SBASE, element);private static final int SSHIFT; //HashEntry数组第一个元素的地址相对于该对象实例起始地址的偏移量 private static final long TBASE; //HashEntry数组中元素基本类型大小的移位量private static final int TSHIFT; // ConcurrentHashMap属性hashSeed,segmentShift,segmentMask,segments的相对实例地址的偏移量private static final long HASHSEED_OFFSET; private static final long SEGSHIFT_OFFSET; private static final long SEGMASK_OFFSET; private static final long SEGMENTS_OFFSET; static &#123; int ss, ts; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class tc = HashEntry[].class; Class sc = Segment[].class; //获取数组中第一个元素的偏移量(get offset of a first element in the array) TBASE = UNSAFE.arrayBaseOffset(tc); SBASE = UNSAFE.arrayBaseOffset(sc); //获取数组中一个元素的大小(get size of an element in the array) ts = UNSAFE.arrayIndexScale(tc); ss = UNSAFE.arrayIndexScale(sc); //其中hashSeed = randomHashSeed(this)，随机一个hashSeed，用于key的hash计算 HASHSEED_OFFSET = UNSAFE.objectFieldOffset(ConcurrentHashMap.class.getDeclaredField("hashSeed")); SEGSHIFT_OFFSET = UNSAFE.objectFieldOffset(ConcurrentHashMap.class.getDeclaredField("segmentShift")); SEGMASK_OFFSET = UNSAFE.objectFieldOffset(ConcurrentHashMap.class.getDeclaredField("segmentMask")); SEGMENTS_OFFSET = UNSAFE.objectFieldOffset(ConcurrentHashMap.class.getDeclaredField("segments")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; if ((ss &amp; (ss-1)) != 0 || (ts &amp; (ts-1)) != 0) throw new Error("data type scale not a power of two"); SSHIFT = 31 - Integer.numberOfLeadingZeros(ss); TSHIFT = 31 - Integer.numberOfLeadingZeros(ts); &#125; JDK1.6版本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; //默认loadFactor=DEFAULT_LOAD_FACTOR=0.75f if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //默认concurrencyLevel=DEFAULT_CONCURRENCY_LEVEL=16， //MAX_SEGMENTS =1&lt;&lt;16即数组segments的最大长度，也是最大并发级别； if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; //保证concurrencyLevel是2^n，默认ssize=16； int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; //定位Segment的index时hash值的移位,默认时候sshift=4,segmentShift=32-4=28； segmentShift = 32 - sshift; //用于&amp; 运算定位Segment的index，默认构造时是0x0f(十进制也就是15) segmentMask = ssize - 1; this.segments = Segment.newArray(ssize); //默认initialCapacity=DEFAULT_INITIAL_CAPACITY=16 //MAXIMUM_CAPACITY=1&lt;&lt;30 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //确定每个segment初始化时候有多少个hash桶，并保证为2^n,默认cap = 1,但是之后每个segment构造完成后这个cap值就没用了。 int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = 1; while (cap &lt; c) cap &lt;&lt;= 1; //确定cap后开始初始化每个segment的table for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt; K,V &gt; (cap, loadFactor);&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); putAll(m);&#125; JDK1.7版本1234567891011121314151617181920212223242526272829303132public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; //cap = MIN_SEGMENT_TABLE_CAPACITY = 2，即每个segment容量最小初始化为2， //而jdk1.6默认cap=1 int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; //与jdk1.6不同点，这里只是构造一个segments和segments[0],懒加载 Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; //这里用UNSAFE给数组ss第一个元素赋值，内存非立即可见 UNSAFE.putOrderedObject(ss, SBASE, s0); this.segments = ss; &#125; // 其余的几个同上 JDK1.8版本基本类HashEntry和Segments JDK1.6版本123456789101112131415161718static final class HashEntry&lt;K,V&gt; &#123; final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next; HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) &#123; this.key = key; this.hash = hash; this.next = next; this.value = value; &#125; @SuppressWarnings("unchecked") static final &lt;K,V&gt; HashEntry&lt;K,V&gt;[] newArray(int i) &#123; return new HashEntry[i]; &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; //segment的table中HashEntry总数目，这里用volatile修饰，并发读的时候，避免无用读取操作 transient volatile int count; //反映segment是否被修改过 transient int modCount; // table的扩容阈值 transient int threshold; // 类似HashMap的table数组 transient volatile HashEntry&lt;K,V&gt;[] table; // 加载因子，确定扩容阈值，所有的segment都是一样的 final float loadFactor; Segment(int initialCapacity, float lf) &#123; loadFactor = lf; setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity)); &#125; @SuppressWarnings("unchecked") static final &lt;K,V&gt; Segment&lt;K,V&gt;[] newArray(int i) &#123; return new Segment[i]; &#125; // 只有持有本segment的锁或者是构造方法中才能调用这个方法 void setTable(HashEntry&lt;K,V&gt;[] newTable) &#123; //默认时候这里的newTable.length = 1 ， threshold = 0 threshold = (int)(newTable.length * loadFactor); table = newTable; &#125; // 跟indexFor算法一样 HashEntry&lt;K,V&gt; getFirst(int hash) &#123; HashEntry&lt;K,V&gt;[] tab = table; return tab[hash &amp; (tab.length - 1)]; &#125; // 加锁读取value，在直接读取value得到null时会调用，源码这里有英文注释：读到value为null，只有当某种重排序的HashEntry初始化代码让volatile变量初始化重排序到构造方法外面时才会出现，这一点旧的内存模型下是合法的，但是不知道会不会发生。 // stackoverflow有讨论:http://stackoverflow.com/questions/5002428/concurrenthashmap-reorder-instruction/5144515#5144515 //在新的内存模型下，是不会发生value= null的，jdk1.7修复了这个问题 V readValueUnderLock(HashEntry&lt;K,V&gt; e) &#123; lock(); try &#123; return e.value; &#125; finally &#123; unlock(); &#125; &#125; // 下面的方法是常见操作，get, put, remove, contains等等 // 读操作之get,直接读value是不用加锁的，碰到读到value == null，才加锁再读一次 V get(Object key, int hash) &#123; if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if (v != null) return v; return readValueUnderLock(e); // recheck &#125; e = e.next; &#125; &#125; return null; &#125; boolean containsKey(Object key, int hash) &#123; if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) return true; e = e.next; &#125; &#125; return false; &#125; //类似get boolean containsValue(Object value) &#123; if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt;[] tab = table; int len = tab.length; for (int i = 0 ; i &lt; len; i++) &#123; for (HashEntry&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; V v = e.value; if (v == null) // recheck v = readValueUnderLock(e); if (value.equals(v)) return true; &#125; &#125; &#125; return false; &#125; //写操作之替换 boolean replace(K key, int hash, V oldValue, V newValue) &#123; lock(); try &#123; HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; boolean replaced = false; if (e != null &amp;&amp; oldValue.equals(e.value)) &#123; // replace不会修改modCount，这降低了containValue方法的准确性，jdk1.7修复了这一点 replaced = true; e.value = newValue; &#125; return replaced; &#125; finally &#123; unlock(); &#125; &#125; //写操作之替换 V replace(K key, int hash, V newValue) &#123; lock(); try &#123; HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; // replace不会修改modCount，这降低了containValue方法的准确性，jdk1.7修复了这一点 oldValue = e.value; e.value = newValue; &#125; return oldValue; &#125; finally &#123; unlock(); &#125; &#125; // 写操作之put V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; lock(); try &#123; int c = count; //先执行扩容，再添加节点，1.6的HashMap是先添加节点，再扩容,由于用的是c++ &gt; threshold,如果 threshold = 12，那么在这个Segment上执行第13次put时，判断语句为 12++ &gt; 12是为false，并未扩容，在第14次 13++&gt;12才扩容的，但是会保证默认情况第二次才扩容：每个Segment的table.length都为1，threthold = 0的，第一次put时候0++ &gt;0是为false,并未扩容，第二次1++&gt;0才会扩容。 if (c++ &gt; threshold) // ensure capacity rehash(); HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); // 定位方式和1.6的HashMap一样 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; if (e != null) &#123; oldValue = e.value; if (!onlyIfAbsent) // put相同的key（相当于replace）不会修改modCount，这降低了containsValue方法的准确性，jdk1.7修复了这一点 e.value = value; &#125; else &#123; oldValue = null; ++modCount; // 也是添加在HashEntry链的头部，前面说了，这里的HashEntry的next指针是final的，new后就不能变 tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; &#125; return oldValue; &#125; finally &#123; unlock(); &#125; &#125; // 扩容时为了不影响正在进行的读线程，最好的方式是全部节点复制一次并重新添加 // 这里根据扩容时节点迁移的性质，最大可能的重用一部分节点，这个性质跟1.8的HashMap中的高低位是一个道理，必须要求hash值是final的 void rehash() &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity &gt;= MAXIMUM_CAPACITY) return; // 扩容前在一个hash桶中的节点，扩容后只会有两个去向，这里是用e.hash &amp; sizeMask； // 根据这个去向，找到最末尾的去向都一样的连续的一部分，这部分可以重用，不需要复制； // HashEntry的next是final的，resize/rehash时需要重新new，这里的特殊之处就是最大程度重用HashEntry链尾部的一部分，尽量减少重新new的次数； // 作者说从统计角度看，默认设置下有大约1/6的节点需要被重新复制一次，所以通常情况还是能节省不少时间的； HashEntry&lt;K,V&gt;[] newTable = HashEntry.newArray(oldCapacity&lt;&lt;1); threshold = (int)(newTable.length * loadFactor); // 跟1.6的HashMap有一样的小问题，可能会过早变为Integer.MAX_VALUE从而导致后续永远不能扩容 int sizeMask = newTable.length - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123; // We need to guarantee that any existing reads of old Map can proceed. So we cannot yet null out each bin. 为了保证其他线程能够继续执行读操作，不执行手动将原来table赋值为null，只是再最后修改一次table的引用 HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; // int idx = e.hash &amp; sizeMask; // Single node on list if (next == null) newTable[idx] = e; else &#123; // Reuse trailing consecutive sequence at same slot HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; // 这个循环是寻找HashEntry链最大的可重用的尾部 // 看过1.8的HashMap就知道，如果hash值是final的，那么每次扩容，扩容前在一条链表上的节点，扩容后只会有两个去向 // 这里重用部分中，所有节点的去向相同，它们可以不用被复制 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; newTable[lastIdx] = lastRun; // 把重用部分整体放在扩容后的hash桶中 // 复制不能重用的部分，并把它们插入到rehash后的所在HashEntry链的头部 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; int k = p.hash &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(p.key, p.hash, n, p.value); &#125; // 这里也可以看出，重用部分rehash后相对顺序不变，并且还是在rehash后的链表的尾部 // 不能重用那些节点在rehash后，再一个个重头添加到链表的头部，如果还在一条链表上面，那么不能重用节点的相对顺序会颠倒 // 所以ConcurrentHashMap的迭代顺序会变化，本身它也不保证迭代顺序不变 &#125; &#125; &#125; table = newTable; &#125; // 因为1.6的HashEntry的next指针是final的，所以比普通的链表remove要复杂些，只有被删除节点的后面可以被重用，前面的都要再重新insert一次 V remove(Object key, int hash, Object value) &#123; lock(); try &#123; int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; //找到被删除的e while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; V v = e.value; if (value == null || value.equals(v)) &#123; oldValue = v; // All entries following removed node can stay in list, but all preceding ones need to be cloned.因为next指针是final的，所以删除不能用简单的链表删除，需要把前面的节点都重新复制再插入一次，后面的节点可以重用；删除后，后面的可以重用的那部分顺序不变且还是放在最后，前面的被复制的那部分顺序颠倒地放在前面 ++modCount; //被删除的e的next标记为newFirst，不断对e之前的元素复制+头插法方式完成新的链表 HashEntry&lt;K,V&gt; newFirst = e.next; for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; count = c; // write-volatile &#125; &#125; return oldValue; &#125; finally &#123; unlock(); &#125; &#125; //清除所有的元素 void clear() &#123; if (count != 0) &#123; lock(); try &#123; HashEntry&lt;K,V&gt;[] tab = table; for (int i = 0; i &lt; tab.length ; i++) tab[i] = null; ++modCount; count = 0; // write-volatile &#125; finally &#123; unlock(); &#125; &#125; &#125; &#125; 附录： jdk1.6的扩容图。我们假设原先某个segment的table大小为2，扩容后的newtable大小为4，table[0]对应一个大小为7的HashEntry，经过e.hash &amp; sizeMask之后，10-14-18是落到newtable[3]，6也是落到newtable[3]，,2-8-4是落到newtable[0]。这个扩容的过程是这样的：首先rehash过程会找到可重用部分，即图上的10-14-18，通过newTable[lastIdx] = lastRun整体的将它们放到newtable[3]的位置去，各个元素的顺序相对原来并没有变化的；对于不可重用的部分，只有遍历和复制的方式，通过头插法，放到newtable中，这时我们发现6被头插到newtable[3]中，所以newtable[3]中的链表元素顺序为6-10-14-18，2-8-4被头插到newtable[0]中，顺序变为倒序了。这些操作完成之后才table = newTable，这是为了保证其他线程能够继续执行读操作，不执行手动将原来table赋值为null，只是再最后修改一次table的引用；对于原先的table，会被gc回收掉。 jdk1.6的删除图。假设我们从segment[0].table[2]中删除98的节点。 JDK1.7版本12345678910111213141516171819202122232425262728293031323334static final class HashEntry&lt;K,V&gt; &#123; final int hash; // hash是final的，1.7的HashMap中不是final的，用final对扩容比较友好 final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; // jdk1.7中next指针不再是final的，改为volatile，使用 setNext 方法（内部用Unsafe的提供的方法）更新 HashEntry(int hash, K key, V value, HashEntry&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; // putOrderedObject，这个方法只有作用于volatile才有效，它能保证写操作的之间的顺序性，但是不保证能立马被其他线程读取到最新结果，是一种lazySet，效率比volatile高，但是只有volatile的“一半”的效果； // 普通的volatile保证写操作的结果能立马被其他线程看到，不论其他线程是读操作还写操作； // putOrderedObject能保证其他线程在写操作时一定能看到这个方法对变量的改变，但是其他线程只是进行读操作时，不一定能看到这个方法对变量的改变； final void setNext(HashEntry&lt;K,V&gt; n) &#123; UNSAFE.putOrderedObject(this, nextOffset, n); &#125; // 初始化执行Unsafe有关的操作 static final sun.misc.Unsafe UNSAFE; static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = HashEntry.class; nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("next")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265 static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; // 尝试次数 transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor; Segment(float lf, int threshold, HashEntry&lt;K,V&gt;[] tab) &#123; this.loadFactor = lf; this.threshold = threshold; this.table = tab; &#125; // jdk1.6中的 newArray、setTable 这两个方法因为实现太简单了，直接不用了; // jdk1.6中的 get、containsKey、containsValue 这几个方法，因为都是读操作，实现基本类似，用 Unsafe 提供的一些底层操作代替了; // jdk1.6中的 getFirst 虽然实现也很简单，但还是用 Unsafe 提供的一些底层方法强化了这个操作; // 保证了对数组元素的volatile读取，1.6的只保证对整个数组的读取是volatile; // jdk1.6中的 readValueUnderLock 在1.7中彻底去掉了; final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); // 看scanAndLockForPut方法的注释 V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; // 1.7的put相同的key（这时候相当于replace）时也会修改modCount了，1.6是不会的，能够更大地保证containValue这个方法的准确性 &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); // 尝试添加在链表头部 else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; // 先加1 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) // 超过最大容量的情况，在put这里一并处理了 rehash(node); else setEntryAt(tab, index, node); // 不扩容时，直接让新节点成为头节点 ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; // 1.7的rehash方法带有参数了，这个参数node就是要新put进去的node，新的rehash方法带有部分put的功能 // 节点迁移的基本思路还是和1.6的一样 @SuppressWarnings("unchecked") private void rehash(HashEntry&lt;K,V&gt; node) &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; int newCapacity = oldCapacity &lt;&lt; 1; threshold = (int)(newCapacity * loadFactor); HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123; HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; if (next == null) // Single node on list 只有一个节点，简单处理 newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot 最大地重用链表尾部的一段连续的节点（这些节点扩容后在新数组中的同一个hash桶中），并标记位置 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; newTable[lastIdx] = lastRun; // Clone remaining nodes 对标记之前的不能重用的节点进行复制，再重新添加到新数组对应的hash桶中去 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; int nodeIndex = node.hash &amp; sizeMask; // add the new node 部分的put功能，把新节点添加到链表的最前面 node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable; &#125; // 为put方法而编写的，在尝试获取锁的同时时进行一些准备工作的方法 // 获取不到锁时，会尝试一定次数的准备工作，这个准备工作指的是“遍历并预先创建要被添加的新节点，同时监测链表是否改变” // 这样有可能在获取到锁时新的要被put的节点已经创建了，可以在put时少做一些工作 // 准备工作中也会不断地尝试获取锁，超过最大准备工作尝试次数就直接阻塞等待地获取锁 private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; if (e == null) &#123; // 遍历完了，发现这条链表上没有“相等”的节点 if (node == null) // speculatively create node 预先创建要被添加的新节点 node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; // 遍历完都没碰见“相等”，不再遍历了，改为 尝试直接获取锁，没获取到锁时尝试监测链表是否改变 &#125; else if (key.equals(e.key)) // 碰见“相等”，不再遍历了，改为 尝试直接获取锁，没获取到锁时尝试监测链表是否改变 retries = 0; else // 遍历链表 e = e.next; &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123; // 超过最大的准备工作尝试次数，放弃准备工作尝试，直接阻塞等待地获取锁 lock(); break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; // 间隔一次判断是否有新节点添加进去 e = first = f; // re-traverse if entry changed 如果链表改变，就重新遍历一次链表 retries = -1; // 重置次数 &#125; &#125; return node; &#125; // 基本同scanAndLockForPut，但是更简单些，只用遍历链表并监测改变，不用创建新节点 private void scanAndLock(Object key, int hash) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; int retries = -1; while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; if (retries &lt; 0) &#123; if (e == null || key.equals(e.key)) retries = 0; else e = e.next; &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; e = first = f; retries = -1; &#125; &#125; &#125; // 因为1.7的HashEntry.next是volatile的，可以修改，因此remove操作简单了很多，就是基本的链表删除操作。 final V remove(Object key, int hash, Object value) &#123; if (!tryLock()) scanAndLock(key, hash); V oldValue = null; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; e = entryAt(tab, index); HashEntry&lt;K,V&gt; pred = null; while (e != null) &#123; K k; HashEntry&lt;K,V&gt; next = e.next; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; V v = e.value; if (value == null || value == v || value.equals(v)) &#123; if (pred == null) setEntryAt(tab, index, next); // remove的是第一个节点 else pred.setNext(next); // 直接链表操作，前面说了1.7的HashEntry.next是volatile的，可以修改，不再跟1.6一样是final的！！！ ++modCount; --count; oldValue = v; &#125; break; &#125; pred = e; e = next; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; // 1.7相对1.6的两点改动： // 1、多了个scanAndLock操作；2、会修改modCount final boolean replace(K key, int hash, V oldValue, V newValue) &#123; if (!tryLock()) scanAndLock(key, hash); boolean replaced = false; try &#123; HashEntry&lt;K,V&gt; e; for (e = entryForHash(this, hash); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; if (oldValue.equals(e.value)) &#123; e.value = newValue; ++modCount; // 1.7的replace方法也会修改modCount了，1.6是不会的，能够更大地保证containValue这个方法 replaced = true; &#125; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return replaced; &#125; // 基本同replace(K key, int hash, V oldValue, V newValue) final V replace(K key, int hash, V value) &#123; if (!tryLock()) scanAndLock(key, hash); V oldValue = null; try &#123; HashEntry&lt;K,V&gt; e; for (e = entryForHash(this, hash); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; e.value = value; ++modCount; // 1.7的replace方法也会修改modCount了，1.6是不会的，能够更大地保证containValue这个方法 break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; // 基本没改变 final void clear() &#123; lock(); try &#123; HashEntry&lt;K,V&gt;[] tab = table; for (int i = 0; i &lt; tab.length ; i++) setEntryAt(tab, i, null); ++modCount; count = 0; &#125; finally &#123; unlock(); &#125; &#125; &#125; JDK1.8版本常用方法读方法，外面封装一层其实还是操作segment。 JDK1.6版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138public V get(Object key) &#123; int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash); &#125;public boolean containsKey(Object key) &#123; int hash = hash(key.hashCode()); return segmentFor(hash).containsKey(key, hash); &#125; private static int hash(int h) &#123; // Spread bits to regularize both segment and index locations, // using variant of single-word Wang/Jenkins hash. h += (h &lt;&lt; 15) ^ 0xffffcd7d; h ^= (h &gt;&gt;&gt; 10); h += (h &lt;&lt; 3); h ^= (h &gt;&gt;&gt; 6); h += (h &lt;&lt; 2) + (h &lt;&lt; 14); return h ^ (h &gt;&gt;&gt; 16); &#125; //定位Segment的index时hash值的移位,默认时候sshift=4,segmentShift=32-4=28；//segmentShift = 32 - sshift; //segmentMask = ssize - 1 = 15final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; &#125; // 不是Map接口的方法，为了兼容Hashtable，等价于containsValue public boolean contains(Object value) &#123; return containsValue( value); &#125; public boolean containsValue(Object value) &#123; if (value == null) throw new NullPointerException(); final Segment&lt;K,V&gt;[] segments = this.segments; int[] mc = new int[segments.length]; // 先不加锁执行RETRIES_BEFORE_LOCK = 2次 for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) &#123; int sum = 0; int mcsum = 0; for (int i = 0; i &lt; segments.length; ++i) &#123; int c = segments[i].count; // 这个c没哪里用，意义不明 mcsum += mc[i] = segments[i].modCount; // 就是 mc[i] = segments[i].count; mssum += mc[i]，临时保存一份modCount if (segments[i].containsValue(value)) // 碰见contains直接return return true; &#125; boolean cleanSweep = true; // mcsum是modCount的和，为0可以认为遍历开始时没有任何put完成过任何HashEntry，即方法开始执行时不包含任何HashEntry，可以认为（近似认为，几率比较大）此时也不包含 if (mcsum != 0) &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; int c = segments[i].count; if (mc[i] != segments[i].modCount) &#123; // modCount改变，说明有其他线程修改了Segment的结构，退出循环。会有replace的问题，前面说了 cleanSweep = false; break; &#125; &#125; &#125; if (cleanSweep) return false; &#125; // 如果连续两次都碰见modCount改变的情况，这时候一次性对全部Segment加锁，最大程度保证遍历时的一致性 // 因为是全部加锁后再遍历，遍历开始后没有线程可以修改任何Segment的结构，可以保证当前线程得到的是准确值 for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); boolean found = false; try &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; if (segments[i].containsValue(value)) &#123; found = true; break; &#125; &#125; &#125; finally &#123; for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); &#125; return found; &#125; //不加锁执行一次public boolean isEmpty() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int[] mc = new int[segments.length]; int mcsum = 0; for (int i = 0; i &lt; segments.length; ++i) &#123; if (segments[i].count != 0) return false; else mcsum += mc[i] = segments[i].modCount; &#125; if (mcsum != 0) &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; if (segments[i].count != 0 || mc[i] != segments[i].modCount) return false; &#125; &#125; return true; &#125; public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; long sum = 0; long check = 0; int[] mc = new int[segments.length]; // 不加锁执行两次，如果两次数据不一样，或者碰到modCount++被修改了，就全部加锁在执行一次 for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) &#123; check = 0; sum = 0; int mcsum = 0; for (int i = 0; i &lt; segments.length; ++i) &#123; sum += segments[i].count; mcsum += mc[i] = segments[i].modCount; &#125; if (mcsum != 0) &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; check += segments[i].count; if (mc[i] != segments[i].modCount) &#123; check = -1; // force retry break; &#125; &#125; &#125; if (check == sum) break; &#125; if (check != sum) &#123; sum = 0; for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); for (int i = 0; i &lt; segments.length; ++i) sum += segments[i].count; for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); &#125; if (sum &gt; Integer.MAX_VALUE) // int溢出处理，因此返回值可能会是错误的。 // 并且因为兼容性的原因，这个还无法解决，只能新增一个方法，1.8的ConcurrentHashMap就是新增了一个返回long型的方法。 return Integer.MAX_VALUE; else return (int)sum; &#125; 写方法 1234567891011121314151617181920212223public V put(K key, V value) &#123; if (value == null) throw new NullPointerException(); int hash = hash(key.hashCode()); // 这里 null key 会抛出NPE return segmentFor(hash).put(key, hash, value, false); &#125; // 下面几个基本思路同put，都是代理给相应的Segment的对应方法进行操作 public V putIfAbsent(K key, V value); public V remove(Object key); public boolean remove(Object key, Object value); public boolean replace(K key, V oldValue, V newValue); public V replace(K key, V value); // putAll和clear都是循环操作，没有全局加锁，在执行期间还是可以执行完成其他的写操作的，事务性比较差的方法，设计成不用全局锁是为了提高效率 public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue()); &#125; public void clear() &#123; for (int i = 0; i &lt; segments.length; ++i) segments[i].clear(); &#125; JDK1.7版本读方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163// get方法整体实现思路跟1.6基本一样 // 1.7的使用了Unsafe.getObjectVolatile，它能为普通对象提供volatile读取功能，能够强化这里的get方法 // get方法的操作都比较简单，就都把操作集中在这里，省略了Segment.get，减少方法调用带来的开销，抽象性层次性也没有变差 public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead 集中在这里手动访问减少方法调用开销 HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp;(tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile(tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null; &#125; private int hash(Object k) &#123; int h = hashSeed; if ((0 != h) &amp;&amp; (k instanceof String)) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // Spread bits to regularize both segment and index locations, // using variant of single-word Wang/Jenkins hash. h += (h &lt;&lt; 15) ^ 0xffffcd7d; h ^= (h &gt;&gt;&gt; 10); h += (h &lt;&lt; 3); h ^= (h &gt;&gt;&gt; 6); h += (h &lt;&lt; 2) + (h &lt;&lt; 14); return h ^ (h &gt;&gt;&gt; 16); &#125; public boolean contains(Object value) &#123; return containsValue( value); &#125; public boolean containsValue(Object value) &#123; // Same idea as size() if (value == null) throw new NullPointerException(); final Segment&lt;K,V&gt;[] segments = this.segments; boolean found = false; long last = 0; int retries = -1; try &#123; outer: for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; long hashSum = 0L; int sum = 0; for (int j = 0; j &lt; segments.length; ++j) &#123; HashEntry&lt;K,V&gt;[] tab; //segmentAt如下解释 Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null &amp;&amp; (tab = seg.table) != null) &#123; for (int i = 0 ; i &lt; tab.length; i++) &#123; HashEntry&lt;K,V&gt; e; for (e = entryAt(tab, i); e != null; e = e.next) &#123; V v = e.value; if (v != null &amp;&amp; value.equals(v)) &#123; found = true; break outer; // 这里就算是contains也会再执行一次，1.6如果第一次contains就直接return，不会执行第二次 &#125; &#125; &#125; sum += seg.modCount; &#125; &#125; if (retries &gt; 0 &amp;&amp; sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return found; &#125; // 使用Unsafe提供的volatile读取功能，通过下标求segments[j] // segments是用final修饰的，构造方法保证它会在ConcurrentHashMap的实例被引用前初始化成正确的值，null的情况只在反序列化时才会出现 static final &lt;K,V&gt; Segment&lt;K,V&gt; segmentAt(Segment&lt;K,V&gt;[] ss, int j) &#123; long u = (j &lt;&lt; SSHIFT) + SBASE; // 计算实际的字节偏移量 return ss == null ? null : (Segment&lt;K,V&gt;) UNSAFE.getObjectVolatile(ss, u); &#125; // 通过下标定位到Segment中下标为 i 的hash桶的第一个节点，也就是链表的头结点，用 Unsafe 提供对数组元素的 // volatile 读取，还要处理下Segment为null的情况static final &lt;K,V&gt; HashEntry&lt;K,V&gt; entryAt(HashEntry&lt;K,V&gt;[] tab, int i) &#123; return (tab == null) ? null : (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile(tab, ((long)i &lt;&lt; TSHIFT) + TBASE); &#125;// isEmpty方法，实现思路跟1.6的基本一样，利用modCount单调递增的性质偷了个懒，只进行sum(modCount)的前后比较，不用一个个单独地前后比较 public boolean isEmpty() &#123; long sum = 0L; final Segment&lt;K,V&gt;[] segments = this.segments; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; if (seg.count != 0) return false; sum += seg.modCount; &#125; &#125; if (sum != 0L) &#123; // recheck unless no modifications for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; if (seg.count != 0) return false; sum -= seg.modCount; // 1.6这里的一个个modCount对比，1.7改为总体对比一次，因为modCount的单调递增的，不会有count可能出现的 ABA 问题 &#125; &#125; if (sum != 0L) return false; &#125; return true; &#125; // size方法，实现思路跟1.6的基本一样，也利用了modCount单调递增的性质偷了个懒 public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size; &#125; JDK1.8版本参考：https://blog.csdn.net/fenglibing/article/details/17119959 https://blog.csdn.net/u011392897/article/details/60466665 https://blog.csdn.net/u011392897/article/details/60469263 https://blog.csdn.net/u011392897/article/details/60479937 https://juejin.im/post/5a815743f265da4e7e10b8e8 https://blog.csdn.net/hitxueliang/article/details/24734861]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(5)]]></title>
      <url>%2F2018%2F06%2F04%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-5%2F</url>
      <content type="text"><![CDATA[2018年-至今149.《富爸爸穷爸爸》-罗伯特清崎 沙伦莱希特 150.《向光生长：阿德勒自我超越心理学》-阿尔弗雷德阿德勒 151.《永恒的边缘》-肯福莱特 152.《智能时代》-吴军 153.《那些我们没谈过的事》-马克李维 154.《怪诞经济学》-利玛窦默特里尼 155.《降临》-特德姜 156.《冷知识》-小巫博士 157.《风口上的猪》-肖璟 158.《十万次相亲》-水水 159.《观念的水位》-刘瑜 160.《激荡十年，水大鱼大：中国企业2008-2018》-吴晓波 161.《思考致富》-拿破仑希尔 162.《做最擅长的事：沈南鹏传》-张笑恒 163.《六祖坛经》-蔡志忠]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[缓存设计在系统中的重要性]]></title>
      <url>%2F2018%2F05%2F15%2F%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E5%9C%A8%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之适配器模式]]></title>
      <url>%2F2018%2F05%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之装饰器模式]]></title>
      <url>%2F2018%2F05%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之责任链模式]]></title>
      <url>%2F2018%2F05%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySql数据库之Schema及数据类型优化]]></title>
      <url>%2F2018%2F05%2F01%2FMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8BSchema%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySql数据库之索引优化]]></title>
      <url>%2F2018%2F05%2F01%2FMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响愈发重要。 索引的数据结构B-Tree索引？​ 维基百科对B树的定义为“在计算机科学中，B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。” ​ 目前大多数的存储引擎使用B-Tree索引，严格来说是 B+树。相比B树，二叉树，Hash，它有哪些优势呢? 相对于二叉树，明显的优势是避免树的深度过大而造成磁盘I/O读写过于频繁；相对于Hash，见下面Hash索引限制描述；相比较B树来说，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历；详情参考这篇文章。 适用场景：等值匹配，全值匹配，匹配最左前缀，匹配列前缀，范围匹配，只访问索引的查询，如覆盖索引。 Hash 索引？​ 哈希索引基于哈希表实现，只有精确匹配索引所有列时才有效。对于每一行数据，存储引擎都会根据索引列计算一个哈希值，哈希索引将所有的hash值存储在索引中，同时在哈希表中保存指向每个数据行的指针。 ​ MySQL中只有Memory引擎显式支持哈希索引。这也是Memory引擎的默认存储引擎，Memory引擎同时也支持B-Tree索引，哈希索引解决碰撞的方式是使用链表。 Hash索引的限制： 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行； 哈希索引数据并不是按照索引列的值顺序存储的，所以也就无法用于排序； 哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引的全部列值内容来计算哈希值的。如：数据列（a,b）上建立哈希索引，如果只查询数据列a，则无法使用该索引； 哈希索引只支持等值比较查询，如：=，in()， &lt;=&gt;，不支持任何范围查询； 访问哈希索引的数据非常快，除非有很多哈希冲突，当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行； 如果哈希冲突很多的话，一些索引维护操作的代价也很高，如：如果在某个选择性很低的列上建立哈希索引（即很多重复值的列），那么当从表中删除一行时，存储引擎需要遍历对应哈希值的链表中的每一行，找到并删除对应的引用，冲突越多，代价越大； 适用场景：只需要做等值比较查询，而不包含排序或范围查询的需求，都适合使用哈希索引。 MyISAM和InnoDB对B-Tree索引实现​ MyISAM索引文件和数据文件是分离的，索引文件仅保存记录所在页的指针（物理位置），通过这些地址来读取页，进而读取被索引的行，对于二级（辅助）索引，与主索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复，可见MyISAM索引是“非聚合的”。 ​ InnoDB的主索引是采用“聚集索引”的数据存储方式，所谓“聚集”，就是指数据行和键值紧凑地存储在一起（InnoDB 只能聚集一个叶子页（16K）的记录），因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形；对于二级（辅助）索引，InnoDB采用的方式是在叶子页中保存主键值，通过这个主键值来回表查询到一条完整记录，因此按辅助索引检索实际上进行了二次查询，效率肯定是没有按照主键检索高的。由于每个辅助索引都包含主键索引，因此，为了减小辅助索引所占空间，我们通常希望 InnoDB 表中的主键索引尽量定义得小一些（值得一提的是，MySIAM会使用前缀压缩技术使得索引变小，而InnoDB按照原数据格式进行存储），并且希望InnoDB的主键是自增长的，因为如果主键并非自增长，插入时，由于写入时乱序的，会使得插入效率变低。 索引的优点​ 最常见的B-Tree索引，按照顺序存储数据，索引可以做ORDER BY和GROUP BY操作。因为数据是有序的，所以B-Tree也会将相关的列存储在一起，因为索引中存储了实际的列值，所以某些查询只是用索引就能够完成全部查询（覆盖索引，索引包含所有满足查询需要的数据的索引，也就是平时所说的不需要回表操作）：索引大大减少了服务器需要扫描的数据量；索引可以帮助服务器避免排序和临时表；索引可以将随机IO变为顺序IO； 索引优化策略独立的列索引列不能是表达式的一部分，也不能是函数的参数，例如 1select * from table where id + 1 = 5; 这个就不对了。此外对于列的类型也要注意一些优化：字段类型优先级： 整型 &gt; date, time &gt; enum, char&gt;varchar &gt; blob；够用就行,不要慷慨 (如smallint,varchar(N))，原因是大的字段浪费内存,影响速度；尽量避免用NULL()，原因是NULL不利于索引,要用特殊的字节来标注； 前缀索引和索引的选择性​ 有时候需要索引很长的字符列，这会让索引变得很大且慢，除了模拟hash值存储的方式外，还可以索引开始部分的字符，这样可以大大节约索引空间，从而提高索引效率，但这样会降低索引的选择性（不重复的索引值(也称为基数)和数据表的记录总数(#T)的比值，范围从1/#T到1之间）。要注意以下几点： 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的； 一般情况下某个列前缀的选择性也是足够高的，足以满足查询性能。对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度； 计算合适的前缀长度的一个方法是计算完整列的选择性，并使前缀的选择性接近于完整列的选择性； 前缀索引是一种能使索引更小、更快的有效办法，但另一方面也有其缺点：MySQL无法使用前缀索引做ORDER BY和GROUP BY , 也无法使用前缀索引做覆盖扫描； 有时候后缀索引也有用途(例如，找到某个域名的所有电子邮件地址)。MySQL原生并不支持反向索引，但是可以把字符串反转后存储，并基于此建立前缀索引。可以通过触发器来维护这种索引。 多列索引合理使用联合索引，不要在where后面用到的每一列都加索引。 选择合适的索引列顺序正确的索引顺序依赖于使用该索引的查询，并同时满足需要考虑如何更好地满足排序和分组的需要。 聚簇索引​ InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和数据行。它的数据实际上存储在索引的叶子页中。”聚簇”表示把数据行和相邻的键值紧凑地存储在一起。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 聚簇索引的优点:可以把相关的数据保存在一起;数据访问更快;使用覆盖索引扫描的查询可以直接使用叶节点中的主键值。 聚簇索引的缺点：更新聚簇索引列的代价很高，因为会强制将每个被更新的行移动到新的位置；可能会导致页分裂；导致全表扫描变慢，尤其是行比较稀疏；二级索引(非聚簇索引)可能比想象的要更大，因为在二级索引的叶子节点包含了引用行的主键列；二级索引访问需要两次索引查询，而不是一次。这是因为二级索引叶子节点保存的不是指向行的物理位置的指针，而是行的主键值。这意味着通过二级索引查找行，存储引擎需要找到二级索引的叶子 节点获得对应的主键值，然后根据这个值去聚簇索引中查找到对应的行。这里做了重复工作：两次B-Tree查找而不是一次。 索引覆盖​ 索引覆盖是指 如果查询的列恰好是索引的一部分,那么查询只需要在索引文件上进行,不需要回行到磁盘再找数据。这种查询速度非常快,称为”索引覆盖”。 索引与排序​ MySQL有两种方式可以生成有序的结果：通过排序操作；或者按索引顺序扫描；如果EXPLAIN出来的type列的值为”index”,则说明MySQL使用了索引来做排序(不要和Extra列的 “Using index”搞混淆了)。 压缩(前缀压缩)索引​ MyISAM使用前缀索引压缩来减少索引的大小，从而让更多的索引可以放入内存中，这在某些情况下能极大地提高性能。默认值压缩字符串，但通过参数设置可以对整数压缩。InnoDB按照原数据格式进行存储。 冗余和重复索引​ MySQL允许在相同列上创建多个索引，无论是有意还是无意的。MySQL需要单独维护重复的索引，并且优化器在优化查询的是时候也需要逐个地进行考虑，这会影响性能。重复索引是指在相同的列上按照相同的顺序创建相同类型的索引。冗余索引，如果创建了索引(A,B)，再创建索引(A)就是冗余索引，因为这只是前一个索引的前缀索引。 未使用的索引对于服务器上一些永远不用的索引，完全是累赘，建议考虑删除。 索引和锁InnoDB只有在访问行的时候才会对其进行加锁，而索引能够减少InnoDB访问的行数，从而减少锁的数量。 如何排查SQL语句？show processlistexplain 参数值 含义 id 表示SELECT语句的编号； select_type 表示SELECT语句的类型。该参数有几个常用的取值：SIMPLE：表示简单查询，其中不包括连接查询和子查询；PRIMARY：表示主查询，或者是最外层的查询语句；UNION：表示连接查询的第二个或后面的查询语句； table 表示查询的表； type 表示表的连接类型。该参数有几个常用的取值：const：表示表中有多条记录，但只从表中查询一条记录；eqref ：表示多表连接时，后面的表使用了UNIQUE或者PRIMARY KEY；ref：表示多表查询时，后面的表使用了普通索引；unique subquery：表示子查询中使用了UNIQUE或者PRIMARY KEY；index_ subquery：表示子查询中使用了普通索引； range ：表示查询语句中给出了查询范围；index ：表示对表中的索引进行了完整的扫描;all ：表示此次查询进行了全表扫描； ———– 该条SQL需要优化； possible_keys 表示查询中可能使用的索引；如果备选的数量大于3那说明已经太多了，因为太多会导致选择索引而损耗性能， 所以建表时字段最好精简，同时也要建立联合索引，避免无效的单列索引； key 表示查询使用到的索引； key_len 表示索引字段的一长度； ref 表示使用哪个列或常数与索引一起来查询记录； rows 表示查询的行数;试图分析所有存在于累计结果集中的行数，虽然只是一个估值，却也足以反映 出SQL执行所需要扫描的行数，因此这个值越小越好； Extra 表示查询过程的附件信息； 使用索引比未使用索引，扫描的行数更少查询速度更快； 在查询语句中使用LIKE关键字进行查询时，如果匹配字符串的第一个字符为“%”时，索引不会被使用。如果“%”不是在第一个位置，索引就会被使用； 使用多列索引时，只有查询条件中使用了该索引中的第一个索引字段时，索引才会被使用； 查询语句只有OR关键字时，如果OR前后的两个条件列都是索引时，查询中将使用索引。只要OR前后有一个条件的列不是索引，那么查询中将不使用索引。注： 1：where 语句里面如果带有or条件, myisam表能用到索引，innodb不行；2：必须所有的or条件都必须是独立索引； 经过普通运算或函数运算后的索引字段不能使用索引； show profiles项目中遇到的问题？参考：https://blog.csdn.net/mine_song/article/details/63251546 https://www.cnblogs.com/vincently/p/4526560.html https://blog.csdn.net/v_JULY_v/article/details/6530142 http://blog.codinglabs.org/articles/theory-of-mysql-index.html https://blog.csdn.net/stfphp/article/details/52827845 https://www.cnblogs.com/xpp142857/p/7373005.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySql数据库之体系结构]]></title>
      <url>%2F2018%2F05%2F01%2FMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[MySQL逻辑架构事务事务及隔离级别并发控制存储引擎]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Restful Webservice与Soap Webservice区别]]></title>
      <url>%2F2018%2F04%2F24%2FRestful-Webservice%E4%B8%8ESoap-Webservice%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[Netty的原理(1)]]></title>
      <url>%2F2018%2F04%2F24%2FNetty%E7%9A%84%E5%8E%9F%E7%90%86-1%2F</url>
      <content type="text"><![CDATA[​ Netty是Java IO 不可绕过的技术，Netty系列学习在李林峰的《Netty权威指南》以及优秀博客和Netty源码上总结思考而来。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[序列化与反序列化]]></title>
      <url>%2F2018%2F04%2F20%2F%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
      <content type="text"><![CDATA[这里介绍几种常见的序列化，包括FastJsonSerialization，FstSerialization，KryoSerialization，Hessian2Serialization，ProtocolBuffer。 FastJsonFstKryoHessian2ProtocolBuffer参考http://www.xuetimes.com/archives/572 https://blog.csdn.net/moonpure/article/details/53175519]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网站流量与性能分析指标]]></title>
      <url>%2F2018%2F04%2F19%2F%E7%BD%91%E7%AB%99%E6%B5%81%E9%87%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%8C%87%E6%A0%87%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（9）]]></title>
      <url>%2F2018%2F04%2F16%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%889%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本篇主要详细介绍动态查找树的演进，包括平衡二叉树，2-3查找树，红黑树，B树以及B+树。 平衡二叉树2-3查找树红黑树B树B+树]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot之MongoDB]]></title>
      <url>%2F2018%2F04%2F15%2FSpringBoot%E4%B9%8BMongoDB%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解http协议(3)]]></title>
      <url>%2F2018%2F04%2F10%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3http%E5%8D%8F%E8%AE%AE-3%2F</url>
      <content type="text"><![CDATA[常见问题一次HTTP操作的流程？域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户。 GET与POST方法有什么区别？ 方法 GET POST 后退按钮/刷新 无害 数据会被重新提交（浏览器应该告知用户数据会被重新提交）。 书签 可收藏为书签 不可收藏为书签 缓存 能被缓存 不能缓存 编码类型 application/x-www-form-urlencoded application/x-www-form-urlencoded 或 multipart/form-data。为二进制数据使用多重编码。 历史 参数保留在浏览器历史中。 参数不会保存在浏览器历史中。 对数据长度的限制 是的。当发送数据时，GET 方法向 URL 添加数据；URL 的长度是受限制的（URL 的最大长度是 2048 个字符）。 无限制。 对数据类型的限制 只允许 ASCII 字符。 没有限制。也允许二进制数据。 安全性 与 POST 相比，GET 的安全性较差，因为所发送的数据是 URL 的一部分。在发送密码或其他敏感信息时绝不要使用 GET ！ POST 比 GET 更安全，因为参数不会被保存在浏览器历史或 web 服务器日志中。 可见性 数据在 URL 中对所有人都是可见的。 数据不会显示在 URL 中。 另外从RFC协议的角度分析： GET的语义是请求获取指定的资源。GET方法是安全、幂等、可缓存的（除非有 Cache-Control Header的约束）,GET方法的报文主体没有任何语义。 POST的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST不安全，不幂等，（大部分实现）不可缓存。 注意理解这里面的安全，幂等，可缓存： Safe - 安全这里的「安全」和通常理解的「安全」意义不同，如果一个方法的语义在本质上是「只读」的，那么这个方法就是安全的。客户端向服务端的资源发起的请求如果使用了是安全的方法，就不应该引起服务端任何的状态变化，因此也是无害的。 此RFC定义，GET, HEAD, OPTIONS 和 TRACE 这几个方法是安全的。但是这个定义只是规范，并不能保证方法的实现也是安全的，服务端的实现可能会不符合方法语义，正如上文说过的使用GET修改用户信息的情况。引入安全这个概念的目的是为了方便网络爬虫和缓存，以免调用或者缓存某些不安全方法时引起某些意外的后果。User Agent（浏览器）应该在执行安全和不安全方法时做出区分对待，并给用户以提示。Idempotent - 幂等幂等的概念是指同一个请求方法执行多次和仅执行一次的效果完全相同。按照RFC规范，PUT，DELETE和安全方法都是幂等的。同样，这也仅仅是规范，服务端实现是否幂等是无法确保的。引入幂等主要是为了处理同一个请求重复发送的情况，比如在请求响应前失去连接，如果方法是幂等的，就可以放心地重发一次请求。这也是浏览器在后退/刷新时遇到POST会给用户提示的原因：POST语义不是幂等的，重复请求可能会带来意想不到的后果。Cacheable - 可缓存性 顾名思义就是一个方法是否可以被缓存，此RFC里GET，HEAD和某些情况下的POST都是可缓存的，但是绝大多数的浏览器的实现里仅仅支持GET和HEAD。关于缓存的更多内容可以去看RFC7234。 在这三个特性里一直在强调同一个事情，那就是协议不等于实现：协议规定安全在实现里不一定安全，协议规定幂等在实现里不一定幂等，协议规定可缓存在实现里不一定可缓存。 URI、URL和URN的区别?这三个缩略词是Tim Berners-Lee在一篇名为RFC 3986: Uniform Resource Identifier (URI): Generic Syntax的文档中定义的互联网标准追踪协议。 URI：Uniform Resource Identifier，即统一资源标志符，用来唯一的标识一个资源。 URL：Uniform Resource Locator，统一资源定位符。即URL可以用来标识一个资源，而且还指明了如何locate这个资源。 URN：Uniform Resource Name，统一资源命名。即通过名字来表示资源的。 URL和URN都是URI的子集。 Session cookie和Session对象的生命周期是一样的吗?当用户关闭了浏览器虽然session cookie已经消失，但session对象仍然保存在服务器端，直到其失效时间。 是否只要关闭浏览器，session就消失了?​ 程序一般都是在用户做log off的时候发个指令去删除session，然而浏览器从来不会主动在关闭之前通知服务器它将要被关闭，因此服务器根本不会有机会知道浏览器已经关闭。服务器会一直保留这个会话对象直到它处于非活动状态超过设定的间隔为止。大部分session机制都使用会话cookie来保存session id，而关闭浏览器后这个session id就消失了，再次连接到服务器时也就无法找到原来的session。如果服务器设置的cookie被保存到硬盘上，或者使用某种手段改写浏览器发出的 HTTP请求报头，把原来的session id发送到服务器，则再次打开浏览器仍然能够找到原来的session。恰恰是由于关闭浏览器不会导致session被删除，迫使服务器为session 设置了一个失效时间，当距离客户上一次使用session的时间超过了这个失效时间时，服务器就可以认为客户端已经停止了活动，才会把session删除以节省存储空间。 参考：https://blog.csdn.net/laven90/article/details/43731301 https://sunshinevvv.coding.me/blog/2017/02/09/HttpGETv.s.POST/ https://www.cnblogs.com/tgwang/p/5170480.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解http协议(2)]]></title>
      <url>%2F2018%2F04%2F10%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3http%E5%8D%8F%E8%AE%AE-2%2F</url>
      <content type="text"><![CDATA[本章主要介绍Cookie与Session以及JWT，同时讨论如何安全进行会话跟踪。 什么是Cookie​ Http协议是无状态的，为了解决Http协议无法维持状态的问题，1994年网景通讯的一名员工 Lou Montulli将 “magic cookies” 的概念应用到 Web 通讯中。他试图解决 Web 的第一个购物车应用，现在购物车成了购物网站的支柱。他的原始说明文档提供了 cookie 工作原理的基本信息，该文档后来被作为规范纳入到 RFC 2109（大多数浏览器的实现参考文档）中，最终被纳入到 RFC 2965 中。Montulli 也被授予 cookie 的美国专利。网景浏览器在它的第一个版本中就开始支持 cookie，现在所有 Web 浏览器都支持 cookie。 ​ Java中把Cookie封装成了javax.servlet.http.Cookie类。每个Cookie都是该Cookie类的对象。服务器通过操作Cookie类对象对客户端Cookie进行操作。通过request.getCookie()获取客户端提交的所有Cookie（以Cookie[]数组形式返回），通过response.addCookie(Cookie cookie)向客户端设置Cookie。 Cookie的属性12345678String name：该Cookie的名称。Cookie一旦创建，名称便不可更改。Object value：该Cookie的值。如果值为Unicode字符，需要为字符编码。如果值为二进制数据，则需要使用BASE64编码。 int maxAge：该Cookie失效的时间，单位秒。如果为正数，则该Cookie在&gt;maxAge秒之后失效。如果为负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。如果为0，表示删除该Cookie。默认为–1。boolean secure：该Cookie是否仅被使用安全协议传输。安全协议。安全协议有HTTPS，SSL等，在网络上传输数据之前先将数据加密。默认为false。String path：该Cookie的使用路径。如果设置为“/sessionWeb/”，则只有contextPath为“/sessionWeb”的程序可以访问该Cookie。如果设置为“/”，则本域名下contextPath都可以访问该Cookie。注意最后一个字符必须为“/”。 String domain：可以访问该Cookie的域名。如果设置为“.google.com”，则以“google.com”结尾的域名都可以访问该Cookie。注意第一个字符必须为“.”。 String comment：该Cookie的用处说明。浏览器显示Cookie信息的时候显示该说明。 int version：该Cookie使用的版本号。0表示遵循Netscape的Cookie规范，1表示遵循W3C的RFC 2109规范.boolean httponly: 若此属性为true，则只有在http请求头中会带有此cookie的信息，而不能通过document.cookie来访问此cookie Cookie的优缺点cookie只能保存字符串类型，以文本的方式； 单个cookie保存的数据不能超过4kb； 有些状态不可能保存在客户端； cookie数据有路径（path）的概念，可以限制cookie只属于某个路径下； 什么是Session为什么有了cookie之后还会有session使用呢？在解决这个疑问，首先要清楚session。Session本身是记录客户状态的机制，决定客户端与服务端交互是继续还是中断，session常被翻译为“会话”，但这是一个抽象的概念，它的基本原理是它将信息保存在服务端，客户端通过一定方式传递sessionid（例如借助cookie）来保持与服务端的连接。session在设计来说比cookie更更安全：sessionID存储在cookie中，若要攻破session首先要攻破cookie；sessionID是要有人登录，或者启动session_start才会有，所以攻破cookie也不一定能得到sessionID；第二次启动session_start后，前一次的sessionID就是失效了，session过期后，sessionID也随之失效；sessionID是加密的； Session优缺点session通过类似与Hashtable的数据结构来保存，能支持任何类型的对象(session中可含有多个对象。 session大小没有限制； Session保存的东西越多，就越占用服务器内存，对于用户在线人数较多的网站，服务器的内存压力会比较大； 什么是JWT​ Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 JWT的结构​ 它是由三部分组成：header，payload，signature。header中通常来说由token的生成算法和类型组成；payload中则用来保存相关的状态信息；signature部分由header，payload，secret_key三部分生成。 ​ 首先用户发出登录请求，服务端根据用户的登录请求进行匹配，如果匹配成功，将相关的信息放入payload中，利用上述算法，加上服务端的密钥生成token，这里需要注意的是secret_key很重要，如果这个泄露的话，客户端就可以随意篡改发送的额外信息，它是信息完整性的保证。生成token后服务端将其返回给客户端，客户端可以在下次请求时，将token一起交给服务端，一般来说我们可以将其放在Authorization首部中，这样也就可以避免跨域问题。接下来，服务端根据token进行信息解析，再根据用户信息作出相应的操作。 Cookie、Session和JWT区别与联系​ cookie的信息是存在客户端浏览器的，不需要维护状态，但是使用cookies时，在多个域名下，会存在跨域问题，同时一般浏览器对cookie数量和大小都有限制；session的信息存在服务端，需要维护状态，当高并发时候会影响服务器的性能, 当有多台机器时，如何共享session也会是一个问题。一般Session机制实现会借助与Cookie传递SessionId。JWT采用token机制，解决http无状态问题的，目前也并不会完全替代Cookie、Session机制。因为它自身也存在一些问题，比如登录状态信息续签问题，比如设置token的有效期为一个小时，那么一个小时后，如果用户仍然在这个web应用上，这个时候当然不能指望用户再登录一次。目前可用的解决办法是在每次用户发出请求都返回一个新的token，前端再用这个新的token来替代旧的，这样每一次请求都会刷新token的有效期。但是这样，需要频繁的生成token；用户主动注销。JWT并不支持用户主动退出登录，当然，可以在客户端删除这个token，但在别处使用的token仍然可以正常访问。所以JWT天然的适合在一定时间内操作，否则链接失效的场景，比如邮箱注册验证链接等。 使用场景Cookie的应用​ 判断用户是否登陆过网站，以便下次登录时能够实现自动登录（或者记住密码）。如果我们删除cookie，则每次登录必须从新填写登录的相关信息；保存上次登录的时间等信息；保存上次查看的页面；浏览计数； Session的应用Session+Cookie​ 虽然Session保存在服务器，对客户端是透明的，它的正常运行仍然需要客户端浏览器的支持。这是因为Session需要使用Cookie作为识别标志。HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一个名为JSESSIONID的Cookie，它的值为该Session的id（也就是HttpSession.getId()的返回值）。Session依据该Cookie来识别是否为同一用户。该Cookie为服务器自动生成的，它的maxAge属性一般为–1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，关闭浏览器就会失效。 ​ 同一机器的两个浏览器窗口访问服务器时，会生成两个不同的Session。但是由浏览器窗口内的链接、脚本等打开的新窗口（也就是说不是双击桌面浏览器图标等打开的窗口）除外。这类子窗口会共享父窗口的Cookie，因此会共享一个Session。注意：新开的浏览器窗口会生成新的Session，但子窗口除外。子窗口会共用父窗口的Session。例如，在链接上右击，在弹出的快捷菜单中选择“在新窗口中打开”时，子窗口便可以访问父窗口的Session。 Session+URL地址重写URL地址重写是对客户端不支持Cookie的解决方案。URL地址重写的原理是将该用户Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。HttpServletResponse类提供了encodeURL(Stringurl)实现URL地址重写。 Session+隐藏的表单域隐藏的表单域是一种最简单的方式，将字段隐藏在HTML表单中，但不在客户端显示。比如在第一张页面中输入用户名和密码登陆，服务器生成响应返回第二张页面。当第二张页面提交时可能仍然需要知道来自第一张页面中的用户名。那么就可以通过隐藏表单域来实现这一连续的过程。当第一张页面提交后，服务器端作出响应返回第二张页面，此页面中用隐藏域记录了来自登陆时的用户名。通俗说就是当服务器回发给客户端的响应中，就同时把用户名再次回发到客户端，用隐藏域隐藏起来，是不可见的。当第二张页面提交时，此隐藏域中的用户名一并随表单提交。这样服务器就仍然可以判断此用户是否与以前的用户相同。于是，再次处理完结果后继续将响应回发给客户端，且此响应中也仍然包含了用户名，在客户端中仍然用隐藏域将这一信息隐藏。这样就完成了一个连续请求的动作，但是对于用户，这是不可见的。 JWT的应用用于设计用户认证和授权系统，甚至实现Web应用的单点登录，多web服务器下实现无状态分布式身份验证等。 参考https://www.cnblogs.com/andy-zhou/p/5360107.html https://www.zhihu.com/question/19786827 https://blog.csdn.net/yunnysunny/article/details/26935637 https://blog.csdn.net/webwalker/article/details/707927 https://www.cnblogs.com/henryhappier/archive/2011/03/03/1969564.html https://blog.csdn.net/qq_29831979/article/details/75374751 https://www.jianshu.com/p/ecd455e1c7cd https://www.cnblogs.com/cencenyue/p/7604651.html https://blog.csdn.net/u011145904/article/details/77745777 https://www.jianshu.com/p/fcc1a6482143?from=timeline]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解http协议(1)]]></title>
      <url>%2F2018%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3http%E5%8D%8F%E8%AE%AE-1%2F</url>
      <content type="text"><![CDATA[头域​ 每个头域由一个域名，冒号（:）和域值三部分组成。域名是大小写无关的，域值前可以添加任何数量的空格符，头域可以被扩展为多行，在每行开始处，使用至少一个空格或制表符。 Host头域：指定请求资源的Intenet主机和端口号，必须表示请求url的原始服务器或网关的位置。HTTP/1.1请求必须包含主机头域，否则系统会以400状态码返回。 User-Agent头域：包含发出请求的用户信息。 Cache-Control头域：指定请求和响应遵循的缓存机制。在请求消息或响应消息中设置Cache-Control并不会修改另一个消息处理过程中的缓存处理过程。请求时的缓存指令包括no-cache、no-store、max-age、max-stale、min-fresh、only-if-cached，响应消息中的指令包括public、private、no-cache、no-store、no-transform、must-revalidate、proxy-revalidate、max-age。 Date头域：表示消息发送的时间，缓存在评估响应的新鲜度时要用到，时间的描述格式由RFC822定义。 HTTP之请求消息Request请求行（request line）、请求头部（header）、空行和请求数据四个部分组成： HTTP之响应消息Response状态行、消息报头、空行和响应正文： HTTP之状态码1xx：指示信息–表示请求已接收，继续处理2xx：成功–表示请求已被成功接收、理解、接受3xx：重定向–要完成请求必须进行更进一步的操作4xx：客户端错误–请求有语法错误或请求无法实现5xx：服务器端错误–服务器未能实现合法的请求 状态码 含义 200 OK 客户端请求成功 400 Bad Request 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务 404 Not Found 请求资源不存在，eg：输入了错误的URL 500 Internal Server Error 服务器发生不可预期的错误 503 Server Unavailable 服务器当前不能处理客户端的请求，一段时间后可能恢复正常]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式服务框架原理(3)]]></title>
      <url>%2F2018%2F04%2F02%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86-3%2F</url>
      <content type="text"><![CDATA[分布式服务框架高可用与管理服务路由集群容错服务降级流量控制服务多版本服务灰度发布分布式消息跟踪]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式服务框架原理(2)]]></title>
      <url>%2F2018%2F04%2F02%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86-2%2F</url>
      <content type="text"><![CDATA[分布式服务框架基础服务通信框架长连接还是短连接​ 相比于短连接，长连接更节省资源：如果每发送一条消息就要创建链路、发起握手认证、关闭链路释放资源，会损耗大量的系统资源。长连接只在首次创建时或者链路断连重连才创建链路，链路创建成功之后服务提供者和消费者会通过业务消息和心跳维系链路，实现多消息复用同一个链路节省资源。 ​ 远程通信是常态，调用时延时关键指标：服务化之后，本地API调用变成了远程服务调用，大量本地方法演化成跨进程通信，网络时延成为关键指标之一。相比于一次简单的服务调用，链路的重建通常耗时更多，这就会导致链路层的时延消耗远远大于服务调用本身的损耗。 BIO还是NIO​ BIO的通信模型如下：通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端连接的请求后，为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数成1：1的正比关系，由于线程是Java虚拟机非常宝贵的系统资源，当线程数膨胀后，系统的性能将急速下降，随着并发访问量的继续增大，系统会发生线程堆栈溢出，创建新线程失败等问题，并最终导致进程宕机或者僵死，不能对外提供服务。 ​ NIO的通信模型如下：采用多路复用技术，一个多路复用器Selector可以同时轮询多个Channel，由于JDK采用了epoll()代替了传统的select实现，所以它并没有最大连接句柄1024/2048的限制。这也就意味着只需一个线程负责Selector的轮询当需要同时处理多个客户端接入请求时，可以利用多线程或者IO多路复用技术进行处理。 各种IO性能对比 可靠性设计链路有效性检测：目前流行和通用做法是心跳检测。可以从三个层面来实现：TCP层面的心跳检测，即TCP的Keep-Alive机制，它的作用域是整个TCP协议栈。协议层的心跳检测，主要存在于长连接协议中，例如SMPP协议。应用层的心跳检测，主要由各业务通过约定方式时给对方发送心跳消息的实现。 断连重连检测：客户端检测到链路中断后，等INTERVAL时间，发起重连操作，如果重连失败，间隔周期INTERVAL后再次发起连接，直到重连成功。 消息缓存重发：并非所有场景都需要 资源优雅释放：Java的优雅停机通过注册JDK的ShutdownHook来实现，当系统接收到退出指令后，首先标记系统处于退出状态，不再接收新的消息，然后将积压的消息处理完，最后调用资源回收接口将资源销毁，最后各线程退出执行。 性能设计从网络传输方式（BIO还是NIO）,序列化性能，线程模型考虑，我们应该采用异步非阻塞通信，高效I/O线程模型，高性能的序列化框架。 序列化与反序列化序列化包括文本类（XML/JSON）和二进制类（PB/Thrift）2种，序列化和反序列化在使用上要独立灵活，易扩展，在功能设计上要具备前后兼容，跨语言支持，性能考虑码流大小，速度，资源占用等。 常见的序列化有fastjson，MessagePack（跨语言），ProtocolBuffer（跨语言），Thrift（跨语言）， Avro（跨语言），Xstream，hessian2（java），java自带序列化，Kryo(java)等。 例如dubbo提供7种序列化，如DubboSerialization（自研究，不建议生产使用），Hessian2Serialization（默认使用），JavaSerialization（原生），CompactedJavaSerialization（压缩java序列化，在原生java序列化基础上，实现了自己定义的类描写叙述符写入和读取。写Object类型的类描写叙述符仅仅写入类名称，而不是类的完整信息，这样有非常多Object类型的情况下能够降低序列化后的size），FstSerialization，KryoSerialization， FastJsonSerialization。 协议栈不同的服务在性能上使用不同协议进行传输，比如对接异构第三方服务时，通常会选择HTTP/Restful等公有协议。 协议栈承载了业务内部各模块之间的消息交互和服务调用，它的主要功能包括： 定义了私有协议的通信模型和消息定义； 支持服务提供者和消费者之间采用点对点长连接通信； 基于Java NIO通信框架，提供高性能的异步通信能力； 提供可扩展的编解码框架，支持多种序列化格式； 握手和安全认证机制； 链路的高可用性。 服务提供者和消费者之间采用单链路，长连接通信，链路创建流程如下： 客户端发送握手请求，携带节点ID等认证信息； 服务端校验：节点ID有效性，重复登录，ip地址黑白名单等，通过后，返回握手应答信息； 链路建立后，客户端发送业务消息； 客户端服务端心跳维持链路； 服务端退出时，关闭连接，客户端感知连接关闭，关闭客户端连接。 Dubbo支持多种协议，包括Dubbo协议，injvm协议，hessian协议，http协议，rest协议，redis协议，rmi协议，thrift协议，webservice协议，memcached协议。 服务间参数传递服务消费者和提供者之间进行通信时，除了接口定义的请求参数，往往还需要携带一些额外参数，例如消息提供者的IP地址，消息调用链的跟踪ID，这些参数不能通过业务接口来进行传递，需要底层的分布式服务框架支持这种惨呼传递方式。大体分为2种：内部传参和外部传参；内部传参指的是服务提供者或者消费者接口内部业务上下文的传递，外部传参指的是服务消费者和提供者之间的参数传递。 Dubbo的服务提供方使用RpcContext.getContext() .getAttachments()，获取参数；服务器消费方使用RpcContext.getContext().setAttachment()，传递参数。 服务注册对于服务提供者，它需要发布服务；对于服务消费者，它最关心如何获取它所需要的服务。如何有效的管理服务订阅和发布是一个分布式服务框架需要解决的一个问题。最常见的是使用Zookeeper作为服务注册中心。 服务发布和引用服务提供者通过配置，注解，API调用等方式，把本地接口发布成远程服务；服务消费者通过对等的方式引用远程服务提供者，实现服务的发布和引用。有4种方式：XML配置，属性配置，API配置， 注解配置。 服务优先级调度为了保证高优先级的服务能够正常运行，保障服务SLA，需要降低一些非核心服务的调度频次，释放部分资源占用，保障系统的整体运行平稳。有4种实现方式：基于线程调度器的优先级调度策略；基于优先级队列的优先级策略；基于加权配置的优先级调度策略；基于服务迁入迁出的优先级调度策略。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java并发之Fork/Join框架]]></title>
      <url>%2F2018%2F03%2F28%2Fjava%E5%B9%B6%E5%8F%91%E4%B9%8BFork-Join%E6%A1%86%E6%9E%B6%2F</url>
      <content type="text"><![CDATA[​ Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。 什么是Fork/Join源码分析使用示例参考https://www.cnblogs.com/senlinyang/p/7885964.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式服务框架原理(1)]]></title>
      <url>%2F2018%2F03%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86-1%2F</url>
      <content type="text"><![CDATA[​ 分布式服务框架不仅仅是RPC框架的调用，还涉及其他的基础设施来支持分布式管理，服务自动发现和服务治理等。之前研究了Dubbo的原理和机制，再回头看李林峰大神对分布式服务框架原理与实践的分析，顿时豁然开朗，之后我会根据《分布式服务框架原理与实践》这本书以及自己的见解，持续更新分布式服务框架的博客。 分布式服务框架总体设计架构特性 RPC层：包括底层通信框架(例如NIO框架的封装、公有协议的封装等)、序列化和反序列化框架、用于屏蔽底通信协议细节和序列化方式差异的Remoting框架。 Filter Chain 层：服务调用职责链,提供多种服务调用切面框架自身和使用者扩展,如负载均衡、服务调用性能统计、服务调用完成通知机制、失败重发等。 Service层：主要包括java动态代理,消费者使用,主要用于将服务提供者的接口封装成远程服务调用;JAVA反射,服务提供者使用,根据消费者请求消息中的接口名、方法名、参数列表反射调用服务提供者的接口本地实现类。再向上就是业务的服务接口定义和实现类,对于使用Spring配置化开发的就是Spring bean, 服务由业务来实现,平台负责将业务接口发布成远程服务。 功能特性 性能特性 可靠性 服务治理 业内分布式服务框架阿里DubboDubbo是阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的RPC实现服务的输出和输入功能，以及SOA服务治理方案，和spring框架无缝集成，详情见Dubbo的原理系列文章。 新浪motanmotan是2016年新浪微博开源的一款RPC框架，据说在新浪微博正支撑着千亿次调用。motan的设计更加精简，配置更加简单，他几乎就是一个剪裁版的dubbo，砍掉了大部分不常用的配置和特性，而简单则意味着对二次开发更加友好，参考这篇文章。 淘宝HSFHSF全称为High-Speed Service Framework，旨在为淘系的应用提供一个分布式的服务框架，HSF从分布式应用层面以及统一的发布/调用方式层面为大家提供支持，从而可以很容易的开发分布式的应用以及提供或使用公用功能模块，而不用考虑分布式领域中的各种细节技术，例如远程通讯、性能损耗、调用的透明化、同步/异步调用方式的实现等等问题。 亚马逊CoralServicecoral Service是亚马逊内部使用的基于Java的分布式服务方案，它的功能特点有支持多协议；轻量级架构，非常容易与已有的系统集成；配置化开发，对业务代码入侵低，开发效率高；与亚马逊其他基础设施集成，实现DevOps。 业内优秀开源RPC框架Facebook的Thrifthttps://github.com/apache/thrift Twitter的Finaglehttps://github.com/twitter/finagle Google的gRpchttps://github.com/grpc/grpc Hadoop的Avro-RPChttps://github.com/apache/avro Caucho的Hessianhttps://github.com/caucho/hessian(目前没有了) 架构演进传统的MVC垂直架构 -&gt; RPC框架 -&gt; 分布式服务框架 -&gt; docker + 微服务方向。 问题rmi与rpc的区别是什么？RPC远程过程调用 (Remote Procedure Call)，通过网络从远程计算机上请求调用某种服务，过程包括：执行客户端调用语句，传送参数；调用本地系统发送网络消息；消息传送到远程主机；服务器得到消息并取得参数；根据调用请求以及参数执行远程过程（服务）；执行过程完毕，将结果返回服务器句柄；服务器句柄返回结果，调用远程主机的系统网络服务发送结果；消息传回本地主机 ；客户端句柄由本地主机的网络服务接收消息；客户端接收到调用语句返回的结果数据。 RMI远程方法调用(Remote Method Invocation)，能够让在客户端Java虚拟机上的对象像调用本地对象一样调用服务端java 虚拟机中的对象上的方法，过程包括：客户调用客户端辅助对象stub上的方法；客户端辅助对象stub打包调用信息（变量，方法名），通过网络发送给服务端辅助对象skeleton；服务端辅助对象skeleton将客户端辅助对象发送来的信息解包，找出真正被调用的方法以及该方法所在对象；调用真正服务对象上的真正方法，并将结果返回给服务端辅助对象skeleton；服务端辅助对象将结果打包，发送给客户端辅助对象stub；客户端辅助对象将返回值解包，返回给调用者；客户获得返回值。 区别在于： ​ RMI中是通过在客户端的Stub对象作为远程接口进行远程方法的调用。每个远程方法都具有方法签名。如果一个方法在服务器上执行，但是没有相匹配的签名被添加到这个远程接口(stub)上，那么这个新方法就不能被RMI客户方所调用。RPC中是通过网络服务协议向远程主机发送请求，请求包含了一个参数集和一个文本值，通常形成“classname.methodname(参数集)”的形式。RPC远程主机就去搜索与之相匹配的类和方法，找到后就执行方法并把结果编码，通过网络协议发回。 ​ RMI只用于Java，RPC是网络服务协议，与操作系统和语言无关。Java是面向对象的，所以RMI的调用结果可以是对象类型或者基本数据类型；RMI的结果统一由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。 rpc框架与分布式服务框架区别？分布式服务框架，不仅具有RPC框架的特性，同时具备服务治理等特性。 SOA与MSA的区别？SOA是指面向服务的体系结构Service Oriented Architecture的简称；MSA是微服务Micro Services Architecture的简称。 服务拆分粒度：SOA首要解决的是异构系统的服务化；MSA专注服务的拆分，原子服务，专注于做一件事情，与面向对象中的“单一职责原则”类似，实现高内聚，低耦合。 服务依赖：SOA主要处理已有系统，重用已有的资产，存在大量服务间依赖，微服务强调服务自治，原子性，避免依赖耦合的产生； 服务规模：SOA服务粒度大，大多数将多个服务合并打包，因此服务实例数有限，微服务强调自治，服务独立部署，导致规模膨胀，对服务治理有挑战； 架构差异：微服务通常是去中心化的，SOA通常是基于ESB(企业服务总线)的； 服务治理：传统基于SOA Governance的静态治理转型为服务运行态微治理、实时生效； 敏捷交付：服务由小研发团队负责设计、开发、测试、部署、线上治理运维整个服务的生命周期； 参考《分布式服务框架原理与实践》 https://www.cnblogs.com/ygj0930/p/6542811.html http://www.cnblogs.com/ygj0930/p/6542811.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo线程池模型]]></title>
      <url>%2F2018%2F03%2F25%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-16%2F</url>
      <content type="text"><![CDATA[​ 对于Dubbo的服务提供者，主要有两种线程池，一种是IO处理线程池，另一种是服务调用线程池。本篇主要对Dubbo线程池模型做一下分析。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper的原理(5)]]></title>
      <url>%2F2018%2F03%2F19%2FZookeeper%E7%9A%84%E5%8E%9F%E7%90%86-5%2F</url>
      <content type="text"><![CDATA[​ 本章开始讲解Zookeeper重要的技术实现，前面两篇Zookeeper的原理(3)和Zookeeper的原理(4)分别讲解了客户端和服务端的设计原理，这一篇我们来聊聊Zookeeper的内存与存储以及运维的问题。 内存与存储​ ZKDatabase是ZooKeeper的内存数据库，负责管理ZooKeeper的所有会话、DataTree存储和事务日志。ZKDatabase会定时向磁盘dump快照数据，同时在ZooKeeper服务器启动的时候，会通过磁盘上的事务日志（在dataLogDir配置路径下的version-2的子目录中）和快照数据文件恢复成一个完整的内存数据库。 ​ ZooKeeper的数据模型是一棵树，DataTree是ZooKeeper内存数据存储的核心，是一个“树”的数据结构，代表了内存中的一份完整的数据。DataTree不包含任何与网络、客户端连接以及请求处理等相关的业务逻辑，是一个非常独立的ZooKeeper组件。 ​ DataNode是数据存储的最小单元，除了保存了节点的数据内容（data[]）、ACL列表（acl）和节点状态（stat）之外，还记录了父节点（parent）的引用和子节点列表（children）两个属性。同时，DataNode还提供了对子节点列表操作的各个接口。 下图是数据初始化的流程： 运维四字命令四字命令的使用方式非常简单，通常有两种方式：第一种是通过Telnet方式，第二种则是使用nc方式。 conf：输出 ZooKeeper服务器运行时使用的基本配置信息。 1234567891011121314[root@VM_0_5_centos ~]# telnet localhost 2181Trying 127.0.0.1...Connected to localhost.Escape character is &apos;^]&apos;.confclientPort=2181dataDir=/home/luckylau/zookeeper-3.4.9/data/version-2dataLogDir=/home/luckylau/zookeeper-3.4.9/logs/version-2tickTime=2000maxClientCnxns=60minSessionTimeout=4000maxSessionTimeout=40000serverId=0Connection closed by foreign host. cons：输出当前这台服务器上所有客户端连接的详细信息。 123456789[root@VM_0_5_centos ~]# telnet localhost 2181Trying 127.0.0.1...Connected to localhost.Escape character is '^]'.cons /124.204.55.194:49205[1](queued=0,recved=1259,sent=1259,sid=0x16223b514550012,lop=PING,est=1521777677833,to=40000,lcxid=0x5,lzxid=0x2b,lresp=1521794385909,llat=0,minlat=0,avglat=0,maxlat=8) /127.0.0.1:53438[0](queued=0,recved=1,sent=0)Connection closed by foreign host. crst：重置所有的客户端连接统计消息。 1234567[root@VM_0_5_centos ~]# telnet localhost 2181Trying 127.0.0.1...Connected to localhost.Escape character is &apos;^]&apos;.crstConnection stats reset.Connection closed by foreign host. dump：输出当前集群的所有会话信息 1234567891011121314[root@VM_0_5_centos ~]# telnet localhost 2181Trying 127.0.0.1...Connected to localhost.Escape character is &apos;^]&apos;.dumpSessionTracker dump:Session Sets (3):0 expire at Fri Mar 23 16:41:20 CST 2018:0 expire at Fri Mar 23 16:41:34 CST 2018:1 expire at Fri Mar 23 16:41:46 CST 2018: 0x16223b514550012ephemeral nodes dump:Sessions with Ephemerals (0):Connection closed by foreign host.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper的原理(4)]]></title>
      <url>%2F2018%2F03%2F18%2FZookeeper%E7%9A%84%E5%8E%9F%E7%90%86-4%2F</url>
      <content type="text"><![CDATA[​ 本章开始讲解Zookeeper重要的技术实现。上一篇我们讲解了Zookeeper客户端的原理与实现，本篇深入解析Zookeeper服务端的相关原理。 服务端会话会话创建流程 上面2个图展示了服务端会话创建处理和事务处理流程图。 初始化阶段​ 在ZooKeeper中，每一个NIOServerCnxn实例维护一个客户端连接，将请求内容从底层I/O中完整的读取出来。对于每个请求ZooKeeper都会检查当前NIOServerCnxn实体是否已经被初始化。如果尚未被初始化，那么就可以确定该客户单请求一定是“会话创建”请求。很显然，在会话创建初期，NIOServerCnxn尚未得到初始化，因此此时的第一个请求必定是“会话创建”请求。 一旦确定当前客户端请求是“会话创建”请求，那么服务端就可以对其进行反序列化，并生成一个ConnectRequest请求实体。 ​ 在ZooKeeper的设计实现中，如果当前ZooKeeper服务器是以ReadOnly模式启动的，那么所有来自非ReadOnly型客户端的请求将无法被处理。因此，针对ConnectRequest，服务器会首先检查其是否是ReadOnly客户端，并以此来决定是否接收该“会话创建”请求。 ​ 在正常情况下，同一个ZooKeeper集群中，服务端的ZXID必定大于客户端的ZXID，因此如果发现客户端的ZXID值大于服务端的ZXID值，那么服务端将不接受该客户端的“会话创建”请求。 ​ 客户端在构造ZooKeeper实例的时候，会有一个sessionTimeout参数用于指定会话的超时时间。客户端向服务器发送这个超时时间后，服务器会根据自己的超时时间限制最终确定该会话的超时时间——这个过程就是sessionTimeout协商过程。默认情况下，ZooKeeper服务端对超时时间的限制介于2个tickTime到20个tickTime之间。即如果我们设置tickTime值为2000（单位：毫秒）的话，那么服务端就会限制客户端的超时时间，使之介于4秒到40秒之间。可以通过zoo.cfg中的tickTime配置来调整这个超时时间的限制。 ​ 服务端根据客户端请求中是否包含sessionID来判断该客户端是否需要重新创建会话。如果客户端请求中已经包含了sessionID，那么就认为该客户端正在进行会话重连。在这种情况下，服务端只需要重新打开这个会话，否则需要重新创建。在创建新的会话时候，服务端首先给每个客户端都分配一个sessionID，通过如下算法保证全局唯一性： 123456public static long initializeNextSession(long id) &#123; long nextSid; nextSid = (Time.currentElapsedTime() &lt;&lt; 24) &gt;&gt;&gt; 8; nextSid = nextSid | (id &lt;&lt;56); return nextSid; &#125; 创建会话重要工作就是向SessionTracker中注册会话。SessionTracker中维护了两个比较重要的数据结构，分别是sessionsWithTimeout和sessionById。前者根据sessionID保存了所有会话的超时时间，而后者则是根据sessionID保存了所有会话实体。在会话创建初期，就应该将该客户端会话的相关信息保存到这两个数据结构中，方便后续会话管理器进行管理。向SessionTracker注册完会话后，接下来还需要对会话进行激活操作。激活会话过程涉及ZooKeeper会话管理的分桶策略。激活会话的核心是为会话安排一个区块，以便会话清理程序能够快速高效地进行会话清理。 123//过期时间设置规则ExpirationTime_ = CurrentTime + SessionTimeoutExpirationTime = (ExpirationTime_/ExpirationInterval + 1)* ExpirationInterval； 服务端在创建一个客户端会话的时候，会同时为客户端生成一个会话密码，连同sessionID一起发送给客户端，作为会话在集群中不同机器间转移的凭证。 预处理阶段​ 将请求交给PrepRequestProcessor处理器进行处理。对于事务请求，ZooKeeper首先会为其创建请求事务头，它包含了sessionID、ZXID、CXID和请求类型，除此之外还会创建事务体CreateSessionTxn。 属性 说明 clientId 客户端ID，用来唯一标识该请求所属的客户端 cxid 客户端的操作序列号 zxid 该事务请求对应的事务ZXID time 服务器开始处理该事务请求的时间 type 事务请求的类型，例如create、delete、setData和createSession等，这些事务类型都被定义在org.apache.zookeeper.ZooDefs.OpCode类中 然后还会再进行一次注册和激活会话，这里的会话注册与激活的目的是处理由非Leader服务器转发过来的会话创建请求。在这种情况下，其实尚未在Leader的SessionTracker中进行会话的注册，因此需要在此处进行一次注册与激活。 事务处理阶段完成请求的预处理后，会将请求交给ProposalRequestProcessor处理器，包括三个子处理流程，分别是Sync流程、Proposal流程和Commit流程。 Sync流程：使用SyncRequestProcessor处理器记录事务日志的过程。Leader服务器和Follower服务器的请求处理链路中都会有这个处理器，两者在事务日志的记录功能上是完全一致的。完成事务日志记录后，每个Follower服务器都会向Leader服务器发送ACK消息，表明自身完成了事务日志的记录，以便Leader服务器统计每个事务请求的投票情况。 Proposal流程：每一个事务请求都需要集群中过半机器投票认可才能被真正应用到ZooKeeper的内存数据库中去的投票与统计过程。 Commit流程：将请求交付给CommitProcessor处理器。 最后请求会交付给FinalRequestProcessor处理器，完成事务请求的内存数据库应用，并将该请求放入commitProposal队列中。 响应处理阶段会话响应阶段非常简单，大体分为以下4个步骤： 统计处理：ZooKeeper会计算请求在服务端处理所花费的时间，同时还会统计客户端连接的一些基本信息，包括lastZxid（最新的ZXID）、lastOp（最后一次和服务端的操作）和lastLatency（最后一次请求处理所花费的时间）等。 创建响应ConnectResponse：ConnectResponse就是一个会话创建成功后的响应，包含了当前客户端与服务端之间的通信协议版本号protocolVersion、会话超时时间、sessionID和会话密码。 序列化ConnectResponse。 I/O层发送响应给客户端。 事务请求处理示例例如SetData请求，大体分为4步骤：请求的预处理、事务处理、事务应用和请求响应。 非事务请求处理示例例如GetData请求 启动单机版启动ZooKeeper服务器的启动，大体可以分为以下五个主要步骤：配置文件解析、初始化数据管理器、初始化网络I/O管理器、数据恢复和对外服务。 集群版启动 Leader选举机制​ ZooKeeper中，提供了三种Leader选举的算法，分别是LeaderElection、UDP版本的FastLeaderElection和TCP版本的FastLeaderElection。 从3.4.0版本开始只保留了TCP版本的FastLeaderElection选举算法。 进入Leader选举的情况包括：服务器初始化启动，服务器运行期间无法和Leader保持连接。 服务器状态： LOOKING：寻找Leader状态。当服务器处于该状态时，他会认为当前集群中没有Leader，因此需要进入Leader选举流程。 FOLLOWING：跟随者状态，表明当前服务器角色是Follower。 LEADING：领导者状态，表明当前服务器角色是Leader。 OBSERVING：观察者状态，表明当前服务器角色是Observer。 投票数据结构： 属性 说明 id 被推举的Leader的SID值 zxid 被推举的Leader的事务ID electionEpoch 逻辑时钟，用来判断多个投票是否在同一轮选举周期中。该值在服务端是一个自增序列。每次进入新一轮的投票后，都会对该值进行加1操作 peerEpoch 被推举的Leader的epoch state 当前服务器的状态 自增选举轮次：在FastLeaderElection实现中，有一个logicalclock属性，用于标识当前Leader的选举轮次，ZooKeeper规定了所有有效地投票都必须在同一轮次中。ZooKeeper在开始新一轮的投票时，会首先对logicalclock进行自增操作。 初始化选票：在开始进行新一轮的投票之前，每个服务器都会首先初始化自己的选票。初始化选票也就是对Vote属性的初始化。 发送选票：放入sendqueue队列中，由发送器WorkerSender负责发送出去。 接收外部投票：从recvqueue队列中获取外部投票。如果服务器发现无法获取到任何的外部投票，那么就会立即确认自己是否和集群中其他服务器保持着有效连接。如果发现没有建立连接，那么就会马上建立连接。如果已经建立了连接，那么就再次发送自己当前的内部投票。 判断选举轮次：当外部投票的选举轮次大于内部投票时候，立即更新自己的选举轮次（logicalclock），并且清空所有已经收到的投票，然后使用初始化的投票来进行PK以确定是否变更内部投票，最终再将内部投票发送出去；外部投票的选举轮次小于内部投票时候，ZooKeeper就会直接忽略该外部投票，不做任何处理，继续处于LOOKING状态；外部投票的选举轮次和内部投票一致，开始进行选票PK。 选票PK：如果外部投票中被推举的Leader服务器的选举轮次大于内部投票，那么就需要进行投票变更；如果选举轮次一致的话，那么就对比两者的ZXID。如果外部投票的ZXID大于内部投票，那么就需要进行投票变更；如果两者的ZXID一致，那么就对比两者的SID。如果外部投票的SID大于内部投票，那么就需要进行投票变更。 变更投票：通过选票PK后，如果确定了外部投票优于内部投票（所谓“优于”，是指外部投票所推举的服务器更适合成为Leader），那么就进行投票变更——使用外部投票的选票信息来覆盖内部投票。变更完成后，再次将这个变更后的内部投票发送出去。 选票归档：无论是否进行了投票变更，都会将刚刚收到的那份外部投票放入“选票集合”recvset中进行归档。recvset用于记录当前服务器在本轮次的Leader选举中收到的所有外部投票。 统计投票：完成了选票归档之后，就可以开始统计投票了。统计投票的过程就是为了统计集群中是否已经有过半的服务器认可了当前的内部投票。如果确定已经有过半的服务器认可了该内部投票，则终止投票，否则就回到LOOKING状态。 更新服务器状态： 统计投票后，如果已经确定可以终止投票，那么就开始更新服务器状态。服务器会首先判断当前被过半服务器认可的投票状态更新为LEADING。如果自己不是被选举产生的Leader的话，那么就会根据具体情况来确定自己是FOLLOWING或是OBSERVING。 ​ Leader是事务请求的唯一调度和处理者，保证集群事务处理的顺序性，同时也是集群内部各服务器的调度者。Follower主要处理客户端的非事务请求，转发事务请求给Leader服务器，同时参与事务请求Proposal的投票，参与Leader选举投票。Observer是3.3.0版本之后的角色，可以处理非事务请求，转发事务请求给Leader服务器，和Follower的区别是不参与任何形式的投票（事务请求Proposal和Leader选举投票）。 集群间的消息通信数据同步型消息在Learner和Leader服务器进行数据同步的时候，网络通信所用到的消息，通常有DIFF、TRUNC、SNAP和UPTODATE四种： 消息类型 发送方→接收方 说明 DIFF, 13 Leader→Learner 用于通知Learner服务器、Leader即将与其进行“DIFF”方式的数据同步 TRUNC，14 Leader→Learner 用于触发Learner服务器进行内存数据库的回滚操作 SNAP，15 Leader→Learner 用于通知Learner服务器，Learner即将与其进行“全量”方式的数据同步 UPTODATE，12 Leader→Learner 用来告诉Learner服务器，已经完成了数据同步，可以开始对外提供服务了 服务器初始化型消息在整个集群或是某些新机器初始化的时候，Leader和Learner之间相互通信所使用的消息类型，常见的有OBSERVERINFO、FOLLOWERINFO、LEADERINFO、ACKEPOCH和NEWLEADER五种： 消息类型 发送方→接收方 说明 OBSERVERINFO, 16 Observer→Leader 该信息通常是由Observer服务器在启动的时候发送给Leader的，用于向Leader服务器注册自己，同时向Leader服务器表明当前Learner服务器的角色是Observer。消息中包含了当前Observer服务器的SID和已经处理的最新ZXID。 FOLLOWERINFO, 11 Follower→Leader 该信息通常是由Follower服务器在启动的时候发送给Leader的，用于向Leader服务器注册自己，同时向Leader服务器表明当前Learner服务器的角色是Follower。消息中包含了当前Follower服务器的SID和已经处理的最新ZXID LEADERINFO，17 Leader→Learner 在Learner连接上Leader后，会向Leader发送LearnerInfo消息（包含了OBSERVERINFO和FOLLOWERINFO两类消息），Leader服务器在接收到该消息后，也会将Leader服务器的基本信息发送给这些Learner，这个消息就是LEADERINFO，通常包含了当前Leader服务器的最新EPOCH值 ACKEPOCH，18 Learner→Leader Learner在接收到Leader发来的LEADERINFO消息后，会将自己最新的ZXID和EPOCH以ACKEPOCH消息的形式发送给Leader NEWLEADER，10 Leader→Learner 该消息通常用于Leader服务器向Learner发送一个阶段性的标识消息——Leader会在和Learner完成一个交互流程后，向Learner发送NEWLEADER消息，同时带上当前Leader服务器处理的最新ZXID。这一系统交互流程包括：足够多的Follower服务器连接上Leader或是完成数据同步 请求处理型消息在进行请求处理的过程中，Leader和Learner服务器之间互相通信所使用的消息，常见的有REQUEST、PROPOSAL、ACK、COMMIT、INFORM和SYNC六种： 消息类型 发送方→接收方 说明 REQUEST，1 Learner→Leader 该消息是ZooKeeper的请求转发消息。在ZooKeeper中，所有的事务请i去必须由Leader服务器来处理。当Learner服务器接收到客户端的事务请求后，就会将请求以REQUEST消息的形式转发给Leader服务器来处理。 PROPOSAL，2 Leader→Follower 该消息是ZooKeeper实现ZAB算法的核心所在，即ZAB协议中的提议。在处理事务请求的时候，Leader服务器会将事务请求以PROPOSAL消息的形式创建投票发送给集群中所有的Follower服务器来进行事务日志的记录。 ACK，3 Follower→Leader Follower服务器在接收到来自Leader的PROPOSAL消息后，会进行事务日志的记录。如果完成了事务日志的记录，那么就会以ACK消息的反馈给Leader。 COMMIT，4 Leader→Follower 该消息用于通知集群中所有的Follower服务器，可以进行事务请求的提交了。Leader服务器在接收到过半的Follower服务器发来的ACK消息后，就进入事务请求的最终提交流程——生成COMMIT消息，告知所有的Follower服务器进行事务请求的提交。 INFORM，8 Leader→Observer 在事务请求提交阶段，针对Follower服务器，Leader仅仅只需要发送一个COMMIT消息，Follower服务器就可以完成事务请求的提交了，因为在这之前的事务请求投票阶段，Follower已经接受过PROPOSAL消息，该消息中包含了事务请求的内存，因此Follower有从之前的Proposal缓存中再次获取到事务请求。而对于Observer来说，由于之前没有参与事务请求的投票，因此没有该事务请求的上下文，显然，如果Leader同样对其发送一个简单地COMMIT消息，Observer服务器是无法完成事务请求的提交的。为了解决这个问题，ZooKeeper特别设计了INFORM消息，该消息不仅能够通知Observer已经可以提交事务请求，同时还会在消息中携带事务请求的内容。 SYNC，7 Leader→Learner 该消息用于通知Learner服务器已经完成了Sync操作。 会话管理型消息ZooKeeper在进行会话管理的过程中，和Learner服务器之间互相通信所使用的消息，常见的有PING和REVALIDATE两种： 消息类型 发送方→接收方 说明 PING，5 Leader→Learner 该消息用于Leader同步Learner服务器上的客户端心跳检测，用以激活存活的客户端。ZooKeeper的客户端往往会随机地和任意一个ZooKeeper服务器保持连接，因此Leader服务器无法直接收到所有客户端的心跳检测，需要委托给Learner来保存这些客户端的心跳检测的客户端列表，同样以PING消息的形式反馈给Leader服务器，由Leader服务器来负责逐个对这些客户端进行会话激活。 REVALIDATE，6 Learner→leader 该消息用于Learner校验会话是否有效，同时也会激活会话。这通常发生在客户端重连的过程中，新的服务器需要向Leader发送REVALIDATE消息以确定该会话是否已经超时。 参考https://blog.csdn.net/cnh294141800/article/details/52959028 《从Paoxs到zookeeper: 分布式一致性原理与实践》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper的原理(3)]]></title>
      <url>%2F2018%2F03%2F18%2FZookeeper%E7%9A%84%E5%8E%9F%E7%90%86-3%2F</url>
      <content type="text"><![CDATA[​ 本章开始讲解Zookeeper重要的技术实现。之前一篇我们讲解了Zookeeper的系统模型，并详细讲解了Watch机制，其中提到了客户端与服务端通信的问题，就此我们深入挖掘Zookeeper的客户端与会话原理。 客户端核心组件客户端是开发人员使用ZooKeeper最主要的途径。包括以下核心组件： ZooKeeper实例：客户端的入口； ClientWatchManager：客户端Watcher管理器； HostProvider：客户端地址列表管理器； ClientCnxn：客户端核心线程，其内部又包含两个线程，即SendThread和EventThread。前者是一个I/O线程，主要负责ZooKeeper客户端和服务端之间的网络I/O通信；后者是一个事件线程，主要负责对服务端事件进行处理。 ZooKeeper实例ZooKeeper客户端的构造方法如下，初始化的过程主要设置默认Watcher，设置ZooKeeper服务器地址列表，创建ClientCnxn。 1234ZooKeeper(String connectString, int sessionTimeout, Watcher watcher);ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly);ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd);ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly); ClientWatchManagerZKWatchManager实现ClientWatchManager接口，内部定义了dataWatches，existWatches，childWatches，主要用于存储Watcher。 123456private final Map&lt;String, Set&lt;Watcher&gt;&gt; dataWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();private final Map&lt;String, Set&lt;Watcher&gt;&gt; existWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();private final Map&lt;String, Set&lt;Watcher&gt;&gt; childWatches = new HashMap&lt;String, Set&lt;Watcher&gt;&gt;(); HostProvider​ 在使用ZooKeeper构造方法时，用户传入的ZooKeeper服务器地址列表，即connectString参数，例如192.168.0.1:2181,192.168.0.1:2181,192.168.0.1:2181，ConnectStringParser解析器首先对传入的connectString做两个主要处理：解析chrootPath，保存服务器地址列表。 ​ 解析chrootPath：3.2.0及其之后版本的ZooKeeper中，添加了“Chroot”特性，该特性允许每个客户端为自己设置一个命名空间（Namespace）。如果一个ZooKeeper客户端设置了Chroot，那么该客户端对服务器的任何操作，都将会被限制在其自己的命名空间下。 ​ 保存服务器地址列表： ConnectStringParser解析器会对服务器地址做一个简单的处理，并将服务器地址和相应的端口封装成一个InetSocketAddress对象，以ArrayList形式保存在ConnectStringParser.serverAddress属性中。然后，经过处理的地址列表会被进一步封装到StaticHostProvider类（StaticHostProvider是对HostProvider的默认实现）中。 HostProvider接口： 接口方法 说明 int size() 该方法用于返回当前服务器地址列表的个数， 不能返回0，也就是说 HostProvider中必须至少有一个服务器地址 InetSocketAddress next(long spinDelay) 该方法用于返回一个 已被解析的服务器地址InetSocketAddress，以便客户端进行服务器连接 void onConnected() 这时一个回调方法，如果客户端与服务器成功创建连接，就通过调用这个方法来通知HostProvider ​ StaticHostProvider实现了next()方法，获取可用的服务器。这个next()方法并非简单的从serverAddress中依次获取一个服务器地址，而是先将随机打散后的服务器地址列表拼装成一个环形循环队列。 ​ 简单来说，有2个指针lastIndex和currentIndex，初始化时候均为-1。每当尝试获取一个可用的服务器，currentIndex向前移动1位。客户端与服务器成功创建连接后调用onConnected，lastIndex = currentIndex。当再次获取一个可用的服务器，currentIndex继续向前移动1位，当currentIndex等于serverAddresses.size()，currentIndex =0；如果服务器的数目为极小，容易出现currentIndex+1之后依然等于lastIndex ，此时做了个小优化，会进行spinDelay毫秒时间的等待，依然使用尝试使用原先的服务器。 ClientCnxn​ ClientCnxn是ZooKeeper客户端的核心工作类，负责维护客户端与服务端之间的网络连接并进行一系列网络通信。 Packet是ClientCnxn内部定义的一个对协议层的封装，作为ZooKeeper中请求与响应的载体，其数据结构如下图所示 ​ Packet的createBB()方法负责对Packet对象进行序列化，最终生成可用于底层网络传输的ByteBuffer对象。在这个过程中，只会将requestHeader、request和readOnly三个属性进行序列化，其余属性都保存在客户端的上下文，不会进行与服务端之间的网络传输。 OutgoingQueue和PendingQueue​ ClientCnxn中，有两个比较核心的队列outgoingQueue和pendingQueue，分别代表客户端的请求发送队列和服务端响应的等待队列。Outgoing队列是一个请求发送队列，专门用于存储那些需要发送到服务端的Packet集合。Pending队列是为了存储那些从客户端发送到服务端的，但是需要等待服务端响应的Packet集合。在正常情况下（即客户端与服务端之间的TCP连接正常且会话有效地情况下），会从outgoingQueue队列中提取出一个可发送的Packet对象，同时生成一个客户端请求序号XID并将其设置到Packet请求头中去，然后将其序列化后进行发送。请求发送完毕后，会立即将该Packet保存到pendingQueue队列中，以便等待服务端响应返回后进行相应的处理。 客户端获取到来自服务器的完整响应数据后，根据不同的客户端请求类型，会进行不同的处理 ：1. 如果检测到当前客户端还尚未进行初始化，那么说明当前客户端与服务端之间正在进行会话创建，那么就直接接收到的ByteBuffer（incomingBuffer）序列化成ConnectResponse对象；2. 如果当前客户端已经处于正常的会话周期，并且接收到的服务端响应是一个事件，那么ZooKeeper客户端会将接收到的ByteBuffer（incomingBuffer）序列化成WatcherEvent对象，并将该事件放入待处理队列中；3. 如果是一个常规的请求响应（指的是Create、GetData和Exist等操作请求），那么会从pendingQueue队列中取出一个Packet来进行相应的处理。ZooKeeper客户端首先会通过检验服务端响应中包含的XID值来确保请求处理的顺序性，然后再将接收到的ByteBuffer（incomingBuffer）序列化成相应的Response对象。 SendThread和EventThread​ SendThread是客户端ClientCnxn内部一个核心的I/O调度线程，用于管理客户端和服务端之间的所有网络I/O操作。在ZooKeeper客户端的实际运行过程中，一方面，SendThread维护了客户端与服务端之间的会话生命周期，其通过在一定的周期频率内向服务端发送一个PING包来实现心跳检测。同时，在会话周期内，如果客户端与服务端之间出现TCP连接断开的情况，那么就会自动且透明化的完成重连操作。SendThread管理了客户端所有的请求发送和响应接收操作，其将上层客户端API操作转换成相应的请求协议并发送到服务端，并完成对同步调用的返回和异步调用的回调。同时，SendThread还负责将来自服务端的事件传递给EventThread去处理。 ​ EventThread是客户端ClientCnxn内部的另一个核心线程，负责客户端的事件处理，并触发客户端注册的Watcher监听。EventThread中有一个waitingEvents队列，用于临时存放那些需要被触发的Object,包括那些客户端注册的Watcher和异步接口中注册的回调器AsyncCallback。同时，EventThread会不断地从waitingEvents这个队列中取出Object，识别出其具体类型（Watcher或者AsyncCallback），并分别调用process和processResult接口方法来实现对事件的触发和回调。 ClientCnxnSocket​ ClientCnxn中，ClientCnxnSocket定义了底层Socket通信的接口。3.4.0版本开始，抽取出了这个接口类。在使用ZooKeeper客户端的时候，可以通过在zookeeper.clientCnxnSocket这个系统变量中配置ClientCnxnSocket实现类的全类名，以指定底层Socket通信层的自定义实现，例如，-Dzookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNIO。在ZooKeeper中，其默认的实现是ClientCnxnSocketNIO。 会话会话状态在理解会话的创建，管理，清理以及重连之前，先看看一个会话有哪些状态。ZooKeeper会话在整个运行期间的生命周期中，会在不同的会话状态之间进行切换，这些状态一般可以分为CONNECTING、CONNECTED、RECONNECTING、RECONNECTED和CLOSE。 会话创建流程前面讲解了客户端一些核心组件，下面我们看一下一次会话创建的流程。 初始化阶段​ 基本上就是上面核心组件的初始过程，包括ZooKeeper对象的实例化，根据传入的Watcher或者默认的Watcher创建ClientWatchManger对象，HostProvider的构造，以及ClientCnxn的创建初始化的同时还有outgoingQueue和pendingQueue，SendThread和EventThread实例化。 会话创建阶段​ SendThread首先会判断当前客户端的状态，进行一系列清理性工作，为客户端发送“会话创建”请求做准备，然后获取一个ZooKeeper服务器的目标地址，委托给ClientCnxnSocket去创建与ZooKeeper服务器的TCP连接。在TCP连接创建完毕后，SendThread会负责根据当前客户端的实际设置，构造出一个ConnectionRequest请求，该请求代表了客户端试图与服务器创建一个会话。同时ZooKeeper客户端还会进一步将该请求包装成网络I/O层的Packet对象，放入请求发送队列outgoingQueue中去。当客户端请求准备完毕后，就可以开始向服务端发送请求了。ClientCnxnSocket负责从outgoingQueue中取出一个待发送的Packet对象，将其序列化成ByteBuffer后，向服务端进行发送。 响应处理阶段​ ClientCnxnSocket接收到服务端的响应后，会首先判断当前的客户端状态是否是“已初始化”，如果尚未完成初始化，那么就认为该响应一定是会话创建请求的响应，直接交由readConnectResult方法来处理该响应。ClientCnxnSocket会对接收到的服务端响应进行反序列化，得到ConnectResponse对象，并从中获取到ZooKeeper服务端分配的会话sessionId。连接成功后，一方面需要通知SendThread线程，进一步对客户端进行会话参数的设置，包括readTimeout和connectTimeout等，并更新客户端状态；另一方面，需要通知地址管理器HostProvider当前成功连接的服务器地址。另外为了能够让上层应用感知到会话的成功创建，SendThread会生成一个事件SyncConnected-None，代表客户端与服务器会话创建成功，并将该事件传递给EventThread线程，EventThread线程收到事件后，会从ClientWatchManager管理器中查询出对应的Watcher，针对SyncConnected-None事件，直接找出存储的默认Watcher，将其放到EventThread的waitingEvents队列中去。 EventThread不断地从waitingEvents队列中取出待处理的Watcher对象，然后直接调用该对象的process接口方法，以达到触发Watcher的目的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper的原理(2)]]></title>
      <url>%2F2018%2F03%2F15%2FZookeeper%E7%9A%84%E5%8E%9F%E7%90%86-2%2F</url>
      <content type="text"><![CDATA[​ 本章开始讲解Zookeeper重要的技术实现。在分布式系统基础理论(3)中，我们讲到了Zookeeper是采用ZAB协议保持一致性的。 系统模型树形结构​ Zookeeper的数据节点称为ZNode，ZNode是Zookeeper中数据的最小单元，每个ZNode都可以保存数据，同时还可以挂载子节点，因此构成了一个层次化的命名空间，称为树。ZNode的节点路径标识方式和Unix文件系统路径非常相似，都是由一系列使用斜杠(/)进行分割的路径表示。 ​ 在Zookeeper中，事务是指能够改变Zookeeper服务器状态的操作，一般包括节点创建与删除，数据节点内容更新和客户端会话创建与失效，对于每个事务请求，Zookeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是64位的数字，每个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出Zookeeper处理这些更新操作请求的全局顺序。 节点特性​ 在Zookeeper中，每个数据节点都是由生命周期的，类型不同则会不同的生命周期，节点类型可以分为持久节点（PERSISTENT）、临时节点（EPHEMERAL）、顺序节点（SEQUENTIAL）三大类，可以通过组合生成如下四种类型节点： 持久节点（PERSISTENT）：节点创建后便一直存在于Zookeeper服务器上，直到有删除操作来主动清楚该节点。 持久顺序节点（PERSISTENT_SEQUENTIAL）：相比持久节点，其新增了顺序特性，每个父节点都会为它的第一级子节点维护一份顺序，用于记录每个子节点创建的先后顺序。在创建节点时，会自动添加一个数字后缀，作为新的节点名，该数字后缀的上限是整形的最大值。 临时节点（EPEMERAL）。临时节点的生命周期与客户端会话绑定，客户端失效，节点会被自动清理。同时，Zookeeper规定不能基于临时节点来创建子节点，即临时节点只能作为叶子节点。 临时顺序节点（EPEMERAL_SEQUENTIAL）。在临时节点的基础添加了顺序特性。 另外就是查看节点的状态，用get操作 12345678910111213[zk: localhost:2181(CONNECTED) 5] get /zk-book123cZxid = 0x3ctime = Wed Mar 14 16:04:56 CST 2018mZxid = 0x3mtime = Wed Mar 14 16:04:56 CST 2018pZxid = 0x3cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 0 版本版本是用来保证分布式数据原子性操作，每个数据节点都具有三种类型的版本信息，对数据节点的任何更新操作都会引起版本号的变化。 version– 当前数据节点数据内容的版本号 cversion– 当前数据子节点的版本号 aversion– 当前数据节点ACL变更版本号 Watcherwatcher用于数据变更通知，可以用于订阅和通知功能。 ​ Zookeeper的Watcher机制主要包括客户端线程、客户端WatcherManager、Zookeeper服务器三部分。客户端在向Zookeeper服务器注册的同时，会将Watcher对象存储在客户端的WatcherManager当中。当Zookeeper服务器触发Watcher事件后，会向客户端发送通知，客户端线程从WatcherManager中取出对应的Watcher对象来执行回调逻辑。 Watcher接口​ Watcher接口类用于表示一个标准的事件处理器，定义事件通知的相关逻辑，包含KeeperState和EventType两个枚举，分别代表通知状态和事件类型，同时定义事件的回调方法：process（WatchedEvent event）方法。其中WatchedEvent 包含通知状态（keeperState）,事件类型（eventType）和和节点路径（path）。要注意与WatcherEvent区别，它们本身都是对服务端事件的封装，只是WatcherEvent实现序列化用于网络传输，到达客户端后又会还原成为WatchedEvent 。 工作机制客户端注册watcher、服务端处理watcher和客户端回调watcher事件。 客户端注册Watcher客户端注册watcher的方式有很多，因为Watcher是一次性的，可以通过创建一个 ZooKeeper 客户端对象实例，传入Watcher；可以通过 getData、exists 和 getChildren 三个接口来向 ZooKeeper 服务器注册 Watcher等。 应用程序客户端调用Zookeeper的API例如getData操作，实际是构建了ClientCnxn 类，在这个类里面新建了2个线程SendThread和EventThread。SendThread 使用的nio操作，负责将ZooKeeper的请求信息封装成一个Packet，发送给 Server ,并维持同Server的心跳；EventThread循环处理watch事件的线程。 SendThread将请求转化为Packet包，放入OutgoingQueue, 然后在run中循坏处理，在这个过程中，如果OutgoingQueue里面有数据需要发送，则发送数据包并把数据包从Outgoing Queue移至Pending Queue，意思是数据我已经发出去了，但还要等待Server端的回复，所以这个请求现在是Pending 的状态。当Server端响应的时候，SendThread通过readResonse进行处理，如果是之前请求的响应，Pending Queue里面一定会有，这时候会从Pending Queue移除, 又通过finishPacket方法从packet中提取Watcher存到ZKWatchManger的dataWatches。 EventThread用来处理Finish Event和Watcher Event。收到Finish Event的时候会把相对应的Package置成Finish状态，这样等待结果的Client函数就能得以返回。收到Watcher Event的时候会联系WatcherManager找到相对应的Watcher，从WatcherManager里面移除这个Watcher(因为每个Watcher只会被通知一次) 并回调Watcher的process函数。所以所有Watcher的process函数是运行在EventThread里面的。 服务端处理Watcher服务端收到客户端的请求时候，首先判断是否需要注册Watcher。当需要注册的时候，就将ServerCnxn对象和数据节点路径传入getData方法中去。ServerCnxn是一个Zookeeper客户端和服务器之间的连接接口，代表了一个客户端和服务器的连接，默认实现是NIOServerCnxn,最终会被存储在WatchManager的watchTable和watch2Paths中。watchTable是从数据节点路径的粒度来托管Watcher。watch2Paths是从Watcher的粒度来控制事件触发需要触发的数据节点路径。 客户端回调WatcherWatchManager除了保存了Watcher,同时还负责Watcher事件的触发，并移除那些已经触发的Watcher。WatchManager只是一个统称，在服务端，DataTree中会托管2个叫做dataWatches和childWatches的WatchManager，分别用于对应数据变更Watcher和子节点变更Watcher。上述的getData接口会被存储在叫dataWatches的WatchManager中。 当数据出现变化，（创建、删除、设置节点数据）时，会触发watch： 1public Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) 封装WatchedEvent: 首先将通知状态（KeeperState）、事件类型（EventType）以及节点路径（Path）封装成一个WatchedEvent对象。 查询Watcher：根据数据节点的节点路径从watchTable中取出对应的Watcher。如果没有找到Watcher，说明没有任何客户端在该数据节点上注册过Watcher，直接退出。而如果找到了这个Watcher，会将其提取出来，同时会直接从watchTable和watch2Paths中将其删除——从这里我们也可以看出，Watcher在服务器是一次性的，及触发一次就失效了。 调用process方法来触发Watcher：会逐个依次的调用从步骤2中找出的所有Watcher的process方法：在请求头中标记“-1”，表明当前是一个通知；将WatchedEvent包装成WatcherEvent，以便进行网络传输序列化；向客户端发送该通知。 ​ 客户端收到服务端响应后，对于一个来自服务端的响应，客户端都是由SendThread.readResponse(ByteBuffer incomingBuffer)方法来统一进行处理的，如果响应头replyHdr中标识了XID为-1，表明这是一个通知类型的响应，对其的处理大体上分为以下4个主要步骤：反序列化：将字节流转换成WatcherEvent对象；处理chrootPath：如果客户端设置了chrootPath属性，那么需要对服务端传过来的完整的节点路径进行chrootPath处理，生成客户端的一个相对节点路径；还原WatchedEvent：将WatcherEvent对象转换成WatchedEvent；回调Watcher：客户端识别出是EventType后，会会从相应的Watcher存储（即dataWatches、existWatches或childWatches中的一个或多个，本例中就是从dataWatches和existWatches两个存储中获取）中去除相应的Watcher。注意，此处使用的是remove接口，因此也表明了客户端的Watcher机制同样也是一次性的，即一旦被触发后，该Watcher就失效了。获取到相关的所有Watcher之后，会将其放入waitingEvents这个队列中去。WaitingEvents是一个待处理Watcher的队列，EventThread的run方法会不断对该队列进行处理，在下一个轮询周期中进行Watcher回调。 Watcher的特性一次性 无论是服务端还是客户端，一旦一个 Watcher 被触发，ZooKeeper 都会将其从相应的存储中移除。因此，在 Watcher 的使用上，需要反复注册。这样的设计有效地减轻了服务端的压力。 客户端串行执行 客户端 Watcher 回调的过程是一个串行同步的过程，这为我们保证了顺序，同时，需要注意的一点是，一定不能因为一个 Watcher 的处理逻辑影响了整个客户端的 Watcher 回调，所以，客户端 Watcher 的实现类要另开一个线程进行处理业务逻辑，以便给其他的 Watcher 调用让出时间。 轻量 WatcherEvent 是 ZooKeeper 整个 Watcher 通知机制的最小通知单元，这个数据结构中只包含三部分内容：通知状态、事件类型和节点路径。也就是说，Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。例如针对 NodeDataChanged 事件，ZooKeeper 的Watcher 只会通知客户端指定数据节点的数据内容发生了变更，而对于原始数据以及变更后的新数据都无法从这个事件中直接获取到，而是需要客户端主动重新去获取数据——这也是 ZooKeeper 的 Watcher 机制的一个非常重要的特性。 ACLZookeeper提供一套ACL权限控制机制来保证数据的安全。分别是：权限模式（Scheme)、授权对象(ID)和权限 (Permission)，通常使用 “scheme：id ：permission”来标识一个有效的 ACL信息。 权限包括： CREATE (C):数据节点的创建权限，允许授权对象在该数据节点下创建子节点；DELETE (D):子节点的刪除权限，允许授权对象刪除该数椐节点的子节点；READ (K):数据节点的读取权限，允许授权对象访问该数据节点并读取其数据内容或子节点列表；WRITE (W):数据节点的更新权限，允许授权对象对该数据节点进行更新操作；ADMIN (A):数椐节点的管理权限，允许授权对象对该数据节点进行ACL相关的设置操作。 参考http://blog.csdn.net/abountwinter/article/details/55188783 http://blog.csdn.net/yinwenjie/article/details/47685077]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式系统基础理论(3)]]></title>
      <url>%2F2018%2F03%2F13%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA-3%2F</url>
      <content type="text"><![CDATA[本篇主要讲解分布式一致性或者叫共识（Consensus）算法（不考虑可能出现消息篡改即拜占庭问题），包括Paxos算法，Raft算法， Viewstamped Replication，ZAB协议。 Paxos算法Paxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。协议本身并没有多难理解，它的难理解性主要体现在：为何如此设计协议以及如何证明其正确性。 Paxos算法的理解Paxos的工程实践Google Chubby​ Google Chubby是一个分布式锁服务，Chubby底层一致性实现就是以Paxos为基础的，应用于BigTable。 Hypertable​ Hypertable以BigTable的论文做指导，采用HBase非常相似的分布式类型，其目的是构建一个分布式海量数据的高并发数据库。包括Hyperspace, RangeServer, Master, DFSBroker。其中Hyperspace是最为重要的组件之一，提供了对分布式服务的支持和对元数据的管理，是保证Hypertable数据一致性的核心。 Raft算法Viewstamped ReplicationZAB协议参考https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95#%E6%83%85%E5%86%B5%E4%B8%80 https://www.cnblogs.com/linbingdong/p/6253479.html http://blog.jobbole.com/106327/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式系统基础理论(2)]]></title>
      <url>%2F2018%2F03%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA-2%2F</url>
      <content type="text"><![CDATA[本篇主要讲解2PC和3PC以及TCC理论,同时介绍一个解决分布式事务的开源项目saga。 最近看了《从Paxos到zookeeper 分布式一致性原理与实践》以及《分布式服务架构：原理，设计与实战》这本书，结合之前的看到的优秀博客，做一下梳理。 ​ 在了解2PC和3PC之前先来了解XA规范。XA是由X/Open组织提出的分布式事务的规范。X/Open DTP模型（1994）包括应用程序（AP）、事务管理器（TM）、资源管理器（RM）、通信资源管理器（CRM）四部分。事务管理器（TM）是交易中间件，资源管理器（RM）是数据库，通信资源管理器（CRM）是消息中间件。 2PC就是基于XA规范实现的,理解了2PC就理解了XA 2PC所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段） 准备阶段(投票阶段)协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志，但不提交，到达一种“万事俱备，只欠东风”的状态 参与者节点响应协调者节点发起的询问，如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息 提交阶段(执行阶段)如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，最后释放所有事务处理过程中使用的锁资源 下图展示正常提交和提交中断。 存在问题同步阻塞问题，执行过程中所有参与节点都是事务阻塞型的，当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态 单点故障，由于协调者的重要性一旦协调者发生故障参与者会一直阻塞下去 数据不一致，在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求，而在这部分参与者接到commit请求之后就会执行commit操作，但是其他部分未接到commit请求的机器则无法执行事务提交，于是整个分布式系统便出现了数据不一致性的现象 太过保守，如果在协调者指示参与者进行事务提交询问的过程中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应的话，这时协调者只能依靠其自身的超时机制来判断是否需要中断事物，这样的策略显得比较保守。换句话说，二阶段提交协议没有设计较为完善的容错机制，任意一个节点的失败都会导致整个事物的失败。 3PC是解决2PC的问题做的改进 3PC CanCommit阶段协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No PreCommit阶段协调者根据参与者的反应情况来决定是否可以进行事务的PreCommit操作。根据响应情况，有以下两种可能： 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。 发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段 事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中 响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。 发送中断请求 协调者向所有参与者发送abort请求 中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断 DoCommit阶段执行提交 发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求 事务提交 参与者接收到doCommit请求或者无法及时收到来自协调者的信息之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 响应反馈 事务提交完之后，向协调者发送Ack响应 完成事务 协调者接收到所有参与者的ack响应之后，完成事务 中断事务 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务 发送中断请求 协调者向所有参与者发送abort请求 事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源 反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息 中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断 存在问题三阶段提交协议在去除阻塞的同时也引入新的问题，在参与者接受到preCommit消息后，如果网络出现分区，此时协调者所在节点和参与者无法正常的网络通信，该参与者依然会在等待超时之后执行了commit操作，这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 2PC与3PC的区别​ 无论是2PC提交还是3PC提交都无法彻底解决分布式的一致性问题。相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。 TCCSERVICECOMB-SAGA参考http://www.hollischuang.com/archives/681 《从Paxos到zookeeper 分布式一致性原理与实践》 《分布式架构：原理，设计，实战》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分布式系统基础理论(1)]]></title>
      <url>%2F2018%2F03%2F09%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%2F</url>
      <content type="text"><![CDATA[本篇主要讲解ACID, CAP和 BASE。 ​ 最近看了《从Paxos到zookeeper 分布式一致性原理与实践》这本书，想提取总结一些分布式相关的内容，做一下梳理，本篇主要讲解ACID, CAP和 BASE。 在《分布式系统概念与设计》一书中对分布式定义如下： ​ 分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。 从ACID到CAP/BASE本地事务ACID​ ACID主要是事务的4个基本特征。事务是指由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元，狭义上的事务特指数据库事务。它在多个程序并发访问数据库的时候，可以在这些应用程序之间提供一个隔离方法，以防止彼此操作互相干扰，另一方面为数据库操作序列提供了以从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持数据一致性的方法。 原子性(Atomicity)：事务必须是一个原子的操作序列单元。只允许出现“全部执行成功”和“全部不执行”两种状态。 一致性(Consistency)：事务的执行不能破坏数据库数据的完整性和一致性。一个事务在执行前后，数据库都必须处于一致性状态。也就是说，事务执行的结果必须是使数据库从一个一致性状态转变到另一个一致性状态。 隔离性(Isolation)：在并发环境中，并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。也即，不同的事务并发操作相同数据时，每个事务都有各自完整的数据空间。 需要注意的是隔离性有4个不同的级别 持久性(Durability): 也称永久性，是指一个事务一旦提交，它对数据库中对应数据的状态变更就是永久性，即使发生系统崩溃或机器宕机等故障。 遵循ACID是本地事务保持数据一致性的关键。 分布式事务​ 分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上。通常一个分布式事务中会涉及对多个数据源或业务系统的操作。通常一个分布式事务可以被定义为一种嵌套型的事务，同时也具有ACID事务特性。但其中的各个子事务的执行又是分布式的。 CAP一个分布式系统不能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三个基本需求，最多只能同时满足其中两项。 一致性（Consistency）是指数据在多个副本之间是否能够保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。在分布式系统中，如果能做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新的值，这样的系统被认为具有强一致性（严格一致性）。 可用性（Availability）是指系统提供的服务必须一致处于可用的状态，对于用户的每一个操作总是能够在有限时间内返回对应的处理结果。 分区容错性（Partition tolerance）是指分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性服务，除非是整个网络环境都发生了故障。网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络等）中，由于一些特殊原因导致这些子网络之间出现网络不连通的状况，但各个子网络的内部网络正常，从而导致整个网络环境被切分成了若干孤立的区域。 BASE​ BASE是Basically Available、Soft state和Eventually consistent三个短语的缩写。BASE是对CAP中一致性和可用性权衡的结果，其来源是对大规模互联网系统分布式实践的总结。其核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用Basically Available是指在分布式系统出现不可预知故障时，允许损失部分可用性，但这绝不等价于系统不可用。例如响应时间损失：查询时间增加；功能上损失：双11部分消费者都被引导到一个降级页面。 弱状态Soft state，和硬状态相对，是指允许系统中的数据存在中间状态，并认为中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 最终一致性Eventually consistent，强调的是系统中所有数据副本，在经过一段时间后，最终能够达到一个一致的状态。最终一致性包括5种情形：1.因果一致性2.读己之所写3.会话一致性4.单调读一致性5.单调写一致性。 总结​ ACID是传统数据库常用的设计理念，追求强一致性模型。BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性是相反的，在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此ACID和BASE又会结合使用。 参考http://www.hollischuang.com/archives/666]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Zookeeper的原理(1)]]></title>
      <url>%2F2018%2F03%2F05%2FZookeeper%E7%9A%84%E5%8E%9F%E7%90%86%EF%BC%881%EF%BC%89%2F</url>
      <content type="text"><![CDATA[​ Apache Zookeeper是由Apache Hadoop的子项目发展而来，于2010年11月正式成为Apache顶级项目。Zookeeper为分布式应用提供高效且可靠的分布式协调服务，提供了统一命名服务、配置管理、分布式锁等分布式的基础服务。Zookeeper并没有直接采用Paxos算法，而是采用了一种被称为ZAB(Zookeeper Atomic Broadcast)的一致性协议。 什么是Zookeeper​ Zookeeper是一个开源的分布式协调服务，由Yahoo创建，是Google Chubby的开源实现。Zookeeper将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 Zookeeper可以保证如下分布式一致性特性： 顺序一致性：从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中； 原子性：所有事务的请求结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么在整个集群中所有机器上都成功应用了某一个事务，要么都没有应用，没有中间状态； 单一视图：无论客户端连接的是哪个Zookeeper服务器，其看到的服务端数据模型都是一致的； 实时性：通常人们看到实时性的第一反应是，一旦一个事务被成功应用，那么客户端能够立即从服务端上读取到这个事务变更后的最新数据状态。这里需要注意的是，Zookeeper仅仅保证在一定的时间内，客户端最终一定能够从服务端上读到最终的数据状态； 可靠性：一旦服务端成功应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更会被一直保留下来，除非有另一个事务又对其进行了变更； Zookeeper能做什么​ 基于Zookeeper实现例如，数据发布/订阅、负载均衡、命名服务、协调通知、集群管理、Master选举、分布式锁、分布式队列等功能 ，可以参考我的Zookpeer-Learning项目 ​ Zookeeper在大型分布式系统中有重要应用，比如Hadoop， HBase， Kafka；在国内阿里，比如消息中间件Metamorphosis, RPC服务框架Dubbo， 基于MySQL Binlog的增量订阅和消费组件Cannal, 分布式数据库同步系统Otter, 轻量级分布式通用搜索平台终搜，实时计算引擎JStorm。 Zookeeper的安装使用在这里以单点部署为例子,我用的root权限，记得环境已经安装了java。 1yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel 首先你可以购买一台腾讯云虚拟机（Centos7），然后登录官网，复制链接, 下载3.4.9版本。 1wget http://archive.apache.org/dist/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz 解压zookeeper-3.4.9.tar.gz 1tar -zxvf zookeeper-3.4.9.tar.gz 在/home/luckylau/zookeeper-3.4.9 目录下创建以下目录： 123cd /home/luckylau/zookeeper-3.4.9/mkdir datamkdir logs 将 zookeeper-3.4.9/conf 目录下的 zoo_sample.cfg 文件拷贝一份，命名为为zoo.cf 1cp zoo_sample.cfg zoo.cfg 修改 zoo.cfg 配置文件 12345678910111213141516171819202122232425262728293031 The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/home/luckylau/zookeeper-3.4.9/data# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1#2888 端口号是 zookeeper 服务之间通信的端口。#3888 是 zookeeper 与其他应用程序通信的端口。server.1=119.27.162.9:2888:3888 更改日志文件位置 12345vim /home/luckylau/zookeeper-3.4.9/bin/zkEnv.shif [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]then ZOO_LOG_DIR=&quot;/home/luckylau/zookeeper-3.4.9/logs&quot;fi 在 dataDir=/home/luckylau/zookeeper-3.4.9/data 下创建 myid 文件 12vi myid1 暴露zookeeper配置 12345vim .bash_profile# zookeeper envexport ZOOKEEPER_HOME=/home/luckylau/zookeeper-3.4.9export PATH=$ZOOKEEPER_HOME/bin:$PATH source .bash_profile 启动并测试 zookeeper 123zkServer.sh startjpszkServer.sh status 基本配置参数 参数名 说明 clientPort 该参数无默认值，必须配置，不支持系统属性方式配置。参数clientPort用于配置当前服务器对外的服务端口，客户端会通过该端口和ZooKeeper服务器创建连接，一般设置为2181。 dataDir 该参数无默认值，必须配置，不支持系统属性方式配置。参数dataDir用于配置ZooKeeper服务器存储快照文件的目录。默认情况下，如果没有配置参数dataLogDir，那么事务日志也会存储在这个目录中。考虑到事务日志的写性能直接影响ZooKeeper整体的服务能力，因此建议同时通过参数dataLogDir来配置ZooKeeper事务日志的存储目录。 tickTime 该参数有默认值：3000，单位是毫秒（ms），可以不配置，不支持系统属性方式配置。参数tickTime用于配置ZooKeeper中最小时间单元的长度，很多运行时的时间间隔都是使用tickTime的倍数来表示的。例如，ZooKeeper中会话的最小超时时间默认是2*tickTime。 参数名 说明 dataLogDir 该参数有默认值：dataDir，可以不配置，不支持系统属性方式配置。参数dataLogDir用于配置ZooKeeper服务器存储事务日志文件的目录。默认情况下，ZooKeeper会将事务日志文件和快照数据存储在同一个目录中，应尽量将这两者的目录区分开来。另外，如果条件允许，可以将事务日志的存储配置在一个单独的磁盘上。事务日志记录对于磁盘的性能要求非常高，为了保证事务的一致性，ZooKeeper在返回客户端事务请求响应之前，必须将本次请求对应的事务日志写入到磁盘中。因此，事务日志写入的性能直接决定了ZooKeeper在处理事务请求时的吞吐。针对同一块磁盘的其他并发读写操作（例如ZooKeeper运行时输出和操作系统自身的读写等），尤其是数据快照操作，会极大地影响事务日志的写性能。因此尽量给事务日志的输出配置一个单独的磁盘或是挂载点，将极大地提升ZooKeeper的整体性能。 initLimit 该参数有默认值：10，即表示是参数tickTime值的10倍，必须配置，且需要配置一个正参数，不支持系统属性方式配置。该参数用于配置Leader服务器等待Follower启动，并完成数据同步的时间。Follower服务器在启动过程中，会与Leader建立连接并完成对数据的同步，从而确定自己对外提供服务的起始状态。Leader服务器允许Follower在initLimit时间内完成这个工作。通常情况下，运维人员不用太在意这个参数的配置，使用其默认值即可。但如果随着ZooKeeper集群管理的数据量增大，Follower服务器在启动的时候，从Leader上进行同步数据的时间也会相应变长，于是无法在较短的时间完成数据同步。因此，在这种情况下，有必要适当调大这个参数。 syncLimit 该参数有默认值：5，即表示是参数tickTime值的5倍，必须配置，且需要配置一个正整数，不支持系统属性方式配置。该参数用于配置Leader服务器和Follower之间进行心跳检测的最大延时时间。在ZooKeeper集群运行过程中，Leader服务器会与所有的Follower进行心跳检测来确定该服务器是否存活。如果Leader服务器在syncLimit时间内无法获取到Follower的心跳检测响应，那么Leader就会认为该Follower已经脱离了和自己的同步。通常情况下，运维人员使用该参数的默认值即可，但如果部署ZooKeeper集群的网络环境质量较低（例如网络延时较大或丢包严重），那么可以适当调大这个参数。 snapCount 该参数有默认值：100000，可以不配置，仅支持系统属性方式配置：zookeeper.snapCount。参数snapCount用于配置相邻两次数据快照之间的事务操作次数，即ZooKeeper会在snapCount次事务操作之后进行一次数据快照。 preAllocSize 该参数有默认值：65536，单位是KB，即64KB，可以不配置，仅支持系统属性方式配置：zookeeper.preAllocSize。参数preAllocSize用于配置ZooKeeper事务日志文件预分配的磁盘空间大小。通常情况下，我们使用ZooKeeper的默认配置65536KB即可，但是如果我们将参数snapCount设置得比默认值更小或更大，那么preAllocSize参数也随之做出变更。举个例子来说：如果我们将snapCount的值设置为500，同时预估每次事务操作的数据量大小至多1KB，那么参数preAllocSize设置为500就足够了。 minSessionTimeout maxSessionTimeout 这两个参数有默认值，分别是参数tickTime值的2倍和20倍，即默认的会话超时时间在2tickTime~20tickTime范围内，单位毫秒，剋有不配置，不支持系统属性方式配置。这两个参数用于服务端对客户端会话的超时时间进行限制，如果客户端设置的超时时间不在该范围内，那么会被服务端强制设置为最大或最小超时时间。 maxClientCnxns 该参数有默认值：60，可以不配置，不支持系统属性方式配置。从Socket局面限制单个客户端与单台服务器之间的并发连接数，即以IP地址粒度来进行连接数的限制。如果将该参数设置为0，则表示对连接数不做任何限制。需要注意该连接数限制选项的使用范围，其仅仅是对单台客户端机器与单台ZooKeeper服务器之间的连接数限制，并不能控制所有客户端的连接数综合。另外，在3.4.0版本以前该参数的默认值都是10，从3.4.0版本开始变成了60，因此运维人员尤其需要注意这个变化，以防ZooKeeper版本变化带来服务端连接限制变化的隐患。 jute.maxbuffer 该参数有默认值：1048575，单位是字节，可以不配置，仅支持系统属性方式配置：jute.maxbuffer。该参数用于配置单个数据节点（ZNode）上可以存储的最大数据量大小。通常情况下，运维人员不需要改动该参数，同时考虑到ZooKeeper上不适宜存储太多的数据，往往还需要将该参数设置的更小。需要注意的是，在变更参数的时候，需要在ZooKeeper集群的所有机器以及所有的客户端上均设置才能生效。 clientPortAddress 该参数没有默认值：可以不配置，不支持系统属性方式配置。针对那些多网卡的机器，该参数允许为每个IP地址指定不同的监听端口。 server.id=host:port:port 该参数没有默认值，在单机模式下剋有不配置，不支持系统属性方式配置。该参数用于配置组成ZooKeeper集群的机器列表，其中id即为ServerID，与每台服务器myid文件中的数字相对应。同时，在该参数中，会配置两个端口：第一个端口用于指定Follower服务器与Leader进行运行时通信和数据同步时所使用的端口、第二个端口则专门用于进行Leader选举过程中的投票通信。在ZooKeeper服务器启动的时候，其会根据myid文件中配置的Server ID来确定自己是哪台服务器，并使用对应配置的端口来进行启动。如果在实际使用过程中，需要在同一台服务器上部署多个ZooKeeper实例来构成伪集群的话，那么这些端口都需要配置成不同，例如：server.1=192.168.0.1:2777:3777server.2=192.168.0.1:2888:3888server.3=192.168.0.1:2999:3999 autopurge.snapRetainCount 该参数有默认值：3，可以不配置，不支持系统属性方式配置。从3.4.0版本开始，ZooKeeper提供了对历史事务日志和快照数据自动清理的支持。参数autopurge.snapRetainCount用于配置ZooKeeper在自动清理的时候需要保留的快照数据文件数量和对应的事务日志文件。需要注意的是，并不是磁盘上的所有事务日志和快照数据文件都可以被清理掉——那样的话将无法恢复书v。因此参数autopurge.snapRetainCount的最小值是3，如果配置autopurge.snapRetainCount值比3小的话，那么会被自动调整到3，即至少需要保留3个快照数据文件和对应的事务日志文件。 autopurge.purgeInterval 该参数有默认值：0，单位是小时，可以不配置，不支持系统属性方式配置。参数autopurge.purgeInterval和参数autopurge.snapRetainCount配套使用，用于配置ZooKeeper进行历史文件自动清理的频率。如果配置该值为0或负数，那么就表明不需要开启定时清理功能。ZooKeeper默认不开启这项功能。 fsync.warningthresholdms 该参数有默认值：1000，单位是毫秒，可以不配置，仅支持系统属性方式配置：fsync.warningthresholdms。参数fsync.warningthresholdms用于配置ZooKeeper进行事务日志fsync操作时消耗时间的报警阈值。一旦进行一个fsync操作消耗的时间大于参数，fsync.warningthresholdms指定的值，那么就在日志中打印出报警日志。 forceSync 该参数有默认值：yes，可以不配置，可选配置项为“yes”和“no”，仅支持系统属性方式配置：zookeeper.forceSync。该参数用于配置ZooKeeper服务器是否在事务提交的时候，将日志写入操作强制刷入磁盘（即调用java.nio.channels.FileChannel.force接口），默认情况下是“yes”，即每次事务日志写入操作都会实时刷入磁盘。如果将其设置为“no”，则能一定程度的提高ZooKeeper的写性能，但同时也会存在类似于机器断电这样的安全风险。 globalOutstandingLimit 该参数有默认值：1000，可以不配置，仅支持系统属性方式配置：zookeeper.globalOutstandingLimit。参数globalOutstandingLimit用于配置ZooKeeper服务器最大请求堆积数量。在ZooKeeper服务器运行的过程中，客户端会源源不断的将请求发送到服务端，为了防止服务端资源（包括CPU、内存和网络等）耗尽，服务端必须限制同时处理的请求数，即最大请求堆积数量。 leaderServes 该参数有默认值：yes，可以不配置，可选配置项为“yes”和“no”，仅支持系统属性方式配置：zookeeper.leaderServers。该参数用于配置Leader服务器是否能够接受客户端的连接，即是否允许Leader向客户端提供服务，默认情况下，Leader服务器能够接受并处理客户端的所有读写请求。在ZooKeeper的架构设计中，Leader服务器主要用来进行事务更新请求的协调以及集群本身的运行时协调，因此，可以设置让Leader服务器不接受客户端的连接，以使其专注于进行分布式协调。 SkipAcl 该参数有默认值：no，可以不配置，可选配置项为“yes”和“no”，仅支持系统属性方式配置：zookeeper.skipACL。该参数用于配置Leader服务器是否跳过ACL权限检查，默认情况下是“no”，即会对每一个客户端请求进行权限检查。如果将其设置为“yes”，则能一定程度的提高能够接受客户端的连接，即是否允许Leader向客户端提供服务，默认情况下ZooKeeper的读写性能，但同时也将向所有客户端开放ZooKeeper的数据，包括那些之前设置过ACL权限的数据节点，也将不再接受权限控制。 cnxTimeout 该参数有默认值：5000，单位是毫秒，可以不配置，仅支持系统属性方式配置：zookeeper.cnxTimeout。该参数用于配置在Leader选举过程中，各服务器之间进行TCP连接创建的超时时间。 electionAlg 在之前的版本中，可以使用该参数来配置选择ZooKeeper进行Leader选举时所使用的算法，但从3.4.0版本开始，ZooKeeper废弃了其他选举算法，只留下了FastLeaderElection算法，因此该参数目前看来没有用了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring的设计思想之整体架构]]></title>
      <url>%2F2018%2F02%2F28%2FSpring%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E4%B9%8B%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[开发常用工具]]></title>
      <url>%2F2018%2F02%2F27%2F%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%2F</url>
      <content type="text"><![CDATA[cron在线http://cron.qqe2.com/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务引用]]></title>
      <url>%2F2018%2F02%2F22%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-12%2F</url>
      <content type="text"><![CDATA[之前讲解了Dubbo服务的发布，下面我们来看看如何进行服务的引用。 在Spring启动的时候，根据dubbo:reference配置会创建一个ReferenceBean。ReferenceBean继承了ReferenceConfig，重点是看init()方法，前面做了很多工作收集配置参数，然后根据参数信息创建代理 1ref = createProxy(map); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495//ReferenceConfigprivate T createProxy(Map&lt;String, String&gt; map) &#123; URL tmpUrl = new URL("temp", "localhost", 0, map); final boolean isJvmRefer; if (isInjvm() == null) &#123; if (url != null &amp;&amp; url.length() &gt; 0) &#123; //指定URL的情况下，不做本地引用 isJvmRefer = false; &#125; else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) &#123; //默认情况下如果本地有服务暴露，则引用本地服务 isJvmRefer = true; &#125; else &#123; isJvmRefer = false; &#125; &#125; else &#123; isJvmRefer = isInjvm().booleanValue(); &#125; // if (isJvmRefer) &#123; URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map); invoker = refprotocol.refer(interfaceClass, url); if (logger.isInfoEnabled()) &#123; logger.info("Using injvm service " + interfaceClass.getName()); &#125; &#125; else &#123; // 用户指定URL，指定的URL可能是对点对直连地址，也可能是注册中心URL if (url != null &amp;&amp; url.length() &gt; 0) &#123; String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) &#123; for (String u : us) &#123; URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) &#123; url = url.setPath(interfaceName); &#125; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; else &#123; urls.add(ClusterUtils.mergeUrl(url, map)); &#125; &#125; &#125; &#125; else &#123; // 通过注册中心配置拼装URL List&lt;URL&gt; us = loadRegistries(false); if (us != null &amp;&amp; us.size() &gt; 0) &#123; for (URL u : us) &#123; URL monitorUrl = loadMonitor(u); if (monitorUrl != null) &#123; map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); &#125; urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); &#125; &#125; if (urls == null || urls.size() == 0) &#123; throw new IllegalStateException("No such any registry to reference " + interfaceName + " on the consumer " + NetUtils.getLocalHost() + " use dubbo version " + Version.getVersion() + ", please config &lt;dubbo:registry address=\"...\" /&gt; to your spring config."); &#125; &#125; if (urls.size() == 1) &#123; invoker = refprotocol.refer(interfaceClass, urls.get(0)); &#125; else &#123; //多注册中心 List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) &#123; invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // 用了最后一个registry url &#125; &#125; if (registryURL != null) &#123; // 有 注册中心协议的URL // 对有注册中心的Cluster 只用 AvailableCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); &#125; else &#123; // 不是 注册中心的URL invoker = cluster.join(new StaticDirectory(invokers)); &#125; &#125; &#125; Boolean c = check; if (c == null &amp;&amp; consumer != null) &#123; c = consumer.isCheck(); &#125; if (c == null) &#123; c = true; // default true &#125; if (c &amp;&amp; !invoker.isAvailable()) &#123; throw new IllegalStateException("Failed to check the status of the service " + interfaceName + ". No provider available for the service " + (group == null ? "" : group + "/") + interfaceName + (version == null ? "" : ":" + version) + " from the url " + invoker.getUrl() + " to the consumer " + NetUtils.getLocalHost() + " use dubbo version " + Version.getVersion()); &#125; if (logger.isInfoEnabled()) &#123; logger.info("Refer dubbo service " + interfaceClass.getName() + " from url " + invoker.getUrl()); &#125; // create service proxy return (T) proxyFactory.getProxy(invoker); &#125; 获取invoker有3种情况，一种是指定url,做点对点；一种是本地暴露；还有一种是注册中心url。 12invoker = refprotocol.refer(interfaceClass, url);//引用本地暴露的urlinvoker = refprotocol.refer(interfaceClass, urls.get(0));//引用注册中心的url 无论是引用本地暴露还是远程暴露的url,都调用refprotocol.refer()，追踪发现refprotocol.refer() 先后经过修饰类 ProtocolFilterWrapper、ProtocolListenerWrapper 最后执行RegistryProtocol。 123456789101112131415161718192021222324252627282930313233343536373839404142434445//RegistryProtocolpublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // group="a,b" or group="*"处理merge情况 Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || "*".equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; return doRefer(cluster, registry, type, url); &#125;//private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; //构建消费者引用的服务方的directory RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); //订阅的url URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; //服务消费方向注册中心注册自己，供其他层使用，比如服务治理 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; //订阅服务提供方 //同时订阅了三种类型providers，routers，configurators。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY)); //默认使用FailoverCluster集群策略类，调用join(Directory&lt;T&gt; directory)方法将RegistryDirectory对象封装成FailoverClusterInvoker对象并返回。 Invoker invoker = cluster.join(directory); //消费者缓存表 ProviderConsumerRegTable.registerConsuemr(invoker, url, subscribeUrl, directory); return invoker; &#125; 上面这段代码重点是消费方的注册和订阅动作 1234567registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125;//注册动作directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + "," + Constants.CONFIGURATORS_CATEGORY + "," + Constants.ROUTERS_CATEGORY));//订阅动作 注册动作，其实调用的是FailbackRegistry的register()方法，和服务发布的注册调用同一个方法。 订阅动作，其实调用的是FailbackRegistry的subscribe()方法，和服务发布的注册调用同一个方法，不同是它订阅providers，routers，configurators。 最后最为重要的是创建代理，传入的参数是cluster.join(directory)返回的invoker，实现在StubProxyFactoryWrapper中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273return (T) proxyFactory.getProxy(invoker);//StubProxyFactoryWrapper实现public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; //AbstractProxyFactory，一般配置就到这里结束 T proxy = proxyFactory.getProxy(invoker); if (GenericService.class != invoker.getInterface()) &#123; String stub = invoker.getUrl().getParameter(Constants.STUB_KEY, invoker.getUrl().getParameter(Constants.LOCAL_KEY)); //处理stub逻辑 if (ConfigUtils.isNotEmpty(stub)) &#123; Class&lt;?&gt; serviceType = invoker.getInterface(); if (ConfigUtils.isDefault(stub)) &#123; if (invoker.getUrl().hasParameter(Constants.STUB_KEY)) &#123; stub = serviceType.getName() + "Stub"; &#125; else &#123; stub = serviceType.getName() + "Local"; &#125; &#125; try &#123; Class&lt;?&gt; stubClass = ReflectUtils.forName(stub); if (! serviceType.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException("The stub implemention class " + stubClass.getName() + " not implement interface " + serviceType.getName()); &#125; try &#123; Constructor&lt;?&gt; constructor = ReflectUtils.findConstructor(stubClass, serviceType); proxy = (T) constructor.newInstance(new Object[] &#123;proxy&#125;); //export stub service URL url = invoker.getUrl(); if (url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT))&#123; url = url.addParameter(Constants.STUB_EVENT_METHODS_KEY, StringUtils.join(Wrapper.getWrapper(proxy.getClass()).getDeclaredMethodNames(), ",")); url = url.addParameter(Constants.IS_SERVER_KEY, Boolean.FALSE.toString()); try&#123; export(proxy, (Class)invoker.getInterface(), url); &#125;catch (Exception e) &#123; LOGGER.error("export a stub service error.", e); &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException("No such constructor \"public " + stubClass.getSimpleName() + "(" + serviceType.getName() + ")\" in stub implemention class " + stubClass.getName(), e); &#125; &#125; catch (Throwable t) &#123; LOGGER.error("Failed to create stub implemention class " + stub + " in consumer " + NetUtils.getLocalHost() + " use dubbo version " + Version.getVersion() + ", cause: " + t.getMessage(), t); // ignore &#125; &#125; &#125; return proxy; &#125;//AbstractProxyFactorypublic &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; Class&lt;?&gt;[] interfaces = null; String config = invoker.getUrl().getParameter("interfaces"); if (config != null &amp;&amp; config.length() &gt; 0) &#123; String[] types = Constants.COMMA_SPLIT_PATTERN.split(config); if (types != null &amp;&amp; types.length &gt; 0) &#123; interfaces = new Class&lt;?&gt;[types.length + 2]; interfaces[0] = invoker.getInterface(); interfaces[1] = EchoService.class; for (int i = 0; i &lt; types.length; i ++) &#123; interfaces[i + 1] = ReflectUtils.forName(types[i]); &#125; &#125; &#125; if (interfaces == null) &#123; interfaces = new Class&lt;?&gt;[] &#123;invoker.getInterface(), EchoService.class&#125;; &#125; return getProxy(invoker, interfaces); &#125;//JavassistProxyFactorypublic &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &#125; 这个代理生成之后，在消费者消费某个服务时候，就进入InvokerInvocationHandler的逻辑，参考这篇文章，这样消费者和提供者之间就架起了桥梁。 总结]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务降级(2)]]></title>
      <url>%2F2018%2F02%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-15%2F</url>
      <content type="text"><![CDATA[​ 在之前微服务架构之Dubbo服务降级(1)讲解了mock的服务降级机制，其实stub可以说范围更广阔，更全面的服务降级。 ​ 官方是这样介绍的：Mock是Stub（本地存根）的一个子集，便于服务提供方在客户端执行容错逻辑，因经常需要在出现RpcException(比如网络失败，超时等)时进行容错，而在出现业务异常(比如登录用户名密码错误)时不需要容错，如果用Stub, 需要捕获并依赖RpcException类，而用Mock就可以不依赖RpcException，因为它的约定就是只有出现RpcException时才执行。Mock通常用于服务降级，比如某验权服务，当服务提供方全部挂掉后，客户端不抛出异常，而是通过Mock数据返回授权失败。 如何使用StubStub 存根，可以在dubbo 提供者端实现，也可在调用消费方实现； 如果消费方实现存根，则服务方 存根 将不起作用。 1&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" stub="com.alibaba.dubbo.demo.DemoServiceStub" /&gt; 我们在com.alibaba.dubbo.demo路径下定义DemoServiceStub类，实现DemoService接口。 12345678910111213141516public class DemoServiceStub implements DemoService &#123; private DemoService demoService;//必须要有，用以接受dubbo在调用远程服务生成的服务代理类 public DemoServiceStub(DemoService demoService) &#123; this.demoService = demoService; &#125; //相当于在远程调用时，人工封装一层,当出现异常才会有stub效果 @Override public String sayHello(String name) &#123; try&#123; return demoService.sayHello(name);//远程调用 &#125;catch(Exception e) &#123; //远程调用失败 return "i am stub , hello"; &#125; &#125; 源码解析我们在这篇文章介绍了dubbo的服务引用，ReferenceConfig的init()在执行ref = createProxy(map)之前有一步骤是checkStubAndMock，如果没有com.alibaba.dubbo.demo.DemoServiceStub实现会报错。在StubProxyFactoryWrapper后面我们看到处理stub的逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//StubProxyFactoryWrapper实现public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; //AbstractProxyFactory，一般配置就到这里结束 T proxy = proxyFactory.getProxy(invoker); if (GenericService.class != invoker.getInterface()) &#123; String stub = invoker.getUrl().getParameter(Constants.STUB_KEY, invoker.getUrl().getParameter(Constants.LOCAL_KEY)); //处理stub逻辑 if (ConfigUtils.isNotEmpty(stub)) &#123; Class&lt;?&gt; serviceType = invoker.getInterface(); if (ConfigUtils.isDefault(stub)) &#123; if (invoker.getUrl().hasParameter(Constants.STUB_KEY)) &#123; stub = serviceType.getName() + "Stub"; &#125; else &#123; stub = serviceType.getName() + "Local"; &#125; &#125; try &#123; Class&lt;?&gt; stubClass = ReflectUtils.forName(stub); if (! serviceType.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException("The stub implemention class " + stubClass.getName() + " not implement interface " + serviceType.getName()); &#125; try &#123; Constructor&lt;?&gt; constructor = ReflectUtils.findConstructor(stubClass, serviceType); //根据构造器，实例化了为新的代理，重大区别 proxy = (T) constructor.newInstance(new Object[] &#123;proxy&#125;); //export stub service URL url = invoker.getUrl(); //我debug时候，这是默认是false,没有暴露 if (url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT))&#123; url = url.addParameter(Constants.STUB_EVENT_METHODS_KEY, StringUtils.join(Wrapper.getWrapper(proxy.getClass()).getDeclaredMethodNames(), ",")); url = url.addParameter(Constants.IS_SERVER_KEY, Boolean.FALSE.toString()); try&#123; export(proxy, (Class)invoker.getInterface(), url); &#125;catch (Exception e) &#123; LOGGER.error("export a stub service error.", e); &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException("No such constructor \"public " + stubClass.getSimpleName() + "(" + serviceType.getName() + ")\" in stub implemention class " + stubClass.getName(), e); &#125; &#125; catch (Throwable t) &#123; LOGGER.error("Failed to create stub implemention class " + stub + " in consumer " + NetUtils.getLocalHost() + " use dubbo version " + Version.getVersion() + ", cause: " + t.getMessage(), t); // ignore &#125; &#125; &#125; //这里的proxy是由stub构造器重新实例化而来 return proxy; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务发布(4)]]></title>
      <url>%2F2018%2F02%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-14%2F</url>
      <content type="text"><![CDATA[zookeeper连接,注册与监听接着微服务架构之Dubbo服务发布(2）我们详细讲解 连接1234//首先获取注册中心的地址URL registryUrl = getRegistryUrl(originInvoker);//返回的格式是zookeeper://final Registry registry = getRegistry(originInvoker); 首先第一个重点来了，追踪代码流程，我们先看其时序图，最终registry的实例是ZookeeperRegistry。 对于ZookeeperRegistry，是很重要的，在实例化的过程中做了很多事情。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//ZookeeperRegistry的构造函数public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; super(url); //FailbackRegistry的构造函数 if (url.isAnyHost()) &#123; throw new IllegalStateException("registry address == null"); &#125; String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (!group.startsWith(Constants.PATH_SEPARATOR)) &#123; group = Constants.PATH_SEPARATOR + group; &#125; this.root = group; zkClient = zookeeperTransporter.connect(url); zkClient.addStateListener(new StateListener() &#123; public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover();//恢复订阅 &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;); &#125;//FailbackRegistry的构造函数public FailbackRegistry(URL url) &#123; super(url);//AbstractRegistry的构造函数 int retryPeriod = url.getParameter(Constants.REGISTRY_RETRY_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RETRY_PERIOD); this.retryFuture = retryExecutor.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // Check and connect to the registry try &#123; //定时的检测并连接注册中心,如果失败了就重连，处理failedRegistered（注册失败）和failedUnregistered（移除注册失败）中的数据 retry(); &#125; catch (Throwable t) &#123; // Defensive fault tolerance logger.error("Unexpected error occur at failed retry, cause: " + t.getMessage(), t); &#125; &#125; &#125;, retryPeriod, retryPeriod, TimeUnit.MILLISECONDS); &#125;//AbstractRegistry的构造函数public AbstractRegistry(URL url) &#123; setUrl(url); // 注册中心是否同步存储文件，默认异步 syncSaveFile = url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); String filename = url.getParameter(Constants.FILE_KEY, System.getProperty("user.home") + "/.dubbo/dubbo-registry-" + url.getParameter(Constants.APPLICATION_KEY) + "-" + url.getAddress() + ".cache"); //缓存地址 File file = null; if (ConfigUtils.isNotEmpty(filename)) &#123; file = new File(filename); if (!file.exists() &amp;&amp; file.getParentFile() != null &amp;&amp; !file.getParentFile().exists()) &#123; if (!file.getParentFile().mkdirs()) &#123; throw new IllegalArgumentException("Invalid registry store file " + file + ", cause: Failed to create directory " + file.getParentFile() + "!"); &#125; &#125; &#125;//创建本地缓存文件 this.file = file; loadProperties();//加载缓存文件到properties notify(url.getBackupUrls()); &#125; 从代码中我们看出包括1.监听状态，恢复连接时候，恢复订阅 2.定时检测并连接注册中心, 如果失败了就重连 3.没有本地缓存文件，就先建立本地缓存文件，然后加载缓存文件的内容。 注册1234567891011121314//获取要注册的提供者的url dubbo://final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);//to judge to delay publish whether or not//默认是trueboolean register = registedProviderUrl.getParameter("register", true);ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registedProviderUrl);if (register) &#123; //创建zookeeper节点 register(registryUrl, registedProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); &#125; 最重要的是register(registryUrl, registedProviderUrl) 1234567891011121314151617181920212223242526272829303132333435363738 public void register(URL registryUrl, URL registedProviderUrl) &#123; Registry registry = registryFactory.getRegistry(registryUrl); //FailbackRegistry registry.register(registedProviderUrl); &#125;//FailbackRegistrypublic void register(URL url) &#123; if (destroyed.get())&#123; return; &#125; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // Sending a registration request to the server side doRegister(url); //ZookeeperRegistry实现 &#125; catch (Exception e) &#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; //可以配置check ，当check = "false"就不检测不抛异常 if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException("Failed to register " + url + " to registry " + getUrl().getAddress() + ", cause: " + t.getMessage(), t); &#125; else &#123; logger.error("Failed to register " + url + ", waiting for retry, cause: " + t.getMessage(), t); &#125; // Record a failed registration request to a failed list, retry regularly failedRegistered.add(url); &#125; &#125; 12345678910111213141516171819202122//ZookeeperRegistryprotected void doRegister(URL url) &#123; try &#123; zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true));//true是临时节点，false是持久节点 &#125; catch (Throwable e) &#123; throw new RpcException("Failed to register " + url + " to zookeeper " + getUrl() + ", cause: " + e.getMessage(), e); &#125; &#125;public void create(String path, boolean ephemeral) &#123; int i = path.lastIndexOf('/'); if (i &gt; 0) &#123; String parentPath = path.substring(0, i); if (!checkExists(parentPath)) &#123; create(parentPath, false);//父类的路径为持久节点 &#125; &#125; if (ephemeral) &#123; createEphemeral(path);//临时节点 &#125; else &#123; createPersistent(path);//持久节点 &#125; &#125; 其中，持久节点,是指在节点创建后,就一直存在,直到有删除操作来主动清除这个节点,也就是说不会因为创建该节点的客户端会话失效而消失。临时节点的生命周期和客户端会话绑定,也就是说,如果客户端会话失效,那么这个节点就会自动被清除掉。 订阅服务提供者而言，它的监听和订阅主要针对的是dubbo-admin控制台下发的override数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344//提供者订阅时，会影响同一JVM既暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl);//添加对该节点的监听 final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener);//发送订阅请求，这里是服务提供者，它订阅的是override数据 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);//FailbackRegistrypublic void subscribe(URL url, NotifyListener listener) &#123; if (destroyed.get())&#123; return; &#125; super.subscribe(url, listener); removeFailedSubscribed(url, listener); try &#123; // Sending a subscription request to the server side doSubscribe(url, listener);//订阅 &#125; catch (Exception e) &#123; Throwable t = e; List&lt;URL&gt; urls = getCacheUrls(url); if (urls != null &amp;&amp; urls.size() &gt; 0) &#123; notify(url, listener, urls); logger.error("Failed to subscribe " + url + ", Using cached list: " + urls + " from cache file: " + getUrl().getParameter(Constants.FILE_KEY, System.getProperty("user.home") + "/dubbo-registry-" + url.getHost() + ".cache") + ", cause: " + t.getMessage(), t); &#125; else &#123; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException("Failed to subscribe " + url + ", cause: " + t.getMessage(), t); &#125; else &#123; logger.error("Failed to subscribe " + url + ", waiting for retry, cause: " + t.getMessage(), t); &#125; &#125; // Record a failed registration request to a failed list, retry regularly addFailedSubscribed(url, listener);//重试，会在retry（）定时处理 &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//ZookeeperRegistryprotected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; String root = toRootPath(); ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; for (String child : currentChilds) &#123; child = URL.decode(child); if (!anyServices.contains(child)) &#123; anyServices.add(child); subscribe(url.setPath(child).addParameters(Constants.INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener);//FailbackRegistry的subscribe &#125; &#125; &#125; &#125;); zkListener = listeners.get(listener); &#125; zkClient.create(root, false); List&lt;String&gt; services = zkClient.addChildListener(root, zkListener); if (services != null &amp;&amp; services.size() &gt; 0) &#123; for (String service : services) &#123; service = URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(Constants.INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; else &#123; //我测试时候，走这个逻辑 List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); //包括router,configurators, providers的持久节点 for (String path : toCategoriesPath(url)) &#123; ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds));//设置了监听回调的地址 &#125; &#125;); zkListener = listeners.get(listener); &#125; zkClient.create(path, false);//创建持久化节点 List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); if (children != null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; notify(url, listener, urls);//服务启动和节点更新回调 &#125; &#125; catch (Throwable e) &#123; throw new RpcException("Failed to subscribe " + url + " to zookeeper " + getUrl() + ", cause: " + e.getMessage(), e); &#125; &#125; 123456789101112131415161718192021//FailbackRegistryprotected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException("notify url == null"); &#125; if (listener == null) &#123; throw new IllegalArgumentException("notify listener == null"); &#125; try &#123; doNotify(url, listener, urls);//AbstractRegistry实现的 &#125; catch (Exception t) &#123; // Record a failed registration request to a failed list, retry regularly Map&lt;NotifyListener, List&lt;URL&gt;&gt; listeners = failedNotified.get(url); if (listeners == null) &#123; failedNotified.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, List&lt;URL&gt;&gt;()); listeners = failedNotified.get(url); &#125; listeners.put(listener, urls); logger.error("Failed to notify for subscribe " + url + ", waiting for retry, cause: " + t.getMessage(), t); &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//AbstractRegistryprotected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException("notify url == null"); &#125; if (listener == null) &#123; throw new IllegalArgumentException("notify listener == null"); &#125; if ((urls == null || urls.size() == 0) &amp;&amp; !Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; logger.warn("Ignore empty notify urls for subscribe url " + url); return; &#125; if (logger.isInfoEnabled()) &#123; logger.info("Notify urls for subscribe url " + url + ", urls: " + urls); &#125; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url);//更新缓存文件 //对于消费者来说这里listener是RegistryDirectory //而对于服务提供者来说这里是OverrideListener，是RegistryProtocol的内部类 listener.notify(categoryList);//对比新旧的信息是否有变化,有则重新暴露服务 &#125; &#125; 1234567891011121314151617181920212223242526272829303132//AbstractRegistry private void saveProperties(URL url) &#123; if (file == null) &#123; return; &#125; try &#123; StringBuilder buf = new StringBuilder(); Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified != null) &#123; for (List&lt;URL&gt; us : categoryNotified.values()) &#123; for (URL u : us) &#123; if (buf.length() &gt; 0) &#123; buf.append(URL_SEPARATOR); &#125; buf.append(u.toFullString()); &#125; &#125; &#125; properties.setProperty(url.getServiceKey(), buf.toString()); long version = lastCacheChanged.incrementAndGet(); if (syncSaveFile) &#123; //同步写 doSaveProperties(version); &#125; else &#123; //异步写 registryCacheExecutor.execute(new SaveProperties(version)); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940//OverrideListener 针对服务的提供者public void notify(List&lt;URL&gt; urls) &#123; List&lt;URL&gt; result = null; for (URL url : urls) &#123; URL overrideUrl = url; if (url.getParameter(Constants.CATEGORY_KEY) == null &amp;&amp; Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) &#123; // 兼容旧版本 overrideUrl = url.addParameter(Constants.CATEGORY_KEY, Constants.CONFIGURATORS_CATEGORY); &#125; if (! UrlUtils.isMatch(subscribeUrl, overrideUrl)) &#123; if (result == null) &#123; result = new ArrayList&lt;URL&gt;(urls); &#125; result.remove(url); logger.warn("Subsribe category=configurator, but notifed non-configurator urls. may be registry bug. unexcepted url: " + url); &#125; &#125; if (result != null) &#123; urls = result; &#125; this.configurators = RegistryDirectory.toConfigurators(urls); List&lt;ExporterChangeableWrapper&lt;?&gt;&gt; exporters = new ArrayList&lt;ExporterChangeableWrapper&lt;?&gt;&gt;(bounds.values()); for (ExporterChangeableWrapper&lt;?&gt; exporter : exporters)&#123; Invoker&lt;?&gt; invoker = exporter.getOriginInvoker(); final Invoker&lt;?&gt; originInvoker ; if (invoker instanceof InvokerDelegete)&#123; originInvoker = ((InvokerDelegete&lt;?&gt;)invoker).getInvoker(); &#125;else &#123; originInvoker = invoker; &#125; URL originUrl = RegistryProtocol.this.getProviderUrl(originInvoker); URL newUrl = getNewInvokerUrl(originUrl, urls); if (! originUrl.equals(newUrl))&#123; RegistryProtocol.this.doChangeLocalExport(originInvoker, newUrl); &#125; &#125; &#125; 总结​ 在服务发布过程中，服务提供者首先连接zookeeper , 返回一个ZookeeperRegistry实例，它在初始化时候做了3件事情：1.监听状态，恢复连接时候，恢复订阅 2.定时检测并连接注册中心, 如果失败了就重连 3.没有本地缓存文件，就先建立本地缓存文件，然后加载缓存文件的内容；注册zookeeper主要是完成zookeeper相关节点的创建；订阅zookeeper主要是在zookeeper中创建configurators持久节点，监听dubbo-admin下发的override数据，并及时更新本地缓存文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务发布(3)]]></title>
      <url>%2F2018%2F02%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-13%2F</url>
      <content type="text"><![CDATA[netty的启动接着微服务架构之Dubbo服务发布(2）我们详细讲解 1final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); 12345678910111213141516private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker) &#123; String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T&gt; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; synchronized (bounds) &#123; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker));//这里最重要的是调用DubboProtocol的export方法，导出完之后，返回一个新的ExporterChangeableWrapper实例 exporter = new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;) protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); &#125; &#125; &#125; return exporter; &#125; DubboProtocol的外面包裹着ProtocolFilterWrapper，再外面还包裹着ProtocolListenerWrapper。会先经过ProtocolListenerWrapper。 12345678910111213141516171819202122232425262728293031323334//DubboProtocolpublic &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; URL url = invoker.getUrl(); // export service. //key由serviceName，version，portgroup,组成 //当nio客户端发起远程调用时，nio服务端通过此key来决定调用哪个Exporter，也就是执行的Invoker。 String key = serviceKey(url); DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); //缓存 exporterMap.put(key, exporter); //是否要支持本地存根 ，可以用stub关键字配置，这也是dubbo服务降级方式，详情见服务降级（2） //export an stub service for dispaching event Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice)&#123; String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0 )&#123; if (logger.isWarnEnabled())&#123; logger.warn(new IllegalStateException("consumer [" +url.getParameter(Constants.INTERFACE_KEY) + "], has set stubproxy support event ,but no stub methods founded.")); &#125; &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125;//根据URL绑定IP与端口，建立NIO框架的Server openServer(url); // modified by lishen optimizeSerialization(url); return exporter;&#125; exporter会被放到bounds中，key就是上面生成的，客户端发请求就根据key找到对应的Exporter，转化为invoker进行调用。 12345678910111213141516171819private void openServer(URL url) &#123; // find server. String key = url.getAddress();//获取提供者的地址 //client can export a service which's only for server to invoke boolean isServer = url.getParameter(Constants.IS_SERVER_KEY, true); if (isServer) &#123; ExchangeServer server = serverMap.get(key); //同一JVM中，同协议的服务，共享同一个Server， //第一个暴露服务的时候创建server， //以后相同协议的服务都使用同一个server if (server == null) &#123; serverMap.put(key, createServer(url)); &#125; else &#123; // server supports reset, use together with override //HeaderExchangeServer处理的，主要是重置如果url带有accepts，threads，heartbeat，heartbeat.timeout等参数信息。 server.reset(url); &#125; &#125;&#125; 我们来看看createServer（URL url）具体实现 12345678910111213141516171819202122232425262728private ExchangeServer createServer(URL url) &#123; //默认开启server关闭时发送readonly事件 url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()); //默认开启heartbeat url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); //默认使用netty String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; ! ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) throw new RpcException("Unsupported server type: " + str + ", url: " + url); url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; //Exchanger默认只有一个实现HeaderExchanger,负责数据交换和网络通信 server = Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; throw new RpcException("Fail to start server(url: " + url + ") " + e.getMessage(), e); &#125; str = url.getParameter(Constants.CLIENT_KEY); if (str != null &amp;&amp; str.length() &gt; 0) &#123; Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) &#123; throw new RpcException("Unsupported client type: " + str); &#125; &#125; return server; &#125; Exchangers.bind(url, requestHandler) 123456789101112131415public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handler == null) &#123; throw new IllegalArgumentException("handler == null"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, "exchange"); return getExchanger(url).bind(url, handler); &#125;public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler)))); &#125;//HeaderExchangeServer实例化时候会启动心跳计数器 接着看Transporters.bind(URL url, ChannelHandler… handlers) 1234567891011121314151617public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException("url == null"); &#125; if (handlers == null || handlers.length == 0) &#123; throw new IllegalArgumentException("handlers == null"); &#125; ChannelHandler handler; if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; handler = new ChannelHandlerDispatcher(handlers); &#125; //getTransporter()获取一个Adaptive的Transporter //然后调用bind方法（默认是NettyTransporter的bind方法） return getTransporter().bind(url, handler); &#125; NettyTransporter的bind方法,目前支持netty和netty4,最后的super都指向了AbstractServer构造方法。 1234567891011121314//netty4public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyServer(url, listener);&#125;public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));&#125;//nettypublic Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyServer(url, listener);&#125;public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));&#125; 12345678910111213141516171819202122232425public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); localAddress = getUrl().toInetSocketAddress(); String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost()); int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort()); if (url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) &#123; bindIp = NetUtils.ANYHOST; &#125; bindAddress = new InetSocketAddress(bindIp, bindPort); this.accepts = url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS); this.idleTimeout = url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT); try &#123; doOpen();//最后的关键，也区分netty和netty4 if (logger.isInfoEnabled()) &#123; logger.info("Start " + getClass().getSimpleName() + " bind " + getBindAddress() + ", export " + getLocalAddress()); &#125; &#125; catch (Throwable t) &#123; throw new RemotingException(url.toInetSocketAddress(), null, "Failed to bind " + getClass().getSimpleName() + " on " + getLocalAddress() + ", cause: " + t.getMessage(), t); &#125; //fixme replace this with better method DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort())); &#125; 最后看看doOpen() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//nettyprotected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerBoss", true)); ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerWorker", true)); ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap = new ServerBootstrap(channelFactory); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); // https://issues.jboss.org/browse/NETTY-365 // https://issues.jboss.org/browse/NETTY-379 // final Timer timer = new HashedWheelTimer(new NamedThreadFactory("NettyIdleTimer", true)); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); /*int idleTimeout = getIdleTimeout(); if (idleTimeout &gt; 10000) &#123; pipeline.addLast("timer", new IdleStateHandler(timer, idleTimeout / 1000, 0, 0)); &#125;*/ pipeline.addLast("decoder", adapter.getDecoder()); pipeline.addLast("encoder", adapter.getEncoder()); pipeline.addLast("handler", nettyHandler); return pipeline; &#125; &#125;); // bind channel = bootstrap.bind(getBindAddress()); &#125; //netty4 protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory("NettyServerBoss", true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory("NettyServerWorker", true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast("logging",new LoggingHandler(LogLevel.INFO))//for debug .addLast("decoder", adapter.getDecoder()) .addLast("encoder", adapter.getEncoder()) .addLast("handler", nettyServerHandler); &#125; &#125;); // bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); &#125; 参考http://blog.csdn.net/jurson99/article/details/50401270 https://www.jianshu.com/p/dcfe426e9cd7]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务发布(2)]]></title>
      <url>%2F2018%2F02%2F07%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-11%2F</url>
      <content type="text"><![CDATA[本地暴露上一篇中微服务架构之Dubbo服务发布(1)我们提到本地暴露，是在exportLocal(URL url)中 传进来的url如图所示 1234567891011121314private void exportLocal(URL url) &#123; //如果协议不是injvm的我们就需要处理，例如传进来是dubbo,我们发现后面的逻辑就是将协议转化为injvm if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; URL local = URL.valueOf(url.toFullString()) .setProtocol(Constants.LOCAL_PROTOCOL) .setHost(LOCALHOST) .setPort(0);//转化为本地url ,即injvm协议的 ServiceClassHolder.getInstance().pushServiceClass(getServiceClass(ref)); Exporter&lt;?&gt; exporter = protocol.export( proxyFactory.getInvoker(ref, (Class) interfaceClass, local)); exporters.add(exporter); logger.info("Export dubbo service " + interfaceClass.getName() + " to local registry"); &#125;&#125; 经过这段代码后 其中protocol.export的实现来自InjvmProtocol，在调用InjvmProtocol类的export方法之前会先调用ProtocolFilterWrapper类的export方法由JavassistProxyFactory提供的getInvoker方法返回的Invoker转化为Exporter。 1234567891011121314151617181920212223//InjvmProtocolpublic &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; return new InjvmExporter&lt;T&gt;(invoker, invoker.getUrl().getServiceKey(), exporterMap);&#125;InjvmExporter(Invoker&lt;T&gt; invoker, String key, Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap) &#123; super(invoker); this.key = key; this.exporterMap = exporterMap; exporterMap.put(key, this);//这里有个缓存 &#125;//JavassistProxyFactorypublic &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125; 流程图为： 这就是本地暴露的过程，那么如何测试本地暴露呢？我们需要这么配置，但之前要保证服务提供方与服务消费方启动在同一个 JVM。 服务消费方配置： 123 &lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" scope="local" registry="N/A"/&gt;或者&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" injvm="true" registry="N/A"/&gt; 服务提供方配置： 1&lt;dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService" registry="N/A" scope="local"/&gt; 从消费方到提供方，消费方主要会涉及Dubbo的服务引用，提供方主要会涉及Dubbo的服务发布，看完这2大块内容，就会明白本地暴露的消费流程。 远程暴露首先我们接着看代码 123456789101112131415161718192021222324252627282930313233if (!Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope)) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Export dubbo service " + interfaceClass.getName() + " to url " + url); &#125; //注册中心的URL地址 if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0) &#123; for (URL registryURL : registryURLs) &#123; //将前面合成的url添加新的参数dynamic url = url.addParameterIfAbsent("dynamic", registryURL.getParameter("dynamic")); URL monitorUrl = loadMonitor(registryURL); // 如果有monitor信息，则在url上增加monitor配置 if (monitorUrl != null) &#123; url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); &#125; if (logger.isInfoEnabled()) &#123; logger.info("Register dubbo service " + interfaceClass.getName() + " url " + url + " to registry " + registryURL); &#125; Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; else &#123; //没有注册中心 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; &#125; 经过上面代码后 其中protocol.export的实现来自RegistryProtocol，在调用RegisterProtocol类的export方法之前会先调用ProtocolFilterWrapper类的export方法, 将由JavassistProxyFactory提供的getInvoker方法返回的Invoker转化为Exporter。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//RegistryProtocolpublic &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; //export invoker //这里会开启netty，具体流程会单独说明 final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //获取注册中心的地址，并连接，注册 URL registryUrl = getRegistryUrl(originInvoker); final Registry registry = getRegistry(originInvoker); final URL registedProviderUrl = getRegistedProviderUrl(originInvoker); boolean register = registedProviderUrl.getParameter("register", true); ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registedProviderUrl); if (register) &#123; register(registryUrl, registedProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); &#125; // 订阅override数据 ，FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); //提供者向注册中心订阅注册服务的覆盖配置，当由此服务的覆盖配置注册进来，就推送消息给提供者，重新暴露服务 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //保证每次export都返回一个新的exporter实例 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;; &#125; 流程图为： 整体总结]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务发布(1)]]></title>
      <url>%2F2018%2F02%2F07%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-10%2F</url>
      <content type="text"><![CDATA[​ 这一部分主要梳理Dubbo的服务发布的原理，会涉及dubbo-config等模块内容，从以下几个方面来一步一步深入学习。 dubbo-config模块包括dubbo-config-api 和dubbo-config-spring 。 dubbo-config-api中重要的类包括ReferenceConfig和ServiceConfig，分别处理消费端的配置（服务引用）和提供服务端的配置（服务发布） dubbo-config-spring 主要是扩展spring配置标签的扩展； 服务发布的开始还是要从ServiceBean说起，我们利用idea的工具查看ServiceBean的继承体系图。 里面有许多与spring相关的东西，其中重要的关注点是InitializeBean和ApplicationListener。我们会遇到这样的配置 12&lt;dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService" delay="5000"/&gt;&lt;dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService" delay="-1"/&gt; 当我们设置为delay=“5000”时，意味着设置延时暴露，这个时候就是通过回调InitializingBean接口的afterPropertySet()方法进行服务发布的。 1234567891011if (!isDelay()) &#123; export();&#125;//这里的isDelay()会返回falseprivate boolean isDelay() &#123; Integer delay = getDelay(); ProviderConfig provider = getProvider(); if (delay == null &amp;&amp; provider != null) &#123; delay = provider.getDelay(); &#125; return supportedApplicationListener &amp;&amp; (delay == null || delay == -1); &#125; 当我们设置为delay=“-1”或者不设置时，意味着延迟到 Spring 初始化完成后， 再暴露服务，这个时候会通知实现了ApplicationListener的接口进行回调onApplicationEvent方法进行服务发布。 123456789public void onApplicationEvent(ContextRefreshedEvent event) &#123; //条件是没有设置delay且没有暴露过 if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) &#123; if (logger.isInfoEnabled()) &#123; logger.info("The service ready on spring started. service: " + getInterface()); &#125; export(); &#125; &#125; 重要的方法出现了，就是ServiceBean继承ServiceConfig的export()。 123456789101112131415161718192021222324//版本是2.6public synchronized void export() &#123; if (provider != null) &#123; if (export == null) &#123; export = provider.getExport();//配置export， 默认是true暴露 &#125; if (delay == null) &#123; delay = provider.getDelay(); &#125; &#125; if (export != null &amp;&amp; !export) &#123; return; &#125; if (delay != null &amp;&amp; delay &gt; 0) &#123; delayExportExecutor.schedule(new Runnable() &#123; public void run() &#123; doExport(); &#125;//delay = "5000"的逻辑 &#125;, delay, TimeUnit.MILLISECONDS); &#125; else &#123; doExport(); //delay = "-1"或者没有配置逻辑 &#125; &#125; 接着就是doExport()方法,前面是做了一系列的检查，provider，application，module，registries，monitor这些参数是否为空，是否是GenericService类型的服务，检查要注册的bean的引用和方法等。在方法的最后会调用doExportUrls方法。 123456789101112131415protected synchronized void doExport() &#123; ...... ...... doExportUrls(); ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref); ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel); &#125;private void doExportUrls() &#123; //加载所有的注册中心，服务有可能注册在多个注册中心,因为我们暴露服务需要注册到注册中心中去。 List&lt;URL&gt; registryURLs = loadRegistries(true); //不同协议的注册。dubbo/hessian/rmi..... for (ProtocolConfig protocolConfig : protocols) &#123; doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; String name = protocolConfig.getName(); if (name == null || name.length() == 0) &#123; name = "dubbo"; //没有配置默认为dubbo &#125; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());//我的是2.6 map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; appendParameters(map, application); appendParameters(map, module); appendParameters(map, provider, Constants.DEFAULT_KEY); appendParameters(map, protocolConfig); appendParameters(map, this); //暴露服务指定了服务的方法，retry次数逻辑处理 if (methods != null &amp;&amp; methods.size() &gt; 0) &#123; for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); String retryKey = method.getName() + ".retry"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if ("false".equals(retryValue)) &#123; map.put(method.getName() + ".retries", "0"); &#125; &#125; List&lt;ArgumentConfig&gt; arguments = method.getArguments(); //方法的参数设置 if (arguments != null &amp;&amp; arguments.size() &gt; 0) &#123; for (ArgumentConfig argument : arguments) &#123; // convert argument type if (argument.getType() != null &amp;&amp; argument.getType().length() &gt; 0) &#123; Method[] methods = interfaceClass.getMethods(); // visit all methods if (methods != null &amp;&amp; methods.length &gt; 0) &#123; for (int i = 0; i &lt; methods.length; i++) &#123; String methodName = methods[i].getName(); // target the method, and get its signature if (methodName.equals(method.getName())) &#123; Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes(); // one callback in the method if (argument.getIndex() != -1) &#123; if (argtypes[argument.getIndex()].getName().equals(argument.getType())) &#123; appendParameters(map, argument, method.getName() + "." + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException("argument config error : the index attribute and type attribute not match :index :" + argument.getIndex() + ", type:" + argument.getType()); &#125; &#125; else &#123; // multiple callbacks in the method for (int j = 0; j &lt; argtypes.length; j++) &#123; Class&lt;?&gt; argclazz = argtypes[j]; if (argclazz.getName().equals(argument.getType())) &#123; appendParameters(map, argument, method.getName() + "." + j); if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) &#123; throw new IllegalArgumentException("argument config error : the index attribute and type attribute not match :index :" + argument.getIndex() + ", type:" + argument.getType()); &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; else if (argument.getIndex() != -1) &#123; appendParameters(map, argument, method.getName() + "." + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException("argument config must set index or type attribute.eg: &lt;dubbo:argument index='0' .../&gt; or &lt;dubbo:argument type=xxx .../&gt;"); &#125; &#125; &#125; &#125; // end of methods for &#125;//如果是泛化实现，generic=true，method=*表示任意方法 if (ProtocolUtils.isGeneric(generic)) &#123; map.put("generic", generic); map.put("methods", Constants.ANY_VALUE); &#125; else &#123; //方法的版本信息 String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put("revision", revision); &#125; String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) &#123; logger.warn("NO method found in service interface " + interfaceClass.getName()); map.put("methods", Constants.ANY_VALUE); &#125; else &#123; map.put("methods", StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), ",")); &#125; &#125; //令牌验证 if (!ConfigUtils.isEmpty(token)) &#123; if (ConfigUtils.isDefault(token)) &#123; map.put("token", UUID.randomUUID().toString()); &#125; else &#123; map.put("token", token); &#125; &#125; // injvm不需要暴露服务，标注notify=false if ("injvm".equals(protocolConfig.getName())) &#123; protocolConfig.setRegister(false); map.put("notify", "false"); &#125; // export service String contextPath = protocolConfig.getContextpath(); if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) &#123; contextPath = provider.getContextpath(); &#125; // 根据参数创建url对象 String host = this.findConfigedHosts(protocolConfig, registryURLs, map); Integer port = this.findConfigedPorts(protocolConfig, name, map); URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? "" : contextPath + "/") + path, map);// 如果url使用的协议存在扩展，调用对应的扩展来修改原url。目前扩展有override，absent if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .hasExtension(url.getProtocol())) &#123; url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .getExtension(url.getProtocol()).getConfigurator(url).configure(url); &#125; //如果我们没有配置scope ,scope为null，此时同时进行本地暴露和远程暴露 String scope = url.getParameter(Constants.SCOPE_KEY); //配置为none不暴露 if (!Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) &#123; //配置不是remote的情况下做本地暴露 (配置为remote，则表示只暴露远程服务) if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) &#123; exportLocal(url); //本地暴露 &#125; //如果配置不是local则暴露为远程服务.(配置为local，则表示只暴露本地服务) if (!Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope)) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Export dubbo service " + interfaceClass.getName() + " to url " + url); &#125; if (registryURLs != null &amp;&amp; registryURLs.size() &gt; 0) &#123; for (URL registryURL : registryURLs) &#123; url = url.addParameterIfAbsent("dynamic", registryURL.getParameter("dynamic")); URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) &#123; url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); &#125; if (logger.isInfoEnabled()) &#123; logger.info("Register dubbo service " + interfaceClass.getName() + " url " + url + " to registry " + registryURL); &#125; Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; else &#123; Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); &#125; &#125; &#125; this.urls.add(url); &#125; 总结整个服务暴露的流程: 首先会检查各种配置信息，填充各种属性，总之就是保证我在开始暴露服务之前，所有的东西都准备好了，并且是正确的。doExport（） 加载所有的注册中心，因为我们要暴露的服务需要注册到注册中心中去。doExportUrls（） 根据配置的协议和注册中心url分别进行导出。doExportUrlsFor1Protocol（） 根据配置筛入一些信息，重点在scope, 如果没有配置scope，即scope =null 时候，同时进行本地和远程暴露；如果scope = “none” 则不进行暴露；如果scope=”remote”只进行远程暴露；如果scope=”local”只进行本地暴露； 后面详细讲解不同暴露的流程。 本地暴露 远程暴露 netty的启动 zoopkeeper连接,注册与监听]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo集群容错(6)]]></title>
      <url>%2F2018%2F02%2F06%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-9%2F</url>
      <content type="text"><![CDATA[以 Invoker 为中心，从 Cluster, Directory, Router, LoadBalance，来解析各个接口。 dubbo提供4种负载均衡策略，根据其思想我做了一个简单的实现，见负载均衡算法。 LoadBalanceRandomLoadBalance随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobinLoadBalance轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActiveLoadBalance最少活跃调用数， 相同的活跃的随机选择，活跃数是指调用前后的计数差， 使慢的提供者收到更少的请求，因为越慢的提供者前后的计数差越大。 ConsistentHashLoadBalance一致性hash, 相同参数的请求总是发到同一个提供者，当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo集群容错(5)]]></title>
      <url>%2F2018%2F02%2F05%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-8%2F</url>
      <content type="text"><![CDATA[以 Invoker 为中心，从 Cluster, Directory, Router, LoadBalance，来解析各个接口。 RouterRouter 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等。下图是dubbo-admin的配置界面。 路由用于灰度发布等业务场景。根据官网描述，目前路由有3种：ConditionRouter, MockInvokersSelector, ScriptRouter。 ScriptRouter：脚本路由规则 支持 JDK 脚本引擎的所有脚本，比如：javascript, jruby, groovy 等，通过 type=javascript 参数设置脚本类型，缺省为 javascript。 MockInvokersSelector：一般dubbo-admin没有配置时候会走这条路线，在微服务架构之Dubbo集群容错(2)有介绍，一般的调用没有设置mock，会在getNormalInvokers方法中的hasMockProviders判断中就返回了；若果设置mock后，就将设置为mock的invoker返回。 ConditionRouter：即条件路由，主要根据dubbo管理控制台配置的路由规则来过滤相关的invoker, 当我们对路由规则点击启用的时候, 就会触发RegistryDirectory类之前提到的notify方法。在RegistryDirectory的notify方法中有这样的几行代码 1234567// routers if (routerUrls != null &amp;&amp; routerUrls.size() &gt; 0) &#123; List&lt;Router&gt; routers = toRouters(routerUrls); if (routers != null) &#123; // null - do nothing setRouters(routers); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142//url转化为routerprivate List&lt;Router&gt; toRouters(List&lt;URL&gt; urls) &#123; List&lt;Router&gt; routers = new ArrayList&lt;Router&gt;(); if (urls == null || urls.size() &lt; 1) &#123; return routers; &#125; if (urls != null &amp;&amp; urls.size() &gt; 0) &#123; for (URL url : urls) &#123; if (Constants.EMPTY_PROTOCOL.equals(url.getProtocol())) &#123; continue; &#125; String routerType = url.getParameter(Constants.ROUTER_KEY); if (routerType != null &amp;&amp; routerType.length() &gt; 0) &#123; url = url.setProtocol(routerType); &#125; try &#123; //ConditionRouterFactory 来获取 Router router = routerFactory.getRouter(url); if (!routers.contains(router)) routers.add(router); &#125; catch (Throwable t) &#123; logger.error("convert router url to router error, url: " + url, t); &#125; &#125; &#125; return routers; &#125;protected void setRouters(List&lt;Router&gt; routers) &#123; // copy list routers = routers == null ? new ArrayList&lt;Router&gt;() : new ArrayList&lt;Router&gt;(routers); // append url router String routerkey = url.getParameter(Constants.ROUTER_KEY); if (routerkey != null &amp;&amp; routerkey.length() &gt; 0) &#123; RouterFactory routerFactory = ExtensionLoader.getExtensionLoader(RouterFactory.class).getExtension(routerkey); routers.add(routerFactory.getRouter(url)); &#125; // append mock invoker selector routers.add(new MockInvokersSelector()); Collections.sort(routers); this.routers = routers; &#125; 123456789101112131415161718192021222324252627282930313233public class ConditionRouterFactory implements RouterFactory &#123; public static final String NAME = "condition"; public Router getRouter(URL url) &#123; return new ConditionRouter(url); &#125;&#125;public ConditionRouter(URL url) &#123; this.url = url; //对应dubbo-admin界面的优先级，默认为0 this.priority = url.getParameter(Constants.PRIORITY_KEY, 0); //当路由结果为空时，是否强制执行，如果不强制执行，路由结果为空的路由规则将自动失效，可不填，缺省为flase。 this.force = url.getParameter(Constants.FORCE_KEY, false); try &#123; String rule = url.getParameterAndDecoded(Constants.RULE_KEY); if (rule == null || rule.trim().length() == 0) &#123; throw new IllegalArgumentException("Illegal route rule!"); &#125; rule = rule.replace("consumer.", "").replace("provider.", ""); int i = rule.indexOf("=&gt;");//切开 String whenRule = i &lt; 0 ? null : rule.substring(0, i).trim(); String thenRule = i &lt; 0 ? rule.trim() : rule.substring(i + 2).trim(); Map&lt;String, MatchPair&gt; when = StringUtils.isBlank(whenRule) || "true".equals(whenRule) ? new HashMap&lt;String, MatchPair&gt;() : parseRule(whenRule); Map&lt;String, MatchPair&gt; then = StringUtils.isBlank(thenRule) || "false".equals(thenRule) ? null : parseRule(thenRule); // NOTE: It should be determined on the business level whether the `When condition` can be empty or not. this.whenCondition = when; this.thenCondition = then; &#125; catch (ParseException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; 其中如何理解ConditionRouter处理流程呢？首先我们要知道基于条件表达式的规则 1host = 10.20.153.10 =&gt; host = 10.20.153.11 规则： “=&gt;”之前的为消费者匹配条件，所有参数和消费者的URL进行对比，当消费者满足匹配条件时，对该消费者执行后面的过滤规则。“=&gt;”之后为提供者地址列表的过滤条件，所有参数和提供者的URL进行对比，消费者最终只拿到过滤后的地址列表。如果匹配条件为空，表示对所有消费方应用，如：=&gt; host != 10.20.153.11如果过滤条件为空，表示禁止访问，如：host = 10.20.153.10 =&gt; 白名单：host != 10.20.153.10,10.20.153.11 =&gt; 黑名单：host = 10.20.153.10,10.20.153.11 =&gt; 表达式： 参数支持：服务调用信息，如：method, argument 等 (暂不支持参数路由)URL本身的字段，如：protocol, host, port 等以及URL上的所有参数，如：application, organization 等 条件支持：等号”=”表示”匹配”，如：host = 10.20.153.10不等号”!=”表示”不匹配”，如：host != 10.20.153.10 值支持：以逗号”,”分隔多个值，如：host != 10.20.153.10,10.20.153.11以星号“”结尾，表示通配，如：host != 10.20.以美元符开头，表示引用消费者参数，如：host = $host 然后到了refreshInvoker(List invokerUrls) ，在这里面有toMethodInvokers方法，主要作用是将invokers列表转成与方法的映射关系，用到route方法 123456789101112private List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, String method) &#123; Invocation invocation = new RpcInvocation(method, new Class&lt;?&gt;[0], new Object[0]); List&lt;Router&gt; routers = getRouters(); if (routers != null) &#123; for (Router router : routers) &#123; if (router.getUrl() != null) &#123; invokers = router.route(invokers, getConsumerUrl(), invocation);//这里是ConditionRouter实现的。 &#125; &#125; &#125; return invokers; &#125; 12345678910111213141516171819202122232425262728293031323334//注意调用时候，这个url是 getConsumerUrl()，即消费者urlpublic &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation)throws RpcException &#123; if (invokers == null || invokers.size() == 0) &#123; return invokers; &#125; try &#123; //消费者与配置不匹配（配置为空，也意味着不匹配），就不用走后面提供者的过滤了 if (!matchWhen(url, invocation)) &#123; return invokers; &#125; List&lt;Invoker&lt;T&gt;&gt; result = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); //而提供者没有配置，则是黑名单 if (thenCondition == null) &#123; logger.warn("The current consumer in the service blacklist. consumer: " + NetUtils.getLocalHost() + ", service: " + url.getServiceKey()); return result; &#125; for (Invoker&lt;T&gt; invoker : invokers) &#123; //提供者过滤（消费者调用的url与提供者url匹配，就加入） if (matchThen(invoker.getUrl(), url)) &#123; result.add(invoker); &#125; &#125; if (result.size() &gt; 0) &#123; return result; &#125; else if (force) &#123; logger.warn("The route result is empty and force execute. consumer: " + NetUtils.getLocalHost() + ", service: " + url.getServiceKey() + ", router: " + url.getParameterAndDecoded(Constants.RULE_KEY)); return result; &#125; &#125; catch (Throwable t) &#123; logger.error("Failed to execute condition router rule: " + getUrl() + ", invokers: " + invokers + ", cause: " + t.getMessage(), t); &#125; //其他情况就返回所有的，也就是说针对条件路由，当经过某条路由规则路由后，没有一个符合规则的Provider，那么此次路由失败，会直接返回路由本条规则前的所有Provider，也就是相当于没有经过该路由的结果。 return invokers; &#125; 参考http://www.bubuko.com/infodetail-2316000.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo集群容错(4)]]></title>
      <url>%2F2018%2F01%2F31%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-7%2F</url>
      <content type="text"><![CDATA[以 Invoker 为中心，从 Cluster, Directory, Router, LoadBalance，来解析各个接口。 Directory目录服务Directory， 代表多个Invoker, 可以看成List,它的值可能是动态变化的比如注册中心推送变更。集群选择调用服务时通过目录服务找到所有服务。 Directory的接口定义 1234public interface Directory&lt;T&gt; extends Node &#123; Class&lt;T&gt; getInterface(); List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException;&#125; StaticDirectory静态目录服务,很明显是不会动态变化的，主要用于服务对多注册中心的引用。如何理解呢？假如我们配置了多注册中心 1234&lt;dubbo:registry id = "hangzhouRegistry" protocol="zookeeper" address="10.0.1.1:2181"/&gt;&lt;dubbo:registry id = "shanghaiRegistry" protocol="zookeeper" address="10.0.1.4:2181" default="false"/&gt;&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" cluster="failback" registry="hangzhouRegistry, shanghaiRegistry"/&gt;&lt;dubbo:reference id="demoService2" check="false" interface="com.alibaba.dubbo.demo.DemoService" cluster="failback"/&gt; 注意： 注册中心后面加上default=”false”是说默认情况下服务不被注册到该中心。上面配置中demoService显现的指定了2个注册中心，所以会被注册到2个注册中心，而demoService2是默认的，所以只会注册到hangzhouRegistry。 我们启动跟踪代码，发现StaticDirectory（如何知道StaticDirectory在哪里使用，可以先全局搜索，再打上断点） 在ReferenceConfig中createProxy使用 123456789101112131415161718192021222324252627private T createProxy(Map&lt;String, String&gt; map) &#123; ....... ....... ....... //多注册中心时候，urls &gt; 1的，比如上面配置 urls.size() == 2 if (urls.size() == 1) &#123; invoker = refprotocol.refer(interfaceClass, urls.get(0)); &#125; else &#123; List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) &#123; //将多个注册中心的invoker汇聚 invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; registryURL = url; // 使用最后的那个， 上面配置会选择10.0.38.4:2181 &#125; if (registryURL != null) &#123; // 有注册中心URL,只用AvailableCluster URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); //用StaticDirectory伪装成cluster的一个invoker invoker = cluster.join(new StaticDirectory(u, invokers)); &#125; else &#123; // 没有注册中心URL invoker = cluster.join(new StaticDirectory(invokers)); &#125; &#125;&#125; 123456public StaticDirectory(URL url, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Router&gt; routers) &#123; super(url == null &amp;&amp; invokers != null &amp;&amp; invokers.size() &gt; 0 ? invokers.get(0).getUrl() : url, routers); if (invokers == null || invokers.size() == 0) throw new IllegalArgumentException("invokers == null"); this.invokers = invokers; &#125; RegistryDirectory注册目录服务， 它的Invoker集合是从注册中心获取的， 它实现了NotifyListener接口，也是RegistryDirectory能根据注册中心动态变化的根源所在。 12345678910111213141516171819202122232425262728public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) &#123; if (forbidden) &#123; throw new RpcException(RpcException.FORBIDDEN_EXCEPTION, "Forbid consumer " + NetUtils.getLocalHost() + " access service " + getInterface().getName() + " from registry " + getUrl().getAddress() + " use dubbo version " + Version.getVersion() + ", Please check registry access list (whitelist/blacklist)."); &#125; List&lt;Invoker&lt;T&gt;&gt; invokers = null; Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // 本地引用 if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) &#123; String methodName = RpcUtils.getMethodName(invocation); Object[] args = RpcUtils.getArguments(invocation); if(args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) &#123; invokers = localMethodInvokerMap.get(methodName + "." + args[0]); // 可根据第一个参数枚举路由 &#125; if(invokers == null) &#123; invokers = localMethodInvokerMap.get(methodName); &#125; if(invokers == null) &#123; invokers = localMethodInvokerMap.get(Constants.ANY_VALUE); &#125; if(invokers == null) &#123; Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator(); if (iterator.hasNext()) &#123; invokers = iterator.next(); &#125; &#125; &#125; return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers; &#125; 我们看到重要的一行，在这里都是读它，那么在哪里写它的呢？就是在回调NotifyListener接口notify方法。 1Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; 123456789101112131415161718192021222324252627282930313233343536373839404142public synchronized void notify(List&lt;URL&gt; urls) &#123; //urls是服务提供者 List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;(); for (URL url : urls) &#123; //协议 会出现“dubbo”,"empty"，"override" ,"route" String protocol = url.getProtocol(); String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);//类型，比如：“providers”,"configurators" if (Constants.ROUTERS_CATEGORY.equals(category) //routers || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123; routerUrls.add(url); &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category)//configurators || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123; configuratorUrls.add(url); &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123;//providers invokerUrls.add(url); &#125; else &#123; logger.warn("Unsupported category " + category + " in notified url: " + url + " from registry " + getUrl().getAddress() + " to consumer " + NetUtils.getLocalHost()); &#125; &#125; // configurators if (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt; 0) &#123; this.configurators = toConfigurators(configuratorUrls); &#125; // routers if (routerUrls != null &amp;&amp; routerUrls.size() &gt; 0) &#123; List&lt;Router&gt; routers = toRouters(routerUrls); if (routers != null) &#123; // null - do nothing setRouters(routers); &#125; &#125; List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference // merge override parameters this.overrideDirectoryUrl = directoryUrl; if (localConfigurators != null &amp;&amp; localConfigurators.size() &gt; 0) &#123; for (Configurator configurator : localConfigurators) &#123; this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); &#125; &#125; // providers refreshInvoker(invokerUrls); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 根据invokerURL列表转换为invoker列表。转换规则如下： * 1.如果url已经被转换为invoker，则不在重新引用，直接从缓存中获取，注意如果url中任何一个参数变更也会重新引用 * 2.如果传入的invoker列表不为空，则表示最新的invoker列表 * 3.如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用。 * @param invokerUrls 传入的参数不能为null */private void refreshInvoker(List&lt;URL&gt; invokerUrls) &#123; if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123; this.forbidden = true;// 禁止访问 this.methodInvokerMap = null; // 置空列表 destroyAllInvokers(); // 关闭所有Invoker &#125; else &#123; this.forbidden = false; // 允许访问 Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls.size() == 0 &amp;&amp; this.cachedInvokerUrls != null) &#123; invokerUrls.addAll(this.cachedInvokerUrls); &#125; else &#123; this.cachedInvokerUrls = new HashSet&lt;URL&gt;(); this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比 &#125; if (invokerUrls.size() == 0) &#123; return; &#125; Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// 将URL列表转成Invoker列表 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表 // state change //如果计算错误，则不进行处理. if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) &#123; logger.error(new IllegalStateException("urls to invokers error .invokerUrls.size :" + invokerUrls.size() + ", invoker.size :0. urls :" + invokerUrls.toString())); return; &#125; this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; this.urlInvokerMap = newUrlInvokerMap; try &#123; destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // 关闭未使用的Invoker &#125; catch (Exception e) &#123; logger.warn("destroyUnusedInvokers error. ", e); &#125; &#125; &#125; 我们追溯发现RegistryDirectory的notify被AbstractRegistry的notify方法调用，而AbstractRegistry的notify方法在FailbackRegistry，ZookeeperRegistry，MulticastRegistry三者中使用，由于我们用的zookeeper，所以查看ZookeeperRegistry。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; String root = toRootPath(); ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; for (String child : currentChilds) &#123; child = URL.decode(child); if (! anyServices.contains(child)) &#123; anyServices.add(child); subscribe(url.setPath(child).addParameters(Constants.INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; &#125;); zkListener = listeners.get(listener); &#125; zkClient.create(root, false); List&lt;String&gt; services = zkClient.addChildListener(root, zkListener); if (services != null &amp;&amp; services.size() &gt; 0) &#123; for (String service : services) &#123; service = URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(Constants.INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; else &#123; List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); for (String path : toCategoriesPath(url)) &#123; ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener = listeners.get(listener); &#125; zkClient.create(path, false); List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); if (children != null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; notify(url, listener, urls);//重点 &#125; &#125; catch (Throwable e) &#123; throw new RpcException("Failed to subscribe " + url + " to zookeeper " + getUrl() + ", cause: " + e.getMessage(), e); &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo服务降级(1)]]></title>
      <url>%2F2018%2F01%2F22%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-6%2F</url>
      <content type="text"><![CDATA[dubbo提供了服务降级的策略，我们首先看一下mock机制的降级原理，下面我们从源码的角度分析其调用过程。 如何使用mock服务降级mock支持的配置大体分为2类，一类用于屏蔽，一类用于容错。可以通过dubbo-admin控制台下发配置。 这里我们只关注配置文件的使用。 屏蔽指的是消费方对该服务的方法调用都直接返回 null 值，不发起远程调用。mock= force:return+null ,这个不能在配置文件使用，通过控制台直接往注册中心写入该mock规则。 容错指的是消费方对该服务的方法调用在失败后，根据配置做不同的返回。 我这里就强调2种，一种是boolean值，默认的为false。如果配置为true，则缺省使用mock类名，即类名+Mock后缀，但该类要和暴露的服务路径相同，没有这个类，项目启动时会报Class Not Found 错误。 1&lt;dubbo:reference id = "test" interface="com.luckylau.api.service.PushRpcService" timeout="3000" version="1.0.0" mock="true"/&gt; 如上所示，我们配置了mock = true , 这时我们需要定义一个PushRpcServiceMock的类，它实现了PushRpcService接口，同时有一个默认的无参数构造函数（也可以不写，java会默认），注意这个类必须放在com.luckylau.api.service路径下，所以在本地代码要有这样的路径存在，专门为降级使用。 另外mock = “default”效果和mock=”true”一样。 这时候如果远程调用失败，就会访问PushRpcServiceMock类的返回。 另外一种是return null。 1&lt;dubbo:reference id = "test" interface="com.luckylau.api.service.PushRpcService" timeout="3000" version="1.0.0" mock="return null"/&gt; 这时候如果远程调用失败，就会直接返回null,不抛出异常。 源码解析首先是服务的引用过程，解决如何知道这个服务是mock的方式，ReferenceConfig的init()在执行ref = createProxy(map)之前有一步骤是checkStubAndMock，做了相关处理，包括如果配置mock = true但没有找到类名+Mock后缀，报Class Not Found 错误等。 然后是实际调用过程，我们跟踪一下源码（2.6版本），首先进入的是 123456789101112131415161718192021222324252627282930public Result invoke(Invocation invocation) throws RpcException &#123; Result result = null; //checkStubAndMock的内部逻辑来决定value的值 String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() == 0 || value.equalsIgnoreCase("false"))&#123; //no mock result = this.invoker.invoke(invocation); &#125; else if (value.startsWith("force")) &#123; if (logger.isWarnEnabled()) &#123; logger.info("force-mock: " + invocation.getMethodName() + " force-mock enabled , url : " + directory.getUrl()); &#125; //force:direct mock result = doMockInvoke(invocation, null); &#125; else &#123; //fail-mock try &#123; result = this.invoker.invoke(invocation); &#125;catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; else &#123; if (logger.isWarnEnabled()) &#123; logger.info("fail-mock: " + invocation.getMethodName() + " fail-mock enabled , url : " + directory.getUrl(), e); &#125; result = doMockInvoke(invocation, e); &#125; &#125; &#125; return result; &#125; 当我们配置mock = “default” ,mock = “true” ,mock = “return null” 时 1String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); value的值为default, true, return+null。它们会进入fail-mock的逻辑，如果调用失败之后，首先判断异常的类型，包括业务错误类型：接口实现类中的方法抛出的错误 ，和非业务错误类型：网络错误、超时错误、禁止访问错误、序列化错误及其他未知的错误。业务错误类型直接抛出，非业务错误类型进入关键的处理： 1result = doMockInvoke(invocation, e); 12345678910111213141516171819202122232425private Result doMockInvoke(Invocation invocation,RpcException e)&#123; Result result = null; Invoker&lt;T&gt; minvoker ; List&lt;Invoker&lt;T&gt;&gt; mockInvokers = selectMockInvoker(invocation); if (mockInvokers == null || mockInvokers.size() == 0)&#123; // minvoker = (Invoker&lt;T&gt;) new MockInvoker(directory.getUrl()); &#125; else &#123; minvoker = mockInvokers.get(0); &#125; try &#123; result = minvoker.invoke(invocation); &#125; catch (RpcException me) &#123; if (me.isBiz()) &#123; result = new RpcResult(me.getCause()); &#125; else &#123; throw new RpcException(me.getCode(), getMockExceptionMessage(e, me), me.getCause()); &#125;// &#125; catch (Throwable me) &#123; throw new RpcException(getMockExceptionMessage(e, me), me.getCause()); &#125; return result; &#125; 123456789101112131415161718192021222324252627 /** * 返回MockInvoker * 契约： * directory根据invocation中是否有Constants.INVOCATION_NEED_MOCK，来判断获取的是一个normal invoker 还是一个 mock invoker * 如果directorylist 返回多个mock invoker，只使用第一个invoker. * @param invocation * @return */ private List&lt;Invoker&lt;T&gt;&gt; selectMockInvoker(Invocation invocation) &#123; List&lt;Invoker&lt;T&gt;&gt; invokers = null; //TODO generic invoker？ if (invocation instanceof RpcInvocation) &#123; //存在隐含契约(虽然在接口声明中增加描述，但扩展性会存在问题.同时放在attachement中的做法需要改进 ((RpcInvocation) invocation).setAttachment(Constants.INVOCATION_NEED_MOCK, Boolean.TRUE.toString());//directory根据invocation中attachment是否有Constants.INVOCATION_NEED_MOCK，来判断获取的是normal invokers or mock invokers try &#123; invokers = directory.list(invocation); &#125; catch (RpcException e) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Exception when try to invoke mock. Get mock invokers error for service:" + directory.getUrl().getServiceInterface() + ", method:" + invocation.getMethodName() + ", will contruct a new mock with 'new MockInvoker()'.", e); &#125; &#125; &#125; return invokers; &#125; 我们单独分析配置mock = “true” 和 mock = “return null”的情况。此时用源码的demo。 首先看mock = “true” 的情况 1&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" mock="true"/&gt; 123456789101112package com.alibaba.dubbo.demo;/** * @author luckylau * @date 2018/1/24/024 13:41 */public class DemoServiceMock implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println("我是Demo Service 的 服务降级 "); return null; &#125;&#125; 在doMockInvoke中result = minvoker.invoke(invocation)非常重要，它的实现在com.alibaba.dubbo.rpc.support的MockInvoker类中，实现如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public Result invoke(Invocation invocation) throws RpcException &#123; String mock = getUrl().getParameter(invocation.getMethodName() + "." + Constants.MOCK_KEY); if (invocation instanceof RpcInvocation) &#123; ((RpcInvocation) invocation).setInvoker(this); &#125; if (StringUtils.isBlank(mock)) &#123; mock = getUrl().getParameter(Constants.MOCK_KEY); &#125; if (StringUtils.isBlank(mock)) &#123; throw new RpcException(new IllegalAccessException("mock can not be null. url :" + url)); &#125; mock = normallizeMock(URL.decode(mock));//关键点 处理 mock="true" "return null" if (Constants.RETURN_PREFIX.trim().equalsIgnoreCase(mock.trim())) &#123; RpcResult result = new RpcResult(); result.setValue(null); return result; &#125; else if (mock.startsWith(Constants.RETURN_PREFIX)) &#123; mock = mock.substring(Constants.RETURN_PREFIX.length()).trim(); mock = mock.replace('`', '"'); try &#123; Type[] returnTypes = RpcUtils.getReturnTypes(invocation); Object value = parseMockValue(mock, returnTypes); return new RpcResult(value); &#125; catch (Exception ew) &#123; throw new RpcException("mock return invoke error. method :" + invocation.getMethodName() + ", mock:" + mock + ", url: " + url, ew); &#125; &#125; else if (mock.startsWith(Constants.THROW_PREFIX)) &#123; mock = mock.substring(Constants.THROW_PREFIX.length()).trim(); mock = mock.replace('`', '"'); if (StringUtils.isBlank(mock)) &#123; throw new RpcException(" mocked exception for Service degradation. "); &#125; else &#123; // user customized class Throwable t = getThrowable(mock); throw new RpcException(RpcException.BIZ_EXCEPTION, t); &#125; &#125; else &#123; //impl mock mock ="true" 会走这里 try &#123; Invoker&lt;T&gt; invoker = getInvoker(mock); return invoker.invoke(invocation); &#125; catch (Throwable t) &#123; throw new RpcException("Failed to create mock implemention class " + mock, t); &#125; &#125;&#125;private String normallizeMock(String mock) &#123; if (mock == null || mock.trim().length() == 0) &#123; return mock; &#125; else if (ConfigUtils.isDefault(mock) || "fail".equalsIgnoreCase(mock.trim()) || "force".equalsIgnoreCase(mock.trim())) &#123; mock = url.getServiceInterface() + "Mock"; //拼接 &#125; if (mock.startsWith(Constants.FAIL_PREFIX)) &#123; mock = mock.substring(Constants.FAIL_PREFIX.length()).trim(); &#125; else if (mock.startsWith(Constants.FORCE_PREFIX)) &#123; mock = mock.substring(Constants.FORCE_PREFIX.length()).trim(); &#125; return mock;&#125; 回到mock = “true”配置时候，会走到这里，我们发现这里的invoker.invoke(invocation) ，调用的是AbstractProxyInvoker,最后会调用到我们定义的这个类DemoServiceMock。 123456789101112131415161718192021222324252627282930private Invoker&lt;T&gt; getInvoker(String mockService) &#123; // Invoker由反射生成，需要缓存生成的Invoker（否则效率低） Invoker&lt;T&gt; invoker = (Invoker&lt;T&gt;) mocks.get(mockService); if (invoker != null) &#123; return invoker; &#125; else &#123; Class&lt;T&gt; serviceType = (Class&lt;T&gt;) ReflectUtils.forName(url.getServiceInterface()); if (ConfigUtils.isDefault(mockService)) &#123; mockService = serviceType.getName() + "Mock"; &#125; // 创建mock类并判断mock类是否是原类的子类 Class&lt;?&gt; mockClass = ReflectUtils.forName(mockService); if (!serviceType.isAssignableFrom(mockClass)) &#123; throw new IllegalArgumentException("The mock implemention class " + mockClass.getName() + " not implement interface " + serviceType.getName()); &#125; try &#123; // 创建实例，并创建对应的代理 T mockObject = (T) mockClass.newInstance(); invoker = proxyFactory.getInvoker(mockObject, (Class&lt;T&gt;) serviceType, url); if (mocks.size() &lt; 10000) &#123; mocks.put(mockService, invoker); &#125; return invoker; &#125; catch (InstantiationException e) &#123; throw new IllegalStateException("No such empty constructor \"public " + mockClass.getSimpleName() + "()\" in mock implemention class " + mockClass.getName(), e); &#125; catch (IllegalAccessException e) &#123; throw new IllegalStateException(e); &#125; &#125; &#125; 123456789101112package com.alibaba.dubbo.rpc.proxy;public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()));//里面的doInvoke来自JavassistProxyFactory &#125; catch (InvocationTargetException e) &#123; return new RpcResult(e.getTargetException()); &#125; catch (Throwable e) &#123; throw new RpcException("Failed to invoke remote proxy method " + invocation.getMethodName() + " to " + getUrl() + ", cause: " + e.getMessage(), e); &#125;&#125;protected abstract Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable; 然后mock = “return null” 的情况 在doMockInvoke中result = minvoker.invoke(invocation)非常重要,而mock = “return null” ，它执行到如下String mock = “return+null” 然后执行到下面，返回null]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo集群容错(3)]]></title>
      <url>%2F2018%2F01%2F19%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-5%2F</url>
      <content type="text"><![CDATA[以 Invoker 为中心，从 Cluster, Directory, Router, LoadBalance，来解析各个接口。 ClusterCluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。 MergeableCluster官方解释：按组合并返回结果 ，比如菜单服务，接口一样，但有多种实现，用group区分，现在消费方需从每种group中调用一次返回结果，合并结果返回，这样就可以实现聚合菜单项。 配置使用： 服务方： 12&lt;dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService1" group="gro_1"/&gt;&lt;dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService2" group="gro_2"/&gt; 消费方： 1&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" group="gro_1,gro_2" merger="true"/&gt; 源码分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public Result invoke(final Invocation invocation) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; invokers = directory.list(invocation); String merger = getUrl().getMethodParameter(invocation.getMethodName(), Constants.MERGER_KEY); //如果merger = null 时候，然后从其中一个组中返回即可 if (ConfigUtils.isEmpty(merger)) &#123; for (final Invoker&lt;T&gt; invoker : invokers) &#123; if (invoker.isAvailable()) &#123; return invoker.invoke(invocation); &#125; &#125; return invokers.iterator().next().invoke(invocation); &#125; Class&lt;?&gt; returnType;//获取调用方法的返回类型 try &#123; returnType = getInterface().getMethod( invocation.getMethodName(), invocation.getParameterTypes()).getReturnType(); &#125; catch (NoSuchMethodException e) &#123; returnType = null; &#125; Map&lt;String, Future&lt;Result&gt;&gt; results = new HashMap&lt;String, Future&lt;Result&gt;&gt;(); for (final Invoker&lt;T&gt; invoker : invokers) &#123; Future&lt;Result&gt; future = executor.submit(new Callable&lt;Result&gt;() &#123; public Result call() throws Exception &#123; return invoker.invoke(new RpcInvocation(invocation, invoker)); &#125; &#125;); results.put(invoker.getUrl().getServiceKey(), future); &#125;//异步调用 Object result = null; List&lt;Result&gt; resultList = new ArrayList&lt;Result&gt;(results.size()); int timeout = getUrl().getMethodParameter(invocation.getMethodName(), Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT);//获取调用超时时间 for (Map.Entry&lt;String, Future&lt;Result&gt;&gt; entry : results.entrySet()) &#123; Future&lt;Result&gt; future = entry.getValue(); try &#123; Result r = future.get(timeout, TimeUnit.MILLISECONDS); if (r.hasException()) &#123; log.error(new StringBuilder(32).append("Invoke ") .append(getGroupDescFromServiceKey(entry.getKey())) .append(" failed: ") .append(r.getException().getMessage()).toString(), r.getException()); &#125; else &#123; resultList.add(r); &#125; &#125; catch (Exception e) &#123; throw new RpcException(new StringBuilder(32) .append("Failed to invoke service ") .append(entry.getKey()) .append(": ") .append(e.getMessage()).toString(), e); &#125; &#125;//在超时间内获取调用结果，如果失败了，记录到日志中 if (resultList.size() == 0) &#123; return new RpcResult((Object) null);//如果返回为空，就直接返回了 &#125; else if (resultList.size() == 1) &#123; return resultList.iterator().next();//如果就一个，就返回它即可 &#125; if (returnType == void.class) &#123; return new RpcResult((Object) null);//如果发现是void类型 返回为null &#125; if (merger.startsWith(".")) &#123; //当配置merger =".addAll" merger = merger.substring(1); Method method; try &#123; //获取结果类型名字为merger的方法，例如 returnType是String merger指定为.compareTo method = returnType.getMethod(merger, returnType);//获得对象所声明的公开方法 &#125; catch (NoSuchMethodException e) &#123; throw new RpcException(new StringBuilder(32) .append("Can not merge result because missing method [ ") .append(merger) .append(" ] in class [ ") .append(returnType.getClass().getName()) .append(" ]") .toString()); &#125; if (method != null) &#123; //修改为公共访问 if (!Modifier.isPublic(method.getModifiers())) &#123; method.setAccessible(true); &#125; result = resultList.remove(0).getValue(); try &#123; if (method.getReturnType() != void.class &amp;&amp; method.getReturnType().isAssignableFrom(result.getClass())) &#123; for (Result r : resultList) &#123; result = method.invoke(result, r.getValue()); &#125; &#125; else &#123; for (Result r : resultList) &#123; method.invoke(result, r.getValue()); &#125; &#125; &#125; catch (Exception e) &#123; throw new RpcException( new StringBuilder(32) .append("Can not merge result: ") .append(e.getMessage()).toString(), e); &#125; &#125; else &#123; throw new RpcException( new StringBuilder(32) .append("Can not merge result because missing method [ ") .append(merger) .append(" ] in class [ ") .append(returnType.getClass().getName()) .append(" ]") .toString()); &#125; &#125; else &#123; Merger resultMerger; //merger = "true" if (ConfigUtils.isDefault(merger)) &#123; resultMerger = MergerFactory.getMerger(returnType);//根据类型获取相应的Merger &#125; else &#123; resultMerger = ExtensionLoader.getExtensionLoader(Merger.class).getExtension(merger);//自定义的 &#125; if (resultMerger != null) &#123; List&lt;Object&gt; rets = new ArrayList&lt;Object&gt;(resultList.size()); for (Result r : resultList) &#123; rets.add(r.getValue()); &#125; result = resultMerger.merge( rets.toArray((Object[]) Array.newInstance(returnType, 0)));//合并结果 &#125; else &#123; throw new RpcException("There is no merger to merge result."); &#125; &#125; return new RpcResult(result); &#125; AvailableCluster根据字面意思就是可用的。主要用于服务注册时候，生产代理对象。后面会讲到如何向注册中心注册，并获取服务端相应的信息，当然也可以配置使用: 1&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.demo.DemoService" cluster="available"/&gt; 源码很简单： 1234567891011121314public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return new AbstractClusterInvoker&lt;T&gt;(directory) &#123; public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; for (Invoker&lt;T&gt; invoker : invokers) &#123; if (invoker.isAvailable()) &#123; return invoker.invoke(invocation); &#125; &#125; throw new RpcException("No provider available in " + invokers); &#125; &#125;;&#125; ForkingCluster并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数（官方虽然这么说，但是还是不知道如何配置）。从代码看默认就是2个 源码分析： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; //如果invokers == null || invokers.size() == 0 抛异常 checkInvokers(invokers, invocation); final List&lt;Invoker&lt;T&gt;&gt; selected; //默认forks = 2 final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS); final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (forks &lt;= 0 || forks &gt;= invokers.size()) &#123; selected = invokers; //全选 &#125; else &#123; selected = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); for (int i = 0; i &lt; forks; i++) &#123; // TODO. Add some comment here, refer chinese version for more details. Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected); if (!selected.contains(invoker)) &#123;//Avoid add the same invoker several times. selected.add(invoker); &#125; &#125; &#125; RpcContext.getContext().setInvokers((List) selected); final AtomicInteger count = new AtomicInteger(); final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;Object&gt;(); for (final Invoker&lt;T&gt; invoker : selected) &#123; executor.execute(new Runnable() &#123; public void run() &#123; try &#123; Result result = invoker.invoke(invocation); ref.offer(result); &#125; catch (Throwable e) &#123; int value = count.incrementAndGet(); if (value &gt;= selected.size()) &#123; ref.offer(e); &#125; &#125; &#125; &#125;); &#125; try &#123; Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS);//取队列头数据返回即可 if (ret instanceof Throwable) &#123; Throwable e = (Throwable) ret; throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, "Failed to forking invoke provider " + selected + ", but no luck to perform the invocation. Last error is: " + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125; return (Result) ret; &#125; catch (InterruptedException e) &#123; throw new RpcException("Failed to forking invoke provider " + selected + ", but no luck to perform the invocation. Last error is: " + e.getMessage(), e); &#125; &#125;&#125; FailfastCluster快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 123456789101112public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; checkInvokers(invokers, invocation);//同样先检测能不能用 Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null);//直接选中一个，进行调用 try &#123; return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; if (e instanceof RpcException &amp;&amp; ((RpcException) e).isBiz()) &#123; // biz exception. throw (RpcException) e; &#125; throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, "Failfast invoke providers " + invoker.getUrl() + " " + loadbalance.getClass().getSimpleName() + " select from all providers " + invokers + " for service " + getInterface().getName() + " method " + invocation.getMethodName() + " on consumer " + NetUtils.getLocalHost() + " use dubbo version " + Version.getVersion() + ", but no luck to perform the invocation. Last error is: " + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125;&#125; FailoverCluster失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。默认配置，详情见微服务架构之Dubbo集群容错(2) FailbackCluster失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 123456789101112protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; checkInvokers(invokers, invocation); Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error("Failback to invoke method " + invocation.getMethodName() + ", wait for retry in background. Ignored exception: " + e.getMessage() + ", ", e); addFailed(invocation, this); //关键点，我们看看这个代码 return new RpcResult(); // ignore &#125; &#125; 1234567891011121314151617181920private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?&gt; router) &#123; if (retryFuture == null) &#123; synchronized (this) &#123; if (retryFuture == null) &#123; retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // collect retry statistics try &#123; retryFailed(); // 重试 &#125; catch (Throwable t) &#123; // Defensive fault tolerance logger.error("Unexpected error occur at collect statistic", t); &#125; &#125; &#125;, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS); &#125; &#125; &#125; failed.put(invocation, router); &#125; 12345678910111213141516void retryFailed() &#123; if (failed.size() == 0) &#123; return; &#125; for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; entry : new HashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;( failed).entrySet()) &#123; Invocation invocation = entry.getKey(); Invoker&lt;?&gt; invoker = entry.getValue(); try &#123; invoker.invoke(invocation); failed.remove(invocation); &#125; catch (Throwable e) &#123; logger.error("Failed retry to invoke method " + invocation.getMethodName() + ", waiting again.", e); &#125; &#125; &#125; FailsafeCluster失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 12345678910public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; checkInvokers(invokers, invocation); Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error("Failsafe ignore exception: " + e.getMessage(), e); return new RpcResult(); // ignore &#125; &#125; BroadcastCluster广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 123456789101112131415161718192021public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; checkInvokers(invokers, invocation);//同样检测invokers == null 或 inovokers.size() == 0 RpcContext.getContext().setInvokers((List) invokers); RpcException exception = null; Result result = null; for (Invoker&lt;T&gt; invoker : invokers) &#123; try &#123; result = invoker.invoke(invocation); //逐一调用 &#125; catch (RpcException e) &#123; exception = e; logger.warn(e.getMessage(), e); &#125; catch (Throwable e) &#123; exception = new RpcException(e.getMessage(), e); logger.warn(e.getMessage(), e); &#125; &#125; if (exception != null) &#123; throw exception; &#125; return result; &#125; 参考：https://www.jianshu.com/u/f7daa458b874]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo集群容错(2)]]></title>
      <url>%2F2018%2F01%2F17%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-4%2F</url>
      <content type="text"><![CDATA[我们首先看看Dubbo远程调用的执行时序图 首先进入的是dubbo-rpc模块 InvokerInvocationHandler123456789101112131415161718package com.alibaba.dubbo.rpc.proxy;public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(invoker, args); &#125; if ("toString".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.toString(); &#125; if ("hashCode".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.hashCode(); &#125; if ("equals".equals(methodName) &amp;&amp; parameterTypes.length == 1) &#123; return invoker.equals(args[0]); &#125; return invoker.invoke(new RpcInvocation(method, args)).recreate(); //重点 &#125; 其中最后一行是重点 1return invoker.invoke(new RpcInvocation(method, args)).recreate(); invoker 是定义的接口，它继承了Node接口，详解见微服务架构之Dubbo集群容错(3)。而这个invoker的实现是MockClusterInvoker类。 然后是dubbo-cluster模块 MockClusterInvoker123456789101112131415161718192021222324252627282930package com.alibaba.dubbo.rpc.cluster.support.wrapper;public Result invoke(Invocation invocation) throws RpcException &#123; Result result = null; String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() == 0 || value.equalsIgnoreCase("false"))&#123; //no mock result = this.invoker.invoke(invocation); &#125; else if (value.startsWith("force")) &#123; if (logger.isWarnEnabled()) &#123; logger.info("force-mock: " + invocation.getMethodName() + " force-mock enabled , url : " + directory.getUrl()); &#125; //force:direct mock result = doMockInvoke(invocation, null); &#125; else &#123; //fail-mock try &#123; result = this.invoker.invoke(invocation); &#125;catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; else &#123; if (logger.isWarnEnabled()) &#123; logger.info("fail-mock: " + invocation.getMethodName() + " fail-mock enabled , url : " + directory.getUrl(), e); &#125; result = doMockInvoke(invocation, e); &#125; &#125; &#125; return result; &#125; 首先是检测是否配置了mock模式， mock模式参考微服务架构之Dubbo服务降级。我们这个流程没有配置mock模式，所以会执行 result = this.invoker.invoke(invocation)，调用的就是AbstractClusterInvoker类的实现。 AbstractClusterInvoker12345678910111213141516public Result invoke(final Invocation invocation) throws RpcException &#123; checkWheatherDestoried(); LoadBalance loadbalance; List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; //如果存在地址信息，则根据地址中的配置加载LoadBalance，如果没有配置，默认是random loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; //没有，使用默认random loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; //如果是异步的话需要加入相应的信息 RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); //根据地址及负载均衡策略发起调用 return doInvoke(invocation, invokers, loadbalance); &#125; 其中 1List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); 是重点，它的实现来自AbstractDirectory类。 AbstractDirectory1234567891011121314151617181920package com.alibaba.dubbo.rpc.cluster.directory;public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; if (destroyed)&#123; throw new RpcException("Directory already destroyed .url: "+ getUrl()); &#125; List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); List&lt;Router&gt; localRouters = this.routers; // local reference if (localRouters != null &amp;&amp; localRouters.size() &gt; 0) &#123; for (Router router: localRouters)&#123; try &#123; if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) &#123; invokers = router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; catch (Throwable t) &#123; logger.error("Failed to execute router: " + getUrl() + ", cause: " + t.getMessage(), t); &#125; &#125; &#125; return invokers; &#125; 其中 1List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); 是重点，对于doList抽象方法目前有2种实现，RegistryDirectory和StaticDirectory。关于这些我们会在微服务架构之Dubbo集群容错(3)中讲解。下面展示的是常用的RegistryDirectory类的实现。 RegistryDirectory1234567891011121314151617181920212223242526272829package com.alibaba.dubbo.registry.integration;public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) &#123; if (forbidden) &#123; throw new RpcException(RpcException.FORBIDDEN_EXCEPTION, "Forbid consumer " + NetUtils.getLocalHost() + " access service " + getInterface().getName() + " from registry " + getUrl().getAddress() + " use dubbo version " + Version.getVersion() + ", Please check registry access list (whitelist/blacklist)."); &#125; List&lt;Invoker&lt;T&gt;&gt; invokers = null; Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // 本地引用 if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) &#123; String methodName = RpcUtils.getMethodName(invocation); Object[] args = RpcUtils.getArguments(invocation); if(args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) &#123; invokers = localMethodInvokerMap.get(methodName + "." + args[0]); // 可根据第一个参数枚举路由 &#125; if(invokers == null) &#123; invokers = localMethodInvokerMap.get(methodName); &#125; if(invokers == null) &#123; invokers = localMethodInvokerMap.get(Constants.ANY_VALUE); &#125; if(invokers == null) &#123; Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator(); if (iterator.hasNext()) &#123; invokers = iterator.next(); &#125; &#125; &#125; return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers; &#125; 然后将invokers返回，我们回到AbstractDirectory类，获得到invokers之后，就是路由了。 1invokers = router.route(invokers, getConsumerUrl(), invocation); 这个是重点，这个route接口有3个是实现，ConditionRouter,MockInvokersSelector,ScriptRouter ，详细见微服务架构之Dubbo集群容错(3)。MockInvokersSelector类在这里是关注重点。 MockInvokersSelector12345678910111213141516171819202122232425262728package com.alibaba.dubbo.rpc.cluster.router;public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(final List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, final Invocation invocation) throws RpcException &#123; if (invocation.getAttachments() == null) &#123; return getNormalInvokers(invokers); &#125; else &#123; String value = invocation.getAttachments().get(Constants.INVOCATION_NEED_MOCK); if (value == null) return getNormalInvokers(invokers); else if (Boolean.TRUE.toString().equalsIgnoreCase(value))&#123; return getMockedInvokers(invokers); &#125; &#125; return invokers; &#125; private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; getNormalInvokers(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; if (!hasMockProviders(invokers)) &#123; return invokers; &#125; else &#123; List&lt;Invoker&lt;T&gt;&gt; sInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(invokers.size()); for (Invoker&lt;T&gt; invoker : invokers) &#123; if (!invoker.getUrl().getProtocol().equals(Constants.MOCK_PROTOCOL)) &#123; sInvokers.add(invoker); &#125; &#125; return sInvokers; &#125; &#125; 一般的调用没有设置mock，会在getNormalInvokers方法中的hasMockProviders判断中就返回了。 好了，这个时候路由也结束了，过程回到AbstractClusterInvoker类。 12//根据地址及负载均衡策略发起调用return doInvoke(invocation, invokers, loadbalance); 根据官网的描述，在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。我们看一下继承AbstractClusterInvoker类的FailoverClusterInvoker。 FailoverClusterInvoker1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.alibaba.dubbo.rpc.cluster.support;@SuppressWarnings(&#123; "unchecked", "rawtypes" &#125;) public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; checkInvokers(copyinvokers, invocation); int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1;//重试次数 if (len &lt;= 0) &#123; len = 1; &#125; // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; //重试时，进行重新选择，避免重试时invoker列表已发生变化. //注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers = list(invocation); //重新检查一下 checkInvokers(copyinvokers, invocation); &#125; Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List)invoked); try &#123; Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn("Although retry the method " + invocation.getMethodName() + " in the service " + getInterface().getName() + " was successful by the provider " + invoker.getUrl().getAddress() + ", but there have been failed providers " + providers + " (" + providers.size() + "/" + copyinvokers.size() + ") from the registry " + directory.getUrl().getAddress() + " on the consumer " + NetUtils.getLocalHost() + " using the dubbo version " + Version.getVersion() + ". Last error is: " + le.getMessage(), le); &#125; return result; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; // biz exception. throw e; &#125; le = e; &#125; catch (Throwable e) &#123; le = new RpcException(e.getMessage(), e); &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(le != null ? le.getCode() : 0, "Failed to invoke the method " + invocation.getMethodName() + " in the service " + getInterface().getName() + ". Tried " + len + " times of the providers " + providers + " (" + providers.size() + "/" + copyinvokers.size() + ") from the registry " + directory.getUrl().getAddress() + " on the consumer " + NetUtils.getLocalHost() + " using the dubbo version " + Version.getVersion() + ". Last error is: " + (le != null ? le.getMessage() : ""), le != null &amp;&amp; le.getCause() != null ? le.getCause() : le); &#125; 首先获取调用方法的重试次数，然后进入for循环，重要的是 1Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); 它在抽象类AbstractClusterInvoker中已经实现 12345678910111213141516171819202122232425262728293031323334353637/** * 使用loadbalance选择invoker.&lt;/br&gt; * a)先lb选择，如果在selected列表中 或者 不可用且做检验时，进入下一步(重选),否则直接返回 * b)重选验证规则：selected &gt; available .保证重选出的结果尽量不在select中，并且是可用的 * * @param availablecheck 如果设置true，在选择的时候先选invoker.available == true * @param selected 已选过的invoker.注意：输入保证不重复 * */ protected Invoker&lt;T&gt; select(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers == null || invokers.size() == 0) return null; String methodName = invocation == null ? "" : invocation.getMethodName(); //是否启用sticky 粘性连接，让客户端总是连接同一提供者 boolean sticky = invokers.get(0).getUrl().getMethodParameter(methodName,Constants.CLUSTER_STICKY_KEY, Constants.DEFAULT_CLUSTER_STICKY) ; &#123; //ignore overloaded method //可选提供者列表已不包含上次的stickyInvoker，设置为null if ( stickyInvoker != null &amp;&amp; !invokers.contains(stickyInvoker) )&#123; stickyInvoker = null; &#125; //ignore cucurrent problem //stickyInvoker不为null,并且没在已选列表中，返回上次的服务提供者stickyInvoker，但使用之前进行强制校验可达性。 //由于stickyInvoker不能包含在selected列表中，通过代码看，可以得知forking和failover(retries != 0)集群策略，用不了sticky属性 if (sticky &amp;&amp; stickyInvoker != null &amp;&amp; (selected == null || !selected.contains(stickyInvoker)))&#123; if (availablecheck &amp;&amp; stickyInvoker.isAvailable())&#123; return stickyInvoker; &#125; &#125; &#125; Invoker&lt;T&gt; invoker = doselect(loadbalance, invocation, invokers, selected); if (sticky)&#123; stickyInvoker = invoker; &#125; return invoker; &#125; 我们发现首先是校验是否配置了sticky， sticky代表粘滞连接，粘滞连接⽤于有状态服务， 尽可能让客户端总是向同⼀提供者发起调⽤， 除⾮该提供者挂了， 再连另⼀台。粘滞连接将⾃动开启延迟连接， 以减少⻓连接数。配置如下： 1&lt;dubbo:protocol name="dubbo" sticky="true" /&gt; 然后最重要的是 1Invoker&lt;T&gt; invoker = doselect(loadbalance, invocation, invokers, selected); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889private Invoker&lt;T&gt; doselect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers == null || invokers.size() == 0) return null; if (invokers.size() == 1) return invokers.get(0); // 如果只有两个invoker，退化成轮循 if (invokers.size() == 2 &amp;&amp; selected != null &amp;&amp; selected.size() &gt; 0) &#123; return selected.get(0) == invokers.get(0) ? invokers.get(1) : invokers.get(0); &#125; Invoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation); //如果 selected中包含（优先判断） 或者 不可用&amp;&amp;availablecheck=true 则重试(这个是针对sticky配置的) if( (selected != null &amp;&amp; selected.contains(invoker)) ||(!invoker.isAvailable() &amp;&amp; getUrl()!=null &amp;&amp; availablecheck))&#123; try&#123; Invoker&lt;T&gt; rinvoker = reselect(loadbalance, invocation, invokers, selected, availablecheck); if(rinvoker != null)&#123; invoker = rinvoker; &#125;else&#123; //看下第一次选的位置，如果不是最后，选+1位置. int index = invokers.indexOf(invoker); try&#123; //最后在避免碰撞 invoker = index &lt;invokers.size()-1?invokers.get(index+1) :invoker; &#125;catch (Exception e) &#123; logger.warn(e.getMessage()+" may because invokers list dynamic change, ignore.",e); &#125; &#125; &#125;catch (Throwable t)&#123; logger.error("clustor relselect fail reason is :"+t.getMessage() +" if can not slove ,you can set cluster.availablecheck=false in url",t); &#125; &#125; return invoker; &#125; /** * 重选，先从非selected的列表中选择，没有在从selected列表中选择. * @param loadbalance * @param invocation * @param invokers * @param selected * @return * @throws RpcException */ private Invoker&lt;T&gt; reselect(LoadBalance loadbalance,Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected ,boolean availablecheck) throws RpcException &#123; //预先分配一个，这个列表是一定会用到的. List&lt;Invoker&lt;T&gt;&gt; reselectInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(invokers.size()&gt;1?(invokers.size()-1):invokers.size()); //先从非select中选 if( availablecheck )&#123; //选isAvailable 的非select for(Invoker&lt;T&gt; invoker : invokers)&#123; if(invoker.isAvailable())&#123; if(selected ==null || !selected.contains(invoker))&#123; reselectInvokers.add(invoker); &#125; &#125; &#125; if(reselectInvokers.size()&gt;0)&#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; &#125;else&#123; //选全部非select for(Invoker&lt;T&gt; invoker : invokers)&#123; if(selected ==null || !selected.contains(invoker))&#123; reselectInvokers.add(invoker); &#125; &#125; if(reselectInvokers.size()&gt;0)&#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; &#125; //最后从select中选可用的. &#123; if(selected != null)&#123; for(Invoker&lt;T&gt; invoker : selected)&#123; if((invoker.isAvailable()) //优先选available &amp;&amp; !reselectInvokers.contains(invoker))&#123; reselectInvokers.add(invoker); &#125; &#125; &#125; if(reselectInvokers.size()&gt;0)&#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; &#125; return null; &#125; 其中重点是 1Invoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation); 包括在后面的reselect时候，也会用到loadbalance.select方法。其实现是AbstractLoadBalance抽象类。 AbstractLoadBalance12345678package com.alibaba.dubbo.rpc.cluster.loadbalance;public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; if (invokers == null || invokers.size() == 0) return null; if (invokers.size() == 1) return invokers.get(0); return doSelect(invokers, url, invocation); &#125; 我们看到经过简单的处理之后，doSelect(invokers, url, invocation)变为重点，它是个抽象方法，有四种实现，分别是RoundRobinLoadBalance，RandomLoadBalance，LeastActiveLoadBalance，ConsistentHashLoadBalance。默认情况是 RandomLoadBalance。 RandomLoadBalance123456789101112131415161718192021222324252627package com.alibaba.dubbo.rpc.cluster.loadbalance;protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; int length = invokers.size(); // 总个数 int totalWeight = 0; // 总权重 boolean sameWeight = true; // 权重是否都一样 for (int i = 0; i &lt; length; i++) &#123; int weight = getWeight(invokers.get(i), invocation); totalWeight += weight; // 累计总权重 if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) &#123; sameWeight = false; // 计算所有权重是否一样 &#125; &#125; if (totalWeight &gt; 0 &amp;&amp; ! sameWeight) &#123; // 如果权重不相同且权重大于0则按总权重数随机 int offset = random.nextInt(totalWeight); // 并确定随机值落在哪个片断上 for (int i = 0; i &lt; length; i++) &#123; offset -= getWeight(invokers.get(i), invocation); if (offset &lt; 0) &#123; return invokers.get(i); &#125; &#125; &#125; // 如果权重相同或权重为0则均等随机 return invokers.get(random.nextInt(length)); &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo基础知识]]></title>
      <url>%2F2018%2F01%2F12%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-3%2F</url>
      <content type="text"><![CDATA[在了解Dubbo时候，需要一些java基础知识和其他相关技术知识，方便理解和开发。 JAVA相关SPI的原理融合Spring动态代理JDK的动态代理 CGLIB的动态代理 javassist的动态代理 Netty相关Zookeeper相关问与答]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo集群容错(1)]]></title>
      <url>%2F2018%2F01%2F11%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-2%2F</url>
      <content type="text"><![CDATA[本篇从大的概念上来介绍集群容错，后续篇章从源码角度解析。 什么是集群容错当我们使用Dubbo的集群环境，会因为某些原因导致服务调用失败的情况，Dubbo提供了多种容错方案，缺省为failover重试。 各节点关系： 这里的 Invoker 是 Provider 的一个可调用 Service 的抽象，Invoker 封装了 Provider 地址及 Service 接口信息。 Directory 代表多个 Invoker，可以把它看成 List ，但与 List 不同的是，它的值可能是动态变化的，比如注册中心推送变更。 Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。 Router 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等。 LoadBalance 负责从多个 Invoker 中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选。 如何配置使用首先看看dubbo目前提供哪些集群解决方案 Feature 优点 缺点 实现类 Failover Cluster 失败自动切换，当出现失败，重试其它服务器，通常用于读操作（推荐使用） 重试会带来更长延迟 FailoverClusterInvoker Failfast Cluster 快速失败，只发起一次调用，失败立即报错,通常用于非幂等性的写操作 如果有机器正在重启，可能会出现调用失败 FailfastClusterInvoker Failsafe Cluster 失败安全，出现异常时，直接忽略，通常用于写入审计日志等操作 调用信息丢失 FailsafeClusterInvoker Failback Cluster 失败自动恢复，后台记录失败请求，定时重发，通常用于消息通知操作 不可靠，重启丢失 FailbackClusterInvoker Forking Cluster 并行调用多个服务器，只要一个成功即返回，通常用于实时性要求较高的读操作 需要浪费更多服务资源 ForkingClusterInvoker Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错，通常用于更新提供方本地状态 速度慢，任意一台报错则报错 BroadcastClusterInvoker failover集群模式: 默认，但是可以配置重试次数 12345&lt;dubbo:service cluster="failover" retries="2" /&gt;&lt;dubbo:reference cluster="failover" retries="2" /&gt;&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; failfast集群模式： 12345&lt;dubbo:service cluster="failfast" /&gt;&lt;dubbo:reference cluster="failfast" /&gt;等价于&lt;dubbo:service cluster="failover" retries="0" /&gt;&lt;dubbo:reference cluster="failover" retries="0" /&gt; failback集群模式： 12&lt;dubbo:service cluster="failback" /&gt;&lt;dubbo:reference cluster="failback" /&gt; forking集群模式： 通过forks=”2”来设置最大并行数（目前还真不知道如何配置） 12&lt;dubbo:service cluster="forking" /&gt;&lt;dubbo:reference cluster="forking" /&gt; 源码解析模块 从官方的介绍我们就很清楚cluster 的设计 ，我们以 Invoker 为中心，从 Cluster, Directory, Router, LoadBalance，来解析各个接口。 directory router loadbalance cluster 参考https://www.gitbook.com/book/dubbo/dubbo-user-book https://www.gitbook.com/book/dubbo/dubbo-dev-book]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微服务架构之Dubbo简介]]></title>
      <url>%2F2018%2F01%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B9%8BDubbo-1%2F</url>
      <content type="text"><![CDATA[什么是Dubbo​ Dubbo是阿里巴巴提供的开源的SOA服务化治理的技术框架。它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。 除了提供服务之外，它还提供了负载均衡，监控中心和调度中心。 下图展示了它涉及的服务治理： ​ 在大规模服务化之前，应用可能只是通过 RMI 或 Hessian 等工具，简单的暴露和引用远程服务，通过配置服务的URL地址进行调用，通过 F5 等硬件进行负载均衡。当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。 此时需要一个服务注册中心，动态的注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和 Failover，降低对 F5 硬件负载均衡器的依赖，也能减少部分成本。 如何使用DubboDubbo的架构 节点角色说明： Provider: 暴露服务的服务提供方。Consumer: 调用远程服务的服务消费方。Registry: 服务注册与发现的注册中心。Monitor: 统计服务的调用次调和调用时间的监控中心。Container: 服务运行容器。 调用关系说明： 服务容器负责启动，加载，运行服务提供者。服务提供者在启动时，向注册中心注册自己提供的服务。服务消费者在启动时，向注册中心订阅自己所需的服务。注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 我们从上面的架构可以看出，使用dubbo之后我们不需要关注服务是如何被远程调用，服务之间调用好像在本地调用一样，充分发掘其强大的服务治理，我们可以减少运维成本，将注意力专注于业务本身的开发。 Dubbo注册中心​ Zookeeper是hadoop的一个子项目，是分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。在于dubbo结合使用时，作为其注册中心，负责dubbo的所有服务地址列表维护，并且可以通过在ZooKeeper节点中设置相应的值来实现对这个服务的权重、优先级、是否可用、路由、权限等的控制。 下图是zookeeper的结构图 关于Zookeeper，请参考这里。 参考https://www.zhihu.com/question/25070185 https://www.gitbook.com/book/dubbo/dubbo-user-book]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(4)]]></title>
      <url>%2F2017%2F12%2F31%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-4%2F</url>
      <content type="text"><![CDATA[2017年-2018年（51本书）98.《你一年的8760小时》-艾力 99.《牛棚杂忆》-季羡林 100.《愚人的坚持》-稻盛和夫，山中伸弥 101.《异类》-马尔柯姆-格拉德威尔 102.《人类动物园》-德斯蒙德莫里斯 103.《美学漫话》-宗白华 104.《逃不开的经济周期》-拉斯特维德 105.《明治维新六十年》-樱雪丸 106.《武士道》-新渡户稻造 107.《我所理解的生活》-韩寒 108.《呀，原来如此》-知乎 109《宋朝原来是这样》-醉罢君山 110《我看到的世界和你们不一样》-眭澔平 111《沸腾十五年》-林军 112《吾国吾民》-林语堂 113《亲密行为》-德斯蒙德莫里斯 114《人人都爱经济学》-王福重 115《人类简史：从动物到上帝》-尤瓦尔赫拉利 116《看见》-柴静 117《当我们谈论爱情时我们在谈论什么》-雷蒙德卡佛 118《把时间当作朋友-运用心智，获得解放》-李笑来 119《设计诗》-朱赢椿 120《沧浪之水》-阎真 121《番茄工作法》-诺特伯格 122《奇特的一生》-格拉宁 123《金融的解释》-王福重 124《精进：如何成为一个很厉害的人》-采铜 125《超级时间整理术》-迈克尔赫佩尔 126《腾讯传1998-2016：中国互联网公司进化论》-吴晓波 127《习惯的力量》-查尔斯杜系格 128《黑天鹅：如何应对不可预知的未来》-纳西姆尼古拉斯塔利布 129《曾在天涯》-阎真 130《日本历史与文化研究》-徐静波 131《知行合一王阳明》-度阴山 132《清晰思考的艺术》-罗尔夫多贝里 133《日本与日本人》-小泉八云 134《马云：未来已来》-阿里巴巴集团 135《日本与日本人》-小泉八云 136《毛泽东传》-罗斯特里尔 137《没有什么了不起》-蔡澜 138《活出生命的意义》-维克多弗兰克尔 139《整理情绪的力量》-有川真优美 140《巨人的陨落》-肯福莱特 141《且以深情共白头》-胡云萍 142《未来简史》-尤瓦尔赫拉利 143 《创业：我们创什么》-财金天下 144 《我有故事，你有酒吗》-关东野客 145 《入骨相思知不知》-微小词 146 《干法》-稻盛和夫 147 《世界的凛冬》-肯福莱特 148 《万万没想到：用理工科的思维理解世界》-万维纲]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot之log4j]]></title>
      <url>%2F2017%2F12%2F28%2FSpringBoot%E4%B9%8Blog4j%2F</url>
      <content type="text"><![CDATA[什么是log4j？​ Log4j有三个主要的组件：Logger(记录器)，Appender (输出源)和Layouts(布局)。可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松地记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。 Logger​ Loggers组件在此系统中被分为五个级别：DEBUG、INFO、WARN、ERROR和FATAL。这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，分别用来指定这条日志信息的重要程度。 其中重要的是name和additivity。 name :定义了logger的层级，如x.y 表示两层，x层和y层，x是y的父层级，x.y所在层级是y层级。additivity：默认为true，表示当前logger将打印日志到当前的appender及所有的父层级所指定的appender；false 为只打到当前自己的appender 日志记录器 添加的输出源 附加特性标识 输出目标 评论 root A1 not applicable A1 根日志记录器是匿名的，但是可以用Logger.getRootLogger()方法来存取。根日志记录器没有默认输出源。 x A-x1, A-x2 true A1, A-x1, A-x2 x和根的输出源 x.y none true A1, A-x1, A-x2 x和根的输出源 x.y.z A-xyz1 true A1, A-x1, A-x2, A-xyz1 x.y.z 、x和根的输出源 security A-sec false A-sec 由于附加标识被设置为false，没有输出源聚集 security.access none true A-sec 由于安全中附加标识被设置为false，所以仅仅有安全的输出源。 Appender允许把日志输出到不同的地方，常使用的类包括： org.apache.log4j.ConsoleAppender（控制台） ConsoleAppender选项： Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。Target=System.err：默认值是System.out。 org.apache.log4j.FileAppender（文件） FileAppender选项： Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。File=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。DatePattern=’.’yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为system.log，前一个月的日志文件名为system.log.yyyy-MM。 1)’.’yyyy-MM：每月2)’.’yyyy-ww：每周3)’.’yyyy-MM-dd：每天4)’.’yyyy-MM-dd-a：每天两次5)’.’yyyy-MM-dd-HH：每小时6)’.’yyyy-MM-dd-HH-mm：每分钟org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。ImmediateFlush=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。MaxFileSize=100KB：后缀可以是KB, MB 或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生system.log.1，system.log.2两个滚动文件和一个system.log文件。org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） Layouts用户希望根据自己的喜好格式化自己的日志输出，Log4j可以在Appenders的后面附加Layouts来完成这个功能。常使用的类如下： org.apache.log4j.HTMLLayout（以HTML表格形式布局） LocationInfo=true：输出java文件名称和行号，默认值是false。Title=My Logging： 默认值是Log4J Log Messages。 org.apache.log4j.PatternLayout（可以灵活地指定布局模式） ConversionPattern=%m%n：设定以怎样的格式显示消息。 格式化符号说明： %p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。%d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d{yyyy/MM/dd HH:mm:ss,SSS}。%r：输出自应用程序启动到输出该log信息耗费的毫秒数。%t：输出产生该日志事件的线程名。%l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。%c：输出日志信息所属的类目，通常就是所在类的全名。%M：输出产生日志信息的方法名。%F：输出日志消息产生时所在的文件名称。%L:：输出代码中的行号。%m:：输出代码中指定的具体日志信息。%n：输出一个回车换行符，Windows平台为”rn”，Unix平台为”n”。%x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。%%：输出一个”%”字符。另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如：1) c：指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。2)%-20c：”-“号表示左对齐。3)%.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等信息） 如何使用log4j?以我在项目中使用为例 xml形式 12345678910111213141516171819202122&lt;appender name="systemLogAppender" class="org.apache.log4j.DailyRollingFileAppender"&gt; &lt;param name="File" value="/system.log" /&gt; &lt;param name="DatePattern" value="'.'yyyy-MM-dd" /&gt; &lt;param name="Append" value="true" /&gt; &lt;layout class="org.apache.log4j.PatternLayout"&gt; &lt;param name="ConversionPattern" value="%-d&#123;HH:mm:ss&#125; %-5p [%t] %C(%F:%L) - %m%n" /&gt; &lt;/layout&gt; &lt;/appender&gt;&lt;appender name="consoleAppender" class="org.apache.log4j.ConsoleAppender"&gt; &lt;layout class="org.apache.log4j.PatternLayout"&gt; &lt;param name="ConversionPattern" value="%-d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [[%t]] %-5p [%c] (%C:%L) - %m%n" /&gt; &lt;/layout&gt; &lt;/appender&gt;&lt;logger name="tech.luckylau" additivity="false"&gt; &lt;level value="INFO" /&gt; &lt;appender-ref ref="systemLogAppender" /&gt; &lt;/logger&gt; &lt;root&gt; &lt;priority value="WARN" /&gt; &lt;appender-ref ref="consoleAppender" /&gt; &lt;/root&gt; log4j.properties形式 1234567891011121314log4j.rootLogger=WARN, consoleAppenderlog4j.appender.consoleAppender=org.apache.log4j.ConsoleAppenderlog4j.appender.consoleAppender.layout=org.apache.log4j.PatternLayoutlog4j.appender.consoleAppender.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [[%t]] %-5p [%c] (%C:%L) - %m%nlog4j.logger.tech.luckylau=Info,systemLogAppenderlog4j.additivity.tech.luckylau=falselog4j.appender.systemLogAppender=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.systemLogAppender.File=/system.loglog4j.appender.systemLogAppender.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.systemLogAppender.Append=truelog4j.appender.systemLogAppender.layout=org.apache.log4j.PatternLayoutlog4j.appender.systemLogAppender.layout.ConversionPattern=%-d&#123;HH:mm:ss&#125; %-5p [%t] %C(%F:%L) - %m%n 如何自定义appender?比如有个需求，使用DailyRollingFileAppender时，错误打印频繁如何限速？这时候可以自定义appender。这里是用ratelimter限速。 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt; &lt;/dependency&gt; 1234567891011121314151617181920public class RateLimiterDailyRollingFileAppender extends DailyRollingFileAppender &#123; private final RateLimiter rateLimiter = rateLimiter = RateLimiter.create(0.5); @Override protected void subAppend(LoggingEvent event) &#123; Level level = event.getLevel(); /** * 处理error */ if(level != null &amp;&amp; level.getSyslogEquivalent() == 3)&#123; if(rateLimiter.tryAcquire())&#123; super.subAppend(event); &#125; return; &#125; super.subAppend(event); &#125;&#125; 参考：Log4j DailyRollingFileAppender源码详读 Log4J日志配置详解 支持设置最大日志数量的DailyRollingFileAppender]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之过滤器模式]]></title>
      <url>%2F2017%2F11%2F25%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%BF%87%E6%BB%A4%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[过滤器模式 123456package test;import java.util.List;public interface Filter &#123; public List&lt;Computer&gt; filter(List&lt;Computer&gt; regulars);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package test;public class Computer &#123; private Brand brand; private Type type; private int price; public Computer(Brand brand, Type type, int price) &#123; this.brand = brand; this.type = type; this.price = price; &#125; public Brand getBrand() &#123; return brand; &#125; public void setBrand(Brand brand) &#123; this.brand = brand; &#125; public Type getType() &#123; return type; &#125; public void setType(Type type) &#123; this.type = type; &#125; public int getPrice() &#123; return price; &#125; public void setPrice(int price) &#123; this.price = price; &#125; @Override public String toString() &#123; return "Computer [brand=" + brand + ", type=" + type + ", price=" + price + "]"; &#125;&#125;enum Brand &#123; Apple("apple"), HUAWEI("hauwei"), Haier("haier"), DELL("dell"), HP("hp"); private String brand; Brand(String brand) &#123; this.brand = brand; &#125; public String getBrand() &#123; return brand; &#125;&#125;enum Type &#123; NOTEBOOK("notebook"), DESKTOP("desktop"); private String type; Type(String type) &#123; this.type = type; &#125; public String getType() &#123; return type; &#125;&#125; 1234567891011121314151617181920package test;import java.util.ArrayList;import java.util.List;public class BrandFilter implements Filter &#123; private Brand brand; public BrandFilter(Brand brand)&#123; this.brand = brand; &#125; @Override public List&lt;Computer&gt; filter(List&lt;Computer&gt; regulars) &#123; // TODO Auto-generated method stub List&lt;Computer&gt; result = new ArrayList&lt;&gt;(); for(Computer regular:regulars)&#123; if(regular.getBrand().equals(brand))&#123; result.add(regular); &#125; &#125; return result; &#125;&#125; 12345678910111213141516171819202122package test;import java.util.ArrayList;import java.util.List;public class TypeFilter implements Filter &#123; private Type type; public TypeFilter(Type type) &#123; this.type = type; &#125; @Override public List&lt;Computer&gt; filter(List&lt;Computer&gt; regulars) &#123; List&lt;Computer&gt; result = new ArrayList&lt;&gt;(); for(Computer regular:regulars)&#123; if(regular.getType().equals(type))&#123; result.add(regular); &#125; &#125; return result; &#125;&#125; 12345678910111213141516171819202122package test;import java.util.ArrayList;import java.util.List;public class PriceFilter implements Filter &#123; private int price; public PriceFilter(int price) &#123; this.price = price; &#125; @Override public List&lt;Computer&gt; filter(List&lt;Computer&gt; regulars) &#123; List&lt;Computer&gt; result = new ArrayList&lt;&gt;(); for(Computer regular:regulars)&#123; if(regular.getPrice() == price)&#123; result.add(regular); &#125; &#125; return result; &#125;&#125; 12345678910111213package test;import java.util.ArrayList;import java.util.List;public class FilterUtils&#123; public static List&lt;Computer&gt; filter(List&lt;Computer&gt; regulars ,List&lt;Filter&gt; filters) &#123; // TODO Auto-generated method stub List&lt;Computer&gt; result = new ArrayList&lt;&gt;(regulars); for(Filter filter: filters)&#123; result =filter.filter(result); &#125; return result; &#125;&#125; 123456789101112131415161718192021222324package test;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class Test &#123; public static void main(String[] args) &#123; List&lt;Computer&gt; regulars = new ArrayList&lt;&gt;(); regulars.add(new Computer(Brand.Apple,Type.NOTEBOOK,8000)); regulars.add(new Computer(Brand.Apple,Type.NOTEBOOK,8000)); regulars.add(new Computer(Brand.DELL,Type.DESKTOP,3000)); regulars.add(new Computer(Brand.HP,Type.NOTEBOOK,6000)); regulars.add(new Computer(Brand.DELL,Type.NOTEBOOK,8000)); regulars.add(new Computer(Brand.Haier,Type.DESKTOP,6000)); regulars.add(new Computer(Brand.HUAWEI,Type.NOTEBOOK,8000)); System.out.println("库存信息"); System.out.println(Arrays.toString(regulars.toArray())); List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); filters.add(new BrandFilter(Brand.Apple)); filters.add(new TypeFilter(Type.NOTEBOOK)); List&lt;Computer&gt; result = FilterUtils.filter(regulars, filters); System.out.println("筛选后的信息"); System.out.println(Arrays.toString(result.toArray())); &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux系统常用监控命令]]></title>
      <url>%2F2017%2F11%2F24%2Flinux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[uptime115:24:23 up 84 days, 17 min, 6 users, load average: 0.67, 0.66, 0.72 15:24:23 //系统当前时间 up 84 days, 17 min //主机已运行时间,时间越大，说明你的机器越稳定 6 users //用户连接数，是总连接数而不是用户数 load average //在过去1分钟、5分钟、15分钟内系统的load值 top123456top - 15:28:53 up 84 days, 22 min, 6 users, load average: 0.19, 0.44, 0.61Tasks: 135 total, 1 running, 134 sleeping, 0 stopped, 0 zombie%Cpu(s): 6.3 us, 0.6 sy, 0.0 ni, 93.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 8010424 total, 131496 free, 7583244 used, 295684 buff/cacheKiB Swap: 4194300 total, 2250812 free, 1943488 used. 127160 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 第一行同uptime 第二行任务（进程） 系统现在共有135个进程，1个运行，134个休眠，停止0个，僵尸有0个 第三行 us,用户时间（User Time）表示CPU执行用户进程所占用的时间，通常情况下希望us的占比越高越好 sy,系统时间（System Time）表示CPU自内核态所花费的时间，sy占比比较高通常意味着系统在某些方面设计得不合理，比如频繁的系统调用导致的用户态和内核态的频繁切换 ni,Nice时间（Nice Time）表示系统在调整进程优先级的时候所花费的时间 id,空闲时间（Idle Time）表示系统处于空闲期，等待进程运行，这个过程所占用的时间。当然，我们希望id的占比越低越好 wa,等待时间（Waiting Time）表示CPU在等待I/O操作所花费的时间，系统不应该花费大量的时间来进行等待，否则便表示可能有某个地方设计不合理 hi,硬件中断处理时间（Hard Irq Time）表示系统处理硬件中断所占用的时间 si,软件中断处理时间（Soft Irq Time）表示系统处理软件中断所占用的时间 st,丢失时间（Steal Time）表示被强制等待虚拟CPU的时间 第四行 内存状态 ，与win概念不一样，linux有一定特殊性，其中有一个思想便是内存利用率最大化，内核会将剩余的内存申请为cached，而cached不属于free范畴。因此，当系统运行时间较长时，会发现cached这块区域比较大，对于有频繁文件读/写操作的系统，这种现象更为明显。 第五行 swap交换分区，对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 第六行 PID — 进程idUSER — 进程所有者PR — 进程优先级NI — nice值。负值表示高优先级，正值表示低优先级VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR — 共享内存大小，单位kbS — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU — 上次更新到现在的CPU时间占用百分比%MEM — 进程使用的物理内存百分比TIME+ — 进程使用的CPU时间总计，单位1/100秒COMMAND — 进程名称（命令名/命令行） df -h磁盘剩余空间也是一个非常关键的指标，如果磁盘没有足够的剩余空间，正常的日志写入以及系统I/O都将无法进行。 iostat -d -k123Linux 3.10.0-514.21.2.el7.x86_64 (iz2zegbc4593l7v9u0xalwz) 11/24/2017 _x86_64_ (4 CPU)Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnvda 3.65 30.76 28.70 223300253 208343752 磁盘I/O的繁忙程度也是一个重要的系统指标 -d表示查看磁盘使用状况，-k表示以KB为单位 显示Device表示设备名称、tps表示每秒处理的I/O请求数、kB_read/s表示每秒从设备读取的数据量、kB_wrtn/s表示美标向设备写入的数据量、kB_read表示读取的数据总量、kB_wrtn表示写入的数据总量。(瞬时) free -m123 total used free shared buff/cache availableMem: 7822 7402 147 0 272 135Swap: 4095 1913 2182 程序运行时的数据加载、线程并发、I/O缓冲等，都依赖于内存，可用内存的大小决定了程序是否能正常运行以及运行的性能 vmstat123procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 1959152 133228 7736 283268 1 1 8 7 0 0 9 1 90 0 0 si表示每秒从磁盘交换到内存的数据量，单位是KB/s，so表示每秒从内存交换到磁盘的数据量，单位也是KB/s (瞬时)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot之MyBatis]]></title>
      <url>%2F2017%2F11%2F12%2FSpringBoot%E4%B9%8BMyBatis%2F</url>
      <content type="text"><![CDATA[什么是MyBatis？​ MyBatis是一个支持普通SQL查询，存储过程和高级映射的优秀持久层框架。MyBatis消除了几乎所有的JDBC代码和参数的手工设置以及对结果集的检索封装。MyBatis可以使用简单的XML或注解用于配置和原始映射，将接口和Java的POJO（Plain Old Java Objects，普通的Java对象）映射成数据库中的记录。 orm工具的基本思想: 从配置文件(通常是XML配置文件中)得到 SqlSessionFactory 由SqlSessionFactory 产生 SqlSession 在SqlSession 中完成对数据的增删改查和事务提交等 在用完之后关闭SqlSession 在java 对象和 数据库之间有做mapping 的配置文件，也通常是xml 文件 ​ 与Hibernate相比较，Hibernate鼓励使用实体对象（EntityObjects）和在其底层自动产生SQL语句，MyBatis框架接受SQL语句，而不是将其对开发人员隐藏起来，这样就可以充分利用数据库特有的特性并且可以准备自定义的查询。 ​ 在性能方面， MyBatis支持数据库连接池，消除为每一个请求创建一个数据库连接的开销，同时提供了内建的缓存机制，在SqlSession级别提供了对SQL查询结果的缓存。 如何使用mybatis？传统使用JDBC假如我们创建一个对象，我们需要做的工作包括：创建一个连接，创建一个Statement对象，设置输入参数，关闭资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Student&#123; private Integer studId; private String name; private String email; private Date dob;&#125;public void createStudent(Student student) &#123; Connection conn = null; try &#123; //获得数据库连接 conn = getDatabaseConnection(); String sql = "INSERT INTO STUDENTS(STUD_ID,NAME,EMAIL,DOB) VALUES(?,?,?,?)"; //创建 PreparedStatement PreparedStatement pstmt = conn.prepareStatement(sql); //设置输入参数 pstmt.setInt(1, student.getStudId()); pstmt.setString(2, student.getName()); pstmt.setString(3, student.getEmail()); pstmt.setDate(4, new java.sql.Date(student.getDob().getTime())); pstmt.executeUpdate(); &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; finally &#123; //关闭连接 if(conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; &#125; &#125; &#125; &#125; protected Connection getDatabaseConnection() throws SQLException &#123; try &#123; Class.forName("com.mysql.jdbc.Driver"); return DriverManager.getConnection("jdbc:mysql://localhost:3306/test", "root", "admin"); &#125; catch (SQLException e) &#123; throw e; &#125; catch (Exception e) &#123; throw new RuntimeException(e.getCause()); &#125; &#125; 单一使用Mybatis为了简化和抽象上述jdbc的处理流程，mybatis是如下处理的。 首先配置文件，包括application.properties 和mybatis-config.xml。 1234jdbc.driverClassName=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/elearningjdbc.username=rootjdbc.password=admin 1234567891011121314151617&lt;configuration&gt; &lt;properties resource="application.properties"/&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="$&#123;jdbc.driverClassName&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="com/mybatis3/mappers/StudentMapper.xml"/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 其次在\src\main\resources\com\mybatis3\mappers路径下，创建和配置StudentMapper.xml ，在\src\main\java\com\mybatis3\mappers路径下，创建接口StudentMapper.java 12345public interface StudentMapper &#123; Student findStudentById(Integer id); void insertStudent(Student student); &#125; 123456789101112&lt;mapper namespace="com.mybatis3.mappers.StudentMapper"&gt; &lt;resultMap type="Student" id="StudentResult"&gt; &lt;id property="studId" column="stud_id" /&gt; &lt;result property="name" column="name" /&gt; &lt;result property="email" column="email" /&gt; &lt;result property="dob" column="dob" /&gt; &lt;/resultMap&gt; &lt;insert id="insertStudent" parameterType="Student"&gt; INSERT INTO STUDENTS(STUD_ID,NAME,EMAIL,DOB) VALUES(#&#123;studId &#125;,#&#123;name&#125;,#&#123;email&#125;,#&#123;dob&#125;) &lt;/insert&gt; &lt;/mapper&gt; 最后代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class MyBatisSqlSessionFactory&#123; private static SqlSessionFactory sqlSessionFactory; private static final Properties PROPERTIES = new Properties(); static &#123; try &#123; InputStream is = DataSourceFactory.class.getResourceAsStream("/application.properties"); PROPERTIES.load(is); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static SqlSessionFactory getSqlSessionFactory() &#123; if(sqlSessionFactory==null) &#123; InputStream inputStream = null; try &#123; inputStream = Resources.getResourceAsStream("mybatis-config.xml"); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125;catch (IOException e) &#123; throw new RuntimeException(e.getCause()); &#125;finally &#123; if(inputStream != null)&#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; &#125; &#125; &#125; &#125; return sqlSessionFactory; &#125; public static SqlSession getSqlSession() &#123; return getSqlSessionFactory().openSession(); &#125; public static Connection getConnection() &#123; String driver = PROPERTIES.getProperty("jdbc.driverClassName"); String url = PROPERTIES.getProperty("jdbc.url"); String username = PROPERTIES.getProperty("jdbc.username"); String password = PROPERTIES.getProperty("jdbc.password"); Connection connection = null; try &#123; Class.forName(driver); connection = DriverManager.getConnection(url, username, password); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return connection; &#125;&#125;public void createStudent(Student student) &#123; SqlSession sqlSession = MyBatisSqlSessionFactory.getSqlSession(); try &#123; StudentMapper studentMapper = sqlSession.getMapper(StudentMapper.class); studentMapper.insertStudent(student); sqlSession.commit(); &#125; finally &#123; sqlSession.close(); &#125; &#125; 下面详细讲解如何配置Mybatis。 通过XML配置Mybatis1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8" ?&gt; &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt; &lt;!-- 配置文件的根元素 --&gt; &lt;configuration&gt; &lt;!-- 属性：定义配置外在化 --&gt; &lt;properties&gt;&lt;/properties&gt; &lt;!-- 设置：定义mybatis的一些全局性设置 --&gt; &lt;settings&gt; &lt;!-- 具体的参数名和参数值 --&gt; &lt;setting name="" value=""/&gt; &lt;/settings&gt; &lt;!-- 类型名称：为一些类定义别名 --&gt; &lt;typeAliases&gt;&lt;/typeAliases&gt; &lt;!-- 类型处理器：定义Java类型与数据库中的数据类型之间的转换关系 --&gt; &lt;typeHandlers&gt;&lt;/typeHandlers&gt; &lt;!-- 对象工厂 --&gt; &lt;objectFactory type=""&gt;&lt;/objectFactory&gt; &lt;!-- 插件：mybatis的插件,插件可以修改mybatis的内部运行规则 --&gt; &lt;plugins&gt; &lt;plugin interceptor=""&gt;&lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 环境：配置mybatis的环境 --&gt; &lt;environments default=""&gt; &lt;!-- 环境变量：可以配置多个环境变量，比如使用多数据源时，就需要配置多个环境变量 --&gt; &lt;environment id=""&gt; &lt;!-- 事务管理器 --&gt; &lt;transactionManager type=""&gt;&lt;/transactionManager&gt; &lt;!-- 数据源 --&gt; &lt;dataSource type=""&gt;&lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 数据库厂商标识 --&gt; &lt;databaseIdProvider type=""&gt;&lt;/databaseIdProvider&gt; &lt;!-- 映射器：指定映射文件或者映射类 --&gt; &lt;mappers&gt;&lt;/mappers&gt; &lt;/configuration&gt; 其中settings属性可以配置如下： 设置参数 描述 默认值 cacheEnabled 该配置影响的所有映射器中配置的缓存的全局开关 true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置fetchType属性来覆盖该项的开关状态 false aggressiveLazyLoading 当启用时，对任意延迟属性的调用会使带有延迟加载属性的对象完整加载；反之，每种属性将会按需加载。 true multipleResultSetsEnabled 是否允许单一语句返回多结果集（需要兼容驱动）。 true useColumnLabel 使用列标签代替列名。不同的驱动在这方面会有不同的表现， 具体可参考相关驱动文档或通过测试这两种不同的模式来观察所用驱动的结果。 true useGeneratedKeys 允许 JDBC 支持自动生成主键，需要驱动兼容。 如果设置为 true 则这个设置强制使用自动生成主键，尽管一些驱动不能兼容但仍可正常工作（比如 Derby）。 False autoMappingBehavior 指定 MyBatis 应如何自动映射列到字段或属性。 NONE 表示取消自动映射；PARTIAL 只会自动映射没有定义嵌套结果集映射的结果集。 FULL 会自动映射任意复杂的结果集（无论是否嵌套）。 PARTIAL defaultExecutorType 配置默认的执行器。SIMPLE 就是普通的执行器；REUSE 执行器会重用预处理语句（prepared statements）； BATCH 执行器将重用语句并执行批量更新。 SIMPLE defaultStatementTimeout 设置超时时间，它决定驱动等待数据库响应的秒数。 Not Set (null) 12345678910111213141516&lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="false"/&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="defaultFetchSize" value="100"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="mapUnderscoreToCamelCase" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt; 其中plugins做一个详细的分析和介绍。 首先在mybatis中要使用插件你必须实现：org.apache.ibatis.plugin.Interceptor接口 1234567package org.apache.ibatis.plugin; import java.util.Properties; public interface Interceptor &#123; public Object intercept(Invocation invctn) throws Throwable; public Object plugin(Object o); public void setProperties(Properties prprts); &#125; ​ MyBatis允许你在已映射的语句执行过程中的某一点进行拦截调用。默认情况下，Mybatis允许使用插件来拦截的方法调用包括：Executor(update,query,flushStatements,commit,rollback,getTransaction,close,isClosed) 123456789101112131415161718public interface Executor &#123; ResultHandler NO_RESULT_HANDLER = null; int update(MappedStatement ms, Object parameter) throws SQLException; &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey cacheKey, BoundSql boundSql) throws SQLException; &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException; &lt;E&gt; Cursor&lt;E&gt; queryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds) throws SQLException; List&lt;BatchResult&gt; flushStatements() throws SQLException; void commit(boolean required) throws SQLException; void rollback(boolean required) throws SQLException; CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql); boolean isCached(MappedStatement ms, CacheKey key); void clearLocalCache(); void deferLoad(MappedStatement ms, MetaObject resultObject, String property, CacheKey key, Class&lt;?&gt; targetType); Transaction getTransaction(); void close(boolean forceRollback); boolean isClosed(); void setExecutorWrapper(Executor executor);&#125; ParameterHandler(getParameterObejct,setParameters) 12345public interface ParameterHandler &#123; Object getParameterObject(); void setParameters(PreparedStatement ps) throws SQLException;&#125; ResultSetHandler(handlerResultSets,handlerOutputParameters) 1234public interface ResultSetHandler &#123; &lt;E&gt; List&lt;E&gt; handleResultSets(Statement stmt) throws SQLException; &lt;E&gt; Cursor&lt;E&gt; handleCursorResultSets(Statement stmt) throws SQLException; void handleOutputParameters(CallableStatement cs) throws SQLException; StatementHandler(prepare,parameterize,batch,update,query) 12345678910111213141516public interface StatementHandler &#123; Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException; void parameterize(Statement statement) throws SQLException; void batch(Statement statement) throws SQLException; int update(Statement statement) throws SQLException; &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException; &lt;E&gt; Cursor&lt;E&gt; queryCursor(Statement statement) throws SQLException; BoundSql getBoundSql(); ParameterHandler getParameterHandler();&#125; 在实际开发中，Executor范围最大 ，其次StatementHandler，最后ParameterHandler 和 ResultSetHandler。ResultSetHandler很少使用，StatementHandler最常用，范围大于ParameterHandler。例如需要拦截加入参数，用范围越小的ParameterHandler越好，当然也可以用StatementHandler。 以分页为例：http://blog.csdn.net/ykzhen2015/article/details/51746568 通过Java API配置MyBatis创建SqlSessionFactory 12345678910111213141516171819202122232425public static SqlSessionFactory getSqlSessionFactory() &#123; SqlSessionFactory sqlSessionFactory = null; try &#123; DataSource dataSource = DataSourceFactory.getDataSource(); TransactionFactory transactionFactory = new JdbcTransactionFactory(); Environment environment = new Environment("development", transactionFactory, dataSource); Configuration configuration = new Configuration(environment); configuration.getTypeAliasRegistry().registerAlias("student", Student.class); configuration.getTypeHandlerRegistry().register(PhoneNumber. class, PhoneTypeHandler.class); configuration.addMapper(StudentMapper.class); sqlSessionFactory = new SqlSessionFactoryBuilder(). build(configuration); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return sqlSessionFactory; &#125; 获得DataSource对象 12345678910public static DataSource getDataSource() &#123; String driver = "com.mysql.jdbc.Driver"; String url = "jdbc:mysql://localhost:3306/test"; String username = "root"; String password = "admin"; PooledDataSource dataSource = new PooledDataSource(driver, url, username, password); return dataSource; &#125; 配置typeAliases 1configuration.getTypeAliasRegistry().registerAlias("Student",Student.class); 注册typeHandlers 1configuration.getTypeHandlerRegistry().register(PhoneNumber.class, PhoneTypeHandler.class); 设置Settings 12345678910111213141516171819configuration.setCacheEnabled(true); configuration.setLazyLoadingEnabled(false); configuration.setMultipleResultSetsEnabled(true); configuration.setUseColumnLabel(true); configuration.setUseGeneratedKeys(false); configuration.setAutoMappingBehavior(AutoMappingBehavior.PARTIAL); configuration.setDefaultExecutorType(ExecutorType.SIMPLE); configuration.setDefaultStatementTimeout(25); configuration.setSafeRowBoundsEnabled(false); configuration.setMapUnderscoreToCamelCase(false); configuration.setLocalCacheScope(LocalCacheScope.SESSION); configuration.setAggressiveLazyLoading(true); configuration.setJdbcTypeForNull(JdbcType.OTHER); Set&lt;String&gt; lazyLoadTriggerMethods = new HashSet&lt;String&gt;(); lazyLoadTriggerMethods.add("equals"); lazyLoadTriggerMethods.add("clone"); lazyLoadTriggerMethods.add("hashCode"); lazyLoadTriggerMethods.add("toString"); configuration.setLazyLoadTriggerMethods(lazyLoadTriggerMethods ); 注册Mapper XML文件 1configuration.addMapper(StudentMapper.class); Spring整合Mybatis​ 正如前面描述如果你只使用MyBatis而没有使用Spring，在每一个方法中，我们需要手动创建SqlSessionFactory对象，并且从SqlSessionFactory对象中创建SqlSession。而且我们还要负责提交或者回滚事务、关闭SqlSession对象。 ​ 通过使用MyBatis-Spring模块，我们可以在Spring的应用上下文ApplicationContext中配置MyBatis Beans,Spring会负责实例化SqlSessionFactory对象以及创建SqlSession对象，并将其注入到DAO或者Service类中。并且，你可以使用Spring的基于注解的事务管理功能，不用自己在数据访问层中书写事务处理代码了。 12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; 首先配置 applicationContext.xml ，包括dataSource，sqlSessionFactory和Dao(采用扫描形式注入) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!--配置数据源--&gt; &lt;bean name="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;property name="url" value="$&#123;jdbc_url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc_username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc_password&#125;" /&gt; &lt;!-- 初始化连接大小 --&gt; &lt;property name="initialSize" value="0" /&gt; &lt;!-- 连接池最大使用连接数量 --&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 连接池最小空闲 --&gt; &lt;property name="minIdle" value="0" /&gt; &lt;!-- 获取连接最大等待时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;property name="validationQuery" value="$&#123;validationQuery&#125;" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="25200000" /&gt; &lt;!-- 打开removeAbandoned功能 --&gt; &lt;property name="removeAbandoned" value="true" /&gt; &lt;!-- 1800秒，也就是30分钟 --&gt; &lt;property name="removeAbandonedTimeout" value="1800" /&gt; &lt;!-- 关闭abanded连接时输出错误日志 --&gt; &lt;property name="logAbandoned" value="true" /&gt; &lt;!-- 监控数据库 --&gt; &lt;!-- &lt;property name="filters" value="stat" /&gt; --&gt; &lt;property name="filters" value="mergeStat" /&gt; &lt;/bean&gt; &lt;!--配置sqlSessionFactory对象--&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 配置MyBatis全局配置文件：MyBatis-config.xml --&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml"/&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- 扫描sql配置文件：mapper需要的xml文件 --&gt; &lt;property name="mapperLocation" value="classpath:mapper/*.xml"/&gt; &lt;!-- 配置数据库表对应的java实体类 --&gt; &lt;property name="typeAliasesPackage" value="com.klm.po" /&gt; &lt;/bean&gt; &lt;!--配置扫描Dao接口包--&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.klm.dao"/&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt; &lt;/bean&gt; 再次配置mybatis的配置文件mybatis-config.xml，除了去掉environment标签，其他没啥区别。 SpringBoot整合Mybatis123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.18&lt;/version&gt; &lt;/dependency&gt; application.properties 1234spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver 举一个简单例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package org.spring.springboot;import javax.sql.DataSource;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.annotation.MapperScan;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.log4j.Logger;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import org.springframework.transaction.PlatformTransactionManager;@SpringBootApplication@MapperScan("com.klm.dao")@EnableAutoConfigurationpublic class Application &#123; private static Logger logger = Logger.getLogger(Application.class); @Bean @ConfigurationProperties(prefix="spring.datasource") public DataSource dataSource() &#123; return new org.apache.tomcat.jdbc.pool.DataSource(); &#125; @Bean public SqlSessionFactory sqlSessionFactoryBean() throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource()); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(resolver.getResources("classpath:/mybatis/*.xml")); return sqlSessionFactoryBean.getObject(); &#125; @Bean public PlatformTransactionManager transactionManager() &#123; return new DataSourceTransactionManager(dataSource()); &#125; public static void main(String[] args) &#123; // 程序启动入口 // 启动嵌入式的 Tomcat 并初始化 Spring 环境及其各 Spring 组件 SpringApplication.run(Application.class,args); &#125;&#125; 如何使用generator生成配置信息？首先pom.xml配置中添加: 123456789101112131415161718192021&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;!--配置文件的路径--&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 然后在${basedir}/src/main/resources/路径下加入generatorConfig.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;context id="generatorTables" targetRuntime="MyBatis3"&gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name="autoDelimitKeywords" value="false"/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name="javaFileEncoding" value="UTF-8"/&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name="javaFormatter" value="org.mybatis.generator.api.dom.DefaultJavaFormatter"/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name="xmlFormatter" value="org.mybatis.generator.api.dom.DefaultXmlFormatter"/&gt; &lt;commentGenerator&gt; &lt;!-- 这个元素用来去除指定生成的注释中是否包含生成的日期 false:表示保护 --&gt; &lt;!-- 如果生成日期，会造成即使修改一个字段，整个实体类所有属性都会发生变化，不利于版本控制，所以设置为true --&gt; &lt;property name="suppressDate" value="true" /&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name="suppressAllComments" value="false" /&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接URL，用户名、密码 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost/springbootdb" userId="root" password="root123"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;!-- This property is used to specify whether MyBatis Generator should force the use of java.math.BigDecimal for DECIMAL and NUMERIC fields, --&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;!-- 生成模型的包名和位置 --&gt; &lt;javaModelGenerator targetPackage="org.spring.springboot.domain" targetProject="src/main/java"&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;!--&lt;property name="constructorBased" value="false"/&gt;--&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="false" /&gt; &lt;!-- for MyBatis3 / MyBatis3Simple 是否创建一个不可变的类，如果为true， 那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 --&gt; &lt;!--&lt;property name="immutable" value="false"/&gt;--&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;!--&lt;property name="rootClass" value="com._520it.mybatis.domain.BaseDomain"/&gt;--&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成映射文件的包名和位置 --&gt; &lt;sqlMapGenerator targetPackage="mapper" targetProject="src/main/resources"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 targetPackage/targetProject:同javaModelGenerator type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）： 1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML； 2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中； 3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML； 注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER --&gt; &lt;!-- 生成DAO的包名和位置 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="org.spring.springboot.dao" targetProject="src/main/java"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="false" /&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要生成哪些表 --&gt; &lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素 选择的table会生成一下文件： 1，SQL map文件 2，生成一个主键类； 3，除了BLOB和主键的其他字段的类； 4，包含BLOB的类； 5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选； 6，Mapper接口（可选） tableName（必要）：要生成对象的表名； 注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会 根据设置的schema，catalog或tablename去查询数据表，按照下面的流程： 1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询； 2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找； 3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找； 4，否则，使用指定的大小写格式查询； 另外的，如果在创建表的时候，使用的""把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名； 这个时候，请设置delimitIdentifiers="true"即可保留大小写格式； 可选： 1，schema：数据库的schema； 2，catalog：数据库的catalog； 3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias_actualColumnName 4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面； 5，enableInsert（默认true）：指定是否生成insert语句； 6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）； 7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句； 8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)； 9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）； 10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句； 11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）； 12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）； 13，modelType：参考context元素的defaultModelType，相当于覆盖； 14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性） 15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性 注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； --&gt; &lt;table tableName="user" domainObjectName="User" mapperName="UserDao" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 这里我们没有加入自己实现的插件，也就是在中无法解析。 最后运行，我使用idea配置的，这里加了“-e ”选项是为了让该插件输出详细信息，这样可以帮助我们定位问题。 深入理解mybatis的原理？参考：深入理解mybatis原理 http://blog.csdn.net/column/details/mybatis-principle.html generator 下载地址 https://github.com/mybatis/generator springboot整合mybatis源码 https://github.com/mybatis/spring-boot-starter Mybatis学习博客 http://limingnihao.iteye.com/blog/781671 Mybatis官方博客 http://www.mybatis.org/mybatis-3/zh/index.html Mybatis 实战教程 http://blog.csdn.net/techbirds_bao/article/details/9233599/ MyBatis xml配置文件详解 http://blog.csdn.net/summer_yuxia/article/details/53169227 MyBATIS插件原理 http://blog.csdn.net/ykzhen2015/article/details/50312651 spring与mybatis三种整合方法 https://www.cnblogs.com/wangmingshun/p/5674633.html Maven项目中Spring整合Mybatis https://www.cnblogs.com/ljdblog/p/5842778.html 基于SpringBoot + Mybatis实现SpringMVC Web项目 http://7player.cn/2015/08/30/%E3%80%90%E5%8E%9F%E5%88%9B%E3%80%91%E5%9F%BA%E4%BA%8Espringboot-mybatis%E5%AE%9E%E7%8E%B0springmvc-web%E9%A1%B9%E7%9B%AE/ 附录： 修改内容 时间 2017-11-12 初始化 2017-11-18 重新架构内容 2017-11-21 完成如何使用mybatis章节 2017-11-23 完成如何使用generator]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式之单例模式]]></title>
      <url>%2F2017%2F10%2F24%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[懒汉式(支持多线程) 123456789101112131415161718public class Singleton &#123; private volatile static Singleton singleton; private Singleton() &#123; &#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 饿汉式（支持多线程） 12345678public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 1234567891011public class Singleton &#123; private static class SingletonHolder&#123; private static Singleton instance = new Singleton(); &#125; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java并发之线程池]]></title>
      <url>%2F2017%2F09%2F09%2Fjava%E5%B9%B6%E5%8F%91%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[​ Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。线程池能够带来3个好处：降低资源消耗 （重复利用已创建的线程降低线程创建和销毁造成的消耗），提高响应速度（当任务到达时，任务可以不需要等到线程创建就能立即执行 ），提高线程的可管理性（线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控）。 线程池的实现原理 ThreadPoolExecutor执行execute方法分下面4种情况： 1.如果当前运行的线程少于corePoolSize，则创建新线程来执行任务。（注意，执行这一步骤需要获取全局锁） 2.如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。 3.如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务。（同样需要全局锁） 4.如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。 线程池的创建12new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime,milliseconds,runnableTaskQueue, handler); corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。 runnableTaskQueue（任务队列）：用于保存等待执行的任务的阻塞队列。 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 PriorityBlockingQueue：一个具有优先级的无限阻塞队列。 maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。 ThreadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。使用开源框架guava提供的ThreadFactoryBuilder可以快速给线程池里的线程设置有意义的名字。 1new ThreadFactoryBuilder().setNameFormat(&quot;XX-task-%d&quot;).build(); RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。 AbortPolicy：直接抛出异常。CallerRunsPolicy：只用调用者所在线程来运行任务。DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。DiscardPolicy：不处理，丢弃掉。也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化存储不能处理的任务。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以，如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。 TimeUnit（线程活动保持时间的单位）：可选的单位有天（DAYS）、小时（HOURS）、分钟（MINUTES）、毫秒（MILLISECONDS）、微秒（MICROSECONDS，千分之一毫秒）和纳秒（NANOSECONDS，千分之一微秒）。 向线程池提交任务execute()和submit() ​ execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。通过以下代码可知execute()方法输入的任务是一个Runnable类的实例。 123456threadsPool.execute(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub &#125;&#125;); ​ submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 1234567891011Future&lt;Object&gt; future = executor.submit(harReturnValuetask);try &#123;Object s = future.get();&#125; catch (InterruptedException e) &#123;// 处理中断异常&#125; catch (ExecutionException e) &#123;// 处理无法执行任务异常&#125; finally &#123;// 关闭线程池executor.shutdown();&#125; 关闭线程池​ 可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。​ 只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。 合理地配置线程池要想合理地配置线程池，就必须首先分析任务特性。 任务的性质：CPU密集型任务、IO密集型任务和混合型任务； 任务的优先级：高、中和低； 任务的执行时间：长、中和短； 任务的依赖性：是否依赖其他系统资源，如数据库连接 ； 例如：CPU密集型任务，配置尽可能小的线程，如配置Ncpu+1个线程的线程池 ；IO密集型任务，应配置尽可能多的线程，如2*Ncpu。混合型的任务。可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数；优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先执行（如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行 ）；执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行；依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。建议使用有界队列。 线程池的监控如果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。 taskCount：线程池需要执行的任务数量； completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount； largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过； getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减； getActiveCount：获取活动的线程数； 通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。 参考：《java并发编程艺术》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之Atomic类]]></title>
      <url>%2F2017%2F09%2F07%2F%E4%BD%A0%E6%87%82java%E5%90%97-21%2F</url>
      <content type="text"><![CDATA[​ Java从JDK 1.5开始提供了java.util.concurrent.atomic包（以下简称Atomic包），这个包中的原子操作类提供了一种用法简单、性能高效、线程安全地更新一个变量的方式。在Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。 Atomic实现原理CAS (compare and swap) + volatile和native方法 原子更新基本类型类​ Atomic包提供了以下3个类：AtomicBoolean：原子更新布尔类型；AtomicInteger：原子更新整型；AtomicLong：原子更新长整型。 12345678910//以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果。int addAndGet（int delta）//如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。boolean compareAndSet（int expect，int update）//以原子方式将当前值加1，注意，这里返回的是自增前的值。int getAndIncrement()//最终会设置成newValue，使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。void lazySet（int newValue）//以原子方式设置为newValue的值，并返回旧值。int getAndSet（int newValue） 原子更新数组​ Atomic包提供了以下4个类 ：AtomicIntegerArray：原子更新整型数组里的元素；AtomicLongArray：原子更新长整型数组里的元素；AtomicReferenceArray：原子更新引用类型数组里的元素；AtomicIntegerArray类主要是提供原子的方式更新数组里的整型。 1234//以原子方式将输入值与数组中索引i的元素相加int addAndGet（int i，int delta）//如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值boolean compareAndSet（int i，int expect，int update） 原子更新引用类型​ 原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类：AtomicReference：原子更新引用类型，AtomicReferenceFieldUpdater：原子更新引用类型里的字段 ，AtomicMarkableReference ：原子更新带有标记位的引用类型。 原子更新字段类​ 如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新：AtomicIntegerFieldUpdater：原子更新整型的字段的更新器，AtomicLongFieldUpdater：原子更新长整型字段的更新器，AtomicStampedReference：原子更新带有版本号的引用类型。 ​ 要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。 123456789101112131415161718192021222324252627import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;public class AtomicIntegerFieldUpdaterTest &#123; // 创建原子更新器，并设置需要更新的对象类和对象的属性 private static AtomicIntegerFieldUpdater&lt;User&gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, "old"); public static void main(String[] args) &#123; // 设置柯南的年龄是10岁 User conan = new User("conan", 10); // 柯南长了一岁，但是仍然会输出旧的年龄 System.out.println(a.getAndIncrement(conan)); // 输出柯南现在的年龄 System.out.println(a.get(conan)); &#125; static class User &#123; private String name; public volatile int old; public User(String name, int old) &#123; this.name = name; this.old = old; &#125; public String getName() &#123; return name; &#125; public int getOld() &#123; return old; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot之Redis]]></title>
      <url>%2F2017%2F08%2F13%2FSpringBoot%E4%B9%8BRedis%2F</url>
      <content type="text"><![CDATA[最近项目使用了Redis，抽个时间系统的整理一下Redis的使用。 目前提供一套学习使用教程，见Git地址。 什么是Redis？​ Redis是Nosql数据库中使用较为广泛的非关系型内存数据库，Redis内部是一个key-value存储系统。它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型，类似于Java中的map）。Redis基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一，也被人们称为数据结构服务器。 为什么要使用Redis？​ 数据结构(Data Structure)需求越来越多, 但memcache中没有, 影响开发效率；性能需求, 随着读操作的量的上升需要解决，经历的过程有：数据库读写分离(M/S)–&gt;数据库使用多个Slave–&gt;增加Cache (memcache)–&gt;转到Redis。没有使用Redis时候需要水平拆分，对表的拆分，将有的用户放在这个表，有的用户放在另外一个表；可靠性需求 ，Cache的”雪崩”问题让人纠结 ，Cache面临着快速恢复的挑战；开发成本需求 。Cache和DB的一致性维护成本越来越高(先清理DB，再清理缓存， 不行啊， 太慢了！) 开发需要跟上不断涌入的产品需求 硬件成本最贵的就是数据库层面的机器，基本上比前端的机器要贵几倍，主要是IO密集型，很耗硬件；维护性复杂 ，一致性维护成本越来越高； ​ 所以大数据时代淘宝、微信、以及微博会广泛使用了redis数据库，将一些固定不变的数据例如学校，区域等固定的信息保存在关系型数据库中。然后对于经常变化的数据例如淘宝每个节日都会有比较热门的搜索显示在搜索框，当节日过去关键字自动删除，为了便于管理，可以将这些数据保存在redis数据库中，并设置过期时间，到达时间就自动删除。 为了缓解数据库压力，微博首先将发送的微博保存到redis数据库，自己可以立即查看到，然后将内存中的数据同步到关系型数据库。 安装Redis以ubantu16 12345678//下载rediswget http://download.redis.io/releases/redis-3.0.7.tar.gz//解压redistar -xvf redis-3.0.7.tar.gz//安装rediscd redis-3.0.7//“有可能需要安装gcc插件：yum install -y gcc ” make 配置Redis的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt; 参数配置属性的说明在application.properties中加入Redis服务端的相关配置。 123456789101112131415161718# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=localhost# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 Redis配置文件redis官方提供的redis.conf文件，足有700+行，其中100多行为有效配置行，另外的600多行为注释说明。 123456# 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes ​ redis配置中对单位的大小写不敏感，1GB、1Gb和1gB都是相同的。由此也说明，redis只支持bytes，不支持bit单位。 ​ redis配置文件被分成了几大块区域，它们分别是： 通用（general）123456789101112daemonize no //当以daemon形式运行时，redis会生成一个pid文件，默认会生成在/var/run/redis.pidpidfile /path/to/redis.pid //配置pid文件port 6379 //端口，默认是6379 ，6379在是手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字tcp-backlog 511 //TCP接收队列长度，受/proc/sys/net/core/somaxconn和tcp_max_syn_backlog这两个内核参数的影响bind 127.0.0.1 //绑定的主机地址timeout 0 //当一个redis-client一直没有请求发向server端，那么server端有权主动关闭这个连接，可以通过timeout来设置“空闲超时时限”，0表示永不关闭。tcp-keepalive 60 //TCP连接保活策略，可以通过tcp-keepalive配置项来进行设置，单位为秒，假如设置为60秒，则server端会每60秒向连接空闲的客户端发起一次ACK请求，以检查客户端是否已经挂掉，对于无响应的客户端则会关闭其连接。所以关闭一个连接最长需要120秒的时间。如果设置为0，则不会进行保活检测。loglevel notice //设置日志等级，共分四级，即debug、verbose、notice、warning。logfile &quot;&quot; //日志名，假如你在daemon情况下将日志设置为输出到标准输出，则日志会被写到/dev/null中。syslog-ident redis //如果希望日志打印到syslog中，也很容易，通过syslog-enabled来控制。另外，syslog-ident还可以让你指定syslog里的日志标志syslog-facility local0 //还支持指定syslog设备，值可以是USER或LOCAL0-LOCAL7databases 16 //这16个数据库的编号将是0到15。默认的数据库是编号为0的数据库,可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库id。 快照（snapshotting）1234567891011save &lt;seconds&gt; &lt;changes&gt;Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。stop-writes-on-bgsave-error yes //默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作，这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难。rdbcompression yes //对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。rdbchecksum yes //在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果你希望获取到最大的性能提升，可以关闭此功能。dbfilename dump.rdb //设置数据库名字。dir ./ //指定本地数据库存放目录。 复制（replication）123456789101112131415slaveof &lt;masterip&gt; &lt;masterport&gt; //设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步。masterauth &lt;master-password&gt; //当master服务设置了密码保护时，slav服务连接master的密码。requirepass foobared //设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭slave-read-only yes //你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve的数据在同master同步之后将很容易被删除，自从redis2.6版本之后，默认从redis为只读。rename-command CONFIG //只读的从redis并不适合直接暴露给不可信的客户端。为了尽量降低风险，可以使用rename-command指令来将一些可能有破坏力的命令重命名，避免外部直接调用。repl-ping-slave-period 10 //从redis会周期性的向主redis发出PING包。你可以通过repl_ping_slave_period指令来控制其周期。默认是10秒。repl-timeout 60//在主从同步时，可能在这些情况下会有超时发生：以从redis的角度来看，当有大规模IO传输时，//以从redis的角度来看，当数据传输或PING时，主redis超时//以主redis的角度来看，在回复从redis的PING时，从redis超时repl-disable-tcp-nodelay no //我们可以控制在主从同步时是否禁用TCP_NODELAY。如果开启TCP_NODELAY，那么主redis会使用更少的TCP包和更少的带宽来向从redis传输数据。但是这可能会增加一些同步的延迟，大概会达到40毫秒左右。如果你关闭了TCP_NODELAY，那么数据同步的延迟时间会降低，但是会消耗更多的带宽。repl-backlog-size 1mb //队列长度（backlog)是主redis中的一个缓冲区，在与从redis断开连接期间，主redis会用这个缓冲区来缓存应该发给从redis的数据。repl-backlog-ttl 3600 //如果主redis等了一段时间之后，还是无法连接到从redis，那么缓冲队列中的数据将被清理掉。如果设置为0，则表示永远不清理。默认是1个小时。slave-priority 100 //我们可以给众多的从redis设置优先级，在主redis持续工作不正常的情况，优先级高的从redis将会升级为主redis。而编号越小，优先级越高。当优先级被设置为0时，这个从redis将永远也不会被选中。min-slaves-to-write 3min-slaves-max-lag 10//有超过M个从redis的连接延时大于N秒，那么主redis就停止接受外来的写请求。假如有大于等于3个从redis的连接延迟大于10秒，那么主redis就不再接受外部的写请求。上述两个配置中有一个被置为0，则这个特性将被关闭。 安全（security）12requirepass luckylau //你的redis-server处于一个不太可信的网络环境中时，相信你会用上这个功能。由于redis性能非常高，所以每秒钟可以完成多达15万次的密码尝试，所以你最好设置一个足够复杂的密码，否则很容易被黑客破解。rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c89 //redis允许我们对redis指令进行更名,当为&quot;&quot;空串时候为禁用掉该命令。 限制（limits）1234maxclients 10000 //如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。maxmemory &lt;bytes//设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。如果redis无法根据移除规则来移除内存中的数据，或者我们设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。但是对于无内存申请的指令，仍然会正常响应，比如GET等。maxmemory-policy volatile-lru//volatile-lru使用LRU算法移除过期集合中的key，allkeys-lru：使用LRU算法移除key，volatile-random：在过期集合中移除随机的key，allkeys-random：移除随机的key，volatile-ttl：移除那些TTL值最小的key，即那些最近才过期的key，noeviction：不进行移除。针对写操作，只是返回错误信息。maxmemory-samples 3//LRU算法和最小TTL算法都并非是精确的算法，而是估算值。所以你可以设置样本的大小。假如redis默认会检查三个key并选择其中LRU的那个，那么你可以改变这个key样本的数量。 追加模式（append only mode）​ 追加文件（Append Only File）是一种更好的保持数据一致性的方式。即使当服务器断电时，也仅会有1秒钟的写请求丢失，当redis进程出现问题且操作系统运行正常时，甚至只会丢失一条写请求。我们建议大家，AOF机制和RDB机制可以同时使用，不会有任何冲突。 123appendonly no //指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no。appendfilename &quot;appendonly.aof&quot; //设置aof文件的名称。appendfsync everysec //no：不调用fsync()。而是让操作系统自行决定sync的时间。这种模式下，redis的性能会最快。always：在每次写请求后都调用fsync()。这种模式下，redis会相对较慢，但数据最安全。everysec：每秒钟调用一次fsync()。这是性能和安全的折衷。 ​ 当fsync方式设置为always或everysec时，如果后台持久化进程需要执行一个很大的磁盘IO操作，那么redis可能会在fsync()调用时卡住。目前尚未修复这个问题，这是因为即使我们在另一个新的线程中去执行fsync()，也会阻塞住同步写调用。​ 为了缓解这个问题，我们可以使用下面的配置项，这样的话，当BGSAVE或BGWRITEAOF运行时，fsync()在主进程中的调用会被阻止。这意味着当另一路进程正在对AOF文件进行重构时，redis的持久化功能就失效了，就好像我们设置了“appendsync none”一样。如果你的redis有时延问题，那么请将下面的选项设置为yes。否则请保持no，因为这是保证数据完整性的最安全的选择。 1no-appendfsync-on-rewrite no ​ 我们允许redis自动重写aof。当aof增长到一定规模时，redis会隐式调用BGREWRITEAOF来重写log文件，以缩减文件体积。 123auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yes //AOF文件可能在尾部是不完整的，那redis重启时load进内存的时候就有问题了，如果yes，会自动发布一个log给客户端然后load（默认）。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。注意，如果在读取的过程中，发现这个aof是损坏的，服务器也是会退出的，这个选项仅仅用于当服务器尝试读取更多的数据但又找不到相应的数据时。 LUA脚本（lua scripting）1lua-time-limit 5000 //lua脚本的最大运行时间是需要被严格限制的，要注意单位是毫秒 慢日志（slow log）​ Redis慢日志是指一个系统进行日志查询超过了指定的时长。这个时长不包括IO操作，比如与客户端的交互、发送响应内容等，而仅包括实际执行查询命令的时间。 12slowlog-log-slower-than 10000//单位是微秒，即1000000表示一秒。负数则会禁用慢日志功能，而0则表示强制记录每一个命令。slowlog-max-len 128//慢日志最大长度，可以随便填写数值，没有上限，但要注意它会消耗内存。你可以使用SLOWLOG RESET来重设这个值。 事件通知（event notification）123notify-keyspace-events &quot;&quot;//Redis能通知 Pub/Sub 客户端关于键空间发生的事件，默认关闭latency-monitor-threshold 0//redis延时监控系统在运行时会采样一些操作，以便收集可能导致延时的数据根源。通过 LATENCY命令 可以打印一些图样和获取一些报告，方便监控。这个系统仅仅记录那个执行时间大于或等于预定时间（毫秒）的操作, 这个预定时间是通过latency-monitor-threshold配置来指定的，当设置为0时，这个监控系统处于停止状态 高级配置客户端输出缓冲的控制项 1234567891011121314hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000 //HyperLogLog稀疏结构表示字节的限制。activerehashing yes//启用哈希刷新，每100个CPU毫秒会拿出1个毫秒来刷新Redis的主哈希表client-output-buffer-limit normal 0 0 0 //客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10//提高该值将在Redis空闲时使用更多的CPU时，但同时当有多个key,同时到期会使Redis的反应更灵敏，以及超时可以更精确地处理。aof-rewrite-incremental-fsync yes //当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步。 Redis的5中数据结构字符串（strings）Strings 数据结构是简单的key-value类型，value其实不仅是String，也可以是数字； 常用命令: set,get,decr,incr,mget 等； 应用场景：String是最常用的一种数据类型，普通的key/ value 存储都可以归为此类，即可以完全实现目前 Memcached 的功能，并且效率更高。还可以享受Redis的定时持久化，操作日志及 Replication等功能。除了提供与 Memcached 一样的get、set、incr、decr 等操作外，Redis还提供了下面一些操作：获取字符串长度；往字符串append内容；设置和获取字符串的某一段内容；设置及获取字符串的某一位(bit)；批量设置一系列字符串的内容； 实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr,decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。 字符串列表（lists）常用命令：lpush,rpush,lpop,rpop,lrange等。 应用场景：Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现。Lists 就是链表，我们可以轻松地实现最新消息排行等功能。Lists的另一个应用就是消息队列，可以利用Lists的PUSH操作，将任务存在Lists中，然后工作线程再用POP操作将任务取出进行执行。Redis还提供了操作Lists中某一段的api，你可以直接查询，删除Lists中某一段的元素。 实现方式：Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，也就是说对于一个具有上百万个元素的lists来说，在头部和尾部插入一个新元素，其时间复杂度是常数级别的，比如用LPUSH在10个元素的lists头部插入新元素，和在上千万元素的lists头部插入新元素的速度应该是相同的。不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。 字符串集合（sets）​ Redis的Set是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。Redis 中 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 常用命令：sadd,spop,smembers,sunion 等。 应用场景：​ Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。Sets 集合的概念就是一堆不重复值的组合。利用Redis提供的Sets数据结构，可以存储一些集合性的数据，比如在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis还为集合提供了求交集、并集、差集等操作，可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。 实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。 有序字符串集合（sorted sets）常用命令：zadd,zrange,zrem,zcard等 使用场景：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。另外还可以用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。 哈希（hashes）常用命令：hget,hset,hgetall 等。 应用场景：在Memcached中，我们经常将一些结构化的信息打包成HashMap，在客户端序列化后存储为一个字符串的值，比如用户的昵称、年龄、性别、积分等，这时候在需要修改其中某一项时，通常需要将所有值取出反序列化后，修改某一项的值，再序列化存储回去。这样不仅增大了开销，也不适用于一些可能并发操作的场合(比如两个并发的操作都需要修改积分)。而Redis的Hash结构可以使你像在数据库中Update一个属性一样只修改某一项属性值。 这里同时需要注意，Redis提供了接口(hgetall)可以直接取到全部的属性数据,但是如果内部Map的成员很多，那么涉及到遍历整个内部 Map的操作，由于Redis单线程模型的缘故，这个遍历操作可能会比较耗时，而另其它客户端的请求完全不响应，这点需要格外注意。 实现方式：上面已经说到Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。 Redis其他应用发布(Publish)与订阅(Subscribe)​ 在Redis中，你可以设定对某一个key值进行消息发布及消息订阅，当一个 key值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 Redis 管道技术​ Redis服务是一种C/S模型，提供请求－响应式协议的TCP服务，所以当客户端请求发出，服务端处理并返回结果到客户端，一般是以阻塞形式等待服务端的响应，但这在批量处理连接时延迟问题比较严重，所以Redis为了提升或弥补这个问题，引入了管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。 HyperLogLog​ Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以HyperLogLog 不能像集合那样，返回输入的各个元素。可用于在访问量巨大时候，计算记录网站每天访问的独立IP数量这样的一个功能。 显示最新的项目列表​ 在Web应用中，“列出最新的回复”之类的查询非常普遍，这通常会带来可扩展性问题。这令人沮丧，因为项目本来就是按这个顺序被创建的，但要输出这个顺序却不得不进行排序操作。类似的问题就可以用Redis来解决。比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。 ​ 我们假设数据库中的每条评论都有一个唯一的递增的ID字段。使用Redis的模板，每次新评论发表时，我们会将它的ID添加到一个Redis列表：PUSH latest.comments我们将列表裁剪为指定长度，因此Redis只需要保存最新的5000条评论：LTRIM latest.comments 0 5000；每次我们需要获取最新评论的项目范围时，如果少于5000个，就会一直询问Redis，只有在start/count参数超出了这个范围的时候，才需要去访问数据库。 排行榜相关​ 典型的比如那些在线游戏的排行榜，比如一个Facebook的游戏，根据得分你通常想要：– 列出前100名高分选手，– 列出某用户当前的全球排名这些操作对于Redis来说小菜一碟，即使你有几百万个用户，每分钟都会有几百万个新的得分。模式是这样的，每次获得新得分时，我们用这样的代码：ZADD leaderboard score userID。得到前100名高分用户很简单：ZREVRANGE leaderboard 0 99，用户的全球排名也相似，只需要：ZRANK leaderboard 。 Redis的持久化和备份​ redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。RDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。​ 其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。​ 如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 RDB​ RDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。​ 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。​ 虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。 AOF​ AOF，英文是Append Only File，即只允许追加不允许改写的文件。AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。​ 因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性。虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。​ 如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。​ 如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件：1.备份被写坏的AOF文件2.运行redis-check-aof –fix进行修复3.用diff -u来看下两个文件的差异，确认问题点4.重启redis，加载修复后的AOF文件 ​ AOF重写的内部运行原理是在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。 Redis的事务​ 事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。Redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了Redis事务处理的基础。 MULTI用来组装一个事务；EXEC用来执行一个事务；DISCARD用来取消一个事务；WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。 123456789101112131415127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; INCR 1QUEUED127.0.0.1:6379&gt; INCR 2QUEUED127.0.0.1:6379&gt; incr 3QUEUED127.0.0.1:6379&gt; PINGQUEUED127.0.0.1:6379&gt; EXEC1) (integer) 12) (integer) 13) (integer) 14) PONG ​ 在上面的例子中，我们看到了QUEUED的字样，这表示我们在用MULTI组装事务时，每一个命令都会进入到内存队列中缓存起来，如果出现QUEUED则表示我们这个命令成功插入了缓存队列，在将来执行EXEC时，这些被QUEUED的命令都会被组装成一个事务来执行。​ 对于事务的执行来说，如果redis开启了AOF持久化的话，那么一旦事务被成功执行，事务中的命令就会通过write命令一次性写到磁盘中去，如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题，那么就可能出现只有部分命令进行了AOF持久化，这时AOF文件就会出现不完整的情况，这时，我们可以使用redis-check-aof工具来修复这一问题，这个工具会将AOF文件中不完整的信息移除，确保AOF文件完整可用。有关事务，大家经常会遇到的是两类错误：调用EXEC之前的错误，调用EXEC之后的错误。​ “调用EXEC之前的错误”，有可能是由于语法有误导致的，也可能时由于内存不足导致的。只要出现某个命令无法成功写入缓冲队列的情况，redis都会进行记录，在客户端调用EXEC时，redis会拒绝执行这一事务。（Redis 2.6.5之前的版本会忽略有语法错误的命令，然后执行事务中其他语法正确的命令。就此例而言，SET key value会被执行，EXEC命令会返回一个结果：1) OK。） 12345678910127.0.0.1:6379&gt;MULTIOK127.0.0.1:6379&gt;SET key valueQUEUED127.0.0.1:6379&gt;SET key(error)ERR wrong number of arguments for &apos;set&apos; command127.0.0.1:6379&gt; errorCOMMAND key(error) ERR unknown command &apos;errorCOMMAND&apos;127.0.0.1:6379&gt;EXEC(error) EXECABORT Transaction discarded because of previous errors. ​ 而对于“调用EXEC之后的错误”，redis则采取了完全不同的策略，即redis不会理睬这些错误，而是继续向下执行事务中的其他命令。这是因为，对于应用层面的错误，并不是redis自身需要考虑和处理的问题，所以一个事务中如果某一条命令执行失败，并不会影响接下来的其他命令的执行。 最后一个就是WATCH，它本身的作用是“监视key是否被改动过”，而且支持同时监视多个key，只要还没真正触发事务，WATCH都会尽职尽责的监视，一旦发现某个key被修改了，在执行EXEC时就会返回nil，表示事务无法触发。 Redis的集群Redis的主从配置​ 像MySQL一样，redis是支持主从同步的，而且也支持一主多从以及多级从结构。主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，比如很消耗性能的SORT就可以由从服务器来承担。redis的主从同步是异步进行的，这意味着主从同步不会影响主逻辑，也不会降低redis的处理性能。主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，这样可以提高主服务器的处理性能。​ 在主从架构中，从服务器通常被设置为只读模式，这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受CONFIG等指令，所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此，那可以考虑给重要指令进行重命名，来避免命令被外人误执行。 ​ 其过程如下：从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。​ 在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。​ 另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。​ 主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。​ 增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。 Redis的Sentinel配置​ 在redis主从复制架构中，如果主服务器宕机，那么这个复制集群能否正常提供服务？答案当然是不能。Sentinel就是来解决redis复制集群主节点单点问题的，它解决的问题是：监控，即sentinel会不断的检查你的主服务器和从服务器是否运行正常；当被监控的某个redis服务器出现问题时，sentinel可以通过API向管理员或者其他应用程序发送通知；自动故障转移：当一个主服务器不能正常工作时，sentinel会开始一次自动故障转移操作，他会将失效主服务器下的一个从服务器升级为新的主服务器，并让失效主机下的其他从服务器改为复制到新的主服务器；当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器。 SpringBoot操作RedisJedisRedisTemplateredis.repositories关于以上3中操作参考文章前面的Git哦。 参考：官方RedisTemplate文档 https://docs.spring.io/spring-data/redis/docs/current/api/org/springframework/data/redis/core/RedisTemplate.html http://blog.csdn.net/yujin2010good/article/details/54729939 http://blog.csdn.net/heiyeshuwu/article/details/41248379 http://oldblog.antirez.com/post/take-advantage-of-redis-adding-it-to-your-stack.html http://coolshell.cn/articles/17416.html http://blog.sina.com.cn/s/blog_6940cab30102uy02.html http://www.cnblogs.com/lei2007/p/3837288.html http://www.jb51.net/article/56448.htm http://blog.csdn.net/zfl092005/article/details/17523945 https://www.cnblogs.com/LiZhiW/p/4851631.html http://www.cnblogs.com/jager/p/6349860.html https://docs.spring.io/spring-data/redis/docs/1.7.6.RELEASE/reference/html/#redis.repositories]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之注解]]></title>
      <url>%2F2017%2F08%2F08%2F%E4%BD%A0%E6%87%82java%E5%90%97-20%2F</url>
      <content type="text"><![CDATA[java的注解（Annotation）机制 什么是注解？​ 在JDK中我们经常看到@Override @SuppressWarnings(“unchecked”)，@Deprecated这三种注解。我们好奇的点开其中的一个实现，代码非常简单。其实在我们使用各种开发框架时候，注解也是经常用到的相关的代码，比如SpringBoot里的@RestController，@Autowired等。下面我们就详细介绍一下注解。 12345//@Override@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125; 如何自定义注解？Java5.0定义了4个标准的meta-annotation类型：@Target，@Retention，@Documented，@Inherited。 @Target​ 说明了Annotation所修饰的对象范围：Annotation可被用于 packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。 1234567ElementType.CONSTRUCTOR:用于描述构造器ElementType.FIELD:用于描述域ElementType.LOCAL_VARIABLE:用于描述局部变量ElementType.METHOD:用于描述方法ElementType.PACKAGE:用于描述包ElementType.PARAMETER:用于描述参数ElementType.TYPE:用于描述类、接口(包括注解类型) 或enum声明 12345@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings &#123; String[] value();&#125; @Retention定义该注解的生命周期。 123RetentionPolicy.SOURCE //在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override,RetentionPolicy.CLASS //在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式。RetentionPolicy.RUNTIME //始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。 @Documented是否将注解信息添加在java文档中。 @Inherited定义该注释和子类的关系，是否允许子类继承该注解。 自定义注解的格式： 1public @interface 注解名 &#123;定义体&#125; 注意事项： 1.可支持基本数据类型，String类型，Class类型，enum类型，Annotation类型，以上所有类型的数组。 2.只能用public或默认(default)这两个访问权修饰.例如,String value();这里把方法设为default默认类型。 3.如果只有一个参数成员,最好把参数名称设为”value”。 示例说明？当RetentionPolicy.RUNTIME为RetentionPolicy.SOURCE或者RetentionPolicy.CLASS是无打印输出的。 12345678910111213import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Contacts &#123; String name() default "luckylau"; String email() default "laujunbupt0913@163.com";&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Maindemo &#123; @Contacts public void output()&#123; System.out.println("output is running"); &#125; @Contacts(name="bilibili",email="bili@bili.com") public void output2()&#123; System.out.println("output2 is running"); &#125; public static void main(String[] args) &#123; Class&lt;Maindemo&gt; myTestClass = Maindemo.class; try &#123; Method method = myTestClass.getMethod("output", new Class[]&#123;&#125;); if (method.isAnnotationPresent(Contacts.class)) &#123; // 获得注解 Contacts annotation = method.getAnnotation(Contacts.class); // 调用注解的内容 System.out.println(annotation.name()); System.out.println(annotation.email()); &#125; &#125; catch (NoSuchMethodException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (SecurityException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; try &#123; Method method = myTestClass.getMethod("output2", new Class[]&#123;&#125;); if (method.isAnnotationPresent(Contacts.class)) &#123; // 获得注解 Contacts annotation = method.getAnnotation(Contacts.class); // 调用注解的内容 System.out.println(annotation.name()); System.out.println(annotation.email()); &#125; &#125; catch (NoSuchMethodException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (SecurityException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot之Swagger2]]></title>
      <url>%2F2017%2F08%2F05%2FSpringBoot%E4%B9%8BSwagger2%2F</url>
      <content type="text"><![CDATA[​ Swagger 2是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。下面介绍如何使用Swagger 2。 配置Swagger 2的依赖12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt; 创建Swagger2配置类在 Application.java 同级创建 Swagger2.java 12345678910111213141516171819202122@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("org.comunication.messagesent.mechanism.api.controller")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .contact("luckylau") .version("1.0") .build(); &#125;&#125; ​ 通过@Configuration注解，让Spring来加载该类配置。再通过@EnableSwagger2注解来启用Swagger2。通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容。 API控制层配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@RestController@RequestMapping(path = "/messageSent", produces = &#123; "application/json;charset=UTF-8" &#125;)@Api(value = "API统一管理入口")public class MessageSendController &#123; private static final Logger logger = LoggerFactory.getLogger(MessageSendController.class); @Autowired private SenderService senderService; @ApiOperation(value = "创建用户", notes = "根据SenderInfo对象创建用户") @ApiImplicitParam(name = "senderInfo", value = "用户详细实体", required = true, dataType = "SenderInfo") @RequestMapping(value = "/sender", method = RequestMethod.POST) public SenderInfo addSender(@RequestBody SenderInfo senderInfo) throws ApiException &#123; logger.info("添加用户成员" + senderInfo.toString()); try &#123; return senderService.addSender(senderInfo); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block throw new ApiException(e.getMessage()); &#125; &#125; @ApiOperation(value = "列出所有的用户成员") @RequestMapping(value = "/senders", method = RequestMethod.GET) public List&lt;SenderInfo&gt; listSenders() &#123; logger.info("列出所有的用户成员"); return senderService.findAllSenderInfo(); &#125; @ApiOperation(value = "根据别名获取用户信息") @ApiImplicitParam(name = "alias", value = "用户别名", required = true, paramType = "path", dataType = "String") @RequestMapping(value = "/sender/&#123;alias&#125;", method = RequestMethod.GET) public SenderInfo getSender(@PathVariable("alias") String alias) &#123; logger.info("获取别名为 " + alias + " 用户"); SenderInfo si = senderService.findByAlias(alias); return si; &#125; @ApiOperation(value = "根据别名删除用户信息") @ApiImplicitParam(name = "alias", value = "用户别名", required = true, paramType = "path", dataType = "String") @RequestMapping(value = "/sender/&#123;alias&#125;", method = RequestMethod.DELETE) public void deleteSender(@PathVariable("alias") String alias) &#123; logger.info("删除别名为 " + alias + " 用户"); senderService.deleteSender(alias); &#125; @ApiOperation(value = "删除所有的用户成员") @RequestMapping(value = "/senders", method = RequestMethod.DELETE) public void deleteAllSender() &#123; logger.info("删除所有的用户"); senderService.deleteAllSender(); &#125; @ApiOperation(value = "更新用户是否激活的状态", notes = "根据url的别名来指定更新对象") @RequestMapping(value = "/sender/&#123;alias&#125;", method = RequestMethod.PUT) @ApiImplicitParams(&#123; @ApiImplicitParam(name = "alias", value = "用户别名", required = true, paramType = "path", dataType = "String"), @ApiImplicitParam(name = "isActive", value = "是否激活", required = true, paramType = "form", dataType = "Boolean") &#125;) public SenderInfo updateSender(@PathVariable("alias") String alias, @RequestParam("isActive") Boolean isActive) &#123; logger.info("修改别名为 " + alias + " 用户的状态"); return senderService.modifyActive(alias, isActive); &#125;&#125; @Api：用在类上，说明该类的作用，如：@Api(value = “API统一管理入口”)@ApiOperation：用在方法上，说明方法的作用@ApiImplicitParams：用在方法上包含一组参数说明@ApiImplicitParam：可以单独使用，也可以用在 @ApiImplicitParams 注解中；用户要了解其参数含义：name：参数名；value：参数的意思；required：参数是否必须传；paramType包括5种类型，分别是 header –&gt; 请求参数的获取：@RequestHeader， query –&gt;请求参数的获取：@RequestParam，path –&gt; 请求参数的获取：@PathVariable，可以不显示标记，body –&gt;如果paramType为空时候，会默认为body，form–&gt;请求参数的获取：@RequestParam。dataType：参数类型。 项目为：MessagePushandEmailSend]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron之OVS]]></title>
      <url>%2F2017%2F07%2F30%2FNeutron%E4%B9%8Bovs%2F</url>
      <content type="text"><![CDATA[​ OVS即开放虚拟交换标准，不仅仅是为了支持OpenFlow协议，而是为了给虚拟化平台上运行的虚拟机实例提供一套纯软件实现的路由交换协议栈。具体点说，Open vSwitch是在开源的Apache2.0许可下的产品级质量的多层虚拟交换标准！它旨在通过编程扩展，使庞大的网络自动化（配置、管理、维护），同时还支持标准的管理接口和协议（如NetFlow， sFlow， SPAN， RSPAN， CLI， LACP，802.1ag）。 Standard 802.1Q VLAN model with trunk and access ports;NIC bonding with or without LACP on upstream switch;NetFlow, sFlow(R), and mirroring for increased visibility;QoS (Quality of Service) configuration, plus policing;Geneve, GRE, GRE over IPSEC, VXLAN, and LISP tunneling;802.1ag connectivity fault management;OpenFlow 1.0 plus numerous extensions;Transactional configuration database with C and Python bindings;High-performance forwarding using a Linux kernel module; ​ OVS bridge 有两种模式：“normal” 和 “flow”。“normal” 模式的 bridge 同普通的 Linux 桥，而 “flow” 模式的 bridge 是根据其流表（flow tables） 来进行转发的。Neutron 使用两种 OVS bridge：br-int 和 br-tun。其中，br-int 是一个 “normal” 模式的虚拟网桥，而 br-tun 是 “flow” 模式的，它比 br-int 复杂得多。详情参考：Neutron二层网络服务实现原理 OVS基础架构 Open vSwitch分为三层： 1)管理层即：ovs-dpctl、ovs-vsctl、ovs-ofctl、ovsdb-tool。2)业务逻辑层即：vswitchd、ovsdb。3)底层服务层即：datapath。 ovs-vswitchd：守护程序，实现交换功能，和Linux内核兼容模块一起，实现基于流的交换flow-based switching。ovsdb：轻量级的数据库服务，主要保存了整个OVS的配置信息，包括接口，交换内容，VLAN等等。ovs-vswitchd会根据数据库中的配置信息工作。ovs-dpctl：一个工具，用来配置交换机内核模块，可以控制转发规则。ovs-vsctl：主要是获取或者更改ovs-vswitchd的配置信息，此工具操作的时候会更新ovsdb-server中的数据库。ovs-ofctl：用来查询和控制Ovs作为Openflow交换机和控制器。 OVS常见命令ovs-vsctl 系列添加网桥 ovs-vsctl add-br br-int 列出网桥 ovs-vsctl list-br 给网桥添加端口 ovs-vsctl add-port br-int tap-xxx 列出挂载某网络接口的所有网桥 ovs-vsctl port-to-br tap-xxx 查看全部信息 ovs-vsctl show ovs-ofctl 系列查看所有网桥 ovs-vsctl list bridge 查看br-tun网桥 ovs-ofctl show br-tun 查看br-tun网桥上所有端口的状态ovs-ofctl dump-ports br-tun 添加一条流表规则 丢弃从port2上发来的所有数据表 ovs-ofctl add-flow br-tun idle_timeout=120,in_port=2,actions=drop 其中每条流规则由一系列字段组成，分为基本字段、条件字段和动作字段三部分。基本字段包括: 生效时间 duration_sec，所属表项 table_id，优先级 priority，处理的数据包数 n_packets，空闲超时时间 idle_timeout ，其中 idle_timeout 以秒为单位，超过设置的空闲超时时间后该流规则将被自动删除，空闲超时时间设置为 0 表示该流规则永不过期，idle_timeout 将不包含于 ovs-ofctl dump-flows brname 的输出中。 条件字段包括: 输入端口号 in_port，dl_vlan=vlan（数据包的 VLAN Tag 值，范围是 0-4095，0xffff 代表不包含 VLAN Tag 的数据包），源目的 mac 地址 dl_src/dl_dst，源目的 ip 地址 nw_src/nw_dst，数据包类型 dl_type，网络层协议类型 nw_proto，匹配源或者目标的 MAC 地址01:00:00:00:00:00/01:00:00:00:00:00 代表广播地址，00:00:00:00:00:00/01:00:00:00:00:00 代表单播地址，dl_type=ethertype匹配以太网协议类型，dl_type=0x0800 代表 IPv4 协议，dl_type=0x086dd 代表 IPv6 协议，dl_type=0x0806 代表 ARP 协议。这些字段可以任意组合，但在网络分层结构中底层的字段未给出确定值时上层的字段不允许给确定值，即一 条流规则中允许底层协议字段指定为确定值，高层协议字段指定为通配符(不指定即为匹配任何值)，而不允许高层协议字段指定为确定值， 而底层协议字段却为通配符(不指定即为匹配任何值)，否则，ovs-vswitchd 中的流规则将全部丢失，网络无法连接。 动作字段包括:正常转发 normal、定向到某交换机端口 output：port、丢弃 drop、mod_vlan_vid、strip_vlan、更改源目的 mac 地址 mod_dl_src/mod_dl_dst 等，一条流规则可有多个动作，动作执行按指定的先后顺序依次完成。 参考：http://www.sdnlab.com/resource/12818.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（8）]]></title>
      <url>%2F2017%2F07%2F27%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%888%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解排序，代码均为自己实现。 排序方法 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n^2) O(n) O(n^2) O(1) 稳定 简单选择排序 O(n^2) O(n^2) O(n^2) O(1) 稳定 直接插入排序 O(n^2) O(n) O(n^2) O(1) 稳定 希尔排序 O(nlogn)~O(n^2) O(n^1.3) O(n^2) O(1) 不稳定 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳定 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 稳定 快速排序 O(nlogn) O(nlogn) O(n^2) O(logn)~O(n) 不稳定 排序的基本概念​ 假设含有n个记录的序列为{r1,r2,……,rn}，其相应的关键字分别为{k1,k2,……,kn}，需确定1，2，……，n的一种排列p1,p2,……,pn，使其相应的关键字满足kp1≤kp2≤……≤kpn（非递减或非递增）关系，即使得序列成为一个按关键字有序的序列{rp1,rp2,……,rpn}，这样的操作就称为排序。假设ki=kj（1≤i≤n,1≤j≤n,i≠j），且在排序前的序列中ri领先于rj（即i&lt;j）。如果排序后ri仍领先于rj，则称所用的排序方法是稳定的；反之，若可能使得排序后的序列中rj领先ri，则称所用的排序方法是不稳定的。 ​ 内排序与外排序：根据在排序过程中待排序的记录是否全部被放置在内存中。内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中。外排序是由于排序的记录个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多次交换数据才能进行。 对于内排序来说，排序算法的性能主要是受三个方面影响：时间性能；辅助空间；算法的复杂性。 排序的结构图如下： 交换排序冒泡排序实现一： 12345678910111213141516171819202122232425public class BubbleSort &#123; public void bubbleSort(int[]nums)&#123; if(nums.length == 0)&#123; return; &#125; for(int i = 1 ;i &lt; nums.length; i++)&#123; for(int j = nums.length - 1 ; j &gt;= i ; j--)&#123; if(nums[j] &lt; nums[j - 1])&#123; int tmp = nums[j]; nums[j] = nums[j-1]; nums[j-1]=tmp; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] nums = &#123;1,2,7,4,9,8,5&#125;; System.out.println(Arrays.toString(nums)); BubbleSort bubbleSort = new BubbleSort(); bubbleSort.bubbleSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 实现二： 123456789101112131415161718192021222324252627public class BubbleSort &#123; public void bubbleSort(int[]nums)&#123; if(nums.length == 0)&#123; return; &#125; boolean flag = true; for(int i = 1 ;i &lt; nums.length &amp;&amp; flag; i++)&#123; flag =false; for(int j = nums.length - 1 ; j &gt;= i ; j--)&#123; if(nums[j] &lt; nums[j - 1])&#123; int tmp = nums[j]; nums[j] = nums[j-1]; nums[j-1]=tmp; flag = true; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] nums = &#123;2,1,3,4,5,6,7,8,9&#125;; System.out.println(Arrays.toString(nums)); BubbleSort bubbleSort = new BubbleSort(); bubbleSort.bubbleSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 快速排序12345678910111213141516171819202122232425262728293031323334353637383940public class QuickSort &#123; public void quickSort(int[] nums)&#123; if(nums.length == 0)&#123; return; &#125; int low = 0; int high = nums.length - 1; helper(nums,low,high); &#125; private void helper(int[]nums, int low ,int high)&#123; if(low &lt; high)&#123; int pivot = Partition(nums ,low,high); helper(nums,0,pivot - 1); helper(nums,pivot + 1,high); &#125; &#125; private int Partition(int[] nums, int low ,int high)&#123; int tmp =nums[low]; while(low &lt; high)&#123; while(low &lt; high &amp;&amp; nums[high] &gt;= tmp)&#123; high--; &#125; nums[low] =nums[high]; while(low &lt; high &amp;&amp; nums[low] &lt;= tmp)&#123; low++; &#125; nums[high]=nums[low]; &#125; nums[low] = tmp; return low; &#125; public static void main(String[] args) &#123; int[] nums = &#123;2,1,3,4,5,6,7,8,9&#125;; System.out.println(Arrays.toString(nums)); QuickSort quickSort = new QuickSort(); quickSort.quickSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 插入排序直接插入排序12345678910111213141516171819202122232425public class InsertionSort &#123; public void insertionSort(int[] nums) &#123; if (nums.length == 0) &#123; return; &#125; int len = nums.length; for (int i = 1; i &lt; len; i++) &#123; for (int j = i; j &gt; 0; j--) &#123; if (nums[j] &lt; nums[j - 1]) &#123; int tmp = nums[j]; nums[j] = nums[j - 1]; nums[j - 1] = tmp; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 2, 1, 3, 4, 9, 6, 7, 8, 5 &#125;; System.out.println(Arrays.toString(nums)); InsertionSort insertionSort = new InsertionSort(); insertionSort.insertionSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 希尔排序1234567891011121314151617181920212223242526272829public class ShellSort &#123; public void shellSort(int[] nums) &#123; if (nums.length == 0) &#123; return; &#125; int len = nums.length; int increment = len / 2; while (increment &gt;= 1) &#123; for (int i = 0; i &lt; len; i++) &#123; for (int j = i; j &lt; len - increment; j += increment) &#123; if (nums[j] &gt; nums[j + increment]) &#123; int tmp = nums[j]; nums[j] = nums[j + increment]; nums[j + increment] = tmp; &#125; &#125; &#125; increment = increment / 2; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 2, 1, 3, 4, 9, 6, 7, 8, 5 &#125;; System.out.println(Arrays.toString(nums)); ShellSort shellSort = new ShellSort(); shellSort.shellSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 选择排序简单选择排序123456789101112131415161718192021222324252627282930public class SelectSort &#123; public void selectSort(int[] nums) &#123; if(nums.length == 0)&#123; return; &#125; int len = nums.length; int min; for(int i = 0 ; i &lt; len; i++)&#123; min = i; for(int j = min + 1; j &lt; len ; j++)&#123; if(nums[j] &lt; nums[min])&#123; min = j; &#125; &#125; if( min != i)&#123; int tmp = nums[min]; nums[min] = nums[i]; nums[i] = tmp; &#125; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 2, 1, 3, 4, 9, 6, 7, 8, 5 &#125;; System.out.println(Arrays.toString(nums)); SelectSort selectSort = new SelectSort(); selectSort.selectSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 堆排序12345678910111213141516171819202122232425262728293031323334353637383940public class HeapSort &#123; public void heapSort(int[] nums) &#123; if (nums.length == 0) &#123; return; &#125; int len = nums.length; for (int i = len / 2; i &gt;= 0; i--) &#123; HeapAdjust(nums, i, len); &#125; for (int i = len - 1; i &gt;= 1; i--) &#123; int tmp = nums[0]; nums[0] = nums[i]; nums[i] = tmp; HeapAdjust(nums, 0, i - 1); &#125; &#125; private void HeapAdjust(int[] nums, int index, int length) &#123; int tmp = nums[index]; for (int i = 2 * index + 1; i &lt; length - 1; i = 2 * i + 1) &#123; if (nums[i] &lt; nums[i + 1]) &#123; i++; &#125; if (tmp &gt;= nums[i]) &#123; break; &#125; nums[index] = nums[i]; index = i; &#125; nums[index] = tmp; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 2, 1, 3, 4, 9, 6, 7, 8, 5 &#125;; System.out.println(Arrays.toString(nums)); HeapSort HeapSort = new HeapSort(); HeapSort.heapSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 归并排序递归实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class MergeSort &#123; public void mergeSort(int[] nums) &#123; if (nums.length == 0) &#123; return; &#125; int len = nums.length; helper(nums, 0, len - 1); &#125; private void helper(int[] nums, int left, int right) &#123; if (left &lt; right) &#123; int mid = left + (right - left) / 2; helper(nums, left, mid); helper(nums, mid + 1, right); merge(nums, left, mid, right); &#125; &#125; private void merge(int[] nums, int left,int mid, int right) &#123; int i = left; int j = mid + 1; int count = 0; int[] tmp = new int[right - left + 1]; while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (nums[i] &lt; nums[j]) &#123; tmp[count++] = nums[i++]; &#125; else &#123; tmp[count++] = nums[j++]; &#125; &#125; while (i &lt;= mid) &#123; tmp[count++] = nums[i++]; &#125; while (j &lt;= right) &#123; tmp[count++] = nums[j++]; &#125; count = 0; while (left &lt;= right) &#123; nums[left++] = tmp[count++]; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 2, 1, 3, 4, 9, 6, 7, 8, 5 &#125;; System.out.println(Arrays.toString(nums)); MergeSort MergeSort = new MergeSort(); MergeSort.mergeSort(nums); System.out.println(Arrays.toString(nums)); &#125;&#125; 非递归实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class MergeSort &#123; public void mergeSort(int[] nums) &#123; if (nums.length == 0) &#123; return; &#125; int sublen = 1; int length = nums.length; while (sublen &lt; length) &#123; for (int i = 0; i &lt; length; i += 2 * sublen) &#123; merge(nums, i, sublen); &#125; sublen *= 2; &#125; &#125; private void merge(int[] nums, int i, int sublen) &#123; int start = i; int count = 0; int[] tmp = new int[2 * sublen]; int frontlen = nums.length &gt; (i + sublen) ? (i + sublen) : nums.length; int j = i + sublen; int rearlen = nums.length &gt; (j + sublen) ? (j + sublen) : nums.length; while (i &lt; frontlen &amp;&amp; j &lt; rearlen) &#123; if (nums[i] &lt; nums[j]) &#123; tmp[count++] = nums[i++]; &#125; else &#123; tmp[count++] = nums[j++]; &#125; &#125; while (i &lt; frontlen) &#123; tmp[count++] = nums[i++]; &#125; while (j &lt; rearlen) &#123; tmp[count++] = nums[j++]; &#125; for (int k = 0; k &lt; count; k++) &#123; nums[start++] = tmp[k]; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 2, 1, 3, 4, 9, 6, 7, 8, 5, 10, 5, 6 &#125;; System.out.println(Arrays.toString(nums)); MergeSort MergeSort = new MergeSort(); MergeSort.mergeSort(nums); System.out.println(Arrays.toString(nums));&#125; 基数排序基于两种不同的排序顺序，我们将基数排序分为LSD（Least significant digital）或MSD（Most significant digital），LSD的排序方式由数值的最右边（低位）开始，而MSD则相反，由数值的最左边（高位）开始。注意一点：LSD的基数排序适用于位数少的数列，如果位数多的话，使用MSD的效率会比较好。 http://www.cnblogs.com/Braveliu/archive/2013/01/21/2870201.html 1234567891011121314151617181920212223242526272829303132333435363738public class RadixSort &#123; public void radixSort(int[]nums ,int radix , int digit)&#123; if(nums.length == 0)&#123; return; &#125; int[] tmp = new int[nums.length]; int[] buckets = new int[radix]; for( int i = 0 , rate = 1; i &lt;= digit; i++)&#123; Arrays.fill(buckets, 0); System.arraycopy(nums, 0, tmp, 0, nums.length); for( int j = 0 ; j &lt; nums.length; j++)&#123; int subKey = (nums[j]/rate)%radix; buckets[subKey]++; &#125; for (int j =1 ; j &lt; radix ; j++)&#123; buckets[j] = buckets[j] + buckets[j - 1]; &#125; for (int k = nums.length - 1; k &gt;=0 ;k--)&#123; int subKey =(tmp[k]/rate)%radix; nums[--buckets[subKey]] = tmp[k]; &#125; rate *=radix; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] nums = &#123; 200, 1, 3, 42, 9, 64, 7, 81, 5, 10, 52, 61 &#125;; System.out.println(Arrays.toString(nums)); RadixSort RadixSort = new RadixSort(); RadixSort.radixSort(nums, 10, 3); System.out.println(Arrays.toString(nums)); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（7）]]></title>
      <url>%2F2017%2F07%2F25%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%887%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解查找，代码均为自己实现。 查找（Searching）是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 顺序表查找​ 顺序查找又叫线性查找，是最基本的查找技术，它的查找过程是：从表中第一个（或最后一个）记录开始，逐个记性记录的关键字和给定值比较，若某个记录的关键字和给定值相等，则查找成功，找到所查的记录；如果直到最后一个（或第一个）记录，其关键字和给定值比较都不等时，则表中没有所查的记录，查找不成功。 12345678910111213141516public class OrderSearch &#123; public int orderSearch(int[] array ,int key)&#123; for ( int i = 0 ;i &lt; array.length ; i++)&#123; if(array[i] == key)&#123; return i; &#125; &#125; return -1; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] array = new int[]&#123;1,3,5,2,9,7&#125;; OrderSearch OrderSearch = new OrderSearch(); System.out.println(OrderSearch.orderSearch(array,9)); &#125;&#125; 有序表查找折半查找​ 折半查找又称二分查找。它的前提是线性表中的记录必须是关键码有序（通常是从小到大有序），线性表必须采用顺序存储。​ 折半查找的基本思想是：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键字相等，则查找成功；若给定值小于中间记录的关键字，则在中间记录的左半区继续查找；若给定值大于中间记录的关键字，则在中间记录的右半区继续查找。不断重复上述过程，直到查找成功，或所有查找区域无记录，查找失败为止。 时间复杂度为O(logn） 1234567891011121314151617181920212223242526272829303132public class BinarySearch &#123; public int binarySearch(int[] array , int key)&#123; if(nums.length==0)&#123; return -1; &#125; int start=0; int end=nums.length-1; while(start+1&lt;end)&#123; int mid=start+(end-start)/2; if(nums[mid]==target)&#123; return mid; &#125;else if (nums[mid]&gt;target)&#123; end=mid; &#125;else&#123; start=mid; &#125; &#125; if(nums[start]==target || nums[end]==target)&#123; return nums[start]==target ? start: end; &#125; return -1; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] array = new int[]&#123;1,2,5,8,9,17&#125;; BinarySearch binarySearch = new BinarySearch(); System.out.println(binarySearch.binarySearch(array, 17)); &#125;&#125; 插值查找​ 算法思想：插值查找的关键是根据要查找的关键字key与查找表中最大最小记录的关键字比较后的查找方法，其核心就在于插值的计算公式(key-a[low])/(a[high]-a[low])。 ​ 时间复杂度：从时间复杂度上看，它也是O(logn) ​ 优缺点：对于表长比较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比这般查找要好很多。 斐波那契查找算法思想：依然是对查找点的优化，采用Fibonacci数组，找到对于当前长度的有序表的黄金分割点，作为每次的中间值。 时间复杂度：时间复杂度和其他两种有序表查找相同，都是O(logn) 优缺点：对于平均性能，斐波那契查找要优于折半查找，但如果是最坏情况，查找效率低于折半查找。 小结：有序表查找是一种针对查找优化的表结构，查找的时间复杂度是O(logn)。但有序表的插入和删除性能是比较差的，插入和删除不能破坏有序表的特性。 线性索引查找​ 索引是把一个关键字与它对应的记录相关联的过程。一个索引由若干个索引构成，每个索引项至少应包含关键字和其对应的记录在存储器中的位置等信息。​ 线性索引是将索引项集合组织为线性结构，称为索引表。 以下重点介绍三种线性索引：稠密索引、分块索引、倒排索引。 稠密索引稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项。 算法思想：稠密索引要应对的可能是成千上万的数据，因此对于稠密索引这个索引表来说，索引项一定是按照关键码有序的排列。因此可以对索引使用折半、插值、斐波那契等有序表查找算法，大大提高了效率。 时间复杂度：因为对于索引的查找使用的也是有序表的查找算法，时间复杂度是O(logn)。 优缺点：和有序表类似的是，稠密索引必须要维护索引的有序性。另外如果数据量很大，也要同时维护一个同样规模的索引，可能就需要反复访问磁盘，降低了查找性能。 分块索引算法思想：如果对索引进行一次分级呢？对于一级索引下，可能会有多个记录，称之为一个块，块内的记录再获得一个二级的索引。这些块有一个条件，就是块内无序，块间有序。块内无序就是在一级索引内部的记录可以是无序的，只要落在索引的范围内就可以；块间有序就是下一个块所有的关键字都要大于上一个块的最大关键字。因此对于一个块结构来讲，它具有最大关键码，块中的记录个数和指向块首数据的指针。 时间复杂度：分块索引在查找时，先找到查找记录所在的块，在查找在块内的为孩子。设n个记录，平均分成m个块，每个块有t个记录，这样平均查找次数就是(m+1)/2 + (t+1)/2 = (n/t + t)/2 + 1 &gt;= logn + 1。所以分块索引的时间复杂度介于O(n)和O(logn)之间。 分块索引兼顾了有序和无序的需求，平衡了插入，删除和查找的性能，普遍用于数据库查找技术等。 倒排索引算法思想：倒排索引主要应用于搜索引擎。基本思想就是将得到的key-value关系进行一个反映射，得到某个value有多少个key指向它。比如查找某个单词出现在哪些文章中，可以先访问文章中的所有单词，建立一个单词的索引，将出现该单词的文章记录到索引中。这样在搜索时直接输入单词，就能得到文章列表。 优缺点：倒排索引的优点是速度快，缺点就是记录不等长，维护比较困难，插入和删除都要做相应的处理。比如删除某个文章，就可能要对所有的单词都进行考察。 二叉排序树算法思想：有序表的问题就是如果插入一个较小的记录，就要把比它大的记录依次移动，腾出插入的位置。如果用二叉树来实现呢，只需要让这个较小的记录成为某个结点的左孩子就可以了。为什么是左孩子呢，和二叉排序数的定义有关，简单来说，二叉排序树的中序遍历就是一个有序表。这样插入任何一个记录都不需要改变已经建好的树。 查找：查找某个记录时，从根结点开始，如果查找记录大于该结点的值，就走右子树；如果小于该结点的值，就走左子树。不断向下查找，直到找到该记录，或者到叶子结点的值和查找记录不同，未找到该记录。 插入：插入和查找类似，向下找到最接近它的结点，然后把该记录作为它的左孩子或者右孩子。 删除：删除相对查找和插入来讲复杂一点，主要复杂在如果处理它的子树。下面的算法是这么处理的：首先获取要删除的节点的parent节点，如果找不到直接返回；找到parent之后，判断删除节点是parent节点的左节点还是右节点，并保存在一个临时的tmp节点；接下来要做删除操作，首先判断的是删除节点是否具有右节点：如果没有右节点的话，且删除节点是parent左节点，就直接让parent左节点指向删除节点的左节点，如果删除节点是parent右节点，同样直接让parent右节点指向删除节点的左节点；没有右节点是最好处理的情况，最复杂的是删除节点有右节点：首先将删除节点记录为father ,删除节点的右节点为tmp；如果tmp没有左节点，只有右节点最好处理了，直接移除father，将tmp补在father；如果tmp有左节点，我们不断向下直到找到最底下的左节点，将其替换删除节点即可。 时间复杂度：如果二叉排序树是平衡的，那么查找的时间复杂度是O(logn)；如果是不平衡，比如最极端的斜树，那么时间复杂度是O(n)。 优缺点：二叉排序树保留了有序表查找高效的特点，最理想的情况能达到O(logn)的时间复杂度，并且解决了插入和删除记录的问题，能够保证树的整体结构不受影响。缺点就是可能在插入的过程中，二叉排序树不能保持平衡，出现了某一边的树远远大于另一边，降低了查找的效率。后面提到的平衡二叉树解决了这个问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class BinarySearchTree &#123;//构建二叉搜索树 public TreeNode createBinarySearch(TreeNode root, TreeNode node) &#123; // write your code here if( root == null ) &#123; return node; &#125; if(root.val &gt; node.val)&#123; root.left = createBinarySearch(root.left,node); &#125;else &#123; root.right = createBinarySearch(root.right,node); &#125; return root; &#125; //移除一个元素 public TreeNode removeNodeFromBinarySearch(TreeNode root, int value) &#123; // write your code here TreeNode dummy = new TreeNode(-1); dummy.left = root; TreeNode parent = findNode(dummy, root,value); TreeNode tmp; if(parent.left !=null &amp;&amp; parent.left.val == value)&#123; tmp =parent.left; &#125;else if (parent.right !=null &amp;&amp; parent.right.val == value)&#123; tmp =parent.right; &#125;else &#123; return dummy.left; &#125; deleteNode(parent,tmp); return dummy.left; &#125; private TreeNode findNode(TreeNode parent , TreeNode node, int value) &#123; if( node == null) &#123; return parent; &#125; if(node.val == value) &#123; return parent; &#125; if(node.val &gt; value) &#123; return findNode(node, node.left,value); &#125;else&#123; return findNode(node,node.right,value); &#125; &#125; private void deleteNode(TreeNode parent, TreeNode node) &#123; if(node.right == null)&#123; if(parent.left ==node) &#123; parent.left = node.left; &#125;else &#123; parent.right = node.left; &#125; &#125;else &#123; TreeNode father = node; TreeNode tmp = node.right; while( tmp.left != null)&#123; father = tmp; tmp = tmp.left; &#125; if(father.left == tmp ) &#123; father.left = tmp.right; &#125;else &#123; father.right = tmp.right; &#125; if(parent.left == node) &#123; parent.left = tmp; &#125;else &#123; parent.right = tmp; &#125; tmp.left = node.left; tmp.right = node.right; &#125; &#125; //搜索一个元素是否存在 public boolean searchBinaryTree(TreeNode root, int value)&#123; if(root == null)&#123; return false; &#125; System.out.println(root.val); if(root.val == value)&#123; return true; &#125; if(root.val &gt; value)&#123; return searchBinaryTree(root.left,value); &#125;else&#123; return searchBinaryTree(root.right,value); &#125; &#125; public static void main(String[] args) &#123; BinarySearchTree BinarySearchTree = new BinarySearchTree(); TreeNode root = new TreeNode(8); root.left = new TreeNode(3); System.out.println(BinarySearchTree.searchBinaryTree(root, 8)); BinarySearchTree.createBinarySearch(root, new TreeNode(9)); System.out.println(root.right.val); BinarySearchTree.createBinarySearch(root, new TreeNode(2)); System.out.println(root.left.val); BinarySearchTree.createBinarySearch(root, new TreeNode(7)); System.out.println(BinarySearchTree.searchBinaryTree(root, 3)); BinarySearchTree.removeNodeFromBinarySearch(root, 2); System.out.println(BinarySearchTree.searchBinaryTree(root, 2)); &#125;&#125;class TreeNode&#123; int val; TreeNode left,right; public TreeNode(int val)&#123; this.val =val; this.left = null; this.right = null; &#125;&#125; 平衡二叉树（AVL树）​ 平衡二叉树是一种二叉排序树，其中每一个节点的的左子树和右子树的高度差之多等于1。我们将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF(Balance Factor)。 最小不平衡子树：距离插入节点最近的，且平衡因子的绝对值大于1的节点为根的子树，我们称为最小不平衡子树。 判断是否为平衡二叉树： 12345678910111213141516171819202122232425262728293031323334public class BalancedBinaryTree &#123; public boolean isBalanced(TreeNode root) &#123; // write your code here return maxDepth(root)!= -1; &#125; private int maxDepth(TreeNode root) &#123; if(root == null) &#123; return 0; &#125; int left = maxDepth(root.left); int right = maxDepth(root.right); if( left == -1 || right == -1 || Math.abs(left - right) &gt; 1 ) &#123; return -1; &#125; return Math.max(left, right) + 1; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub TreeNode root = new TreeNode(3); TreeNode node9= new TreeNode(9); TreeNode node20 = new TreeNode(20); TreeNode node15 = new TreeNode(15); TreeNode node7 = new TreeNode(7); //node3.left = node9; node3.right = node20; node20.left = node15; node20.right = node7; BalancedBinaryTree balancedBinaryTree = new BalancedBinaryTree(); System.out.println(balancedBinaryTree.isBalanced(root)); &#125;&#125; 多路查找树多路查找树(mutil-way search tree)，其每一个节点的孩子树可以多于两个，且每个节点处可存储多个元素。 散列表查找散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key)。 散列技术最适合的求解问题是查找与给定值相等的记录。我们把上述的对应关系f称为散列函数，又称为哈希函数。采用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间称为散列表或者哈希表。 散列函数的构造方法： ​ 直接定址法：取关键字的某个线性函数，f(key)=a*key+b；优点：简单、均匀、不会产生冲突，适合事先知道关键字的分布，查找表较小且连续，不常用。​ 数字分析法：抽取，使用关键字的一部分来计算存储位置，适合事先知道关键字的分布且关键字若干位的分布较均匀，关键字位数较多。​ 平方取中法：先（关键字^2）再抽取中间位，适合不知道关键字分布，关键字位数较少。​ 除留余数法：散列表长m，f(key)=key MOD p，(p≦m)，其中可以对关键字取模，也可以在折叠、平方取中后再取模，缺点：p值取的不好，很容易有冲突、出现同义词，取的好也不容易避免冲突，最常用。​ 随机数法：f(key)=random(key)，适合关键字长度不等。 处理散列冲突的方法： ​ 开放定址探测法：单向寻找，线性探测法。改进，di=1^2,-1^2,2^2,-2^2,…,q^2,-q^2,(q≦m/2)，双向寻找，二次探测法，伪随机数，随机种子，di=random(di)，随机探测法。​ 再散列函数法：一旦发生冲突就换一个散列函数，优点：使得关键字不会产生聚集。缺点：增加了计算时间。​ 链地址法：有冲突的关键字存储在一个单链表中，同义词子表。优点：冲突较多时，不会找不到空地址缺点：查找时可能需要遍历单链表。​ 公共溢出区法：有冲突的关键字都放在公共溢出表，散列表=基本表+溢出表。查找：先通过散列函数得到散列地址在基本表中找，如果没有，再到溢出表中顺序找。适合冲突较少的情况。散列表的查找：散列表的查找性能取决于：1）关键字的分布，2）散列函数的选择，3）处理冲突的方法，4）装填因子α装填因子=记录个数/散列表长度，α=n/m，通常将散列表的空间设置的比查找表/集合大，空间换时间。 常见算法题https://github.com/Luckylau/my-algorithm-training/tree/master/java/N-Series/BinarySearchandSortedSearch]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java虚拟机之垃圾收集器与内存分配策略]]></title>
      <url>%2F2017%2F07%2F10%2F%E4%BD%A0%E6%87%82java%E5%90%97-19%2F</url>
      <content type="text"><![CDATA[垃圾收集器与内存分配策略 Java技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。 ​ Java内存运行时区域的各个部分，其中程序计数器、 虚拟机栈、 本地方法栈3个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。 每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。 而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存。 内存的回收部分堆的回收策略判断对象是否存活？引用计数算法（误区）​ 引用计数算法：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。例如微软公司的COM（Component Object Model）技术、 使用ActionScript 3的FlashPlayer、 Python语言和在游戏脚本领域被广泛应用的Squirrel中都使用了引用计数算法进行内存管理。 但是，至少主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。 1234567891011121314151617181920212223242526272829public class ReferenceCountingGC &#123; public Object instance=null; private static final int _1MB=1024*1024; private byte[]bigSize=new byte[2*_1MB]; public static void testGC()&#123; ReferenceCountingGC objA=new ReferenceCountingGC(); ReferenceCountingGC objB=new ReferenceCountingGC(); objA.instance=objB; objB.instance=objA; objA=null; objB=null; //假设在这行发生GC,objA和objB是否能被回收？ System.gc(); &#125; public static void main(String[] args) &#123; ReferenceCountingGC.testGC(); &#125;&#125;/*[GC (System.gc()) [PSYoungGen: 6758K-&gt;632K(38400K)] 6758K-&gt;640K(125952K), 0.0011725 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 632K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;527K(87552K)] 640K-&gt;527K(125952K), [Metaspace: 2570K-&gt;2570K(1056768K)], 0.0039905 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap PSYoungGen total 38400K, used 333K [0x00000000d5f00000, 0x00000000d8980000, 0x0000000100000000) eden space 33280K, 1% used [0x00000000d5f00000,0x00000000d5f534a8,0x00000000d7f80000) from space 5120K, 0% used [0x00000000d7f80000,0x00000000d7f80000,0x00000000d8480000) to space 5120K, 0% used [0x00000000d8480000,0x00000000d8480000,0x00000000d8980000) ParOldGen total 87552K, used 527K [0x0000000081c00000, 0x0000000087180000, 0x00000000d5f00000) object space 87552K, 0% used [0x0000000081c00000,0x0000000081c83d88,0x0000000087180000) Metaspace used 2577K, capacity 4486K, committed 4864K, reserved 1056768K class space used 286K, capacity 386K, committed 512K, reserved 1048576K*/ ​ 由此可见虚拟机并不是通过引用计数算法来判断对象是否存活的。 可达性分析算法​ 这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。在Java语言中，可作为GC Roots的对象包括下面4种：虚拟机栈（栈帧中的本地变量表）中引用的对象；方法区中类静态属性引用的对象；方法区中常量引用的对象；本地方法栈中JNI（即一般说的Native方法）引用的对象； ​ 但是即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize（）方法。 当对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，那么很快被回收。如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、 低优先级的Finalizer线程去执行它。 这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize（）方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。 finalize（）方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize（）中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。 垃圾收集理论算法？标记-清除算法​ 最基础的收集算法。算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法​ 为了解决上述算法的效率问题，一种称为“复制”（Copying）的收集算法出现了。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。 当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 它的主要不足在于将内存缩小为了原来的一半，未免太高了一点。 ​ 我们可以基于此思想回收新生代。IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 标记-整理算法​ 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，比如就不适合老年代的回收。根据老年代的特点，有人提出了“标记-整理”（Mark-Compact）算法，它的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法​ 分代收集算法（当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法）主要是结合我们上述所讲的几种算法特点，首先根据对象存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代。这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、 没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 如何触发GC回收垃圾？​ 垃圾回收之前，需要判定哪些对象存活，判定对象存活，也就重在枚举“GC Roots”。我们知道可作为GC Roots的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，但是现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。同时可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行——这里“一致性”的意思是指在整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果准确性就无法得到保证。 ​ 以上是枚举“GC Roots”遇到的问题。为了解决当执行系统停顿下来后，一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。 在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。 这样，GC在扫描时就可以直接得知这些信息了。 在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，那将会需要大量的额外空间，这样GC的空间成本将会变得很高。 ​ 实际上，HotSpot也的确没有为每条指令都生成OopMap，只是在“特定的位置”( 循环的末尾， 方法临返回前 / 调用方法的call指令后 ，可能抛异常的位置 )记录了这些信息，这些位置称为安全点（Safepoint），即程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。 所谓的安全点(Safe Point)顾名思义是指一些特定的位置，当线程运行到这些位置时，线程的一些状态可以被确定(the thread’s representation of it’s Java machine state is well described)，比如记录OopMap的状态，从而确定GC Root的信息，使JVM可以安全的进行一些操作，比如开始GC。 ​ 对于Sefepoint，另一个需要考虑的问题是如何在GC发生时让所有线程（这里不包括执行JNI调用的线程）都“跑”到最近的安全点上再停顿下来。 这里有两种方案可供选择：抢先式中断（Preemptive Suspension）和主动式中断（Voluntary Suspension），其中抢先式中断不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。 现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应GC事件。主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方在安全点和创建对象需要分配内存的地方。 ​ 使用Safepoint似乎已经完美地解决了如何进入GC的问题，但实际情况却并不一定。Safepoint机制保证了程序执行时，在不太长的时间内就会遇到可进入GC的Safepoint。 但是程序“不执行”的时候呢？所谓的程序不执行就是没有分配CPU时间，典型的例子就是线程处于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，“走”到安全的地方去中断挂起，JVM也显然不太可能等待线程重新被分配CPU时间。 对于这种情况，就需要安全区域（Safe Region）来解决。 ​ 安全区域是指在一段代码片段之中，引用关系不会发生变化。 在这个区域中的任意地方开始GC都是安全的。 我们也可以把Safe Region看做是被扩展了的Safepoint。在线程执行到Safe Region中的代码时，首先标识自己已经进入了Safe Region，那样，当在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程了。 在线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。 ​ 总结：安全点保证了程序执行时，如何进入GC问题。安全域可以说是安全点的扩展，它解决的是“不执行”的程序的进入GC问题。 GC有以下几个区分：Minor GC，Major GC/Full GC 。 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。 老年代 GC（Major GC / Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程） 。MajorGC 的速度一般会比 Minor GC 慢 10倍以上。 垃圾收集器如何实现？​ 如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、 不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。 Serial收集器（复制算法）​ Serial收集器是最基本、 发展历史最悠久的收集器。JDK 1.3.1之前，是虚拟机新生代收集的唯一选择。 这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。“StopThe World”这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。 我们试想一下要是你的计算机每运行一个小时就会暂停响应5分钟，你会有什么样的心情？但是到现在为止，它依然是虚拟机运行在Client模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。 所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。 ParNew收集器（复制算法）​ ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数（例如：-XX：SurvivorRatio、 -XX：PretenureSizeThreshold、 -XX：HandlePromotionFailure等）、 收集算法、 Stop The World、 对象分配规则、 回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 ​ ParNew收集器除了多线程收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 ​ ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。 当然，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。 它默认开启的收集线程数与CPU的数量相同，在CPU非常多（譬如32个，现在CPU动辄就4核加超线程，服务器超过32个逻辑CPU的情况越来越多了）的环境下，可以使用-XX：ParallelGCThreads参数来限制垃圾收集的线程数。 Parallel Scavenge收集器（复制算法）​ Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 ​ Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参数。MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。不过不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、 每次停顿100毫秒，现在变成5秒收集一次、 每次停顿70毫秒。 停顿时间的确在下降，但吞吐量也降下来了。 ​ GCTimeRatio参数的值应当是一个大于0且小于100的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。 如果把此参数设置为19，那允许的最大GC时间就占总时间的5%（即1/（1+19）），默认值为99，就是允许最大1%（即1/（1+99））的垃圾收集时间。 ​ 除上述两个参数之外，Parallel Scavenge收集器还有一个参数-XX：+UseAdaptiveSizePolicy值得关注。 这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX：SurvivorRatio）、 晋升老年代对象年龄（-XX：PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。如果手工优化存在困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择。 只需要把基本的内存数据设置好（如-Xmx设置最大堆），然后使用MaxGCPauseMillis参数（更关注最大停顿时间）或GCTimeRatio（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。 Serial Old收集器（标记-整理算法）​ Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”算法。这个收集器的主要意义也是在于给Client模式下的虚拟机使用。如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。 Parallel Old收集器（标记-整理算法）​ Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器是在JDK 1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。 原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old收集器外别无选择（Parallel Scavenge收集器无法与CMS收集器配合）。 由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”。直到Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。 CMS收集器（标记-清除算法）​ CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。 目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 CMS收集器就非常符合这类应用的需求。从名字（包含“Mark Sweep”）上就可以看出，CMS收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括： ​ 初始标记（CMS initial mark）​ 并发标记（CMS concurrent mark）​ 重新标记（CMS remark）​ 并发清除（CMS concurrent sweep） ​ 初始标记、 重新标记这两个步骤仍然需要“Stop The World”。 初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC RootsTracing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 ​ 整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 通过下图可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间。 ​ CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、 低停顿，Sun公司的一些官方文档中也称之为并发低停顿收集器（Concurrent Low Pause Collector）。 但是CMS还远达不到完美的程度，它有以下3个明显的缺点： ​ CMS收集器对CPU资源非常敏感。 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量+3）/4，占cpu的资源为（CPU数量+3）/（4 *CPU数量） = （25% + 3 /（4 *CPU数量））也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是CPU低于4（例如3）时候，并发回收时垃圾收集线程占了50 %。 ​ CMS收集器无法处理浮动垃圾（Floating Garbage），可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。 这一部分垃圾就称为“浮动垃圾”。 也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。在JDK 1.5的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在JDK 1.6中，CMS收集器的启动阈值已经提升至92%。 要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。 所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高很容易导致大量“Concurrent Mode Failure”失败，性能反而降低。 ​ CMS是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。 空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC。 为了解决这个问题，CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。虚拟机设计者还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认值为0，表示每次进入FullGC时都进行碎片整理）。 G1收集器​ G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一。G1是一款面向服务端应用的垃圾收集器。 HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。 它的特点如下： ​ 并行与并发：G1能充分利用多CPU、 多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。 ​ 分代收集：与其他收集器一样，分代概念在G1中依然得以保留。 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、 熬过多次GC的旧对象以获取更好的收集效果。 ​ 空间整合：与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。 这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 ​ 可预测的停顿：降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 ​ G1它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。 这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。但是Region不可能是孤立的。 一个对象分配在某个Region中，它并非只能被本Region中的其他对象引用，而是可以与整个Java堆任意的对象发生引用关系。 那在做可达性判定确定对象是否存活的时候，岂不是还得扫描整个Java堆才能保证准确性？这个问题其实并非在G1中才有，只是在G1中更加突出而已。 在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用Remembered Set来避免全堆扫描的。 G1中每个Region都有一个与之对应的Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。 当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。 G1收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking）并发标记（Concurrent Marking）最终标记（Final Marking）筛选回收（Live Data Counting and Evacuation） ​ 初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 而最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 最后在筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 理解GC日志?1233.125: [GC [DefNew: 3324K-&gt;152K(3712K), 0.0025925 secs] 3324K-&gt;152K(11904K), 0.0031680 secs] 100.667: [Full GC [Tenured: 0K-&gt;210K(10240K), 0.0149142 secs] 4603K-&gt;210K(19456K), [Perm : 2999K-&gt;2999K(21248K)], 0.0150007 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] 解释： “33.125：”和“100.667：”代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数。 GC日志开头的“［GC”和“［Full GC”说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC的。如果有“Full”，说明这次GC是发生了Stop-The-World的。 “［DefNew”、“［Tenured”、“［Perm”表示GC发生的区域，这里显示的区域名称与使用的GC收集器是密切相关的，例如上面样例所使用的Serial收集器中的新生代名为“Default New Generation”，所以显示的是“［DefNew”。如果是ParNew收集器，新生代名称就会为“［ParNew”，意为“Parallel New Generation”。如果采用Parallel Scavenge收集器，那它配套的新生代称为“PSYoungGen”，老年代和永久代同理，名称也是由收集器决定的。 方括号内部的“3324K-&gt;152K(3712K)”含义是“GC前该内存区域已使用容量-&gt; GC后该内存区域已使用容量 (该内存区域总容量)”。方括号之外的“3324K-&gt;152K(11904K)”表示“GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量 (Java堆总容量)”。 “0.0025925 secs”表示该内存区域GC所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如“［Times： user=0.01 sys=0.00， real=0.02 secs］”，这里面的user、sys和real与Linux的time命令所输出的时间含义一致，分别代表用户态消耗的CPU时间、内核态消耗的CPU事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。 垃圾收集器参数调试？堆大小设置 -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 回收器相关配置 参数 描述 -XX:+UseSerialGC Jvm运行在Client模式下的默认值，打开此开关后，使用Serial + Serial Old的收集器组合进行内存回收。（串行收集器） -XX:+UseParNewGC 打开此开关后，使用ParNew + Serial Old的收集器进行垃圾回收 。（并行收集器） -XX:+UseConcMarkSweepGC 使用ParNew + CMS + Serial Old的收集器组合进行内存回收，Serial Old作为CMS出现“Concurrent Mode Failure”失败后的后备收集器使用。（并发收集器） -XX:+UseParallelGC Jvm运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old的收集器组合进行回收 -XX:+UseParallelOldGC 使用Parallel Scavenge + Parallel Old的收集器组合进行回收 （并行年老代收集器） -XX:SurvivorRatio 新生代中Eden区域与Survivor区域的容量比值，默认为8，代表Eden:Subrvivor = 8:1 -XX:PretenureSizeThreshold 直接晋升到老年代对象的大小，设置这个参数后，大于这个参数的对象将直接在老年代分配 -XX:MaxTenuringThreshold 晋升到老年代的对象年龄，每次Minor GC之后，年龄就加1，当超过这个参数的值时进入老年代 -XX:UseAdaptiveSizePolicy 动态调整java堆中各个区域的大小以及进入老年代的年龄 -XX:+HandlePromotionFailure 是否允许新生代收集担保，进行一次minor gc后, 另一块Survivor空间不足时，将直接会在老年代中保留 -XX:ParallelGCThreads 设置并行GC进行内存回收的线程数 -XX:GCTimeRatio GC时间占总时间的比列，默认值为99，即允许1%的GC时间，仅在使用Parallel Scavenge 收集器时有效 -XX:MaxGCPauseMillis 设置GC的最大停顿时间，在Parallel Scavenge 收集器下有效 -XX:CMSInitiatingOccupancyFraction 设置CMS收集器在老年代空间被使用多少后出发垃圾收集，默认值为68%，仅在CMS收集器时有效，-XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSCompactAtFullCollection 由于CMS收集器会产生碎片，此参数设置在垃圾收集器后是否需要一次内存碎片整理过程，仅在CMS收集器时有效 -XX:+CMSFullGCBeforeCompaction 设置CMS收集器在进行若干次垃圾收集后再进行一次内存碎片整理过程，通常与UseCMSCompactAtFullCollection参数一起使用 -XX:+UseFastAccessorMethods 原始类型优化 -XX:+DisableExplicitGC 是否关闭手动System.gc -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX:LargePageSizeInBytes 内存页的大小不可设置过大，会影响Perm的大小，-XX:LargePageSizeInBytes=128m 辅助信息-XX:+PrintGC 12输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] -XX:+PrintGCDetails12输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps12-XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationConcurrentTime 12打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用输出形式：Application time: 0.5291524 seconds -XX:+PrintGCApplicationStoppedTime 12打印垃圾回收期间程序暂停的时间。可与上面混合使用输出形式：Total time for which application threads were stopped: 0.0468229 seconds -XX:PrintHeapAtGC 12345678910111213141516171819202122232425打印GC前后的详细堆栈信息输出形式：34.702: [GC &#123;Heap before gc invocations=7:def new generation total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000)eden space 49152K, 99% used [0x1ebd0000, 0x21bce430, 0x21bd0000)from space 6144K, 55% used [0x221d0000, 0x22527e10, 0x227d0000)to space 6144K, 0% used [0x21bd0000, 0x21bd0000, 0x221d0000)tenured generation total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000)the space 69632K, 3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000)compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations=8:def new generation total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000)eden space 49152K, 0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000)from space 6144K, 55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000)to space 6144K, 0% used [0x221d0000, 0x221d0000, 0x227d0000)tenured generation total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000)the space 69632K, 4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000)compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)&#125;, 0.0757599 secs] -Xloggc:filename 1与上面几个配合使用，把相关日志信息记录到文件以便分析 方法区的回收策略​ 也称持久代（ permanent generation ）回收，虽然Java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以回收70%～95%的空间，而永久代的垃圾收集效率远低于此。但是废弃常量和无用的类仍然是永久代的垃圾收集主要回收两部分内容。 ​ 回收废弃常量与回收Java堆中的对象非常类似。 以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。 常量池中的其他类（接口）、 方法、 字段的符号引用也与此类似。 ​ 回收无用的类要比废弃常量麻烦，在于如何判断类是”无用的”。满足下面3个条件断定是无用的类：该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；加载该类的ClassLoader已经被回收；该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。这样虚拟机可以对满足上述3个条件的无用类进行回收，要特别注意的是这里说的仅仅是“可以”，而并不是和对象一样，不使用了就必然会回收。 是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose：class以及-XX：+TraceClassLoading、 -XX：+TraceClassUnLoading查看类加载和卸载信息，其中-verbose：class和-XX：+TraceClassLoading可以在Product版的虚拟机中使用，-XX：+TraceClassUnLoading参数需要FastDebug版的虚拟机支持。 内存的分配部分对象优先在Eden分配？​ 大多数情况下，对象在新生代Eden区中分配。 当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。 大对象直接进入老年代？​ 所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组。大对象对虚拟机的内存分配来说就是一个坏消息，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。 这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制。 长期存活的对象将进入老年代？· 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。 为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。 如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。 对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。 对象晋升老年代的年龄阈值，可以通过参数-XX：MaxTenuringThreshold设置。 动态对象年龄判定？​ 为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 空间分配担保？​ 在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。 如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。 如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。 ​ 下面解释一下“冒险”是冒了什么风险。新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在MinorGC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。 与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。这里取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。 虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。对于HandlePromotionFailure开关虽然源码中还定义HandlePromotionFailure参数，但是在代码中已经不会再使用它。 JDK 6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将进行Full GC。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（6）]]></title>
      <url>%2F2017%2F07%2F07%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%886%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解图，代码均为自己实现。 图图（Graph）是由定点的有穷非空集合和顶点之间边的集合组成，通常表示为：G（V,E），其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。 线性表中将数据元素称为元素，树中将数据元素称为结点，图中将数据元素称为顶点。 线性表中可以没有数据元素，称为空表。树中可以没有结点，称为空树。在图结构中，不允许没有顶点。在定义中，顶点集合有穷非空。 线性表中，相邻数据元素之间有线性关系。树结构中，相邻两层结点之间有层次关系。在图中，任意两个顶点之间都有可能有关系，顶点之间的逻辑关系有边来表示。边集可以为空。 各种图的相关概念 无向边：若顶点vi到vj之间的边没有方向，则称这条边为无向边（Edge），用无序偶对(vi , vj)来表示。 无向图：若图中任意两个顶点之间的边都是无向边，则称该图为无向图。 有向边：若从顶点vi到vj的边有方向，则称这条边为有向边，也称为弧（Arc），用有序偶对来表示，vi 称为弧尾（Tail），vj 称为弧头（Head）。 有向图：若图中任意两个顶点之间的边都是有向边，则称该图为有向图。 简单图：在图中，若不存在顶点到其自身的边，且同一条边不重复出现，则称这样的图为简单图。 无向完全图：在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图。 有向完全图：在有向图中，如果任意两个顶点之间都存在方向互为相反的两条弧，则称该图为有向完全图。 权：与图的边或弧相关的数叫做权（Weight）。 网：带权的图称为网（Network）。 图的存储结构邻接矩阵​ 图的邻接矩阵（Adjacency Matrix）存储方式使用过两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组（称为邻接矩阵）存储图中的边或弧的信息。 邻接矩阵有向图和邻接矩阵无向图结构一样，只是在存储矩阵值时只存储对应方向的点。 缺点：对于边数相对顶点较少的图，这种结构是存在对存储空间的极大浪费。 邻接矩阵无向图123456789101112131415161718192021222324252627282930313233343536373839404142434445public class MatrixNDG &#123; int size; char[] vertexs; int[][] matrix; public MatrixNDG(char[] vertexs,char[][] edges)&#123; this.vertexs = vertexs; this.size = vertexs.length; this.matrix = new int[size][size]; for(char[] c : edges)&#123; int p = getPostion(c[0]); int q = getPostion(c[1]); matrix[p][q] = 1; matrix[q][p] = 1; &#125; &#125; public MatrixNDG(char[] vertexs,char[][] edges,int[] weight)&#123; int i , j ,k = 0; this.vertexs = vertexs; this.size = vertexs.length; this.matrix = new int[size][size]; for(i = 0 ; i &lt; size ; i++)&#123; for(j = 0 ; j &lt;size; j++)&#123; matrix[i][j] =Integer.MAX_VALUE; &#125; &#125; for(j = 0 ; j &lt; size; j++)&#123; matrix[j][j] = 0; &#125; for(char[] c : edges)&#123; int p = getPostion(c[0]); int q = getPostion(c[1]); matrix[p][q] = weight[k]; matrix[q][p] = weight[k]; k++; &#125; &#125; private int getPostion(char c)&#123; for ( int i = 0; i &lt; vertexs.length ; i++)&#123; if (c == vertexs[i]) &#123; return i; &#125; &#125; return -1; &#125; &#125; 邻接矩阵有向图12345678910111213141516171819202122232425262728293031323334353637383940414243public class MatrixNDG &#123; int size; char[] vertexs; int[][] matrix; public MatrixNDG(char[] vertexs,char[][] edges)&#123; this.vertexs = vertexs; this.size = vertexs.length; this.matrix = new int[size][size]; for(char[] c : edges)&#123; int p = getPostion(c[0]); int q = getPostion(c[1]); matrix[p][q] = 1; &#125; &#125; public MatrixNDG(char[] vertexs,char[][] edges,int[] weight)&#123; int i , j ,k = 0; this.vertexs = vertexs; this.size = vertexs.length; this.matrix = new int[size][size]; for(i = 0 ; i &lt; size ; i++)&#123; for(j = 0 ; j &lt;size; j++)&#123; matrix[i][j] =Integer.MAX_VALUE; &#125; &#125; for(j = 0 ; j &lt; size; j++)&#123; matrix[j][j] = 0; &#125; for(char[] c : edges)&#123; int p = getPostion(c[0]); int q = getPostion(c[1]); matrix[p][q] = weight[k]; k++; &#125; &#125; private int getPostion(char c)&#123; for ( int i = 0; i &lt; vertexs.length ; i++)&#123; if (c == vertexs[i]) &#123; return i; &#125; &#125; return -1; &#125; &#125; 邻接表数组与链表相结合的存储方法称为邻接表（Adjacency List）。 邻接表无向图邻接表有向图十字链表把邻接表和逆邻接表结合 邻接多重表略 边集数组略 图的遍历深度优先遍历（Depth_First_Search）DFS，顾名思义，就是从一个顶点出发，往最深里找。 邻接矩阵的深度优先遍历 无向图和有向图 邻接表的深度优先遍历 无向图和有向图 广度优先遍历（Breath_First_Search）BFS，也就是从一个顶点出发，一层层找。 邻接矩阵的广度优先遍历 无向图和有向图 12345678910111213141516171819public List&lt;Character&gt; breadthFirstSearch(char v)&#123; hasVisit = new boolean[vertexs.length]; List&lt;Character&gt; res =new ArrayList&lt;Character&gt;(); Queue&lt;Character&gt; queue = new LinkedList&lt;Character&gt;(); hasVisit[getPostion(v)] = true; queue.offer(v); while(!queue.isEmpty())&#123; Character ch = queue.poll(); int i = getPostion(ch); res.add(ch); for (int j = 0; j &lt; vertexs.length; j++ ) &#123; if (matrix[i][j] != 0 &amp;&amp; matrix[i][j] != Integer.MAX_VALUE &amp;&amp; !hasVisit[j]) &#123; hasVisit[j] = true; queue.offer(vertexs[j]); &#125; &#125; &#125; return res; &#125; 邻接表的广度优先遍历 无向图和有向图 最小生成树最短路径迪杰斯特拉算法 弗洛伊德算法 关键路径]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（5）]]></title>
      <url>%2F2017%2F07%2F05%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%885%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解树，代码均为自己实现。 树树（Tree）是n（n&gt;=0）个结点的有限集。 n=0又称为空树。在任意一课非空的树中：有且仅有一个特定的称为跟（Root）的结点；当n&gt;1时，其余结点可分为m（m&gt;0）个互不相交的有限集，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。 树是一种一对多的数据结构。 需要注意的是：当n&gt;0时根结点是惟一的，不可能存在多个根结点。 ​m&gt;0时，子树的个数没有限制，但它们一定是互不相交的。如果相交，就不符合树的定义。 结点拥有的子树称为结点的度。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点。除根结点外，分支结点也称为内部结点。树的度是树内各结点的度的最大值。 树中结点最大的层次称为树的深度或高度。 树的存储结构树有两种实现方式：数组和链表； 树有三种不同表示法：双亲表示法、孩子表示法、孩子兄弟表示法。 二叉树二叉树（Binary Tree）是n（n&gt;=0）个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两棵互不相交的、分别称为根结点的左子树和右子树的二叉树组成。 二叉树的特点每个结点最多有两棵子树，所以二叉树中不存在大于2的结点。注意不是只有两棵子树，而是最多有。没有子树或者有一棵子树都是可以的。左子树和右子树是有顺序的，次序不能颠倒。就像人的左右手。即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。 二叉树有5种基本形态​ 空二叉树。 ​ 只有一个根结点。 ​ 根结点只有左子树。 ​ 根结点只有右子树。 ​ 根结点既有左子树又有右子树。 特殊二叉树斜树：只有左子树或者只有右子树。线性表是一种特殊的树。 满二叉树：所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上。 满二叉树的特点有： 叶子只能在最下一层。出现在其他层就不可能达到平衡。 非叶子结点的度一定是2。否则就是“缺胳膊少腿了”。 在同样深度的二叉树中，满二叉树的结点个数越多，叶子树越多。 完全二叉树： 叶子结点只能在最下两层。 最下层的叶子一定集中在左部连续的位置。 倒数第二层，若有叶子结点，一定都在右部连续位置。 如果结点度为1，则该结点只有左孩子，即不存在右子树的情况。 同样结点数从二叉树，完全二叉树的深度最小。 判断一棵树是否是完全二叉树，心中默默给每个结点按照满二叉树的结构逐层顺序编号，如果编号出现空档，就不是完全二叉树，否则就是。 满二叉树是特殊的完全二叉树。 完全二叉树必须先满足左后满足右，缺的元素只能是满二叉树最下一层的，高度差小于或等于1。 二叉树的性质12345678性质1：在二叉树的第i层上至多有2^(i-1)个结点（i≥1）。性质2：深度为k的二叉树至多有2^k-1个结点（k≥1）。性质3：对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2，则n0=n2+1。性质4：具有n个结点的完全二叉树的深度为|log2n+1|（|x|表示不大于x的最大整数）。性质5：如果对一棵有n个结点的完全二叉树（其深度为）的结点按层序编号（从第1层到第层，每层从左到右），对任一结点i（1≤i≤n）有：1．如果i=1，则结点i是二叉树的根，无双亲；如果i&gt;1，则其双亲是结点。2．如果2i&gt;n，则结点i无左孩子（结点i为叶子结点）；否则其左孩子是结点2i。3．如果2i+1&gt;n，则结点i无右孩子；否则其右孩子是结点2i+1。 二叉树的存储结构二叉树有两种存储结构：顺序存储结构和二叉链表。 顺序存储结构：一般只有完全二叉树才考虑顺序存储结构，因为完全二叉树的严格性，可以充分利用顺序存储空间。其他二叉树都会造成空间的浪费，特别是右斜树。 二叉链表： 123456789public class TreeNode&lt;E&gt; &#123; public E val; public TreeNode left,right; public TreeNode(E val)&#123; this.val = val; this.left = null; this.right = null; &#125;&#125; 遍历二叉树定义树1234567891011121314public class TreeNode &#123; public int val; public TreeNode left,right; public TreeNode(int val)&#123; this.val = val; this.left = null; this.right = null; &#125; @Override public String toString()&#123; return this.val+""; &#125;&#125; 前序遍历实现一：递归方式 1234567891011121314public ArrayList&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; // write your code here ArrayList&lt;Integer&gt; preorder = new ArrayList&lt;Integer&gt;(); traverse(root,preorder); return preorder; &#125;private void traverse(TreeNode root ,List&lt;Integer&gt; preorder) &#123; if ( root == null ) &#123; return; &#125; preorder.add(root.val); traverse (root.left , preorder); traverse (root.right ,preorder); &#125; 实现二：分治思想 123456789101112131415public ArrayList&lt;Integer&gt; preorderTraversal3(TreeNode root) &#123; // write your code here ArrayList&lt;Integer&gt; preorder = new ArrayList&lt;Integer&gt;(); if ( root == null) &#123; return preorder; &#125; ArrayList&lt;Integer&gt; left = preorderTraversal(root.left); ArrayList&lt;Integer&gt; right = preorderTraversal(root.right); preorder.add(root.val); preorder.addAll(left); preorder.addAll(right); return preorder; &#125; 中序遍历实现一：递归方式 1234567891011121314public ArrayList&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; ArrayList&lt;Integer&gt; inorder = new ArrayList&lt;Integer&gt;(); traverse(root,inorder); return inorder; &#125; private void traverse(TreeNode root ,List&lt;Integer&gt; inorder) &#123; if ( root == null ) &#123; return; &#125; traverse (root.left , inorder); inorder.add(root.val); traverse (root.right ,inorder); &#125; 实现二：分治思想 123456789101112131415public ArrayList&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; // write your code here ArrayList&lt;Integer&gt; inorder = new ArrayList&lt;Integer&gt;(); if ( root == null) &#123; return inorder; &#125; ArrayList&lt;Integer&gt; left = inorderTraversal(root.left); ArrayList&lt;Integer&gt; right = inorderTraversal(root.right); inorder.addAll(left); inorder.add(root.val); inorder.addAll(right); return inorder; &#125; 后序遍历实现一：递归方式 12345678910111213public ArrayList&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; // write your code here ArrayList&lt;Integer&gt; preorder = new ArrayList&lt;Integer&gt;(); traverse(root,preorder); return preorder; &#125;private void traverse(TreeNode root ,List&lt;Integer&gt; preorder) &#123; if ( root == null ) &#123; return; &#125; traverse (root.left , preorder); traverse (root.right ,preorder); preorder.add(root.val); 实现二：分治思想 1234567891011121314151617public ArrayList&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; // write your code here ArrayList&lt;Integer&gt; postorder = new ArrayList&lt;Integer&gt;(); if ( root == null) &#123; return postorder; &#125; ArrayList&lt;Integer&gt; left = postorderTraversal(root.left); ArrayList&lt;Integer&gt; right = postorderTraversal(root.right); postorder.addAll(left); postorder.addAll(right); postorder.add(root.val); return postorder; &#125; 层序遍历12345678910111213141516171819202122232425public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result =new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); // write your code here if (root == null) &#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.offer(root); while ( !queue.isEmpty()) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); int size = queue.size(); for ( int i =0;i &lt; size ; i++) &#123; TreeNode tmp = queue.poll(); list.add(tmp.val); if(tmp.left !=null) &#123; queue.offer(tmp.left); &#125; if(tmp.right !=null) &#123; queue.offer(tmp.right); &#125; &#125; result.add(list); &#125; return result; &#125; 已知前序遍历序列和中序遍历序列，可以唯一确定一棵二叉树。 已知后序遍历序列和中序遍历序列，可以唯一确定一棵二叉树。 已知前序遍历序列和后序遍历序列，不可以唯一确定一棵二叉树。 线索二叉树​ 为了充分利用二叉链表的空指针，把空指针指向前驱和后继，这种指向前驱和后继的指针称为线索，加上线索的二叉链表称为线索链表， 相应的二叉树就称为线索二叉树。 ​ 对二叉树以某种次序遍历使其变为线索二叉树的过程称作是线索化。线索化的过程就是在遍历的过程中修改空指针的过程。 ​ 为了判别某一结点的lchild是指向左孩子还是前驱，rchild是指向右孩子还是后继，引入ltag和rtag两个标志域。 1lchild ltag data rtag rchild ​ 其中，ltag为0时指向该结点的左孩子，为1时指向该结点的前驱；rtag为0时指向该结点的右孩子，为1时指向该结点的后继。 树、森林与二叉树的转换略 赫夫曼树赫夫曼树：带全路径长度WPL最小的二叉树。先取最小权值的结点作为叶子结点，逐级递增就能构造出哈夫曼树。把左结点标为0，右结点标为1，就能构造出赫夫曼编码。 树相关算法题以下是涉及到树我的github的算法题集合 https://github.com/Luckylau/my-algorithm-training/tree/master/java/N-Series/BinaryTree%26DivideConquer%26DFS%26BFS]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（4）]]></title>
      <url>%2F2017%2F07%2F04%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%884%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解串，代码均为自己实现。 串串（string）是由零个或多个字符组成的有限序列，又名字符串。 串的存储结构​ 串的顺序存储结构是用一组地址连续的存储单元来存储串中的字符序列的。按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区。 用“\0”来表示串的终结，不计入串长度，但是计入数组长度。 两个长度不同的串不可能相等。 ​ 串的链式存储结构要考虑一个结点是存放一个字符（会造成很大的空间浪费）还是多个字符。除了链接串与串的操作有一定方便外，总的来说不如顺序存储量或，性能也不如顺序存储结构好。 朴素的模式匹配算法串的模式匹配：串的定位操作。时间复杂度：O(1)–最好；O(n+m)–平均；O(n-m+1)*m–最不好 1234567891011121314151617181920212223242526272829303132public class Index &#123; public int index(String s , String t , int post)&#123; if(s == null || t == null)&#123; return -1; &#125; int len1 = s.length(); int len2 = t.length(); int i = post; int j = 0; while (i &lt; len1 &amp;&amp; j &lt; len2) &#123; if (s.charAt(i) == t.charAt(j)) &#123; i++; j++; &#125;else&#123; i = i - j + 1; j = 0; &#125; &#125; if (j &gt;= len2)&#123; return i - len2; &#125;else&#123; return -1; &#125; &#125; public static void main(String[] args) &#123; String s ="luckylau is good man"; String t =" good"; Index Index = new Index(); System.out.println(Index.index(s, t, 0)); System.out.println(Index.index(s, t, 8)); &#125;&#125; KMP模式匹配算法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class IndexKMP &#123; public int indexKMP(String s ,String t ,int post)&#123; if(s == null || t == null)&#123; return -1; &#125; int len1 = s.length(); int len2 = t.length(); int i = post; int j = 0; int[] next = getNext(t); while (i &lt; len1 &amp;&amp; j &lt; len2) &#123; if (j== -1 || s.charAt(i) == t.charAt(j)) &#123; i++; j++; &#125;else&#123; j = next[j]; &#125; &#125; if (j &gt;= len2)&#123; return i - len2; &#125;else&#123; return -1; &#125; &#125; private int[] getNext(String t)&#123; int [] next = new int [t.length()]; int i = 0; int j = -1; next[i] = j; while (i &lt; t.length() - 1)&#123; if (j == -1 || t.charAt(i) == t.charAt(j))&#123; i++; j++; next[i] =j; &#125;else&#123; j = next[j]; &#125; &#125; return next; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub String s ="luckylau is good man"; String t =" good"; IndexKMP Index = new IndexKMP(); System.out.println(Index.indexKMP(s, t, 0)); System.out.println(Index.indexKMP(s, t, 8)); &#125;&#125; 改进版 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class IndexKMP &#123; public int indexKMP(String s ,String t ,int post)&#123; if(s == null || t == null)&#123; return -1; &#125; int len1 = s.length(); int len2 = t.length(); int i = post; int j = 0; int[] next = getNext(t); while (i &lt; len1 &amp;&amp; j &lt; len2) &#123; if (j== -1 || s.charAt(i) == t.charAt(j)) &#123; i++; j++; &#125;else&#123; j = next[j]; &#125; &#125; if (j &gt;= len2)&#123; return i - len2; &#125;else&#123; return -1; &#125; &#125; private int[] getNext(String t)&#123; int [] next = new int [t.length()]; int i = 0; int j = -1; next[i] = j; while (i &lt; t.length() - 1)&#123; if (j == -1 || t.charAt(i) == t.charAt(j))&#123; i++; j++; if(t.charAt(i) == t.charAt(j))&#123; next[i] = next[j]; &#125;else&#123; next[i] = j; &#125; &#125;else&#123; j = next[j]; &#125; &#125; return next; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub String s ="luckylau is good man"; String t =" good"; IndexKMP Index = new IndexKMP(); System.out.println(Index.indexKMP(s, t, 0)); System.out.println(Index.indexKMP(s, t, 8)); &#125;&#125; 串相关算法题以下是涉及到串我的github的算法题集合 N-Series]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（3）]]></title>
      <url>%2F2017%2F06%2F29%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%883%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解栈和队列，代码均为自己实现。 栈与队列栈是限定仅在表尾进行插入和删除操作的线性表。（类似弹夹中的子弹）队列是只允许在一端进行插入操作、而在另一端进行删除操作的线性表。（类似等待客服电话排队） 栈的抽象数据类型栈本身也是一种线性表，除了删除和添加改名为pop(弹)和push(压)，抽象功能没有特别的地方。为了方便实现我们还是自定义栈的接口 ，另外注意一点是java的sdk继承vector实现的stack，相关操作使用synchronized，具有安全性。 12345678public interface IStack&lt;E&gt; &#123; boolean isEmpty(); boolean push(E e); E peek(); E pop(); int size(); void clear();&#125; 栈的顺序存储结构(两栈共享空间)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.util.Arrays;public class Mystack&lt;E&gt; implements IStack&lt;E&gt; &#123; private Object[] elementData; private int size; private int top; public Mystack()&#123; this(10); &#125; public Mystack (int initcapactity)&#123; if(initcapactity &gt; 0) &#123; this.elementData = new Object[initcapactity]; this.size = initcapactity; this.top = -1; &#125;else&#123; throw new RuntimeException("stack init capactity &lt; 0"); &#125; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return top == -1; &#125; @Override public boolean push(E e) &#123; // TODO Auto-generated method stub if(top == size - 1)&#123; ensureCapacity(); &#125; elementData[++top]=e; return true; &#125; private void ensureCapacity()&#123; int oldcapacity = elementData.length; int newcapacity = oldcapacity + (oldcapacity &gt;&gt; 1); size = newcapacity; Arrays.copyOf(elementData, newcapacity); &#125; @Override public E peek() &#123; // TODO Auto-generated method stub if(top == -1)&#123; throw new RuntimeException("stack is empty"); &#125; E e=elementData(top); return e; &#125; @Override public E pop() &#123; // TODO Auto-generated method stub if(top == -1)&#123; throw new RuntimeException("stack is empty"); &#125; E e=elementData(top); elementData[top]=null; top--; return e; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return top + 1; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for (int i = 0 ; i &lt; elementData.length; i++) &#123; elementData[i] = null; &#125; top = -1; &#125; @SuppressWarnings("unchecked") E elementData(int top)&#123; return (E) elementData[top]; &#125; @Override public String toString()&#123; String str ="["; for (int i = 0 ; i &lt;= top; i++) &#123; str = str + elementData[i] + ","; &#125; str = str + "]"; return str; &#125;&#125; 1234567891011121314151617public class Teststack &#123; public static void main(String[] args) &#123; IStack&lt;String&gt; stack = new Mystack&lt;String&gt;(); System.out.println("stack.size()"+stack.size()); System.out.println(stack.isEmpty()); stack.push("a"); stack.push("b"); stack.push("c"); stack.push("d"); System.out.println("stack.size() = "+stack.size()); System.out.println(stack.toString()); stack.pop(); System.out.println(stack.peek()); stack.clear(); System.out.println(stack.size()); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112public class Sharestack&lt;E&gt;&#123; private Object[] elementData; private int size; private int top1; private int top2; public Sharestack()&#123; this(20); &#125; public Sharestack (int initcapactity)&#123; if(initcapactity &gt; 0) &#123; this.elementData = new Object[initcapactity]; this.size = initcapactity; this.top1 = -1; this.top2 = size; &#125;else&#123; throw new RuntimeException("stack init capactity &lt; 0"); &#125; &#125; public boolean isEmpty() &#123; // TODO Auto-generated method stub return top1 == -1 &amp;&amp; top2 == size; &#125; public boolean push(int i ,E e) &#123; // TODO Auto-generated method stub if(top1 == size - 1 || top2 == 0)&#123; throw new RuntimeException("stack is full"); &#125; if(i == 1)&#123; elementData[++top1]=e; &#125; else if (i == 2)&#123; elementData[--top2]=e; &#125; else&#123; throw new RuntimeException("i is 1 or 2"); &#125; return true; &#125; public E peek(int i) &#123; // TODO Auto-generated method stub E e; if(i == 1)&#123; if(top1 == -1)&#123; throw new RuntimeException("stack is empty"); &#125; e=elementData(top1); &#125;else if(i == 2)&#123; if(top2 == size)&#123; throw new RuntimeException("stack is empty"); &#125; e=elementData(top2); &#125;else&#123; throw new RuntimeException("i is 1 or 2"); &#125; return e; &#125; public E pop(int i) &#123; // TODO Auto-generated method stub E e; if(i == 1)&#123; if(top1 == -1)&#123; throw new RuntimeException("stack is empty"); &#125; e=elementData(top1); elementData[top1]=null; top1--; &#125;else if(i == 2)&#123; if(top2 == size)&#123; throw new RuntimeException("stack is empty"); &#125; e=elementData(top2); elementData[top2]=null; top2++; &#125;else&#123; throw new RuntimeException("i is 1 or 2"); &#125; return e; &#125; public int size(int i) &#123; // TODO Auto-generated method stub if(i == 1)&#123; return top1 + 1; &#125;else if(i == 2)&#123; return size - top2; &#125;else&#123; throw new RuntimeException("i is 1 or 2"); &#125; &#125; public void clear() &#123; // TODO Auto-generated method stub for (int i = 0 ; i &lt; elementData.length; i++) &#123; elementData[i] = null; &#125; top1 = -1; top2 = size; &#125; @SuppressWarnings("unchecked") E elementData(int top)&#123; return (E) elementData[top]; &#125; @Override public String toString()&#123; String str ="stack 1:["; for (int i = 0 ; i &lt;= top1; i++) &#123; str = str + elementData[i] + ","; &#125; str = str + "] stack 2:["; for (int i = size - 1 ; i &gt;=top2; i--) &#123; str = str + elementData[i] + ","; &#125; str =str +"]"; return str; &#125;&#125; 1234567891011121314151617181920212223public class Testsharestack &#123; public static void main(String[] args) &#123; Sharestack&lt;String&gt; stack = new Sharestack&lt;String&gt;(); System.out.println("stack1.size() = "+stack.size(1)); System.out.println("stack2.size() = "+stack.size(2)); System.out.println(stack.isEmpty()); stack.push(1,"a"); stack.push(2,"b"); stack.push(1,"c"); stack.push(2,"d"); System.out.println("stack1.size() = "+stack.size(1)); System.out.println("stack2.size() = "+stack.size(2)); System.out.println(stack.toString()); stack.pop(1); System.out.println(stack.peek(1)); System.out.println(stack.toString()); stack.clear(); System.out.println(stack.size(1)); System.out.println(stack.size(2)); stack.push(1,"a"); System.out.println(stack.toString()); &#125;&#125; 栈的链式存储结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class Mystack&lt;E&gt; implements IStack&lt;E&gt;&#123; private Node&lt;E&gt; top; private int size; public Mystack()&#123; &#125; private static class Node&lt;E&gt;&#123; private E item; private Node&lt;E&gt; next; public Node(E item , Node&lt;E&gt; next)&#123; this.item = item; this.next = next; &#125; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return size == 0; &#125; @Override public boolean push(E e) &#123; // TODO Auto-generated method stub if(top == null)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e,null); top = newNode; &#125;else&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e,top); top = newNode; &#125; size++; return true; &#125; @Override public E peek() &#123; // TODO Auto-generated method stub return top.item; &#125; @Override public E pop() &#123; // TODO Auto-generated method stub Node&lt;E&gt; e = top; E item = e.item; e = null; top = top.next; return item; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return size; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for(Node&lt;E&gt; x = top; x != null;) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x = next; &#125; top = null; size = 0; &#125; @Override public String toString()&#123; String str = "["; for(Node&lt;E&gt; x = top; x != null;) &#123; Node&lt;E&gt; next = x.next; str = str + x.item + ","; x = next; &#125; str = str + "]"; return str; &#125;&#125; 123456789101112131415161718192021public class Teststack &#123; public static void main(String[] args) &#123; IStack&lt;String&gt; stack = new Mystack&lt;String&gt;(); System.out.println("stack.size()"+stack.size()); System.out.println(stack.isEmpty()); stack.push("a"); stack.push("b"); stack.push("c"); stack.push("d"); System.out.println("stack.size() = "+stack.size()); System.out.println(stack.toString()); stack.pop(); System.out.println(stack.peek()); System.out.println(stack.toString()); stack.clear(); System.out.println(stack.size()); stack.push("a"); System.out.println(stack.peek()); System.out.println(stack.toString()); &#125;&#125; 队列的抽象数据类型队列本身也是一种线性表，不同的是插入只能是队尾，删除只能是队首，抽象功能同样没有特别的地方。 123456789public interface IQueue&lt;E&gt; &#123; boolean offer(E e); E poll();//the head of this queue, or &#123;@code null&#125; if this queue is empty boolean isEmpty(); void clear(); E element(); //NoSuchElementException if this queue is empty E peek(); //the head of this queue, or &#123;@code null&#125; if this queue is empty int size();&#125; 队列的顺序存储结构（循环队列）循环队列指队列的首尾相接的顺序存储结构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.util.NoSuchElementException;public class MyQueue&lt;E&gt; implements IQueue&lt;E&gt; &#123; private Object[] elementData; private int front; private int rear; private int length; public MyQueue()&#123; this(10); &#125; public MyQueue(int capacity)&#123; this.elementData = new Object[capacity]; this.length = capacity; this.front = 0; this.rear = 0; &#125; @Override public boolean offer(E e) &#123; // TODO Auto-generated method stub if (front == (rear + 1) % length) &#123; throw new RuntimeException("queue is full"); &#125; elementData[rear] =e; rear = (rear + 1) % length; return true; &#125; @Override public E poll() &#123; // TODO Auto-generated method stub if (front == rear)&#123; return null; &#125; E e = elementData(front); elementData[front] =null; front = (front + 1) % length; return e; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return front == rear; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for(int i = 0 ; i &lt; elementData.length; i++)&#123; elementData[i] = null; &#125; front = rear = 0; &#125; @Override public E element() &#123; // TODO Auto-generated method stub if (front == rear)&#123; throw new NoSuchElementException("queue is empty"); &#125; E e = elementData(front); return e; &#125; @Override public E peek() &#123; // TODO Auto-generated method stub if (front == rear)&#123; return null; &#125; E e = elementData(front); return e; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return (length + rear - front) % length; &#125; @SuppressWarnings("unchecked") E elementData(int i)&#123; return (E) elementData[i]; &#125; @Override public String toString()&#123; String str ="["; for(int i = front ; i != rear; i = (i + 1) % length)&#123; str = str + elementData[i] + ","; &#125; str = str + "]"; return str; &#125;&#125; 123456789101112131415161718192021222324252627282930public class Testqueue &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub IQueue&lt;String&gt; queue = new MyQueue&lt;String&gt;(6); System.out.println(queue.isEmpty()); queue.offer("a"); queue.offer("b"); queue.offer("c"); queue.offer("d"); queue.offer("e"); System.out.println(queue.toString()); System.out.println(queue.size()); queue.poll(); System.out.println(queue.peek()); queue.poll(); System.out.println(queue.peek()); System.out.println(queue.size()); System.out.println(queue.toString()); queue.offer("a"); System.out.println(queue.peek()); System.out.println(queue.toString()); queue.offer("b"); System.out.println(queue.toString()); queue.clear(); System.out.println(queue.toString()); System.out.println(queue.isEmpty()); &#125;&#125; 队列的链式存储结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import java.util.NoSuchElementException;public class MyQueue&lt;E&gt; implements IQueue&lt;E&gt; &#123; private Node&lt;E&gt; front; private Node&lt;E&gt; rear; private final Node&lt;E&gt; node; private int size; public MyQueue()&#123; node = new Node&lt;E&gt;(null,null); this.front = node; this.rear = node; &#125; private static class Node&lt;E&gt;&#123; private E item; private Node&lt;E&gt; next; public Node(E item , Node&lt;E&gt; next)&#123; this.item = item; this.next = next; &#125; &#125; @Override public boolean offer(E e) &#123; // TODO Auto-generated method stub final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e, null); rear.next = newNode; rear = newNode; size++; return true; &#125; @Override public E poll() &#123; // TODO Auto-generated method stub if(front.next == null)&#123; return null; &#125; Node&lt;E&gt; e = front.next; front.next = e.next; size--; return e.item; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return size == 0; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for(Node&lt;E&gt; x = front; x != null;)&#123; Node&lt;E&gt; next = x.next; x.item =null; x.next = null; x = next; &#125; front = rear = node; size =0; &#125; @Override public E element() &#123; // TODO Auto-generated method stub if(front.next == null)&#123; throw new NoSuchElementException("queue is empty"); &#125; Node&lt;E&gt; e =front.next; return e.item; &#125; @Override public E peek() &#123; // TODO Auto-generated method stub if(front.next == null)&#123; return null; &#125; Node&lt;E&gt; e =front.next; return e.item; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return size; &#125; @Override public String toString()&#123; String str = "["; for(Node&lt;E&gt; x = front.next; x !=null;) &#123; Node&lt;E&gt; next = x.next; if(x.item != null)&#123; str = str + x.item +","; &#125; x = next; &#125; str = str + "]"; return str; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435public class Testqueue &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub IQueue&lt;String&gt; queue = new MyQueue&lt;String&gt;(); System.out.println(queue.isEmpty()); queue.offer("a"); queue.offer("b"); queue.offer("c"); queue.offer("d"); queue.offer("e"); System.out.println(queue.toString()); System.out.println(queue.size()); queue.poll(); System.out.println(queue.peek()); queue.poll(); System.out.println(queue.peek()); System.out.println(queue.size()); System.out.println(queue.toString()); queue.offer("a"); System.out.println(queue.peek()); System.out.println(queue.toString()); queue.offer("b"); System.out.println(queue.toString()); queue.clear(); queue.offer("a"); queue.offer("b"); queue.offer("c"); queue.offer("d"); queue.offer("e"); queue.clear(); System.out.println(queue.toString()); System.out.println(queue.isEmpty()); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（2）]]></title>
      <url>%2F2017%2F06%2F28%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%882%EF%BC%89%2F</url>
      <content type="text"><![CDATA[本文在阅读大话数据结构这本书的基础上，结合java语言的特点，来理解线性表，代码均为自己实现。 线性表线性表表示0个或者多个数据元素的有限序列。 线性表的特性有: 除第一个元素外,每一个元素均有一个直接前驱，除最后一个元素外,每一个元素均有一个直接后继。 线性表抽象数据类型IList接口如下： 123456789public interface IList&lt;E&gt; &#123; boolean isEmpty(); void clear(); E get(int i); boolean contains(Object o); E insert(int i , E e); E remove(int i); int size();&#125; 线性表的顺序存储结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public class SequenceList&lt;E&gt; implements IList&lt;E&gt; &#123; private final static int CAPACITY = 10; private final static Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA =new Object[CAPACITY]; private Object[] elementData; private int size; @SuppressWarnings("unchecked") E elementData(int index)&#123; return (E) elementData[index]; &#125; public SequenceList()&#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; public SequenceList(int capacity)&#123; this.elementData = new Object[capacity]; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return size == 0; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for ( int i = 0; i &lt; size ; i++) &#123; elementData[i] = null; &#125; size = 0; &#125; @Override public E get(int i) &#123; // TODO Auto-generated method stub if( i &gt;= size)&#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(i)); &#125; return elementData(i); &#125; @Override public boolean contains(Object o) &#123; // TODO Auto-generated method stub for(int i = 0 ; i &lt; size ; i++) &#123; if(o.equals(elementData[i]))&#123; return true; &#125; &#125; return false; &#125; @Override public E insert(int i, E e) &#123; // TODO Auto-generated method stub if( i &gt;= size)&#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(i)); &#125; ensureCapacityInternal(++size); int length = size - i; System.arraycopy(elementData, i, elementData, i + 1, length); elementData[i] = e; return e; &#125; private String outOfBoundsMsg(int i) &#123; return "Index: " + i + ", Size: " + size; &#125; @Override public E remove(int i) &#123; // TODO Auto-generated method stub if( i &gt;= size)&#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(i)); &#125; E oldvalue = elementData(i); int length = size - i - 1; System.arraycopy(elementData, i + 1, elementData, i, length); elementData[--size] = null; return oldvalue; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return size; &#125; @Override public boolean add(E e) &#123; // TODO Auto-generated method stub ensureCapacityInternal(size + 1); elementData[size++] = e; return true; &#125; private void ensureCapacityInternal(int capacity)&#123; if(elementData.length - capacity &lt; 0) &#123; grow(capacity); &#125; &#125; private void grow(int capacity)&#123; int oldcapacity = elementData.length; int newcapacity = oldcapacity + (oldcapacity &gt;&gt; 1); if(newcapacity &lt; capacity)&#123; newcapacity = capacity; &#125; elementData =Arrays.copyOf(elementData, newcapacity); &#125;&#125; 123456789101112131415161718192021222324252627public class Testdemo &#123; public static void main(String[] args) &#123; IList&lt;String&gt; list = new SequenceList&lt;String&gt;(); System.out.println(list.size()); System.out.println(list.isEmpty()); list.add("a"); list.add("b"); list.add("c"); list.add("d"); list.insert(2, "e"); list.insert(2, "f"); list.insert(2, "g"); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; list.remove(2); list.remove(2); list.remove(2); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; System.out.println(list.contains("c")); list.clear(); System.out.println(list.size()); &#125;&#125; 线性表的链式存储结构单链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public class SinglelinkedList&lt;E&gt; implements IList&lt;E&gt; &#123; private int size = 0; private Node&lt;E&gt; first; private Node&lt;E&gt; last; public SinglelinkedList()&#123; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return size == 0; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for(Node&lt;E&gt; x = first; x != null;)&#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x = next; &#125; first = null; last = null; size = 0; &#125; @Override public E get(int index) &#123; // TODO Auto-generated method stub checkElementIndex(index); Node&lt;E&gt; x =first; if (index == 0) &#123; return x.item; &#125; for (int i = 0 ; i &lt; index ; i++) &#123; x = x.next; &#125; E elem =x.item; return elem; &#125; @Override public boolean contains(Object o) &#123; // TODO Auto-generated method stub if(first == null)&#123; return false; &#125; Node&lt;E&gt; x = first; for( int i = 0 ; i &lt; size ; i++)&#123; if(x.item.equals(o))&#123; return true; &#125; x = x.next; &#125; return false; &#125; @Override public E insert(int index, E e) &#123; // TODO Auto-generated method stub checkElementIndex(index - 1); if(index == 0)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e, first); first = newNode; &#125;else if(index == size)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e, null); last.next =newNode; last = newNode; &#125;else&#123; Node&lt;E&gt; x =first; for (int i = 0 ; i &lt; index - 1; i++) &#123; x = x.next; &#125; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e,x.next); x.next = newNode; &#125; size++; return e; &#125; @Override public E remove(int index) &#123; // TODO Auto-generated method stub if(first == null)&#123; return null; &#125; checkElementIndex(index); if(index == 0)&#123; E elem =first.item; first = first.next; size--; return elem; &#125;else&#123; Node&lt;E&gt; x =first; for (int i = 0 ; i &lt; index - 1; i++) &#123; x = x.next; &#125; Node&lt;E&gt; tmp = x.next; E elem = tmp.item; x.next = tmp.next; size--; return elem; &#125; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return size; &#125; @Override public boolean add(E e) &#123; // TODO Auto-generated method stub final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e,null); if(first == null &amp;&amp; last == null)&#123; last = newNode; first = newNode; &#125;else&#123; last.next = newNode; last = newNode; &#125; size++; return true; &#125; private void checkElementIndex(int i)&#123; if( i &gt;= size)&#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(i)); &#125; &#125; private String outOfBoundsMsg(int i) &#123; return "Index: " + i + ", Size: " + size; &#125; private static class Node&lt;E&gt;&#123; E item; Node&lt;E&gt; next; public Node(E item ,Node&lt;E&gt; last)&#123; this.item = item; this.next = last; &#125; &#125;&#125; 双向循环链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178public class DoublylinkedList&lt;E&gt; implements IList&lt;E&gt; &#123; private int size = 0; private Node&lt;E&gt; first; private Node&lt;E&gt; last; public DoublylinkedList()&#123; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return size == 0; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for(Node&lt;E&gt; x = first; x != null;)&#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.before = null; x = next; &#125; first = null; last = null; size = 0; &#125; @Override public E get(int index) &#123; // TODO Auto-generated method stub if (index == 0) &#123; return first.item; &#125;else if(index &lt; (size &gt;&gt;1))&#123; Node&lt;E&gt; x =first; for (int i = 0 ; i &lt; index ; i++) &#123; x = x.next; &#125; E elem =x.item; return elem; &#125;else&#123; Node&lt;E&gt; x =last; for ( int i = size - 1; i &gt; index; i--)&#123; x = x.before; &#125; E elem =x.item; return elem; &#125; &#125; @Override public boolean contains(Object o) &#123; // TODO Auto-generated method stub if(first == null)&#123; return false; &#125; Node&lt;E&gt; x = first; for( int i = 0 ; i &lt; size ; i++)&#123; if(x.item.equals(o))&#123; return true; &#125; x = x.next; &#125; return false; &#125; @Override public E insert(int index, E e) &#123; // TODO Auto-generated method stub checkElementIndex(index - 1); if(index == 0)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(last,e, first); first.before = newNode; first = newNode; last.next = first; &#125;else if(index == size)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(last,e, first); first.before = newNode; last.next =newNode; last = newNode; &#125;else if(index &lt; (size &gt;&gt;1))&#123; Node&lt;E&gt; x = first; for (int i = 0 ; i &lt; index - 1; i++) &#123; x = x.next; &#125; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(x,e,x.next); x.next.before = newNode; x.next = newNode; &#125;else &#123; Node&lt;E&gt; x = last; for(int i = size - 1; i &gt; index - 1; i--)&#123; x =x.before; &#125; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(x,e,x.next); x.next.before = newNode; x.next = newNode; &#125; size++; return e; &#125; @Override public E remove(int index) &#123; // TODO Auto-generated method stub if(first == null)&#123; return null; &#125; checkElementIndex(index); if(index == 0)&#123; E elem =first.item; Node&lt;E&gt; x = first.next; x.before = last; last.next = x; first = x; size--; return elem; &#125;else&#123; Node&lt;E&gt; x =first; for (int i = 0 ; i &lt; index - 1; i++) &#123; x = x.next; &#125; Node&lt;E&gt; tmp = x.next; E elem = tmp.item; x.next = tmp.next; tmp.next.before =x; size--; return elem; &#125; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return size; &#125; @Override public boolean add(E e) &#123; // TODO Auto-generated method stub final Node&lt;E&gt; newNode = new Node&lt;E&gt;(null,e,null); if(first == null &amp;&amp; last == null)&#123; last = newNode; last.before = last; last.next = last; first = newNode; &#125;else&#123; newNode.before = last; last.next = newNode; last = newNode; last.next = first; first.before = last; &#125; size++; return true; &#125; private void checkElementIndex(int i)&#123; if( i &gt;= size)&#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(i)); &#125; &#125; private String outOfBoundsMsg(int i) &#123; return "Index: " + i + ", Size: " + size; &#125; private static class Node&lt;E&gt;&#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; before; public Node(Node&lt;E&gt; before,E item ,Node&lt;E&gt; last)&#123; this.before = before; this.item = item; this.next = last; &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839public class Testdemo &#123; public static void main(String[] args) &#123; IList&lt;String&gt; list = new DoublylinkedList&lt;String&gt;(); System.out.println("list.size()"+list.size()); System.out.println(list.isEmpty()); list.add("a"); list.add("b"); list.add("c"); list.add("d"); System.out.println("list.size() = "+list.size()); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; list.insert(4, "e"); list.insert(5, "f"); list.insert(6, "g"); System.out.println("list.size() = "+list.size()); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; list.insert(5, "f"); list.remove(0); list.remove(2); list.remove(2); System.out.println("list.size() = "+list.size()); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; System.out.println("index &gt; size "+list.get(4)); System.out.println("index &gt; size "+list.get(5)); System.out.println("index &gt; size "+list.get(6)); System.out.println("index &gt; size "+list.get(7)); System.out.println("index &gt; size "+list.get(8)); System.out.println(list.contains("c")); list.clear(); System.out.println(list.size()); &#125;&#125; 循环链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139public class CircularlinkedList&lt;E&gt; implements IList&lt;E&gt; &#123; private int size = 0; private Node&lt;E&gt; first; private Node&lt;E&gt; last; public CircularlinkedList()&#123; &#125; @Override public boolean isEmpty() &#123; // TODO Auto-generated method stub return size == 0; &#125; @Override public void clear() &#123; // TODO Auto-generated method stub for(Node&lt;E&gt; x = first; x != null;)&#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x = next; &#125; first = null; last = null; size = 0; &#125; @Override public E get(int index) &#123; // TODO Auto-generated method stub Node&lt;E&gt; x =first; if (index == 0) &#123; return x.item; &#125; for (int i = 0 ; i &lt; index ; i++) &#123; x = x.next; &#125; E elem =x.item; return elem; &#125; @Override public boolean contains(Object o) &#123; // TODO Auto-generated method stub if(first == null)&#123; return false; &#125; Node&lt;E&gt; x = first; for( int i = 0 ; i &lt; size ; i++)&#123; if(x.item.equals(o))&#123; return true; &#125; x = x.next; &#125; return false; &#125; @Override public E insert(int index, E e) &#123; // TODO Auto-generated method stub checkElementIndex(index - 1); if(index == 0)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e, first); first =newNode; last.next= first; &#125;else if(index == size)&#123; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e, first); last.next =newNode; last = newNode; &#125;else&#123; Node&lt;E&gt; x =first; for (int i = 0 ; i &lt; index - 1; i++) &#123; x = x.next; &#125; final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e,x.next); x.next = newNode; &#125; size++; return e; &#125; @Override public E remove(int index) &#123; // TODO Auto-generated method stub if(first == null)&#123; return null; &#125; checkElementIndex(index); if(index == 0)&#123; E elem =first.item; first = first.next; last.next = first; size--; return elem; &#125;else&#123; Node&lt;E&gt; x =first; for (int i = 0 ; i &lt; index - 1; i++) &#123; x = x.next; &#125; Node&lt;E&gt; tmp = x.next; E elem = tmp.item; x.next = tmp.next; size--; return elem; &#125; &#125; @Override public int size() &#123; // TODO Auto-generated method stub return size; &#125; @Override public boolean add(E e) &#123; // TODO Auto-generated method stub final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e,null); if(first == null &amp;&amp; last == null)&#123; last = newNode; last.next = newNode; first = last; &#125;else&#123; last.next = newNode; last = newNode; last.next = first; &#125; size++; return true; &#125; private void checkElementIndex(int i)&#123; if( i &gt;= size)&#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(i)); &#125; &#125; private String outOfBoundsMsg(int i) &#123; return "Index: " + i + ", Size: " + size; &#125; private static class Node&lt;E&gt;&#123; E item; Node&lt;E&gt; next; public Node(E item ,Node&lt;E&gt; last)&#123; this.item = item; this.next = last; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738public class Testdemo &#123; public static void main(String[] args) &#123; IList&lt;String&gt; list = new CircularlinkedList&lt;String&gt;(); System.out.println("list.size()"+list.size()); System.out.println(list.isEmpty()); list.add("a"); list.add("b"); list.add("c"); list.add("d"); System.out.println("list.size() = "+list.size()); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; list.insert(4, "e"); list.insert(5, "f"); list.insert(6, "g"); System.out.println("list.size() = "+list.size()); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; list.remove(0); list.remove(2); list.remove(2); System.out.println("list.size() = "+list.size()); for ( int i = 0; i &lt; list.size();i++)&#123; System.out.println(list.get(i)); &#125; System.out.println("index &gt; size "+list.get(4)); System.out.println("index &gt; size "+list.get(5)); System.out.println("index &gt; size "+list.get(6)); System.out.println("index &gt; size "+list.get(7)); System.out.println("index &gt; size "+list.get(8)); System.out.println(list.contains("c")); list.clear(); System.out.println(list.size()); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读大话数据结构（1）]]></title>
      <url>%2F2017%2F06%2F27%2F%E9%98%85%E8%AF%BB%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%881%EF%BC%89%2F</url>
      <content type="text"><![CDATA[程序 = 数据结构 + 算法 基本概念和术语​ 数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。不仅包括整型、实型等数值类型，还包括字符以及声音、图像、视频等非数值类型。​ 数据元素：是组成数据的、有一定意义的基本单位，在计算机中通常作为整体处理，也被称为记录。​ 数据项：一个数据元素可以由若干个数据项组成。数据项是数据不可分割的最小单位。虽然数据项是数据的最小单位，但真正讨论问题时，数据元素才是数据结构中建立数据模型的着眼点。​ 数据对象：是性质相同的数据元素的集合，是数据的子集。在不产生混淆的的情况下，我们都将数据对象简称为数据。 ​ 数据结构：是相互之间存在的一种或多种特定关系的数据元素的集合。 按照不同的视点，将数据结构分为逻辑结构和物理结构。​ 逻辑结构：是指数据对象中数据元素之间的相互关系。逻辑结构分为以下四种：​ 集合结构：集合结构中的数据元素除了同属于一个集合外，它们之间没有其他关系。​ 线性结构：线性结构中的数据元素之间是一对一的关系（个人感觉就是链表那种关系）。​ 树形结构：树形结构中的数据元素之间存在一种一对多的层次关系。​ 图形结构：图形结构的数据元素是多对多的关系。 ​ 物理结构：是指数据的逻辑结构在计算机中的存储形式。 ​ 顺序存储：是把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系一般是一致的。（例如数组） 链式存储结构：是把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的。（例如链表） 算法算法的五个基本特性：输入、输出、有穷性、确定性和可行性。​ 输入输出：算法具有零个或多个输入，至少有一个或多个输出。​ 有穷性：指算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成。​ 确定性：算法的每一步骤都具有确定的含义，不会出现二义性。​ 可行性：算法的每一步都必须是可行的，即每一步都能够通过执行有限次数完成。 算法设计的要求：​ 正确性： 算法程序没有语法错误。​ 算法程序对于合法输入数据能够产生满足要求的输出结果。​ 算法程序对于非法的输入数据能够得出满足规格说明的结果。 算法程序对于精心选择的、甚至刁难的测试数据都有满足要求的输出结果。 ​ 可读性：算法设立的另一个目的就是为了便于阅读、理解和交流。​ 健壮性：输入不合法时，算法应作出相应处理，而不是产生异常的结果。​ 时间效率高和存储量低。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java的内存模型]]></title>
      <url>%2F2017%2F06%2F26%2Fjava%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[内存模型的基本概念​ 计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 ​ 也就是说，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 1i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法(硬件层面上提供的方式)： 通过在总线加LOCK#锁的方式 ​ 这种方式阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。虽然解决了缓存不一致性，但是由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 通过缓存一致性协议 ​ 最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 ​ 但是有两种情况下处理器不会使用缓存锁定 ：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 另外在理解并发时候，我们需要掌握三个概念：原子性问题，可见性问题，有序性问题，后面在java的内存模型详细说明。 原子性问题：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 可见性问题：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性问题：程序执行的顺序按照代码的先后顺序执行。 java的内存模型​ Java虚拟机规范中试图定义一种Java内存模型(Java Memory Model,JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。 在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模型，因此，会由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错，因此在某些场景就必须针对不同的平台来编写程序。经过长时间的验证和修补，在JDK 1.5（实现了JSR-133[2]）发布后，Java内存模型已经成熟和完善起来了。 ​ Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 在java中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间是共享的。而局部变量（Local variables），方法定义参数（java语言规范称之为formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，不受内存模型的影响。所以java的内存模型保证的是这些共享数据在线程之间的传递。 java的内存模型的抽象​ 下图是java的内存模型的抽象，线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在，它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。所以这里所讲的主内存、本地内存与Java内存区域中的Java堆、 栈、 方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、 主内存、 本地内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而本地内存则对应于虚拟机栈中的部分区域。 从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措施）可能会让本地内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是本地内存。 线程A与线程B之间如要通信的话，必须要经历下面2个步骤： ​ 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。 ​ 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。 内存间交互操作​ Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、 不可再分的（对于double和long类型的变量来说，load、 store、 read和write操作在某些平台上允许有例外。 lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 ​ 如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。 注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。 也就是说，read与load之间、 store与write之间是可插入其他指令的，如对主内存中的变量a、 b进行访问时，一种可能出现顺序是read a、 read b、 load b、 load a。 除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则： 不允许read和load、 store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说，就是对一个变量实施use、 store操作之前，必须先执行过了assign和load操作。 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、 write操作）。 附录：对于long和double型变量的特殊规则 ​ 允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据类型的load、 store、 read和write这4个操作的原子性，这点就是所谓的long和double的非原子性协定（Nonatomic Treatment ofdouble and long Variables）。在实际开发中，目前各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要把用到的long和double变量专门声明为volatile。 原子性、 可见性与有序性原子性（Atomicity）：由Java内存模型来直接保证的原子性变量操作包括read、 load、assign、 use、 store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的。 如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。 除此之外使用循环CAS实现原子操作，例如原子包装类。 可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的，而final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。 有序性（Ordering）：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。 前半句是指“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。 ​ Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行地进入。 重排序​ 为了提高编译效率，Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 ​ 对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。​ JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 JMM把内存屏障指令分为下列四类： 屏障类型 指令示例 说明 LoadLoad Barriers Load1; LoadLoad; Load2 确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。 StoreStore Barriers Store1; StoreStore; Store2 确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。 LoadStore Barriers Load1; LoadStore; Store2 确保Load1数据装载，之前于Store2及所有后续的存储指令刷新到内存。 StoreLoad Barriers Store1; StoreLoad; Load2 确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 对于使用volatile关键字： 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 happens-before原则​ 从JDK5开始，java使用新的JSR -133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 1234程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读。传递性：如果A happens- before B，且B happens- before C，那么A happens- before C。 ​ 注意，两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。 happens-before与JMM的关系： as-if-serial语义​ as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守as-if-serial语义。as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。asif-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 总结：JMM是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Volatile,Synchronized ,Final和 Lock的使用]]></title>
      <url>%2F2017%2F06%2F25%2FSynchronized-%E5%92%8C-Lock%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[Volatile的用法在学习volatile关键字用法之前，首先了解java的内存模型。 volatile的定义与实现原理​ volatile 变量可以被看作是一种 “程度较轻的 synchronized”；与 synchronized 块相比，volatile 变量所需的编码较少，并且运行时开销也较少，但是它所能实现的功能也仅是 synchronized 的一部分。在某些情况下，如果读操作远远大于写操作，volatile 变量还可以提供优于锁的性能优势。 ​ 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。禁止进行指令重排序。但是不能保证原子性！ 在了解volatile实现原理之前，需要了解CPU的相关术语： 关于如何实现可见性和禁止指令重排序，《深入理解Java虚拟机》有如下描述： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 volatile关键字的场景正确使用 volatile 变量的条件是对变量的写操作不依赖于当前值和该变量没有包含在具有其他变量的不变式中。如何理解？简单来说这2个条件保证了操作具有原子性。 场景一：状态标志 12345678910111213141516171819202122232425import java.util.concurrent.TimeUnit;public class ReadQueue &#123; private volatile static boolean flag = true; public void setFlag()&#123; flag = false; &#125; public void readOperator()&#123; if(!flag)&#123; System.out.println("flag is reset by false"); System.exit(0); &#125; while(flag)&#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println("flag is true ,so i am reading ..."); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031public class Main &#123; public static void main(String[] args) &#123; final ReadQueue ReadQueue = new ReadQueue(); new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; ReadQueue.readOperator(); &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; TimeUnit.SECONDS.sleep(10); ReadQueue.setFlag(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;).start(); &#125;&#125; 场景二：一次性安全发布（one-time safe publication） 在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。这就是造成著名的双重检查锁定（double-checked-locking）问题的根源。如下： 1234567891011121314151617public class Singleton &#123; private volatile static Singleton singleton = null; //volatile 很重要 public Singleton () &#123; &#125; public static Singleton getInstance()&#123; if(singleton == null) &#123; synchronized (Singleton.class) &#123; //1 if(singleton == null) &#123; //2 singleton = new Singleton(); //3 &#125; &#125; &#125; return singleton; &#125;&#125; 线程 1 进入 getInstance() 方法。由于 instance 为 null，线程 1 在 //1 处进入synchronized 块。 线程 1 前进到 //3 处，但在构造函数执行之前，使实例成为非null。 线程 1 被线程 2 预占。 线程 2 检查实例是否为 null。因为实例不为 null，线程 2 将instance 引用返回，返回一个构造完整但部分初始化了的Singleton 对象。 线程 2 被线程 1 预占。 线程 1 通过运行 Singleton 对象的构造函数并将引用返回给它，来完成对该对象的初始化。 这时候线程2实际得到的是一个未完全初始化的Singleton 对象。 那么为什么会出现上述描述的过程呢？ 归根是指令重排序引起。指令重排序是为了优化指令，提高程序运行效率。指令重排序包括编译器重排序和运行时重排序。JVM规范规定，指令重排序可以在不影响单线程程序执行结果前提下进行。例如 instance = new Singleton() 可分解为如下伪代码： 123memory = allocate(); //1：分配对象的内存空间 ctorInstance(memory); //2：初始化对象 instance = memory; //3：设置instance指向刚分配的内存地址 但是经过重排序后如下： 1234memory = allocate(); //1：分配对象的内存空间 instance = memory; //3：设置instance指向刚分配的内存地址 //注意，此时对象还没有被初始化！ ctorInstance(memory); //2：初始化对象 将第2步和第3步调换顺序，在单线程情况下不会影响程序执行的结果，但是在多线程情况下就不一样了。线程A执行了instance = memory（这对另一个线程B来说是可见的），此时线程B执行外层 if (instance == null)，发现instance不为空，随即返回，但是得到的却是未被完全初始化的实例，在使用的时候必定会有风险，这正是双重检查锁定的问题所在！ 附录支持多线程的其他单例模式实现： 1.提前初始化 12345678910public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 2.延迟初始化占位类模式 1234567891011public class Singleton &#123; private static class InstanceHolder&#123; private static Singleton instance = new Singleton(); &#125; public Singleton () &#123; &#125; public static Singleton getInstance()&#123; return InstanceHolder.instance; &#125;&#125; 场景三：独立观察（independent observation） 场景四：“volatile bean” 模式 场景五：开销较低的“读－写锁”策略 123456789101112131415161718192021222324252627import java.util.concurrent.TimeUnit;public class ReadWriteQueue &#123; private volatile Object data = null; public void getData() &#123; try &#123; System.out.println(Thread.currentThread().getName() + " be ready to read data"); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + " read the data:" + data); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; public synchronized void putData(Object data) &#123; try &#123; System.out.println(Thread.currentThread().getName() + " be ready to write data"); TimeUnit.SECONDS.sleep(5); this.data =data; System.out.println(Thread.currentThread().getName() + " write the data:" + data); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728public class Main &#123; public static void main(String[] args) &#123; final ReadWriteQueue ReadWriteQueue = new ReadWriteQueue(); for (int i = 0 ; i &lt; 5; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; ReadWriteQueue.getData(); &#125; &#125; &#125;).start(); &#125; for ( int i = 0 ; i &lt; 1; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; ReadWriteQueue.putData(new Random().nextInt(300)); &#125; &#125; &#125;).start(); &#125; &#125;&#125; 锁的相关概念介绍可重入锁如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。 可中断锁synchronized就不是可中断锁，而Lock是可中断锁。如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。下面的lockInterruptibly()的用法时已经体现了Lock的可中断性。 公平锁公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。 共享锁和排它锁共享锁就是允许多个线程同时获取一个锁，一个锁可以同时被多个线程拥有。排它锁，也称作独占锁，一个锁在某一时刻只能被一个线程占有，其它线程必须等待锁被释放之后才可能获取到锁。 ReentrantLock就是一种排它锁。CountDownLatch是一种共享锁。这两类都是单纯的一类，即，要么是排它锁，要么是共享锁。ReentrantReadWriteLock是同时包含排它锁和共享锁特性的一种锁，这里主要以ReentrantReadWriteLock为例来进行分析学习。我们使用ReentrantReadWriteLock的写锁时，使用的便是排它锁的特性；使用ReentrantReadWriteLock的读锁时，使用的便是共享锁的特性。 Synchronized的用法Synchonized实现原理​ 从JVM规范中可以看到Synchonized在JVM里的实现原理，JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。但是二者都可以通过monitorenter和monitorexit指令来实现。 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。在java6中，锁引用了无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态4种状态，这几个状态会随着竞争情况逐渐升级 。 synchronized是Java中的关键字，是一种同步锁。它修饰的对象有以下几种： 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象； 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象； 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的所有对象； 修改一个类，其作用的范围是synchronized后面括号括起来的部分，作用的对象是这个类的所有对象。 修饰一个代码块一个线程访问一个对象中的synchronized(this)同步代码块时，其他试图访问该对象同步代码块的线程将被阻塞,但是仍然可以访问该对象中的非synchronized(this)同步代码块。 12345678910111213141516171819202122public class SyncThread implements Runnable &#123; private static int count; public SyncThread() &#123; count = 0; &#125; @Override public void run() &#123; synchronized(this) &#123; for (int i = 0; i &lt; 5; i++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public int getCount() &#123; return count; &#125;&#125; 1234567891011public class Main &#123; public static void main(String[] args) &#123; SyncThread syncThread =new SyncThread(); Thread thread1=new Thread(syncThread,"1号"); Thread thread2=new Thread(syncThread,"2号"); Thread thread3=new Thread(syncThread,"3号"); thread1.start(); thread2.start(); thread3.start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233class Counter implements Runnable&#123; private int count; public Counter() &#123; count = 0; &#125; @Override public void run() &#123; countAdd(); printCount(); &#125; public void countAdd() &#123; synchronized(this) &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + "线程计数为:" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public void printCount() &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + "打印计数为:" + count); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 1234567891011public class Main &#123; public static void main(String[] args) &#123; Counter counter =new Counter(); Thread thread1=new Thread(counter,"1号"); Thread thread2=new Thread(counter,"2号"); Thread thread3=new Thread(counter,"3号"); thread1.start(); thread2.start(); thread3.start(); &#125;&#125; 除了synchronized(this)还可以修饰某一个特定的对象控制访问; 1234567891011121314151617181920212223242526272829303132333435363738public class Account &#123; private String name; private float amount; public Account(String name, float amount) &#123; this.name = name; this.amount = amount; &#125; //存钱 public void deposit(float amt) &#123; try &#123; Thread.sleep(5); amount += amt; System.out.println(Thread.currentThread().getName()+" deposit, finally the amount:" +amount); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //取钱 public void withdraw(float amt) &#123; try &#123; Thread.sleep(6); amount -= amt; System.out.println(Thread.currentThread().getName()+" withdraw, finally the amount:" +amount); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public String getName() &#123; return name; &#125; public float getBalance() &#123; return amount; &#125;&#125; 123456789101112131415161718192021222324public class AccountOperator implements Runnable &#123; private String operator; private Account account; public AccountOperator (Account account,String operator) &#123; this.account = account; this.operator = operator; &#125; @Override public void run() &#123; // TODO Auto-generated method stub if(operator.equals("deposit"))&#123; synchronized (account) &#123; account.deposit(500); &#125; &#125;else&#123; synchronized (account) &#123; account.withdraw(500);; &#125; &#125; &#125;&#125; 123456789101112131415public class Main &#123; public static void main(String[] args) &#123; Account account =new Account("lucky",2000); for(int i = 0; i &lt; 20; i++)&#123; if(i%2 == 0)&#123; new Thread(new AccountOperator(account, "deposit")).start(); &#125;else&#123; new Thread(new AccountOperator(account, "withdraw")).start(); &#125; &#125; while(Thread.activeCount() &gt; 1) Thread.yield(); System.out.println("finally, amount :"+account.getBalance()); &#125;&#125; 修饰一个方法Synchronized作用于整个方法的写法 1234public synchronized void method()&#123; // todo&#125; 123456public void method()&#123; synchronized(this) &#123; // todo &#125;&#125; 虽然可以使用synchronized来定义方法，但synchronized并不属于方法定义的一部分，因此，synchronized关键字不能被继承。如果在父类中的某个方法使用了synchronized关键字，而在子类中覆盖了这个方法，在子类中的这个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上synchronized关键字才可以。当然，还可以在子类方法中调用父类中相应的方法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此，子类的方法也就相当于同步了。 12345678class Parent &#123; public synchronized void method() &#123; &#125;&#125;class Child extends Parent &#123; public synchronized void method() &#123; &#125;&#125; 123456789class Parent &#123; public synchronized void method() &#123; &#125;&#125;class Child extends Parent &#123; public void method() &#123; super.method(); &#125;&#125; 修饰一个静态的方法静态方法是属于类的而不属于对象的。synchronized修饰的静态方法锁定的是这个类的所有对象。 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; int count = 0; SyncThread syncThread1 =new SyncThread(count,"1号"); SyncThread syncThread2 =new SyncThread(count,"2号"); SyncThread syncThread3 =new SyncThread(count,"3号"); Thread thread1=new Thread(syncThread1,"1号"); Thread thread2=new Thread(syncThread2,"2号"); Thread thread3=new Thread(syncThread3,"3号"); thread1.start(); thread2.start(); thread3.start(); &#125;&#125; 12345678910111213141516171819202122232425public class SyncThread implements Runnable &#123; private static int count; private String name; public SyncThread(int count,String name) &#123; this.count = count; this.name = name; &#125; @Override public void run() &#123; method(); &#125; public int getCount() &#123; return count; &#125; public synchronized static void method()&#123; for (int i = 0; i &lt; 5; i++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 修饰一个类用法如下 1234567class ClassName &#123; public void method() &#123; synchronized(ClassName.class) &#123; // todo &#125; &#125;&#125; 123456789101112131415161718192021222324252627public class SyncThread implements Runnable &#123; private static int count; private String name; public SyncThread(int count,String name) &#123; this.count = count; this.name = name; &#125; @Override public void run() &#123; method(); &#125; public int getCount() &#123; return count; &#125; public void method() &#123; synchronized (SyncThread.class) &#123; for (int i = 0; i &lt; 5; i++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; Final 的用法对于final域，编译器和处理器要遵守两个重排序规则： 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。 只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。 Lock的用法ReentrantLock的用法lock的接口12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。一般使用如下： 123456789Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125; tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock(long time, TimeUnit unit)方法，在时间期限之内如果还拿不到锁，就返回false。如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 123456789101112Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则直接做其他事情&#125; lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。 123456789public void method() throws InterruptedException &#123; lock.lockInterruptibly(); try &#123; //..... &#125; finally &#123; lock.unlock(); &#125; &#125; ​ ReentrantLock是Lock接口一种常见的实现，它是支持重进入的锁即表示该锁能够支持一个线程对资源的重复加锁。该锁还支持获取锁时的公平与非公平的选择。ReentrantLock是JDK1.5引入的，它拥有与synchronized相同的并发性和内存语义，并提供了超出synchonized的其他高级功能(例如，公平锁、中断锁等候、条件变量等)，并且使用ReentrantLock比synchronized能获得更好的可伸缩性。重要介绍一下Condition的使用。 Condition 将 Object的通信方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set （wait-set）。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 通信方法的使用。 在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。 Condition的强大之处在于它可以为多个线程间建立不同的Condition， 使用synchronized/wait()只有一个阻塞队列，notifyAll会唤起所有阻塞队列下的线程，而使用lock/condition，可以实现多个阻塞队列，signalAll只会唤起某个阻塞队列下的阻塞线程。 使用synchronized/wait()实现生产者消费者模式如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.util.Date;import java.util.LinkedList;import java.util.List;import java.util.concurrent.TimeUnit;public class EventStorage &#123; private int maxSize; private List&lt;Date&gt; storage; public EventStorage()&#123; maxSize = 10; storage = new LinkedList&lt;Date&gt;(); &#125; public synchronized void set()&#123; while(storage.size() == maxSize)&#123; System.out.println("--------------满仓-----------------"); try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; ((LinkedList&lt;Date&gt;) storage).offer(new Date()); System.out.println(Thread.currentThread().getName()+" Set:"+storage.size()); notifyAll(); &#125; public synchronized void get(String name)&#123; while(storage.size()==0)&#123; System.out.println(name+"---------------------------等待中--------------------"); try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.printf(name+"Get:%d:%s\n",storage.size(),((LinkedList&lt;Date&gt;) storage).poll()); notifyAll(); &#125; &#125; 12345678910111213public class Producer implements Runnable &#123; private EventStorage storage; public Producer(EventStorage storage)&#123; this.storage = storage; &#125; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; storage.set(); &#125; &#125;&#125; 12345678910111213141516public class Consumer implements Runnable&#123; private EventStorage storage; private String name; public Consumer(EventStorage storage,String name)&#123; this.storage = storage; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; storage.get(name); &#125; &#125;&#125; 12345678910111213141516public class Main &#123; public static void main(String[] args) &#123; EventStorage stor= new EventStorage(); for(int i = 0 ;i &lt; 6; i++) &#123; Consumer consumer = new Consumer(stor,i+"号消费者"); Thread th1 = new Thread(consumer); th1.start(); &#125; for(int i =0 ; i &lt; 2; i++) &#123; Producer producer = new Producer(stor); Thread th2 = new Thread(producer,i+"号生产者"); th2.start(); &#125; &#125;&#125; 使用lock/condition实现生产者消费者模式如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import java.util.Date;import java.util.LinkedList;import java.util.List;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class EventStorage &#123; private final Lock lock; private final Condition notFull; private final Condition notEmpty; private int maxSize; private List&lt;Date&gt; storage; public EventStorage()&#123; maxSize = 10; storage = new LinkedList&lt;Date&gt;(); lock = new ReentrantLock(); notFull =lock.newCondition(); notEmpty =lock.newCondition(); &#125; public void set()&#123; lock.lock(); try &#123; while(storage.size() == maxSize)&#123; System.out.println("--------------满仓-----------------"); try &#123; notFull.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; TimeUnit.SECONDS.sleep(1); ((LinkedList&lt;Date&gt;) storage).offer(new Date()); System.out.println(Thread.currentThread().getName()+" Set:"+storage.size()); notEmpty.signalAll(); &#125; catch (InterruptedException e ) &#123; // TODO: handle exception e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void get(String name)&#123; lock.lock(); try &#123; while(storage.size()==0)&#123; System.out.println(name+"---------------------------等待中--------------------"); try &#123; notEmpty.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; TimeUnit.SECONDS.sleep(1); System.out.printf(name+"Get:%d:%s\n",storage.size(),((LinkedList&lt;Date&gt;) storage).poll()); notFull.signalAll(); &#125; catch (InterruptedException e) &#123; // TODO: handle exception e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; ReentrantReadWriteLock的用法ReentrantReadWriteLock，首先要做的是与ReentrantLock划清界限。它和后者都是单独的实现，彼此之间没有继承或实现的关系。 ReadWriteLock接口一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程。也就是说读写锁使用的场合是一个共享资源被大量读取操作，而只有少量的写操作（修改数据）。 123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing */ Lock writeLock();&#125; ReadLock获取的是共享锁，WriteLock获取的是独占锁。当写操作时，其他线程无法读取或写入数据，而当读操作时，其它线程无法写入数据，但却可以读取数据 。所以读写锁：分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁；如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！ ReentrantReadWriteLock的特性公平性：非公平锁（默认） 这个和独占锁的非公平性一样，由于读线程之间没有锁竞争，所以读操作没有公平性和非公平性，写操作时，由于写操作可能立即获取到锁，所以会推迟一个或多个读操作或者写操作。因此非公平锁的吞吐量要高于公平锁。公平锁 利用AQS的CLH队列，释放当前保持的锁（读锁或者写锁）时，优先为等待时间最长的那个写线程分配写入锁，当前前提是写线程的等待时间要比所有读线程的等待时间要长。同样一个线程持有写入锁或者有一个写线程已经在等待了，那么试图获取公平锁的（非重入）所有线程（包括读写线程）都将被阻塞，直到最先的写线程释放锁。如果读线程的等待时间比写线程的等待时间还有长，那么一旦上一个写线程释放锁，这一组读线程将获取锁。 重入性：读写锁允许读线程和写线程按照请求锁的顺序重新获取读取锁或者写入锁。当然了只有写线程释放了锁，读线程才能获取重入锁。写线程获取写入锁后可以再次获取读取锁，但是读线程获取读取锁后却不能获取写入锁。读写锁最多支持65535个递归写入锁和65535个递归读取锁。 锁降级：写线程获取写入锁后可以获取读取锁，然后释放写入锁，这样就从写入锁变成了读取锁，从而实现锁降级的特性。 12345678ReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.writeLock().lock(); System.out.println("writeLock"); rtLock.readLock().lock(); System.out.println("get read lock"); //虽然不会导致死锁，但没有正确的释放锁。从写锁降级成读锁，并不会自动释放当前线程获取的写锁，仍然需要显示的释放，否则别的线程永远也获//取不到写锁。rtLock.writeLock().unlock(); 锁升级：读取锁是不能直接升级为写入锁的。因为获取一个写入锁需要释放所有读取锁，所以如果有两个读取锁视图获取写入锁而都不释放读取锁时就会发生死锁。 下面就是锁升级，ReentrantReadWriteLock是不支持的，会产生死锁。 12345ReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.readLock().lock(); System.out.println("get readLock."); rtLock.writeLock().lock(); System.out.println("blocking"); 可以这样实现： 123456ReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.readLock().lock(); System.out.println("get readLock."); rtLock.readLock().unlock(); rtLock.writeLock().lock(); System.out.println("blocking"); 锁获取中断：读取锁和写入锁都支持获取锁期间被中断。这个和独占锁一致。 条件变量：写入锁提供了条件变量(Condition)的支持，这个和独占锁一致，但是读取锁却不允许获取条件变量，将得到一个UnsupportedOperationException异常。 重入数：读取锁和写入锁的数量最大分别只能是65535（包括重入数）。 123456789101112131415161718192021222324252627282930import java.util.Random;public class Main &#123; public static void main(String[] args) &#123; final ReadWriteQueue ReadWriteQueue = new ReadWriteQueue(); for (int i = 0 ; i &lt; 20; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; ReadWriteQueue.getData(); &#125; &#125; &#125;).start(); &#125; for ( int i = 0 ; i &lt; 1; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; ReadWriteQueue.putData(new Random().nextInt(300)); &#125; &#125; &#125;).start(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;public class ReadWriteQueue &#123; private Object data = null; private ReentrantReadWriteLock rwlock = new ReentrantReadWriteLock(); public void getData() &#123; try &#123; rwlock.readLock().lock(); System.out.println(Thread.currentThread().getName() + " be ready to read data"); TimeUnit.SECONDS.sleep(5); System.out.println(Thread.currentThread().getName() + " read the data:" + data); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally&#123; rwlock.readLock().unlock(); &#125; &#125; public void putData(Object data) &#123; try &#123; rwlock.writeLock().lock(); System.out.println(Thread.currentThread().getName() + " be ready to write data"); TimeUnit.SECONDS.sleep(5); this.data =data; System.out.println(Thread.currentThread().getName() + " write the data:" + data); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally&#123; rwlock.writeLock().unlock(); &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Runnable，Callable及Future，FutureTask的用法]]></title>
      <url>%2F2017%2F06%2F22%2FRunnable-Callable%E5%8F%8AFuture%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
      <content type="text"><![CDATA[内容 时间 初始化 2017-06-22 更新FutureTask 2017-09-11 RunnableRunnable是个接口，在它里面只声明了一个run()方法： 123public interface Runnable &#123; public abstract void run();&#125; 使用很简单： 1.实现该接口并重写run方法 2.利用该类的对象创建线程 3.线程启动时就会自动调用该对象的run方法 相对于继承Thread来创建线程方式，使用Runnable可以让你的实现类同时实现多个接口，而相对于Callable及Future，Runnable方法并不返回任务执行结果且不能抛出异常。 通常在开发中结合ExecutorService使用,将任务的提交与任务的执行解耦开,同时也能更好地利用Executor提供的各种特性。 1234567ExecutorService executor = Executors.newCachedThreadPool(); executor.submit(new Runnable() &#123; public void run() &#123; //TODO &#125; &#125;);executor.shutdown(); Callable它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call()： 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。 Callable并不像Runnable那样通过Thread的start方法就能启动实现类的run方法，所以它通常利用ExecutorService的submit方法去启动call方法自执行任务，而ExecutorService的submit又返回一个Future类型的结果，因此Callable通常也与Future一起使用。 123456ExecutorService pool = Executors.newCachedThreadPool(); Future&lt;String&gt; future = pool.submit(new Callable&#123; public void call()&#123; //TODO &#125; &#125;); 或者利用FutureTask封装Callable再由Thread去启动（少用） 1234567FutureTask&lt;String&gt; task = new FutureTask(new Callable&#123; public void call()&#123; //TODO &#125; &#125;); Thead thread = new Thread(task); thread.start(); 通过Executors.callable(Runnable task,T result)可以执行Runnable并返回”结果”，但是这个结果并不是Runnable的执行结果(Runnable的run方法是void类型)，而是执行者预定义的结果，这点可以从其实现原理RunnableAdpter源码看出: 123456789101112131415161718public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);//通过RunnableAdapter实现&#125; static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; //将传入的结果的直接返回 &#125; &#125; Future它也是一个接口，主要对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。Future提供了以下几个方法。 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true； isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 FutureTask​ FutureTask是Future接口的一个唯一实现类。FutureTask可用于异步获取执行结果或取消执行任务的场景。通过传入Runnable或者Callable的任务给FutureTask，直接调用其run方法或者放入线程池执行，之后可以在外部通过FutureTask的get方法异步获取执行结果，因此，FutureTask非常适合用于耗时的计算，主线程可以在完成自己的任务后，再去获取结果。另外，FutureTask还可以确保即使调用了多次run方法，它都只会执行一次Runnable或者Callable任务，或者通过cancel取消FutureTask的执行等。 我们查看源码发现FutureTask类实现了RunnableFuture接口，而RunnableFuture继承了Runnable接口和Future接口。 1234public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;&#123;&#125;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; FutureTask提供了2个构造器： 1234public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125; FutureTask 有两个很重要的属性 分别是 state 和runner ，futureTask之所以可以支持cancel操作 就是因为这两个属性其中 state为 枚举值： 1234567NEW 新建 0COMPLETING 执行中 1NORMAL 正常 2EXCEPTIONAL 异常 3CANCELLED 取消 4INTERRUPTING 中断中 5INTERRUNPED 被中断 6 state的状态变化可以有四种方式： 1234NEW-&gt;COMPLETING-&gt;NORMAL 正常完成的流程NEW-&gt;COMPLETING-&gt;EXCEPTIONAL 出现异常的流程NEW-&gt;CANCELED 被取消NEW-&gt;INTERRUNPING-&gt;INTERRRUNPTED 被中断 FutureTask执行多任务计算的使用场景 示例一： 123456789101112131415161718192021222324252627282930313233343536import java.util.ArrayList;import java.util.List;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.FutureTask;public class FutureTaskForMultiCompute &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub List&lt;FutureTask&lt;Result&gt;&gt; taskList = new ArrayList&lt;FutureTask&lt;Result&gt;&gt;(); ExecutorService exec = Executors.newFixedThreadPool(5); for(int i = 0 ; i &lt; 10; i++) &#123; final Result result = new Result(); FutureTask&lt;Result&gt; ft =new FutureTask&lt;Result&gt;(new ComputeTask(result,i+"号线程"),result); taskList.add(ft); exec.submit(ft); &#125; System.out.println("所有计算任务提交完毕, 主线程接着干其他事情！"); System.out.println("我在等待他们的返回结果...."); long total = 0; for(FutureTask&lt;Result&gt; ft:taskList)&#123; try &#123; Result res=ft.get(); System.out.println(res.toString()); total +=res.getDuration(); &#125; catch (InterruptedException | ExecutionException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; exec.shutdown(); System.out.println("总耗时为： "+total); &#125;&#125; 12345678910111213141516171819202122232425262728import java.util.concurrent.TimeUnit;public class ComputeTask implements Runnable&#123; private String name; private Result result; public ComputeTask(Result result,String name)&#123; this.result = result; this.name = name; &#125; public String getName() &#123; return name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub Long duration = (long)(Math.random()*20); try &#123; TimeUnit.SECONDS.sleep(duration); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; result.setName(this.name); result.setDuration(duration); System.out.println("子线程"+this.getName()+"已完成计算任务"); &#125;&#125; 12345678910111213141516171819202122public class Result&#123; private String name; private Long duration; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public Long getDuration() &#123; return duration; &#125; public void setDuration(Long duration) &#123; this.duration = duration; &#125; @Override public String toString() &#123; return "Result [name=" + name + ", duration=" + duration + "]"; &#125;&#125; 示例二： 12345678910111213141516171819202122232425262728293031import java.util.concurrent.Callable;import java.util.concurrent.TimeUnit;public class ComputeTask implements Callable&lt;Result&gt;&#123; private String name; private Result result; public ComputeTask(Result result,String name)&#123; this.result = result; this.name = name; &#125; public String getName() &#123; return name; &#125; @Override public Result call() throws Exception &#123; // TODO Auto-generated method stub Long duration = (long)(Math.random()*20); try &#123; TimeUnit.SECONDS.sleep(duration); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; result.setName(this.name); result.setDuration(duration); System.out.println("子线程"+this.getName()+"已完成计算任务"); return result; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536import java.util.ArrayList;import java.util.List;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.FutureTask;public class FutureTaskForMultiCompute &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub List&lt;FutureTask&lt;Result&gt;&gt; taskList = new ArrayList&lt;FutureTask&lt;Result&gt;&gt;(); ExecutorService exec = Executors.newFixedThreadPool(5); for(int i = 0 ; i &lt; 10; i++) &#123; final Result result = new Result(); FutureTask&lt;Result&gt; ft =new FutureTask&lt;Result&gt;(new ComputeTask(result,i+"号线程")); taskList.add(ft); exec.submit(ft); &#125; System.out.println("所有计算任务提交完毕, 主线程接着干其他事情！"); System.out.println("我在等待他们的返回结果...."); long total = 0; for(FutureTask&lt;Result&gt; ft:taskList)&#123; try &#123; Result res=ft.get(); System.out.println(res.toString()); total +=res.getDuration(); &#125; catch (InterruptedException | ExecutionException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; exec.shutdown(); System.out.println("总耗时为： "+total); &#125;&#125; 123456789101112131415161718192021public class Result&#123; private String name; private Long duration; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public Long getDuration() &#123; return duration; &#125; public void setDuration(Long duration) &#123; this.duration = duration; &#125; @Override public String toString() &#123; return "Result [name=" + name + ", duration=" + duration + "]"; &#125;&#125; FutureTask在高并发环境下确保任务只执行一次 12345678910111213141516171819202122232425262728293031323334353637import java.util.HashMap;import java.util.Map;import java.util.Random;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;public class Connection &#123; private static Map&lt;String, Connection&gt; connectionPool = new HashMap&lt;String, Connection&gt;(); private String name; private static Random random = new Random(); private static ReentrantLock lock = new ReentrantLock(); public Connection (String name)&#123; this.name = name; &#125; public static Connection getConnection(String key)&#123; try&#123; lock.lock(); if(connectionPool.containsKey(key))&#123; return connectionPool.get(key); &#125; else&#123; //创建 Connection Connection conn = createConnection(); connectionPool.put(key, conn); return conn; &#125; &#125; finally&#123; lock.unlock(); &#125; &#125; private static Connection createConnection()&#123; return new Connection("db-connect-"+random.nextInt(1000)); &#125; public String getName() &#123; return name; &#125;&#125; 12345678910111213public class RequestDemo implements Runnable&#123; private String key; public RequestDemo(String key)&#123; this.key = key; &#125; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println(Thread.currentThread().getName() + "请求连接"); Connection con=Connection.getConnection(key); System.out.println(Thread.currentThread().getName() + " 获得的连接名字为："+con.getName()); &#125;&#125; 123456789public class Main &#123; public static void main(String[] args) &#123; for(int i = 0; i &lt; 100 ; i++)&#123; RequestDemo re = new RequestDemo("db"); Thread th =new Thread(re); th.start(); &#125; &#125;&#125; 在上面的例子中，我们通过加锁确保高并发环境下的线程安全，也确保了connection只创建一次，然而确牺牲了性能。改用ConcurrentHash的情况下，几乎可以避免加锁的操作，性能大大提高，但是在高并发的情况下有可能出现Connection被创建多次的现象。(我们将上述的HashMap换成ConcurrentHash，去掉lock,发现Connection会被创建多次),我们使用FutureTask可以解决这个问题。 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Random;import java.util.concurrent.Callable;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.FutureTask;public class Connection &#123; private static ConcurrentHashMap&lt;String,FutureTask&lt;Connection&gt;&gt;connectionPool = new ConcurrentHashMap&lt;String, FutureTask&lt;Connection&gt;&gt;(); private String name; private static Random random = new Random(); public Connection (String name)&#123; this.name = name; &#125; public static Connection getConnection(String key) throws Exception&#123; FutureTask&lt;Connection&gt;connectionTask=connectionPool.get(key); if(connectionTask!=null)&#123; return connectionTask.get(); &#125;else&#123; Callable&lt;Connection&gt; callable = new Callable&lt;Connection&gt;()&#123; @Override public Connection call() throws Exception &#123; // TODO Auto-generated method stub return createConnection(); &#125; &#125;; FutureTask&lt;Connection&gt;newTask = new FutureTask&lt;Connection&gt;(callable); connectionTask = connectionPool.putIfAbsent(key, newTask); if(connectionTask==null)&#123; connectionTask = newTask; connectionTask.run(); &#125; return connectionTask.get(); &#125; &#125; private static Connection createConnection()&#123; return new Connection("db-connect-"+random.nextInt(1000)); &#125; public String getName() &#123; return name; &#125;&#125; FutureTask的实现FutureTask的实现基于AbstractQueuedSynchronizer（以下简称为AQS）。java.util.concurrent中的很多可阻塞类（比如ReentrantLock）都是基于AQS来实现的。AQS是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列。JDK 6中AQS被广泛使用，基于AQS实现的同步器包括：ReentrantLock、Semaphore、ReentrantReadWriteLock、CountDownLatch和FutureTask。 每一个基于AQS实现的同步器都会包含两种类型的操作，如下： 至少一个acquire操作。这个操作阻塞调用线程，除非/直到AQS的状态允许这个线程继续执行。FutureTask的acquire操作为get()/get（long timeout，TimeUnit unit）方法调用。至少一个release操作。这个操作改变AQS的状态，改变后的状态可允许一个或多个阻塞线程被解除阻塞。FutureTask的release操作包括run()方法和cancel（…）方法。基于“复合优先于继承”的原则，FutureTask声明了一个内部私有的继承于AQS的子类Sync，对FutureTask所有公有方法的调用都会委托给这个内部子类。 AQS被作为“模板方法模式”的基础类提供给FutureTask的内部子类Sync，这个内部子类只需要实现状态检查和状态更新的方法即可，这些方法将控制FutureTask的获取和释放操作。具体来说，Sync实现了AQS的tryAcquire Shared（int）方法和tryReleaseShared（int）方法，Sync通过这两个方法来检查和更新同步状态。 Sync是FutureTask的内部私有类，它继承自AQS。创建FutureTask时会创建内部私有的成员对象Sync，Future Task所有的的公有方法都直接委托给了内部私有的Sync。 FutureTask.get()方法会调用AQS.acquireSharedInterruptibly（int arg）方法： 调用AQS.acquireSharedInterruptibly（int arg）方法，这个方法首先会回调在子类Sync中实现的tryAcquire Shared()方法来判断acquire操作是否可以成功。acquire操作可以成功的条件为：state为执行完成状态RAN或已取消状态CANCELLED，且runner不为null。 如果成功则get()方法立即返回。如果失败则到线程等待队列中去等待其他线程执行release操作。 当其他线程执行release操作（比如FutureTask.run()或FutureTask.cancel（…））唤醒当前线程后，当前线程再次执行tryAcquireShared()将返回正值1，当前线程将离开线程等待队列并唤醒它的后继线程。 最后返回计算的结果或抛出异常。 FutureTask.run()方法的执行过程： 执行在构造函数中指定的任务（Callable.call()） 以原子方式来更新同步状态（调用AQS.compareAndSetState（int expect，int update），设置state为执行完成状态RAN）。如果这个原子操作成功，就设置代表计算结果的变量result的值为Callable.call()的返回值，然后调用AQS.releaseShared（int arg）。 AQS.releaseShared（int arg）首先会回调在子类Sync中实现的tryReleaseShared（arg）来执行release操作（设置运行任务的线程runner为null，然会返回true）；AQS.releaseShared（int arg），然后唤醒线程等待队列中的第一个线程。 调用FutureTask.done() 。 参考：http://www.cnblogs.com/MOBIN/p/6185387.html http://www.importnew.com/17572.html http://blog.csdn.net/chdjj/article/details/38900521 http://blog.csdn.net/liulipuo/article/details/39029643 http://blog.csdn.net/linchunquan/article/details/22382487 http://blog.csdn.net/javazejian/article/details/50896505 《java的并发编程艺术》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[进程和线程的区别]]></title>
      <url>%2F2017%2F06%2F20%2F%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[进程和线程的概念​ 先了解一下操作系统的一些相关概念，大部分操作系统(如Windows、Linux)的任务调度是采用时间片轮转的抢占式调度方式，也就是说一个任务执行一小段时间后强制暂停去执行下一个任务，每个任务轮流执行。任务执行的一小段时间叫做时间片，任务正在执行时的状态叫运行状态，任务执行一段时间后强制暂停去执行下一个任务，被暂停的任务就处于就绪状态等待下一个属于它的时间片的到来。这样每个任务都能得到执行，由于CPU的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发(并发简单来说多个任务同时执行)。 进程​ 计算机的核心是CPU，它承担了所有的计算任务；而操作系统是计算机的管理者，它负责任务的调度、资源的分配和管理，统领整个计算机硬件；应用程序侧是具有某种功能的程序，程序是运行于操作系统之上的。 ​ 进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。进程是一种抽象的概念，从来没有统一的标准定义。进程一般由程序、数据集合和进程控制块三部分组成。程序用于描述进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时所需要的数据和工作区；程序控制块(Program Control Block，简称PCB)，包含进程的描述信息和控制信息，是进程存在的唯一标志。 进程具有的特征：动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的；并发性：任何进程都可以同其他进程一起并发执行；独立性：进程是系统进行资源分配和调度的一个独立单位；结构性：进程由程序、数据和进程控制块三部分组成。 进程的生命周期 ​ 在早期只有进程的操作系统中，进程有五种状态，创建、就绪、运行、阻塞(等待)、退出。 创建：进程正在创建，还不能运行。操作系统在创建进程时要进行的工作包括分配和建立进程控制块表项、建立资源表格并分配资源、加载程序并建立地址空间； 就绪：时间片已用完，此线程被强制暂停，等待下一个属于他的时间片到来； 运行：此线程正在执行，正在占用时间片； 阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完； 退出：进程已结束，所以也称结束状态，释放操作系统分配的资源。 线程​ 在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。​ 后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程，线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间。 一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。 线程的生命周期​ 当线程的数量小于处理器的数量时，线程的并发是真正的并发，不同的线程运行在不同的处理器上。但当线程的数量大于处理器的数量时，线程的并发会受到一些阻碍，此时并不是真正的并发，因为此时至少有一个处理器会运行多个线程。在单个处理器运行多个线程时，并发是一种模拟出来的状态。操作系统采用时间片轮转的方式轮流执行每一个线程。现在，几乎所有的现代操作系统采用的都是时间片轮转的抢占式调度方式，如我们熟悉的Unix、linux、Windows及Mac OS X等流行的操作系统。 创建：一个新的线程被创建，等待该线程被调用执行；就绪：时间片已用完，此线程被强制暂停，等待下一个属于他的时间片到来；运行：此线程正在执行，正在占用时间片；阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完；退出：一个线程完成任务或者其他终止条件发生，该线程终止进入退出状态，退出状态释放该线程所分配的资源。 线程优先级​ 操作系统(如Windows、Linux、Mac OS X)的任务调度除了具有前面提到的时间片轮转的特点外，还有优先级调度(Priority Schedule)的特点。优先级调度决定了线程按照什么顺序轮流执行，在具有优先级调度的系统中，线程拥有各自的线程优先级(Thread Priority)。具有高优先级的线程会更早地执行，而低优先级的线程通常要等没有更高优先级的可执行线程时才会被执行。 ​ 线程的优先级可以由用户手动设置，此外系统也会根据不同情形调整优先级。通常情况下，频繁地进入等待状态(进入等待状态会放弃之前仍可占用的时间份额)的线程(如IO线程)，比频繁进行大量计算以至于每次都把所有时间片全部用尽的线程更受操作系统的欢迎。因为频繁进入等待的线程只会占用很少的时间，这样操作系统可以处理更多的任务。我们把频繁等待的线程称之为IO密集型线程(IO Bound Thread)，而把很少等待的线程称之为CPU密集型线程(CPU Bound Thread)。IO密集型线程总是比CPU密集型线程更容易得到优先级的提升。 线程饿死​ 在优先级调度下，容易出现一种线程饿死的现象。一个线程饿死是说它的优先级较低，在它执行之前总是有比它优先级更高的线程等待执行，因此这个低优先级的线程始终得不到执行。当CPU密集型的线程优先级较高时，其它低优先级的线程就很可能出现饿死的情况；当IO密集型线程优先级较高时，其它线程相对不容易造成饿死的，因为IO线程有大量的等待时间。为了避免线程饿死，调度系统通常会逐步提升那些等待了很久而得不到执行的线程的优先级。这样，一个线程只要它等待了足够长的时间，其优先级总会被提升到可以让它执行的程度，也就是说这种情况下线程始终会得到执行，只是时间的问题。 在优先级调度环境下，线程优先级的改变有三种方式： 用户指定优先级； 根据进入等待状态的频繁程度提升或降低优先级(由操作系统完成)； 长时间得不到执行而被提升优先级。 多线程与多核上面提到的时间片轮转的调度方式说一个任务执行一小段时间后强制暂停去执行下一个任务，每个任务轮流执行。很多操作系统的书都说“同一时间点只有一个任务在执行”。其实“同一时间点只有一个任务在执行”这句话是不准确的，至少它是不全面的。我们分析一下多核的情况。 这是我的电脑的CPU情况图： ​ ​ 多核(心)处理器是指在一个处理器上集成多个运算核心从而提高计算能力，也就是有多个真正并行计算的处理核心，每一个处理核心对应一个内核线程。内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。一般一个处理核心对应一个内核线程，比如单核处理器对应一个内核线程，双核处理器对应两个内核线程，四核处理器对应四个内核线程。 ​ 现在的电脑一般是双核四线程、四核八线程，是采用超线程技术将一个物理处理核心模拟成两个逻辑处理核心，对应两个内核线程，所以在操作系统中看到的CPU数量是实际物理CPU数量的两倍。但是我的如上图是四核四线程，似乎没有用这个超线程技术。 ​ 超线程技术就是利用特殊的硬件指令，把一个物理芯片模拟成两个逻辑处理核心，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。这种超线程技术(如双核四线程)由处理器硬件的决定，同时也需要操作系统的支持才能在计算机中表现出来。 ​ 程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程(我们在这称它为用户线程)，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。用户线程与内核线程的对应关系有三种模型：一对一模型、多对一模型、多对多模型，在这以4个内核线程、3个用户线程为例对三种模型进行说明。 一对一模型​ 对于一对一模型来说，一个用户线程就唯一地对应一个内核线程(反过来不一定成立，一个内核线程不一定有对应的用户线程)。这样，如果CPU没有采用超线程技术(如四核四线程的计算机，就如上图展示的我使用的计算机)，一个用户线程就唯一地映射到一个物理CPU的线程，线程之间的并发是真正的并发。一对一模型使用户线程具有与内核线程一样的优点，一个线程因某种原因阻塞时其他线程的执行不受影响；此处，一对一模型也可以让多线程程序在多处理器的系统上有更好的表现。但一对一模型也有两个缺点：1.许多操作系统限制了内核线程的数量，因此一对一模型会使用户线程的数量受到限制；2.许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降。 多对一模型​ 多对一模型将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，因此相对一对一模型，多对一模型的线程切换速度要快许多；此外，多对一模型对用户线程的数量几乎无限制。但多对一模型也有两个缺点：1.如果其中一个用户线程阻塞，那么其它所有线程都将无法执行，因为此时内核线程也随之阻塞了；2.在多处理器系统上，处理器数量的增加对多对一模型的线程性能不会有明显的增加，因为所有的用户线程都映射到一个处理器上了。 多对多模型​ 多对多模型结合了一对一模型和多对一模型的优点，将多个用户线程映射到多个内核线程上。多对多模型的优点有：1.一个用户线程的阻塞不会导致所有线程的阻塞，因为此时还有别的内核线程被调度来执行；2.多对多模型对用户线程的数量没有限制；3.在多处理器的操作系统中，多对多模型的线程也能得到一定的性能提升，但提升的幅度不如一对一模型的高。 进程与线程的区别线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位； 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线； 进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见； 调度和切换：线程上下文切换比进程上下文切换要快得多。 总之，线程和进程都是一种抽象的概念，线程是一种比进程更小的抽象，线程和进程都可用于实现并发。 在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。它相当于一个进程里只有一个线程，进程本身就是线程。所以线程有时被称为轻量级进程(Lightweight Process，LWP）。 后来，随着计算机的发展，对多个任务之间上下文切换的效率要求越来越高，就抽象出一个更小的概念——线程，一般一个进程会有多个(也可是一个)线程。 漫话进程和线程1.计算机的核心是CPU，它承担了所有的计算任务。它就像一座工厂，时刻在运行。 2.假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。 3.进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。 4.一个车间里，可以有很多工人。他们协同完成一个任务。 5.线程就好比车间里的工人。一个进程可以包括多个线程。 6.车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存。 7.可是，每间房间的大小不同，有些房间最多只能容纳一个人，比如厕所。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。 8.一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫”互斥锁”（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。 9.还有些房间，可以同时容纳n个人，比如厨房。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。 10.这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做”信号量”（Semaphore），用来保证多个线程不会互相冲突。 不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。 操作系统的设计，因此可以归结为三点： （1）以多进程形式，允许多个任务同时运行； （2）以多线程形式，允许单个任务分成不同的部分运行； （3）提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。 参考：http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html http://blog.csdn.net/luoweifu/article/details/46595285]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之线程工厂和异常处理]]></title>
      <url>%2F2017%2F06%2F20%2F%E4%BD%A0%E6%87%82java%E5%90%97-18%2F</url>
      <content type="text"><![CDATA[用线程工厂创建线程ThreadFactory接口实现一个线程对象工厂 123456789101112131415161718192021222324252627282930313233343536import java.util.ArrayList;import java.util.Date;import java.util.Iterator;import java.util.List;import java.util.concurrent.ThreadFactory;public class MyTreadFactory implements ThreadFactory &#123; private int counter; private String name; private List&lt;String&gt; stats; public MyTreadFactory(String name)&#123; counter = 0; stats = new ArrayList&lt;String&gt;(); this.name = name; &#125; @Override public Thread newThread(Runnable r) &#123; // TODO Auto-generated method stub Thread t = new Thread(r, name+"_thread_"+counter); counter++; stats.add(String.format("Created thread %d with name %s on %s\n", t.getId(),t.getName(),new Date())); return t; &#125; public String getStats()&#123; StringBuffer sb = new StringBuffer(); Iterator&lt;String&gt; it = stats.iterator(); while(it.hasNext())&#123; sb.append(it.next()); sb.append("\n"); &#125; return sb.toString(); &#125;&#125; 12345678910111213import java.util.concurrent.TimeUnit;public class Task implements Runnable&#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 12345678910111213141516171819202122public class Main &#123; public static void main(String[] args) &#123; MyTreadFactory factory = new MyTreadFactory("threadFactory"); Task task = new Task(); Thread thread; System.out.println("Starting the Threads "); for (int i = 0; i &lt; 10; i++) &#123; thread = factory.newThread(task); thread.start(); try &#123; thread.join(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; System.out.println("Finish the Threads "); System.out.println("Factory stats:"); System.out.printf("%s\n",factory.getStats()); &#125; &#125; 在线程中处理不受控制的异常在一个线程对象的run()方法里抛出一个检查异常，我们必须捕获并处理它们。因为run( )方法不接受throws子句。当一个非检查异常抛出，默认的的行为是在控制台写下stack trace并退出程序。 123456789101112public class Task implements Runnable&#123; private int num =8; private int res =0; @Override public void run() &#123; while(true)&#123; res=12/num; System.out.println("res: " +res ); num --; &#125; &#125; &#125; 12345678910111213import java.lang.Thread.UncaughtExceptionHandler;public class ExceptionHandler implements UncaughtExceptionHandler&#123; @Override public void uncaughtException(Thread t, Throwable e) &#123; // TODO Auto-generated method stub System.out.printf("An exception has been captured\n"); System.out.printf("Thread:%s\n",t.getId()); System.out.printf("Exception:%s :%s\n",e.getClass().getName(),e.getMessage()); System.out.printf("Stack Traace"); e.printStackTrace(System.out); System.out.printf("Thread status:%s\n",t.getState()); &#125;&#125; 12345678public class Main &#123; public static void main(String[] args) &#123; Task task = new Task(); Thread thread = new Thread(task); thread.setUncaughtExceptionHandler(new ExceptionHandler()); thread.start(); &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之同步方法]]></title>
      <url>%2F2017%2F06%2F19%2F%E4%BD%A0%E6%87%82java%E5%90%97-17%2F</url>
      <content type="text"><![CDATA[java的Thread类和Runnable接口 同步方法在Java中，synchronized是用来表示同步的，我们可以synchronized来修饰一个方法。也可以synchronized来修饰方法里面的一个语句块。但是要注意在static方法和非static方法使用synchronized。大家都知道，static的方法属于类方法，它属于这个类，那么static获取到的锁，是属于类的锁。而非static方法获取到的锁，是属于当前对象的锁。所以，他们之间不会产生互斥。解决方式是用Lock。 12345678910111213141516171819202122232425262728293031323334353637383940public class Account &#123; private double balance; public double getBalance() &#123; return balance; &#125; public void setBalance(double balance) &#123; this.balance = balance; &#125; public synchronized void addAmount(double amount)&#123; System.out.println("addAmount..."); double tmp = balance; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; tmp+=amount; balance = tmp; System.out.println("after addAmount: "+balance); &#125; public synchronized void subtractAmount(double amount)&#123; System.out.println("subtractAmount......"); double tmp = balance; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; tmp-=amount; balance=tmp; System.out.println("after subtractAmount: "+balance); &#125; &#125; 12345678910111213141516public class Bank implements Runnable&#123; private Account account; public Bank(Account account) &#123; this.account = account; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for(int i=0;i&lt;100;i++)&#123; account.subtractAmount(1000); &#125; &#125; &#125; 12345678910111213141516public class Company implements Runnable&#123; private Account account; public Company(Account account) &#123; this.account = account; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for(int i=0;i&lt;100;i++)&#123; account.addAmount(1000); &#125; &#125; &#125; 12345678910111213141516171819202122public class Main &#123; public static void main(String[] args) &#123; Account account = new Account(); account.setBalance(1000); Company company = new Company(account); Thread companyThread = new Thread(company); Bank bank = new Bank(account); Thread bankThread = new Thread(bank); System.out.printf("Account:Initial balance:%f\n", account.getBalance()); bankThread.start(); companyThread.start(); try &#123; bankThread.join(); companyThread.join(); System.out.printf("Account:Initial balance:%f\n", account.getBalance()); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; &#125; &#125; 在同步的类里安排独立属性​ 当你使用synchronized关键字来保护代码块时，你必须通过一个对象的引用作为参数。通常，你将会使用this关键字来引用执行该方法的对象，但是你也可以使用其他对象引用。通常情况下，这些对象被创建只有这个目的。比如，你在一个类中有被多个线程共享的两个独立属性。你必须同步访问每个变量，如果有一个线程访问一个属性和另一个线程在同一时刻访问另一个属性，这是没有问题的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Cinema &#123; private long vacanciesCinema1; private long vacanciesCinema2; private final Object controlCinema1,controlCinema2; public Cinema()&#123; controlCinema1 = new Object(); controlCinema2 = new Object(); vacanciesCinema1 = 20; vacanciesCinema2 = 20; &#125; public boolean sellTickets1(int number) &#123; System.out.println("sellTickets1"); synchronized (controlCinema1) &#123; if(number &lt; vacanciesCinema1)&#123; vacanciesCinema1 -=number; return true; &#125;else&#123; return false; &#125; &#125; &#125; public boolean sellTickets2(int number) &#123; System.out.println("sellTickets2"); synchronized (controlCinema2) &#123; if(number &lt; vacanciesCinema2)&#123; vacanciesCinema2 -=number; return true; &#125;else&#123; return false; &#125; &#125; &#125; public boolean returnTickets1(int number)&#123; System.out.println("returnTickets1"); synchronized (controlCinema1) &#123; vacanciesCinema1 +=number; return true; &#125; &#125; public boolean returnTickets2(int number)&#123; System.out.println("returnTickets2"); synchronized (controlCinema2) &#123; vacanciesCinema2 +=number; return true; &#125; &#125; public long getVacanciesCinema1() &#123; return vacanciesCinema1; &#125; public void setVacanciesCinema1(long vacanciesCinema1) &#123; this.vacanciesCinema1 = vacanciesCinema1; &#125; public long getVacanciesCinema2() &#123; return vacanciesCinema2; &#125; public void setVacanciesCinema2(long vacanciesCinema2) &#123; this.vacanciesCinema2 = vacanciesCinema2; &#125; &#125; 1234567891011121314151617181920public class TicketOffice1 implements Runnable&#123; private Cinema cinema; public TicketOffice1(Cinema cinema)&#123; this.cinema = cinema; &#125; @Override public void run() &#123; cinema.sellTickets1(2); cinema.sellTickets1(2); cinema.sellTickets2(2); cinema.returnTickets1(2); cinema.sellTickets1(2); cinema.sellTickets2(2); cinema.sellTickets2(2); cinema.sellTickets2(2); &#125; &#125; 123456789101112131415161718192021public class TicketOffice2 implements Runnable&#123; private Cinema cinema; public TicketOffice2(Cinema cinema)&#123; this.cinema = cinema; &#125; @Override public void run() &#123; cinema.sellTickets2(2); cinema.sellTickets2(2); cinema.sellTickets1(2); cinema.sellTickets1(1); cinema.returnTickets2(2); cinema.sellTickets1(2); cinema.sellTickets2(2); cinema.sellTickets1(2); &#125; &#125; 123456789101112131415161718192021public class Main &#123; public static void main(String[] args) &#123; Cinema cinema = new Cinema(); TicketOffice1 ticketOffice1 = new TicketOffice1(cinema); Thread thread1 = new Thread(ticketOffice1,"TicketOffice1"); TicketOffice2 ticketOffice2 = new TicketOffice2(cinema); Thread thread2 = new Thread(ticketOffice2,"TicketOffice2"); thread1.start(); thread2.start(); try &#123; thread1.join(); thread2.join(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.printf("Room 1 Vacancies: %d\n",cinema.getVacanciesCinema1()); System.out.printf("Room 2 Vacancies: %d\n",cinema.getVacanciesCinema2()); &#125;&#125; 在同步代码中使用条件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.Date;import java.util.LinkedList;import java.util.List;import java.util.concurrent.TimeUnit;public class EventStorage &#123; private int maxSize; private List&lt;Date&gt; storage; public EventStorage()&#123; maxSize = 10; storage = new LinkedList&lt;Date&gt;(); &#125; public synchronized void set()&#123; while(storage.size() == maxSize)&#123; System.out.println("--------------满仓-----------------"); try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; ((LinkedList&lt;Date&gt;) storage).offer(new Date()); System.out.println("Set:"+storage.size()); notifyAll(); &#125; public synchronized void get()&#123; while(storage.size()==0)&#123; System.out.println("---------------------------等待中--------------------"); try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.printf("Get:%d:%s\n",storage.size(),((LinkedList&lt;Date&gt;) storage).poll()); notifyAll(); &#125; &#125; 12345678910111213public class Producer implements Runnable &#123; private EventStorage storage; public Producer(EventStorage storage)&#123; this.storage = storage; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for(int i=0;i&lt;100;i++)&#123; storage.set(); &#125; &#125;&#125; 123456789101112public class Consumer implements Runnable &#123; private EventStorage storage; public Consumer(EventStorage storage)&#123; this.storage = storage; &#125; @Override public void run() &#123; for(int i=0;i&lt;100;i++)&#123; storage.get(); &#125; &#125; &#125; 1234567891011public class Main &#123; public static void main(String[] args) &#123; EventStorage stor= new EventStorage(); Consumer consumer = new Consumer(stor); Thread th1 = new Thread(consumer); Producer producer = new Producer(stor); Thread th2 = new Thread(producer); th1.start(); th2.start(); &#125;&#125; 使用Lock同步代码块Lock 接口比synchronized关键字提供更多额外的功能。在使用Lock时需要注意的是要释放Lock锁。 12345678910111213141516171819202122import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class PrintQueue &#123; private final Lock queuelock = new ReentrantLock(); public void printJob(Object document)&#123; queuelock.lock();//获取Lock对象的控制权 try &#123; Long duration = (long)(Math.random()*10000); System.out.println(Thread.currentThread().getName() +"PrintQueue:Printing a Job during " +(duration/1000)+" seconds"); Thread.sleep(duration); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally&#123; queuelock.unlock();//释放Lock对象的控制 &#125; &#125; &#125; 1234567891011121314public class Job implements Runnable &#123; private PrintQueue printQueue; public Job(PrintQueue printQueue)&#123; this.printQueue = printQueue; &#125; @Override public void run() &#123; // TODO Auto-generated method stub System.out.printf("%s:Going to print a document\n", Thread.currentThread().getName()); printQueue.printJob(new Object()); System.out.printf("%s:The document has been printed\n",Thread.currentThread().getName()); &#125;&#125; 123456789101112public class Main &#123; public static void main(String[] args) &#123; PrintQueue printQueue = new PrintQueue(); Thread thread[] = new Thread[10]; for(int i=0;i&lt;10;i++)&#123; thread[i] = new Thread(new Job(printQueue),"Thread"+i); &#125; for(int i=0;i&lt;10;i++)&#123; thread[i].start(); &#125; &#125; &#125; 使用读写锁同步数据访问1234567891011121314151617public class Main &#123; public static void main(String[] args) &#123; PricesInfo priceinfo = new PricesInfo(); Reader [] readers = new Reader[5]; Thread [] threadreaders = new Thread[5]; for(int i =0 ;i &lt;5;i ++)&#123; readers[i]=new Reader(priceinfo); threadreaders[i]=new Thread(readers[i]); &#125; for ( int i = 0; i &lt; 5; i++ ) &#123; threadreaders[i].start(); &#125; Writer writer = new Writer(priceinfo); new Thread(writer).start(); &#125;&#125; 12345678910111213public class Reader implements Runnable &#123; private PricesInfo pricesInfo; public Reader(PricesInfo pricesInfo)&#123; this.pricesInfo = pricesInfo; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for(int i=0;i&lt;15;i++)&#123; pricesInfo.getPrice(); &#125; &#125;&#125; 1234567891011121314151617import java.util.Random;public class Writer implements Runnable&#123; private PricesInfo pricesInfo; public Writer(PricesInfo pricesInfo)&#123; this.pricesInfo = pricesInfo; &#125; @Override public void run() &#123; for(int i=0;i&lt;3;i++)&#123; int p1 = new Random().nextInt(47); int p2 = new Random().nextInt(47)*10; pricesInfo.setPrices(p1, p2); &#125; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class PricesInfo &#123; private int price1; private int price2; private ReadWriteLock lock; public PricesInfo()&#123; price1 = 1; price2 = 1; lock = new ReentrantReadWriteLock(); &#125; public void getPrice() &#123; lock.readLock().lock(); System.out.println(Thread.currentThread().getName()+" begin to getPrice"); isSleep(true); System.out.printf("%s:Price 1:%d Price 2:%d\n", Thread.currentThread().getName(),getPrice1(),getPrice2()); lock.readLock().unlock(); &#125; public int getPrice1() &#123; return price1; &#125; public int getPrice2() &#123; return price2; &#125; public void setPrices(int price1,int price2)&#123; lock.writeLock().lock(); System.out.println("Writer:Attempt to modify the prices1: "+price1+" price2:"+price2); isSleep(true); System.out.println("Writer:Prices have been modified,prices1:"+price1+" price2:"+price2); this.price1 = price1; this.price2 = price2; lock.writeLock().unlock(); &#125; private static void isSleep(boolean bool)&#123; if(bool)&#123; try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;else&#123; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之守护线程]]></title>
      <url>%2F2017%2F06%2F19%2F%E4%BD%A0%E6%87%82java%E5%90%97-16%2F</url>
      <content type="text"><![CDATA[java的Thread类和Runnable接口 守护线程​ Thread有两种线程，即“守护线程Daemon”与“用户线程User”。守护线程的优先级非常低，通常在程序里没有其他线程运行时才会执行它。当守护线程是程序里唯一在运行的线程时，JVM会结束守护线程并终止程序。守护线程通常用于在同一程序里给普通线程（也叫使用者线程）提供服务。它们通常无限循环的等待服务请求或执行线程任务。它们不能做重要的任务，因为我们不知道什么时候会被分配到CPU时间片，并且只要没有其他线程在运行，它们可能随时被终止。JAVA中最典型的这种类型代表就是垃圾回收器。 ​ setDaemon(boolean on)方法可以方便的设置线程的Daemon模式，true为Daemon模式，此方法必须在线程启动之前调用，当线程正在运行时调用会产生异常。当一个守护线程中产生了其他线程，那么这些新产生的线程不用设置Daemon属性，都将是守护线程。Java垃圾回收线程就是一个典型的守护线程，当我们的程序中不在有任何运行中的Thread，程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开。 示例一： 12345678910111213public class DataSourcesLoader implements Runnable &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.printf("Beginning data sources loading : %s\n", new Date()); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.printf("Data sources loading has finished :%s\n",new Date()); &#125;&#125; 1234567891011121314151617import java.util.concurrent.TimeUnit;public class Daemon extends Thread &#123; private int times =1; @Override public void run() &#123; // TODO Auto-generated method stub while(true)&#123; try &#123; TimeUnit.SECONDS.sleep(1) &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("后台运行的守护线程:"+(times ++) + "s"); &#125; &#125;&#125; 12345678910public class Main &#123; public static void main(String[] args) &#123; DataSourcesLoader dsLoader = new DataSourcesLoader(); Daemon daemon =new Daemon(); daemon.setDaemon(true); daemon.start(); Thread thread1 = new Thread(dsLoader,"DataSourcesLoader"); thread1.start(); &#125;&#125; 示例二： 123456789101112131415161718192021222324252627282930import java.util.Deque;import java.util.concurrent.TimeUnit;public class CleanerTask extends Thread &#123; private Deque&lt;Event&gt; deque; public CleanerTask(Deque&lt;Event&gt; deque) &#123; this.deque = deque; this.setDaemon(true); &#125; @Override public void run() &#123; while (true) &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; System.out.printf("Cleaner is running ....\n"); if (deque.size()==0) &#123; System.out.println("deque is empty"); &#125;else&#123; Event e = deque.getLast(); System.out.printf("Cleaner: %s\n",e.getEvent()); deque.removeLast(); System.out.printf("Cleaner: Size of the queue: %d\n",deque. size()); &#125; &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930import java.util.Date;import java.util.Deque;import java.util.Random;import java.util.concurrent.TimeUnit;public class WriterTask implements Runnable&#123; private Deque&lt;Event&gt; deque; private Random rand =new Random(); public WriterTask (Deque&lt;Event&gt; deque)&#123; this.deque=deque; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for (int i=1; i&lt;100; i++) &#123; Event event=new Event(); event.setDate(new Date()); event.setEvent(String.format("The thread %s has generated an event",Thread.currentThread().getId())); deque.addFirst(event); System.out.println("The thread "+Thread.currentThread().getId()+" has generated an event"); try &#123; TimeUnit.SECONDS.sleep(rand.nextInt(20)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 123456789101112131415161718import java.util.Date;public class Event &#123; private Date date; private String event; public Date getDate() &#123; return date; &#125; public void setDate(Date date) &#123; this.date = date; &#125; public String getEvent() &#123; return event; &#125; public void setEvent(String event) &#123; this.event = event; &#125;&#125; 12345678910111213141516import java.util.ArrayDeque;import java.util.Deque;public class Main &#123; public static void main(String[] args) &#123; Deque&lt;Event&gt; deque = new ArrayDeque&lt;Event&gt;(); WriterTask writer = new WriterTask(deque); for (int i = 0; i &lt; 10; i++) &#123; Thread thread = new Thread(writer); thread.start(); &#125; CleanerTask cleaner = new CleanerTask(deque); cleaner.start(); &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之抽象类和接口]]></title>
      <url>%2F2017%2F06%2F18%2F%E4%BD%A0%E6%87%82java%E5%90%97-15%2F</url>
      <content type="text"><![CDATA[java的抽象类和接口 什么是java的抽象类和接口？​ abstract class和interface是Java语言中对于抽象类定义进行支持的两种机制，正是由于这两种机制的存在，才赋予了Java强大的面向对象能力。 在面向对象的概念中，我们知道所有的对象都是通过类来描绘的，但是反过来却不是 这样。并不是所有的类都是用来描绘对象的，如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类。抽象类往往用来表征我们在对问题领 域进行分析、设计中得出的抽象概念，是对一系列看上去不同，但是本质上相同的具体概念的抽象。而接口呢，它则是一组规则的集合，它规定了实现本接口的类必须拥有的一组规则。体现了自然界“如果你是……则必须能……”的理念。下面详细分析抽象类和接口以及它们之间的区别。 抽象类和接口的区别和联系？语法层面上的区别： 1）抽象类可以提供成员方法的实现细节，而接口中只能存在public abstract 方法； 2）抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是public static final类型的； 3）接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法； 4）一个类只能继承一个抽象类，而一个类却可以实现多个接口。 跨域层面上的区别： ​ 抽象类所体现的是一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在”is-a” 关系，即父类和派生类在概念本质上应该是相同的。对于接口则不然，并不要求接口的实现者和接口定义在概念本质上是一致的， 仅仅是实现了接口定义的契约而已。抽象类所跨域的是具有相似特点的类，而接口却可以跨域不同的类。 设计层面上的区别： 抽象类是对一种事物的抽象，即对类抽象，而接口是对行为的抽象。抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类局部（行为）进行抽象。从动机角度，使用抽象类是很好的解决了代码的复用，而使用接口的却实现了多态性。 设计层面不同，抽象类作为很多子类的父类，它是一种模板式设计。而接口是一种行为规范，它是一种辐射式设计。 考虑这样一个例子，假设在我们的问题领域中有一个关于Door的抽象概念，该Door具有执行两个动作open和close，此时我们可以通过abstract class或者interface来定义一个表示该抽象概念的类型，定义方式分别如下所示： 1234public abstract class door &#123; abstract void open(); abstract void close(); &#125; 1234public interface door&#123; void open(); void close();&#125; 其他具体的Door类型可以extends使用abstract class方式定义的Door或者implements使用interface方式定义的Door。看起来好像使用abstract class和interface没有大的区别。如果现在要求Door还要具有报警的功能。我们该如何设计针对该例子的类结构呢？ 方案一： 简单的在Door的定义中增加一个alarm方法。 对于抽象类，所有继承于这个抽象类的子类都具备了报警功能，但是有的门并不一定具备报警功能。 对于接口，需要用到报警功能的类就需要实现这个接口中的open( )和close( )，也许这个类根本就不具备open( )和close( )这两个功能，比如火灾报警器。 12345public abstract class Door&#123; abstract void open(); abstract void close(); abstract void alarm(); &#125; 12345public interface door&#123; void open(); void close(); void alarm();&#125; 也就是说这种方法违反了面向对象设计中的一个核心原则ISP（Interface Segregation Priciple），在Door的定义中把Door概念本身固有的行为方法和另外一个概念”报警器”的行为方法混在了一起。 ISP（Interface Segregation Principle）：面向对象的一个核心原则。它表明使用多个专门的接口比使用单一的总接口要好。 一个类对另外一个类的依赖性应当是建立在最小的接口上的。 一个接口代表一个角色，不应当将不同的角色都交给一个接口。没有关系的接口合并在一起，形成一个臃肿的大接口，这是对角色和接口的污染。 方案二： 既然open()、close()和alarm()属于两个不同的概念，那么我们依据ISP原则将它们分开定义在两个代表两个不同概念的抽象类里面，一个使用抽象类定义，一个是用接口定义。 123public interface Alarm&#123; void alarm(); &#125; 1234public abstract class Door&#123; abstract void open(); abstract void close(); &#125; 12345public class AlarmDoor extends Door implements Alarm&#123; void open()&#123;&#125; void close()&#123;&#125; void alarm()&#123;&#125; &#125; 抽象类和接口使用注意？抽象类使用之前需要注意： 抽象类不能被实例化，实例化的工作应该交由它的子类来完成，它只需要有一个引用即可。 抽象方法必须由子类来进行重写，同时必须为public或者protected（因为如果为private，则不能被子类继承，子类便无法实现该方法），缺省情况下默认为public；。 只要包含一个抽象方法的抽象类，该方法必须要定义成抽象类，不管是否还包含有其他方法。 抽象类中可以包含具体的方法，当然也可以不包含抽象方法。 子类中的抽象方法不能与父类的抽象方法同名。 abstract不能与final并列修饰同一个类。 abstract 不能与private、static、final或native并列修饰同一个方法。 接口使用之前需要注意： 接口的所有方法的访问权限自动被声明为public，而且只能是public。 接口中可以定义“成员变量”，或者说是不可变的常量，因为接口中的“成员变量”会自动变为为public static final。可以通过类命名直接访问：ImplementClass.name。 接口中不存在实现的方法。 实现接口的非抽象类必须要实现该接口的所有方法。抽象类可以不用实现。 不能使用new操作符实例化一个接口，但可以声明一个接口变量，该变量必须引用（refer to)一个实现该接口的类的对象。可以使用 instanceof 检查一个对象是否实现了某个特定的接口。例如：if( anObject instanceof Comparable) {}。 在实现多接口的时候一定要避免方法名的重复。 抽象类的特殊使用？抽象类使用static注意事项： 1.关于外部抽象类不能声明为static,例如将上述的Employee改为public static abstract class Employee {…}，会报Illegal modifier for the class Employee; only public, abstract &amp; final are permitted，但是内部抽象类可以。 12345public abstract class Employee &#123; public abstract static class Salary&#123; public abstract void printSalary(); &#125; &#125; 1234567public class Salesman extends Employee.Salary &#123; @Override public void printSalary() &#123; // TODO Auto-generated method stub System.out.println("Salesman's salary is $36000.00"); &#125;&#125; 123456789public class Demo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Salesman s = new Salesman(); s.printSalary(); Employee.Salary s2= new Salesman(); s.printSalary(); &#125;&#125; 2.可以直接调用抽象类中用static声明的方法，就像普通类一样。 3.利用抽象类对用户隐藏不需要知道的子类。 1234567891011public abstract class Employee &#123; public abstract void printSalary(); private static class Salesman extends Employee&#123; public void printSalary()&#123; System.out.println(" the Salary is $36000.00"); &#125; &#125; public static Employee getInstance()&#123; return new Salesman(); &#125;&#125; 1234567public class Demo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Employee s =Employee.getInstance(); s.printSalary(); &#125;&#125; 抽象类常规示例： 1234567891011121314151617181920212223242526272829303132public abstract class Employee &#123; private String name; private String address; private int telephone; public Employee(String name, String address, int telephone) &#123; System.out.println("Constructing an Employee"); this.name = name; this.address = address; this.telephone = telephone; &#125; public double computePay() &#123; System.out.println("Inside Employee computePay"); return 0.0; &#125; public void mailCheck() &#123; System.out.println("Inside Employee mailCheck"); System.out.println("Mailing a check to " + this.name + " " + this.address); &#125; public String toString() &#123; return name + " " + address + " " + telephone; &#125; abstract public void contactConsumer(); public String getName() &#123; return name; &#125; &#125; 123456789101112131415161718public class Salesman extends Employee &#123; private double salary; public Salesman(String name, String address, int telephone,double salary) &#123; super(name, address, telephone); // TODO Auto-generated constructor stub this.salary =salary; &#125; @Override public void contactConsumer() &#123; // TODO Auto-generated method stub System.out.println("Salesman contact Consumer sometimes"); &#125; public void mailCheck()&#123; System.out.println("Salesman mailCheck "); System.out.println("Mailing check to " + getName() + " with salary " + salary); &#125;&#125; 123456789101112131415161718192021222324public class Demo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Salesman s = new Salesman("Mohd Mohtashim", "Ambehta, UP", 3, 3600.00); System.out.println(s.computePay()); s.mailCheck(); System.out.println("==========================="); Employee e = new Salesman("John Adams", "Boston, MA", 2, 2400.00); System.out.println(e.computePay()); e.mailCheck(); &#125;&#125;//outputConstructing an EmployeeInside Employee computePay0.0Salesman mailCheck Mailing check to Mohd Mohtashim with salary 3600.0===========================Constructing an EmployeeInside Employee computePay0.0Salesman mailCheck Mailing check to John Adams with salary 2400.0 Java8的接口新特性？静态方法 static定义的方法用接口名调用 默认方法 default定义的普通方法用对象调用 123456789public interface Flyanimal &#123; public void eat(); public static void fly() &#123; System.out.println("i can fly now"); &#125; default void run()&#123; System.out.println("i can run now"); &#125;&#125; 12345678910111213public class Animal implements Flyanimal&#123; @Override public void eat() &#123; // TODO Auto-generated method stub System.out.println("i am eating now "); &#125; public static void main(String[] args) &#123; Flyanimal animal = new Animal(); animal.eat(); animal.run(); Flyanimal.fly(); &#125;&#125; 参考：http://blog.csdn.net/wenwen091100304/article/details/48381023 http://www.cnblogs.com/azai/archive/2009/11/10/1599584.html http://www.runoob.com/java/java-abstraction.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HTTP和HTTPS解读]]></title>
      <url>%2F2017%2F06%2F16%2FHTTP%E5%92%8CHTTPS%E8%A7%A3%E8%AF%BB%2F</url>
      <content type="text"><![CDATA[Http 与 Https的区别​ Hyper Text Transfer Protocol，超文本传输协议，是互联网上使用最广泛的一种协议，所有WWW文件必须遵循的标准。HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全。​ Hyper Text Transfer Protocol over Secure Socket Layer，安全的超文本传输协议，网景公司设计了SSL(Secure Sockets Layer)协议用于对Http协议传输的数据进行加密，保证会话过程中的安全性。HTTP 和 HTTPS 的不同之处： HTTP 的 URL 以 http:// 开头，而 HTTPS 的 URL 以 https:// 开头HTTP 是不安全的，而 HTTPS 是安全的HTTP 标准端口是 80 ，而 HTTPS 的标准端口是 443在 OSI 网络模型中，HTTP 工作于应用层，而 HTTPS 工作在传输层HTTP 无需加密，而 HTTPS 对传输的数据进行加密HTTP 无需证书，而 HTTPS 需要认证证书 HTTP 和HTTPS(SSL) 包含动作区别：HTTP:浏览器打开一个 TCP 连接浏览器发送 HTTP 请求到服务器端服务器发送 HTTP 回应信息到浏览器TCP 连接关闭HTTPS:验证服务器端允许客户端和服务器端选择加密算法和密码，确保双方都支持验证客户端(可选)使用公钥加密技术来生成共享加密数据创建一个加密的 SSL 连接基于该 SSL 连接传递 HTTP 请求HTTPS有单向认证和双向认证两种方式。 1.客户端向服务端发送SSL协议版本号、加密算法种类、随机数等信息。2.服务端给客户端返回SSL协议版本号、加密算法种类、随机数等信息，同时也返回服务器端的证书，即公钥证书。3.客户端使用服务端返回的信息验证服务器的合法性，包括： 证书是否过期发行服务器证书的CA是否可靠返回的公钥是否能正确解开返回证书中的数字签名服务器证书上的域名是否和服务器的实际域名相匹配验证通过后，将继续进行通信，否则，终止通信 4.客户端向服务端发送自己所能支持的对称加密方案，供服务器端进行选择。5.服务器端在客户端提供的加密方案中选择加密程度最高的加密方式。6.服务器将选择好的加密方案通过明文方式返回给客户端。7.客户端接收到服务端返回的加密方式后，使用该加密方式生成产生随机码，用作通信过程中对称加密的密钥，使用服务端返回的公钥进行加密，将加密后的随机码发送至服务器。8.服务器收到客户端返回的加密信息后，使用自己的私钥进行解密，获取对称加密密钥。9.在接下来的会话中，服务器和客户端将会使用该密码进行对称加密，保证通信过程中信息的安全。双向认证和单向认证原理基本差不多，只是除了客户端需要认证服务端以外，增加了服务端对客户端的认证。 1.客户端向服务端发送SSL协议版本号、加密算法种类、随机数等信息。2.服务端给客户端返回SSL协议版本号、加密算法种类、随机数等信息，同时也返回服务器端的证书，即公钥证书。3.客户端使用服务端返回的信息验证服务器的合法性，包括： 证书是否过期发行服务器证书的CA是否可靠返回的公钥是否能正确解开返回证书中的数字签名服务器证书上的域名是否和服务器的实际域名相匹配验证通过后，将继续进行通信，否则，终止通信 4.服务端要求客户端发送客户端的证书，客户端会将自己的证书发送至服务端。5.验证客户端的证书，通过验证后，会获得客户端的公钥。6.客户端向服务端发送自己所能支持的对称加密方案，供服务器端进行选择。7.服务器端在客户端提供的加密方案中选择加密程度最高的加密方式。8.将加密方案通过使用之前获取到的公钥进行加密，返回给客户端。9.客户端收到服务端返回的加密方案密文后，使用自己的私钥进行解密，获取具体加密方式，而后，产生该加密方式的随机码，用作加密过程中的密钥，使用之前从服务端证书中获取到的公钥进行加密后，发送给服务端。10.服务端收到客户端发送的消息后，使用自己的私钥进行解密，获取对称加密的密钥，在接下来的会话中，服务器和客户端将会使用该密码进行对称加密，保证通信过程中信息的安全。 SSL加密技术​ SSL加密技术是全球许多知名企业为了保护敏感数据在传送过程中的安全而采用的一种加密机制，全称是Security Socket Layer。但加密和解密过程需要耗费系统大量的开销，严重降低机器的性能，相关测试数据表明使用HTTPS协议传输数据的工作效率只有使用HTTP协议传输的十分之一。​ 为了保护敏感数据在传送过程中的安全，全球许多知名企业采用SSL（Security Socket Layer）加密机制。 SSL是Netscape公司所提出的安全保密协议，在浏览器（如Internet Explorer、Netscape Navigator）和Web服务器（如Netscape的Netscape Enterprise Server、ColdFusion Server等等）之间构造安全通道来进行数据传输，SSL运行在TCP/IP层之上、应用层之下，为应用程序提供加密数据通道，它采用了RC4、MD5以及RSA等加密算法，使用40 位的密钥，适用于商业信息的加密。同时，Netscape公司相应开发了HTTPS协议并内置于其浏览器中，HTTPS实际上就是HTTP over SSL，它使用默认端口443，而不是像HTTP那样使用端口80来和TCP/IP进行通信。HTTPS协议使用SSL在发送方把原始数据进行加密，然后在接受方进行解密，加密和解密需要发送方和接受方通过交换共知的密钥来实现，因此，所传送的数据不容易被网络黑客截获和解密。​ 然而，加密和解密过程需要耗费系统大量的开销，严重降低机器的性能，相关测试数据表明使用HTTPS协议传输数据的工作效率只有使用HTTP协议传输的十分之一。假如为了安全保密，将一个网站所有的Web应用都启用SSL技术来加密，并使用HTTPS协议进行传输，那么该网站的性能和效率将会大大降低，而且没有这个必要，因为一般来说并不是所有数据都要求那么高的安全保密级别。SSL 数据加密应用——SSL数字证书SSL 数字证书根据可信强度，可以分为以下几种：域名型 SSL 证书（DVSSL）企业型 SSL 证书（OVSSL）增强型 SSL 证书（EVSSL）企业 PKI 管理 参考：http://blog.csdn.net/duanbokan/article/details/50847612http://blog.csdn.net/flylovesky127/article/details/21516801]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之反射的机制与用途]]></title>
      <url>%2F2017%2F06%2F14%2F%E4%BD%A0%E6%87%82java%E5%90%97-14%2F</url>
      <content type="text"><![CDATA[java的反射机制 什么是java.lang.Class类？​ 众所周知Java有个Object类，是所有Java类的继承根源，其内声明了数个应该在所有Java类中被改写的方法：hashCode()、equals()、clone()、toString()、getClass()等。其中getClass()返回一个Class类的对象。 ​ Class类十分特殊。它和一般class一样继承自Object，其实体用以表达Java程序运行时的class和interface，也用来表达enum、array、primitive Java types（boolean, byte, char, short, int, long, float, double）以及关键词void，也就是说运行时的class和interface，基本的 Java 类型（boolean、byte、char、short、int、long、float 和 double）和关键字 void 也都对应一个 Class 对象。 Class 没有公共构造方法，Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的一个Class object（对象），因此不能显式地声明一个Class对象。 ​ 每个数组属于被映射为 Class 对象的一个类，所有具有相同元素类型和维数的数组都共享该 Class 对象。 ​ 一般某个类的Class对象被载入内存，它就用来创建这个类的所有对象。 什么是反射机制？​ Class类是Reflection起源。针对任何想探勘的class，唯有先为它产生一个Class object，接下来才能经由它唤起为数十多个的Reflection APIs。Reflection 是Java被视为动态（或准动态）语言的一个关键性质。这个机制允许程序在运行时透过Reflection APIs取得任何一个已知名称的class的内部信息，包括其modifiers（诸如public, static 等等）、superclass（例如Object）、实现之interfaces（例如Serializable），也包括fields和methods的所有信息，并可于运行时改变fields内容或调用methods。 ​ Reflection。这个字的意思是“反射、映象、倒影”，用在Java身上指的是我们可以于运行时加载、探知、使用编译期间完全未知的classes。换句话说，Java程序可以加载一个运行时才得知名称的class，获悉其完整构造（但不包括methods定义），并生成其对象实体、或对其fields设值、或唤起其methods。这种“看透class”的能力（the ability of the program to examine itself）被称为introspection（内省、内观、反省）。Reflection和introspection是常被并提的两个术语。 在JDK中，主要由以下类来实现Java反射机制，这些类都位于java.lang.reflect包中：Class类：代表一个类。Field 类：代表类的成员变量（成员变量也称为类的属性）。Method类：代表类的方法。Constructor 类：代表类的构造方法。Array类：提供了动态创建数组，以及访问数组的元素的静态方法。 反射机制有什么优势？在运行时判断任意一个对象所属的类。 在运行时构造任意一个类的对象。 在运行时判断任意一个类所具有的成员变量和方法。 在运行时调用任意一个对象的方法。 生成动态代理。 如何使用反射机制？通过Class类获取成员变量，成员方法和构造器首先是获取类的Class对象，因为它是Reflection API 中的核心类，有4中方式： 方法 举例 运用.class 语法 Class&lt;?&gt; classType= Boolean.class; System.out.println(classType); 输出：class java.lang.Boolean 运用static method Class.forName() Class&lt;?&gt; classType = Class.forName(“java.lang.Boolean”); System.out.println(classType5); 输出：class java.lang.Boolean 运用primitive wrapper classes的TYPE 语法（这里返回的是原生类型，和Boolean.class返回的不同） Class&lt;?&gt; classType= Boolean.TYPE; System.out.println(classType3); 输出：boolean 调用getClass Boolean var= true; Class&lt;?&gt; classType = var.getClass(); System.out.println(classType); 输出：class java.lang.Boolean 然后获取类的属性和方法以及构造器： public String getName()：获得类的完整名字。 public Field[] getFields()：返回一个包含某些 Field 对象的数组，这些对象反映此 Class 对象所表示的类或接口的所有可访问公共字段。 public Field getField(String name) ：返回一个 Field 对象，它反映此 Class 对象所表示的类或接口的指定公共成员字段。 public Field[] getDeclaredFields()：返回 Field 对象的一个数组，这些对象反映此 Class 对象所表示的类或接口所声明的所有字段。 public Field getDeclaredField(String name)： 返回一个 Field 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明字段。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package test;import java.lang.reflect.Field;public class MethodDemo &#123; public static Object getStaticProperty(String className, String fieldName)throws Exception &#123; Class cl = Class.forName(className); Field field = cl.getDeclaredField(fieldName); field.setAccessible(true); Object property = field.get(cl); return property; &#125; public static Object getProperty(Object owner, String fieldName)throws Exception &#123; Class cl = owner.getClass(); Field field = cl.getDeclaredField(fieldName); field.setAccessible(true);//访问私有 Object property = field.get(cl); return property; &#125; public static Field getField(Object owner, String fieldName)throws Exception &#123; Class cl = owner.getClass(); Field field = cl.getDeclaredField(fieldName); field.setAccessible(true);//访问私有 return field; &#125; public static void main(String[] args) &#123; People p = new People(); String str ="abc"; try &#123; System.out.println(MethodDemo.getStaticProperty("test.People", "org")); System.out.println(MethodDemo.getProperty(p, "org")); System.out.println(p.getName()); Field field =MethodDemo.getField(p, "name"); field.set(p, "tom"); System.out.println(str); Field field2 =MethodDemo.getField(str, "value"); field2.set(str, "def".toCharArray()); System.out.println(str); System.out.println(p.getName()); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;class People&#123; private String name ; private Integer age ; private static String org ="baidu"; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; &#125; public Method getMethod(String name,Class&lt;?&gt;… parameterTypes)：返回一个 Method 对象，它反映此 Class 对象所表示的类或接口的指定公共成员方法。public Method[] getMethods()：返回一个包含某些 Method 对象的数组，这些对象反映此 Class 对象所表示的类或接口（包括那些由该类或接口声明的以及从超类和超接口继承的那些的类或接口）的公共 member 方法。public Method getDeclaredMethod(Stringname,Class&lt;?&gt;… parameterTypes)：返回一个 Method 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明方法。public Method[] getDeclaredMethods()：返回 Method 对象的一个数组，这些对象反映此 Class 对象表示的类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package test;import java.lang.reflect.Method;public class MethodDemo &#123; public static Object invokeMethod(Object owner, String methodName, Object[] args) throws Exception &#123; Class ownerClass = owner.getClass(); Class[] argsClass = new Class[args.length]; for (int i = 0, j = args.length; i &lt; j; i++) &#123; argsClass[i] = args[i].getClass(); &#125; Method method = ownerClass.getMethod(methodName,argsClass); //method.setAccessible(true);//访问私有 return method.invoke(owner, args); &#125; public static Object invokeMethod(Object owner, String methodName) throws Exception &#123; Class ownerClass = owner.getClass(); Method method = ownerClass.getMethod(methodName); //method.setAccessible(true);//访问私有 return method.invoke(owner); &#125; public static void main(String[] args) &#123; Person per = new Person("tom",12); try &#123; MethodDemo.invokeMethod(per, "print"); System.out.println(MethodDemo.invokeMethod(per, "eat",new Object[]&#123;"apple"&#125;)); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;class Person&#123; private String name; private Integer age; public Person()&#123; &#125; public Person(String name ,Integer age)&#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public void print()&#123; System.out.println("name:" + this.name + " age:" + this.age); &#125; public String eat(String fruit)&#123; if(fruit.equals("apple"))&#123; return "happy"; &#125; return "sad"; &#125; &#125; public Constructor getConstructor(Class&lt;?&gt;… parameterTypes) ：返回一个 Constructor 对象，它反映此 Class 对象所表示的类的指定公共构造方法。public Constructor&lt;?&gt;[] getConstructors()：返回一个包含某些 Constructor 对象的数组，这些对象反映此 Class 对象所表示的类的所有公共构造方法。public Constructor getDeclaredConstructor(Class&lt;?&gt;… parameterTypes)：返回一个 Constructor 对象，该对象反映此 Class 对象所表示的类或接口的指定构造方法。public Constructor&lt;?&gt;[] getDeclaredConstructors()：返回 Constructor 对象的一个数组，这些对象反映此 Class 对象表示的类声明的所有构造方法。它们是公共、保护、默认（包）访问和私有构造方法。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.Method;import java.lang.reflect.Type;import java.util.Collection;public class RefConstructor &#123; public static void main(String args[]) throws Exception &#123; RefConstructor ref = new RefConstructor(); ref.getConstructor(); &#125; public void getConstructor() throws Exception &#123; Class c = null; c = Class.forName("java.util.ArrayList"); Class cs[] = &#123;java.util.Collection.class&#125;; System.out.println("\n-------------------------------\n"); Constructor cst1 = c.getConstructor(cs); System.out.println("1、通过参数获取指定Class对象的构造方法："); System.out.println(cst1.toString()); Constructor cst2 = c.getDeclaredConstructor(cs); System.out.println("2、通过参数获取指定Class对象所表示的类或接口的构造方法："); System.out.println(cst2.toString()); Constructor cst3 = c.getEnclosingConstructor(); System.out.println("3、获取本地或匿名类Constructor 对象，它表示基础类的立即封闭构造方法。"); if (cst3 != null) System.out.println(cst3.toString()); else System.out.println("-- 没有获取到任何构造方法！"); Constructor[] csts = c.getConstructors(); System.out.println("4、获取指定Class对象的所有构造方法："); for (int i = 0; i &lt; csts.length; i++) &#123; System.out.println(csts[i].toString()); &#125; System.out.println("\n-------------------------------\n"); Type types1[] = c.getGenericInterfaces(); System.out.println("1、返回直接实现的接口："); for (int i = 0; i &lt; types1.length; i++) &#123; System.out.println(types1[i].toString()); &#125; Type type1 = c.getGenericSuperclass(); System.out.println("2、返回直接超类："); System.out.println(type1.toString()); Class[] cis = c.getClasses(); System.out.println("3、返回超类和所有实现的接口："); for (int i = 0; i &lt; cis.length; i++) &#123; System.out.println(cis[i].toString()); &#125; Class cs1[] = c.getInterfaces(); System.out.println("4、实现的接口"); for (int i = 0; i &lt; cs1.length; i++) &#123; System.out.println(cs1[i].toString()); &#125; System.out.println("\n-------------------------------\n"); Field fs1[] = c.getFields(); System.out.println("1、类或接口的所有可访问公共字段："); if(0==fs1.length)&#123; System.out.println("-- 没有获取到可访问公共字段！"); &#125;else&#123; for (int i = 0; i &lt; fs1.length; i++) &#123; System.out.println(fs1[i].toString()); &#125; &#125; try &#123; System.out.println("2、类或接口的指定已声明指定公共成员字段："); Field f1 = c.getField("MIN_VALUE"); System.out.println(f1.toString()); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println("-- 没有获取到MIN_VALUE公共成员字段！"); &#125; Field fs2[] = c.getDeclaredFields(); System.out.println("3、类或接口所声明的所有字段："); for (int i = 0; i &lt; fs2.length; i++) &#123; System.out.println(fs2[i].toString()); &#125; Field f2 = c.getDeclaredField("serialVersionUID"); System.out.println("4、类或接口的指定已声明指定字段："); System.out.println(f2.toString()); System.out.println("\n-------------------------------\n"); Method m1[] = c.getMethods(); System.out.println("1、返回类所有的公共成员方法："); for (int i = 0; i &lt; m1.length; i++) &#123; System.out.println(m1[i].toString()); &#125; try &#123; System.out.println("2、返回指定公共成员方法："); Method m2 = c.getMethod("addAll", new Class[]&#123;Collection.class&#125;); System.out.println(m2.toString()); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println("-- 没有获取指定公共成员方法！"); &#125; try &#123; System.out.println("3、返回指定公共成员方法："); Method m2 = c.getMethod("listIterator", new Class[]&#123;&#125;); System.out.println(m2.toString()); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println("-- 没有获取指定公共成员方法！"); &#125; &#125;&#125; 获取类、属性、方法的修饰域类Class、Method、Constructor、Field都有一个public方法int getModifiers()。该方法返回一个int类型的数，表示被修饰对象（ Class、 Method、 Constructor、 Field ）的修饰类型的组合值。 123456789101112131415161718192021222324252627282930package test;import java.lang.reflect.Modifier;public class modifier &#123; public static String getField(Object owner, String fieldName)throws Exception &#123; Class cl = owner.getClass(); int mod= cl.getDeclaredField(fieldName).getModifiers(); return Modifier.toString(mod); &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub Feature feature = new Feature(); try &#123; System.out.println(modifier.getField(feature, "name")); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;class Feature&#123; private String name ; private Integer age ; private static String org ="baidu"; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; &#125; 新建类的实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.lang.reflect.Constructor;public class Instance &#123; //有参数 public static Object newInstance(String className, Object[] args) throws Exception &#123; Class cl = Class.forName(className); Class[] argsClass = new Class[args.length]; for (int i = 0, j = args.length; i &lt; j; i++) &#123; argsClass[i] = args[i].getClass(); &#125; Constructor cons = cl.getConstructor(argsClass); return cons.newInstance(args); &#125; //无参数 public static Object newInstance(String className) throws Exception &#123; Class cl = Class.forName(className); Constructor cons = cl.getDeclaredConstructor(); return cons.newInstance(); &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub try &#123; Person per1=(Person) Instance.newInstance("test.Person", new Object[]&#123;"tom",12&#125;); System.out.println(per1.getName()); Person per2=(Person) Instance.newInstance("test.Person"); per2.setName("jerry"); System.out.println(per2.getName()); String str = (String) Instance.newInstance("java.lang.String", new Object[]&#123;"abcdef"&#125;); System.out.println(str); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;class Person&#123; private String name; private Integer age; public Person()&#123; &#125; public Person(String name ,Integer age)&#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 动态创建和访问数组元素123456789101112131415161718192021222324252627package test;import java.lang.reflect.Array;public class Arrayreflect public static void main(String[] args) &#123; try &#123; Class&lt;?&gt; classType = Class.forName("java.lang.String"); Object array = Array.newInstance(classType, 10); Array.set(array, 2, "lucky"); String s =(String) Array.get(array, 2); System.out.println(s); Class&lt;?&gt; classType2 = Class.forName("java.lang.String"); int [] dim = new int [] &#123;10,10,10&#125;; Object arrays = Array.newInstance(classType2, dim); //获取三维数组的第三个数组组件array2Obj，是一个二维数组 Object array2Obj_2d = Array.get(arrays, 3); //获取array2Obj_2的第二个数组组件，是一个一维数组 Object array2Obj_1d = Array.get(array2Obj_2d, 2); //设置下标为8的值为abcdf Array.set(array2Obj_1d, 8, "abcdf"); String arrayCast[][][] = (String[][][]) arrays; System.out.println(arrayCast[3][2][8]); &#125; catch (ClassNotFoundException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 示例代码使用： 12345678910111213141516package test;import java.lang.reflect.Array;public class GrowArray &#123; public static Object growArray(Object array ,int size)&#123; Class&lt;?&gt; classtype =array.getClass().getComponentType(); Object arrayObject = Array.newInstance(classtype, size); System.arraycopy(array, 0, arrayObject, 0, Math.min(Array.getLength(array), size)); return arrayObject; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[] a= new int[]&#123;1,2,3&#125;; int[] b =(int[]) GrowArray.growArray(a, 5); System.out.println(b.length); &#125;&#125; 动态创建代理类代理模式：代理模式的作用=为其他对象提供一种代理以控制对这个对象的访问。 代理模式的角色：抽象角色：声明真实对象和代理对象的共同接口。代理角色：代理角色内部包含有真实对象的引用，从而可以操作真实对象。真实角色：代理角色所代表的真实对象，是我们最终要引用的对象。 java.lang.reflect.Proxy Proxy 提供用于创建动态代理类和实例的静态方法，它还是由这些方法创建的所有动态代理类的超类 InvocationHandler 是代理实例的调用处理程序 实现的接口，每个代理实例都具有一个关联的调用处理程序。对代理实例调用方法时，将对方法调用进行编码并将其指派到它的调用处理程序的 invoke 方法。 动态Proxy是这样的一种类:​ 它是在运行生成的类，在生成时你必须提供一组Interface给它，然后该class就宣称它实现了这些interface。你可以把该class的实例当作这些interface中的任何一个来用。当然，这个Dynamic Proxy其实就是一个Proxy，它不会替你作实质性的工作，在生成它的实例时你必须提供一个handler，由它接管实际的工作。 12345package proxy;public interface Subject &#123; public void Request(); public String Response(String request);&#125; 12345678910111213141516171819package proxy;public class RealSubject implements Subject &#123; @Override public void Request() &#123; // TODO Auto-generated method stub System.out.println("RealSubject"); &#125; @Override public String Response(String request) &#123; // TODO Auto-generated method stub System.out.println("request : "+request); if(request.equals("ok"))&#123; return "202"; &#125;else&#123; return null; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637package proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class DynamicSubject implements InvocationHandler&#123; private Object sub; public DynamicSubject(Object sub) &#123; this.sub = sub; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // TODO Auto-generated method stub System.out.println("Method:"+ method + ",Args:" + args); return method.invoke(sub, args); &#125; public static void main(String[] args) &#123; RealSubject realSub = new RealSubject(); InvocationHandler handler = new DynamicSubject(realSub); Class&lt;?&gt; classType = handler.getClass(); /* * 通过Proxy的newProxyInstance方法来创建我们的代理对象，我们来看看其三个参数 * 第一个参数 handler.getClass().getClassLoader() ，我们这里使用handler这个类的ClassLoader对象来加载我们的代理对象 * 第二个参数realSubject.getClass().getInterfaces()，我们这里为代理对象提供的接口是真实对象所实行的接口，表示我要代理的是该真实对象，这样我就能调用这组接口中的方法了 * 第三个参数handler， 我们这里将这个代理对象关联到了上方的 InvocationHandler 这个对象上 * Subject sub = (Subject)Proxy.newProxyInstance(classType.getClassLoader(), new Class[]&#123;Subject.class&#125;, handler); */ Subject sub = (Subject)Proxy.newProxyInstance(classType.getClassLoader(), realSub.getClass().getInterfaces(), handler); System.out.println(sub.getClass()); sub.Request(); System.out.println(sub.Response("ok")); &#125;&#125; 另外附录一个例子说明动态代理的用处 我们有一个字体提供类，有多个方法 123456package ProxyDemo;public interface FontProvider &#123; public String getFont(String name); public void setFont(String size); public void deleteFont(String name);&#125; 12345678910111213141516171819package ProxyDemo;public class FontProviderFromDisk implements FontProvider &#123; @Override public String getFont(String name) &#123; // TODO Auto-generated method stub System.out.println("字体名字: " +name); return name + " from Disk"; &#125; @Override public void setFont(int size) &#123; // TODO Auto-generated method stub System.out.println("set font size : " +size); &#125; @Override public void deleteFont(String name) &#123; // TODO Auto-generated method stub System.out.println("delete font name : " +name); &#125;&#125; 123456package ProxyDemo;public abstract class ProviderFactory &#123; public static FontProvider getFontProvider() &#123; return new FontProviderFromDisk(); &#125;&#125; 1234567891011package ProxyDemo;public class Main &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub FontProvider fontProvider = ProviderFactory.getFontProvider(); String font = fontProvider.getFont("微软雅黑"); System.out.println(font); fontProvider.deleteFont("宋体"); fontProvider.setFont(10); &#125;&#125; 现在我们希望给他加上一个日志系统，最直接的对FontProviderFromDisk中的所有方法修改，加入日志，显然这是很繁琐的。另外有两种方式 方法一：静态代理 首先定义LogProvider类，实现FontProvider接口，充当代理，当然也要修改ProviderFactory工厂。 12345678910111213141516171819202122232425package ProxyDemo;import java.util.logging.Logger;public class LogProvider implements FontProvider &#123; private FontProvider fontProvider; private Logger logger =Logger.getLogger("LogProvider"); public LogProvider(FontProvider fontProvider) &#123; this.fontProvider = fontProvider; &#125; public String getFont(String name) &#123; logger.info("get Font " + name); return fontProvider.getFont(name); &#125; @Override public void setFont(int size) &#123; // TODO Auto-generated method stub logger.info("set Font size " + size); fontProvider.setFont(size); &#125; @Override public void deleteFont(String name) &#123; // TODO Auto-generated method stub logger.info("delete Font " + name); fontProvider.deleteFont(name);; &#125;&#125; 123456package ProxyDemo;public abstract class ProviderFactory &#123; public static FontProvider getFontProvider() &#123; return new LogProvider(new FontProviderFromDisk()); &#125;&#125; 问题来了，假如又有一个ImgeProvider接口以及实现类ImgeProviderFromDisk也需要加入日志系统，我们这时要扩展LogProvider，实现ImgeProvider接口。随着越来越多的类需要加入日志系统，代理类LogProvider的实现会越来越繁多。那么动态代理就体现其优越了。 方法二：动态代理 原先接口实现类如ImgeProviderFromDisk，FontProviderFromDisk的代码不需要改动，同时代理类的代码实现后也不需要改动了。相比较静态代理来说，代理类轻松很多了。 123456789101112131415161718package ProxyDemo;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.util.logging.Logger;public class LogProvider implements InvocationHandler &#123; private Object provider; private Logger logger =Logger.getLogger("LogProvider"); public LogProvider(Object provider) &#123; this.provider = provider; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // TODO Auto-generated method stub logger.info(method.getName() + args[0].toString()); return method.invoke(provider, args); &#125;&#125; 1234567891011121314package ProxyDemo;import java.lang.reflect.Proxy;public abstract class ProviderFactory &#123; public static FontProvider getFontProvider() &#123; Class cl = LogProvider.class; return (FontProvider) Proxy.newProxyInstance(cl.getClassLoader(), new Class[] &#123; FontProvider.class &#125;, new LogProvider(new FontProviderFromDisk())); &#125; public static ImgeProvider getImgeProvider() &#123; Class cl = LogProvider.class; return (FontProvider) Proxy.newProxyInstance(cl.getClassLoader(), new Class[] &#123; ImgeProvider.class &#125;, new LogProvider(new ImgeProviderFromDisk())); &#125;&#125; 参考：http://lavasoft.blog.51cto.com/62575/43218/ http://blog.csdn.net/yongjian1092/article/details/7364451 http://azrael6619.iteye.com/blog/429797 http://www.cnblogs.com/yaozhongxiao/archive/2013/05/21/3091353.html http://www.cnblogs.com/lzq198754/p/5780331.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot之Spring-data-jpa]]></title>
      <url>%2F2017%2F06%2F12%2FSpringBoot%E4%B9%8BSpring-data-jpa%2F</url>
      <content type="text"><![CDATA[什么是Spring-data-jpa？JPA（Java Persistence API，Java持久化API），定义了对象-关系映射（ORM）以及实体对象持久化的标准接口。 Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得对数据的访问变得方便快捷，并支持map-reduce框和云计算数据服务。 Spring Data 包含多个子项目，Spring-data-jpa是其中一个用于简化JPA开发的框架。 Spring Data JPA的核心概念： Repository：最顶层的接口，是一个空的接口，目的是为了统一所有Repository的类型，且能让组件扫描的时候自动识别。CrudRepository ：是Repository的子接口，提供CRUD的功能PagingAndSortingRepository：是CrudRepository的子接口，添加分页和排序的功能JpaRepository：是PagingAndSortingRepository的子接口，增加了一些实用的功能，比如：批量操作等。JpaSpecificationExecutor：用来做负责查询的接口Specification：是Spring Data JPA提供的一个查询规范，要做复杂的查询，只需围绕这个规范来设置查询条件即可。 配置Spring-data-jpa的使用123456789101112131415&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt; &lt;/parent&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;-! 连接mysql数据库 -&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; SpringBoot的DataSource属性的说明123456789101112131415161718192021222324252627spring.datasource.username=rootspring.datasource.password=root123spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.platform=mysql#指定初始化数据源，是否用data.sql来初始化，默认: truespring.datasource.initialize=false#指定Data (DML)脚本spring.datasource.data=classpath:sql/data.sql#指定Schema (DDL)脚本spring.datasource.schema=classpath:sql/schema-mysql.sql#指定SQL scripts编码spring.datasource.sqlScriptEncoding=UTF-8#初始化出错是否继续进行spring.datasource.continueOnError=true#是否在启动时初始化schema，默认为falsespring.jpa.generate-ddl=false#指定DDL mode (none, validate, update, create, create-drop). #当使用内嵌数据库时，默认是create-drop，否则为nonespring.jpa.hibernate.ddl-auto=update#是否开启sql的log，默认为: falsespring.jpa.show-sql=false#指定命名策略spring.jpa.hibernate.naming-strategy=org.hibernate.cfg.ImprovedNamingStrategy#方言spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5Dialect#spring.data.jpa.repositories.enabled=true Spring-data-jpa的常用接口说明结合项目：MessagePushandEmailSend 实体类123456789101112131415161718192021222324252627282930313233343536373839404142import java.io.Serializable;import java.util.List;import javax.persistence.CascadeType;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.FetchType;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.JoinColumn;import javax.persistence.OneToMany;import javax.persistence.Table;import org.hibernate.annotations.GenericGenerator;@Entity@Table(name = "user_info")public class UserInfoE implements Serializable&#123; /** * */ private static final long serialVersionUID = -498870986608804909L; @Id @GenericGenerator(name ="user_info-uuid",strategy ="uuid") @GeneratedValue(generator ="user_info-uuid") private String id; // SMTP服务器地址 @Column(nullable = true, length = 128) private String smtpServer; // 发件人邮箱地址 @Column(nullable = true, length = 128) private String sender; // 收件人邮箱地址 @Column(nullable = true, length = 128) private String receiverAddr; // 登录SMTP服务器的用户名 @Column(nullable = true, length = 128) private String username; // 登录SMTP服务器的密码 @Column(nullable = true, length = 128) private String password; @OneToMany(fetch=FetchType.EAGER,cascade=CascadeType.ALL,orphanRemoval=true) @JoinColumn(name="id") private List&lt;MessageInfoE&gt; messageinfo;&#125; 接口Repository Repository 接口是 Spring Data 的一个核心接口，它不提供任何方法，开发者需要在自己定义的接口中声明需要的方法。 1234public interface UserDao extends Repository&lt;AccountInfo, Long&gt; &#123; …… &#125; //等价@RepositoryDefinition(domainClass = AccountInfo.class, idClass = Long.class) public interface UserDao &#123; …… &#125; CrudRepository 使用 CrudRepository 的副作用是它可能暴露了你不希望暴露给业务层的方法。比如某些接口你只希望提供增加的操作而不希望提供删除的方法。针对这种情况，开发者只能退回到 Repository 接口，然后到 CrudRepository 中把希望保留的方法声明复制到继承Repository 的自定义的接口中即可。 PagingAndSortingRepository 它继承自 CrudRepository 接口，在 CrudRepository 基础上新增了两个与分页有关的方法。但是，我们很少会将自定义的持久层接口直接继承自 PagingAndSortingRepository，而是在继承 Repository 或 CrudRepository 的基础上，在自己声明的方法参数列表最后增加一个 Pageable 或 Sort 类型的参数，用于指定分页或排序信息即可，这比直接使用 PagingAndSortingRepository 提供了更大的灵活性。 JpaRepository 继承自 PagingAndSortingRepository 的针对 JPA 技术提供的接口，它在父接口的基础上，提供了其他一些方法，比如 flush()，saveAndFlush()，deleteInBatch() 等。如果有这样的需求，则可以继承该接口。 Spring Data JPA本身会提供3中方式创建查询： 通过解析方法名创建查询 Keyword Sample JPQL snippet IsNotNull findByAgeNotNull … where x.age not null Like findByNameLike … where x.name like ?1 NotLike findByNameNotLike … where x.name not like ?1 StartingWith findByNameStartingWith … where x.name like ?1(parameter bound with appended %) EndingWith findByNameEndingWith … where x.name like ?1(parameter bound with prepended %) Containing findByNameContaining … where x.name like ?1(parameter bound wrapped in %) OrderBy findByAgeOrderByName … where x.age = ?1 order by x.name desc Not findByNameNot … where x.name &lt;&gt; ?1 In findByAgeIn … where x.age in ?1 NotIn findByAgeNotIn … where x.age not in ?1 True findByActiveTrue … where x.avtive = true Flase findByActiveFalse … where x.active = false And findByNameAndAge … where x.name = ?1 and x.age = ?2 Or findByNameOrAge … where x.name = ?1 or x.age = ?2 Between findBtAgeBetween … where x.age between ?1 and ?2 LessThan findByAgeLessThan … where x.age &lt; ?1 GreaterThan findByAgeGreaterThan … where x.age &gt; ?1 After/Before … … IsNull findByAgeIsNull … where x.age is null 第一步，解析时，会先把方法名多余的前缀截取掉，比如find、findBy、read、readBy、get、getBy，然后对剩下部分进行解析。 第二步，例如findByUserDepUuid()先判断userDepUuid （根据POJO 规范，首字母变为小写）是否为查询实体的一个属性，如果是，则表示根据该属性进行查询；如果没有该属性，继续第二步； 从右往左截取第一个大写字母开头的字符串此处为Uuid），然后检查剩下的字符串是否为查询实体的一个属性，如果是，则表示根据该属性进行查询；如果没有该属性，则重复第二步，继续从右往左截取；最后假设user为查询实体的一个属性； 接着处理剩下部分（DepUuid），先判断user 所对应的类型是否有depUuid属性，如果有，则表示该方法最终是根据“ Doc.user.depUuid” 的取值进行查询；否则继续按照步骤二 的规则从右往左截取，最终表示根据“Doc.user.dep.uuid” 的值进行查询。 可能会存在一种特殊情况，比如Doc包含一个user 的属性，也有一个userDep 属性，此时会存在混淆。可以明确在属性之间加上”_” 以显式表达意图，比如”findByUser_DepUuid()” 或者”findByUserDep_uuid()”。 使用 @Query 创建查询 通过调用 JPA 命名查询语句创建查询 1234567891011121314151617181920@Entity@NamedQuery(name = "User.findByEmailAddress", query = "select u from User u where u.emailAddress = ?1")public class User &#123;&#125;//单一查询@Entity@NamedQueries(&#123; @NamedQuery(name = "User.findByEmailAddress", query = "select u from User u where u.emailAddress = ?1"), @NamedQuery(name = "User.findByName", query = "select u from User u where u.name = ?1"), &#125;)public class User &#123;&#125;//多个命名查询public interface UserRepository extends JpaRepository&lt;User, Long&gt; &#123; User findByEmailAddress(String emailAddress); User findByName(String name);&#125; 参考：https://segmentfault.com/a/1190000004316491]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git常用命令]]></title>
      <url>%2F2017%2F06%2F09%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[1.添加.gitignore并生效 vim .gitignore 1234*.project.settings/.classpath.gitignore git rm -r --cached . git add . git commit -m &#39;update .gitignore&#39; 2.回滚某个版本 git reset --hard commit_id git push origin -- force 3.Github上fork项目后与原项目保持同步 1234567891011121314151617181920212223242526272829303132333435//首先下载自己fork的项目，我叫luckylau$ git clone https://github.com/Luckylau/PiggyMetrics.git//查看远端分支￥cd PiggyMetrics/$ git remote -vorigin https://github.com/Luckylau/PiggyMetrics.git (fetch)origin https://github.com/Luckylau/PiggyMetrics.git (push)//加入新的远端分支 名字随便取，我取作者的名字sgshq$ git remote add sqshq https://github.com/sqshq/PiggyMetrics.git//再次查看远端分支$ git remote -vorigin https://github.com/Luckylau/PiggyMetrics.git (fetch)origin https://github.com/Luckylau/PiggyMetrics.git (push)sqshq https://github.com/sqshq/PiggyMetrics.git (fetch)sqshq https://github.com/sqshq/PiggyMetrics.git (push)==============================================================开始保持同步的操作//把原项目更新的内容fetch到本地$ git fetch sqshqFrom https://github.com/sqshq/PiggyMetrics * [new branch] master -&gt; sqshq/master//查看分支$ git branch -av* master 914ed47 Merge pull request #17 from ddubson/master remotes/origin/HEAD -&gt; origin/master remotes/origin/master 914ed47 Merge pull request #17 from ddubson/master remotes/sqshq/master 914ed47 Merge pull request #17 from ddubson/master//合并$ git checkout masterAlready on &apos;master&apos;Your branch is up-to-date with &apos;origin/master&apos;.$ git merge sqshq/masterAlready up-to-date.//推到githubgit push -u origin master]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(4)]]></title>
      <url>%2F2017%2F06%2F07%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-4%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： 网络的工作原理 实现 IP 编址方案和 IP 服务，以满足中型企业分支机构网络的网络需求 子网划分基础​ 如果要使用一个网络地址创建 6 个网络，该如何办呢?必须进行子网划分，它让你能够将大型网络划分成一系列小网络。 好处在于： 减少网络流量 优化网络性能 简化管理 有助于覆盖大型地理区域 ​ 要让子网划分方案管用，网络中的每台机器都必须知道主机地址的哪部分为子网地址，这是通过给每台机器分配子网掩码实现的。子网掩码是一个长 32 位的值，让 IP 分组的接收方能够将 IP 地址的网络 ID 部分和主机 D 部分区分开来。 A 类、 B 类和 C 类网络的默认子网掩码如下： ​ 此外，你还需要理解一个名词CIDR ( Classless Inter-Domain Routing ，元类域间路由选择) /8 ~ /15 只能用于标准的 A 类网络， /16 ~ /23 可用于标准的 A 类和 标准的B 类网络，而/24 ~ /30 可用于标准的 A 类、标准的 B 类和标准的 C 类网络。 C 类网络的子网划分二进制 十进制 CIDR00000000 = 0 /2410000000 = 128 /2511000000 = 192 /2611100000 = 224 /2711110000 = 240 /2811111000 = 248 /2911111100 = 252 /30 你不能使用/31 和/32 ，因为至少需要 2 个主机位，这样才有可供分配给主机的IP 地址。 给网络选择子网掩码后，需要计算该子网掩码提供的子网数以及每个子网的合法主机地址和广播地址。为此，你只需回答下面 5 个简单的问题。 选定的子网掩码将创建多少个子网? 每个子网可包含多少台主机? 有哪些合法的子网? 每个子网的广播地址是什么? 每个子网可包含哪些主机地址? 多少个子网? 2的x次方个，其中 x 为被遮盖(取值为 1 )的位数。例如，在 11000000 中，取值为 1的位数为 2 ，因此子网数为 2的2次方 (4 个)。 每个子网可包含多少台主机? 2的Y次方 -2 个，其中 y 为未遮盖(取值为 0) 的位数。例如，在 11000000中，取值为 0 的位数为 6 ，因此每个子网可包含的主机数为 26 - 2 (62) 个。减去的两个为子网地址和广播地址，它们不是合法的主机地址。 有哪些合法的子网?块大小(增量)为 256 减去子网掩码。一个例子是 256 -192 = 64 ，即子网掩码为 192 时，块大小为 64。从 0 开始不断增加剧，直到到达子网掩码值，中间的结果就是子网，即 0 、 64 、 128 和 192 ，是不是很容易? 每个子网的广播地址是什么?这很容易确定。前面确定了子网为 0 、 64 、 128 和 192 ，而广播地址总是下一个子网前面的数。例如，子网 0 的广播地址为 63 ，因为下一个子网为 64; 子网64 的广播地址为 127 ，因为下一个子网为 128 ，以此类推。请记住，最后一个子网的广播地址总是 255 。 合法的主机地址有哪些?合法的主机地址位于两个子网之间，但全为 0 和全为 1 的地址除外。例如，如果子网号为 64 ，而广播地址为 127 ，则合法的主机地址范围为 65~126 ，即子网地址和广播地址之间的数字。 示例如下： 节点地址= 192.168.10.33子网掩码= 255.255.255.224 （/27）属于哪个子网？广播地址是多少？ 多少个子网？/27 对应11100000，即是2的3次方=8，其中3对应1的个数 每个子网可包含多少台主机? 既是2的5次方-2=30，其中 5对应0的个数 有哪些合法的子网?我们从第四个字节计算 256-224=32 ，从0开始不断增加剧，直到到达子网掩码值，中间的结果就是子网，即 0，32，64，96，128，160，192，224 每个子网的广播地址是什么?这很容易确定。前面确定了子网为0，32，64，96，128，160，192，224，而广播地址总是下一个子网前面的数，即是31，63，95，127，159，191，223，255 则上述节点在192.168.10.32，255.255.255.224的子网中，广播地址是192.168.10.63 B 类网络的子网划分二进制 CIDR 二进制 CIDR 255.255.0.0 (/16)255.255.128.0 (/17) 255.255.255.0 (/24)255.255.192.0 (/18) 255.255.255.128 (/25)255.255.224.0 (/19) 255.255.255.192 (/26)255.255.240.0 (/20) 255.255.255.224 (/27)255.255.248.0 (/21) 255.255.255.240 (/28)255.255.252.0 (/22) 255.255.255.248 (/29)255.255.254.0 (/23) 255.255.255.252 (/30) 示例如下： 节点地址：172.168.10.33 子网掩码：255.255.255.224（/27） 属于哪个子网?该子网的广播地址是多少? 多少个子网？/27 对应11111111 11100000，即是2的11次方=2048，其中11对应1的个数 每个子网可包含多少台主机? 即是2的5次方-2=30，其中5对应0的个数 有哪些合法的子网? 256-224= 32 ，第四个字节的可能取值为 0、 32、 64 、 96 、 128 、 160 、 192和 224，第三个字节取值有2的8次方个，即0-255。合计有2的8次方乘以2的3次方就是2的11次方=2048个，列举前8个为 172.168.0.0/27，172.168.0.32/27，172.168.0.64/27，172.168.0.96/27， 172.168.0.128/27，172.168.0.160/27，172.168.0.192/27，172.168.0.224/27。 后8个为 172.168.255.0/27，172.168.255.32/27，172.168.255.64/27，172.168.255.96/27， 172.168.255.128/27，172.168.255.160/27，172.168.255.192/27，172.168.255.224/27。 则上述节点在172.168.10.32/27子网中, 广播地址是172.168.10.63 A 类网络的子网划分二进制 CIDR 二进制 CIDR 255.0.0.0 (/8)255.128.0. 0 (/9) 255.255.240.0 (/20)255.192.0.0 (/10) 255.255.248. 0 (/21)255.224.0.0 (/11) 255.255.252. 0 (/22)255.240.0. 0 (/12) 255.255.254.0 (/23)255.248.0 .0 (/13) 255.255.255.0 (/24)255.252.0.0 (/14) 255.255.255.128 (/25)255.254.0.0 (/15) 255.255.255.192 (/26)255.255.0. 0 (/16) 255.255.255.224 (/27)255.255.128.0 (/17) 255.255.255.240 (/28)255.255.192.0 (/18) 255.255.255.248 (/29)255.255.224.0 (/19) 255.255.255.252 (/30) 示例如下： 节点地址：10.168.10.33 子网掩码：255.255.255.224（/27） 属于哪个子网?该子网的广播地址是多少? 多少个子网？/27 对应11111111 11111111 11100000，即是2的19次方=524288，其中19对应1的个数 每个子网可包含多少台主机? 即是2的5次方-2=30，其中5对应0的个数 有哪些合法的子网? 我们此刻从第四个字节计算 256-224= 32 ，第四个字节的可能取值为 0、 32、 64 、 96 、 128 、 160 、 192和 224，第三个字节取值有2的8次方个，即0-255。第二个字节取值有2的8次方个，即0-255。合计有2的8次方乘以2的3次方再乘以2的8次方就是2的19次方=524288个，列举前8个为 10.0.0.0/27，10.0.0.32/27，10.0.0.64/27，10.0.0.96/27， 10.0.0.128/27，10.0.0.160/27，10.0.0.192/27，10.0.0.224/27。 后8个为 10.255.255.0/27，10.255.255.32/27，10.255.255.64/27，10.255.255.96/27， 172.255.255.128/27，172.255.255.160/27，172.255.255.192/27，172.255.255.224/27。 则上述节点在10.168.10.32/27子网中, 广播地址是10.168.10.63 工具程序地址： https://github.com/Luckylau/UsefulTools/tree/master/NetUtils]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java虚拟机之类的加载器机制与过程]]></title>
      <url>%2F2017%2F06%2F02%2F%E4%BD%A0%E6%87%82java%E5%90%97-13%2F</url>
      <content type="text"><![CDATA[JVM类加载器机制与类加载过程 修改内容 时间 初始化 2017-6-02 丰富 2017-7-14 java是一种动态语言​ 我们都知道JVM（java虚拟机）执行的不是本地机器码指令，而是执行一种称之为字节码的指令（存在于class文件中）。这就要求虚拟机在真正执行字节码之前，先把相关的class文件加载到内存中。虚拟机不是一次性加载所有需要的class文件，因为它在执行的时候根本不会知道以后会用到哪些class文件。它是每用到一个类，就会在运行时“动态地”加载和这个类相关的class文件。这就是java被称之为动态性语言的根本原因。除了动态加载类之外，还会动态的初始化类，对类进行动态链接。其中在JVM中负责对类进行加载的正是本文要介绍的类加载器(ClassLoader)，所以，类加载器是JVM不可或缺的重要组件。 虚拟机类加载机制类加载的生命周期​ 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、 转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载、 连接和初始化过程都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性，Java里天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。 ​ 类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、 验证（Verification）、 准备（Preparation）、 解析（Resolution）、 初始化（Initialization）、 使用（Using）和卸载（Unloading）7个阶段。 其中验证、 准备、 解析3个部分统称为连接（Linking）。 类加载的过程类加载包括加载（Loading）、 验证（Verification）、 准备（Preparation）、 解析（Resolution）。 加载​ “加载”是“类加载”（Class Loading）过程的一个阶段。在加载阶段，虚拟机需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 ​ 相对于类加载过程的其他阶段，一个非数组类的加载阶段（准确地说，是加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的，因为加载阶段既可以使用系统提供的引导类加载器来完成，也可以由用户自定义的类加载器去完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式（即重写一个类加载器的loadClass( )方法）。 数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的。 但数组类与类加载器仍然有很密切的关系，因为数组类的元素类型（ElementType，指的是数组去掉所有维度的类型）最终是要靠类加载器去创建，一个数组类创建过程就遵循以下规则： 如果数组的组件类型（Component Type，指的是数组去掉一个维度的类型）是引用类型，那就递归采用上述加载过程去加载这个组件类型，数组C将在加载该组件类型的类加载器的类名称空间上被标识（一个类必须与类加载器一起确定唯一性）。如果数组的组件类型不是引用类型（例如int[]数组），Java虚拟机将会把数组C标记为与引导类加载器关联。数组类的可见性与它的组件类型的可见性一致，如果组件类型不是引用类型，那数组类的可见性将默认为public。 加载阶段与连接阶段的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 验证​ 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。从整体上看，验证阶段大致上会完成下面4个阶段的检验动作：文件格式验证、元数据验证、 字节码验证、 符号引用验证。 准备​ 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 有两点需要注意：这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中；这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为： 1public static int value=123; 那变量value在准备阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器＜clinit＞（）方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。 上面提到，在“通常情况”下初始值是零值，那相对的会有一些“特殊情况”：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，假设上面类变量value的定义变为 1public static final int value=123; 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 ​ 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。 符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。 各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 ​ 直接引用（Direct References）：直接引用可以是直接指向目标的指针、 相对偏移量或是一个能间接定位到目标的句柄。 直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。 如果有了直接引用，那引用的目标必定已经在内存中存在。 虚拟机规范之中并未规定解析阶段发生的具体时间，只要求了在执行anewarray、checkcast、 getfield、 getstatic、 instanceof、 invokedynamic、 invokeinterface、 invokespecial、invokestatic、 invokevirtual、 ldc、 ldc_w、 multianewarray、 new、 putfield和putstatic这16个用于操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析。 所以虚拟机实现可以根据需要来判断到底是在类被加载器加载时就对常量池中的符号引用进行解析，还是等到一个符号引用将要被使用前才去解析它。 初始化的过程​ 其中对于初始化阶段，虚拟机规范则是严格规定了有且只有5种情况必须立即对类进行“初始化”（而加载、 验证、 准备自然需要在此之前开始）。 第一种：遇到new、 getstatic、 putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。 生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、 读取或设置一个类的静态字段（被final修饰、 已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 第二种：使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 第三种：当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 第四种：当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类。 第五种：当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、 REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 类加载器​ 从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。 类加载器与Class 实例的关系 引导类加载器(Bootstrap Class Loader)​ 负责加载JVM虚拟机运行时所需的基本系统级别的类，如java.lang.String, java.lang.Object等等。引导类加载器(Bootstrap Classloader)会读取 {JRE_HOME}/lib 下的jar包和配置，然后将这些系统类加载到方法区内。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。 ​ 引导类加载器(Bootstrap ClassLoader)加载系统类后，JVM内存会呈现如下格局：对于某一个特定的类而言，在方法区中它应该有运行时常量池、类型信息、字段信息、方法信息、类加载器的引用，对应class实例的引用等信息，其中类加载器的引用,由于这些类是由引导类加载器(Bootstrap Classloader)进行加载的，而 引导类加载器是有C++语言实现的，所以是无法访问的，故而该引用为NULL。对应class实例的引用， 类加载器在加载类信息放到方法区中后，会创建一个对应的Class 类型的实例放到堆(Heap)中, 作为开发人员访问方法区中类定义的入口和切入点。 扩展类加载器（Extension ClassLoader）​ 这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载&lt;JAVA_HOME&gt;\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader）​ 这个类加载器由sun.misc.Launcher $AppClassLoader实现。 由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。 它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 ​ 说明：除了引导类加载器(Bootstrap Class Loader )之外的其他类加载器，都有一个能力，就是判断某一个类是否被引导类加载器加载过，如果加载过，可以直接返回对应的Class instance，如果没有，则返回null。图上的指向引导类加载器的虚线表示类加载器有限的访问引导类加载器的功能。 双亲委派模型12sun.misc.Launcher launcher = sun.misc.Launcher.getLauncher(); //获取Java启动器 ClassLoader classLoader = launcher.getClassLoader(); //获取类加载器ClassLoader用来加载class到内存来 ​ launcher.getClassLoader() 方法将会返回 AppClassLoader 实例，AppClassLoader将ExtClassLoader作为自己的父加载器。当AppClassLoader加载类时，会首先尝试让父加载器ExtClassLoader进行加载，如果父加载器ExtClassLoader加载成功，则AppClassLoader直接返回父加载器ExtClassLoader加载的结果；如果父加载器ExtClassLoader加载失败，AppClassLoader则会判断该类是否是引导的系统类(即是否是通过Bootstrap类加载器加载，这会调用Native方法进行查找)；若要加载的类不是系统引导类，那么ClassLoader将会尝试自己加载，加载失败将会抛出“ClassNotFoundException”。 上述应用类加载器的模式就是我们说的双亲委派模型（parent-delegation model） 对于某个特定的类加载器而言，应该为其指定一个父类加载器，当用其进行加载类的时候： 委托父类加载器帮忙加载； 父类加载器加载不了，则查询引导类加载器有没有加载过该类； 如果引导类加载器没有加载过该类，则当前的类加载器应该自己加载该类； 若加载成功，返回 对应的Class 对象；若失败，抛出异常“ClassNotFoundException”。 双亲委派模型中的”双亲”并不是指它有两个父类加载器的意思，一个类加载器只应该有一个父加载器。 双亲加载模型如下： ​ 使用双亲委派模型的好处在于Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存在在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的Bootstrap ClassLoader进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个java.lang.Object的同名类并放在ClassPath中，那系统中将会出现多个不同的Object类，程序将混乱。因此，如果开发者尝试编写一个与rt.jar类库中重名的Java类，可以正常编译，但是永远无法被加载运行。 举例子比如我们通过window的cmd命令执行javac test.java 生成class文件后，再执行java test运行时，有如下几个过程。 第一步，根据JVM内存配置要求，为JVM申请特定大小的内存空间。 第二步，创建一个引导类加载器实例，初步加载系统类到内存方法区区域中。 第三步，创建JVM 启动器实例 Launcher,并取得类加载器ClassLoader 第四步，使用类加载器ClassLoader加载test 第五步，使用Main类的main方法作为程序入口运行程序 第六步，方法执行完毕，JVM销毁，释放内存 面试题1.类加载器有哪些？其组织结构是怎样的？有哪些特性？ ​ JVM自身定义了三个类加载器：引导类加载器(Bootstrap Class Loader)、拓展类加载器(Extension Class Loader )、应用加载器(Application Class Loader)。当然用户可以自定义类加载器。 ​ 引导类加载器(Bootstrap Class Loader): 该类加载器使JVM使用C/C++底层代码实现的加载器，用以加载JVM运行时所需要的系统类，这些系统类在{JRE_HOME}/lib目录下。由于类加载器是使用平台相关的底层C/C++语言实现的， 所以该加载器不能被Java代码访问到。但是，我们可以查询某个类是否被引导类加载器加载过。我们经常使用的系统类如：java.lang.String,java.lang.Object,java.lang*……. 这些都被放在 {JRE_HOME}/lib/rt.jar包内， 当JVM系统启动的时候，引导类加载器会将其加载到 JVM内存的方法区中。 ​ 拓展类加载器(Extension Class Loader): 该加载器是用于加载 java 的拓展类 ，拓展类一般会放在 {JRE_HOME}/lib/ext/ 目录下，用来提供除了系统类之外的额外功能。拓展类加载器是是整个JVM加载器的Java代码可以访问到的类加载器的最顶端，即是超级父加载器，拓展类加载器是没有父类加载器的。 ​ 应用类加载器(Applocatoin Class Loader): 该类加载器是用于加载用户代码，是用户代码的入口。我经常执行指令 java xxx.x.xxx.x.x.XClass , 实际上，JVM就是使用的AppClassLoader加载 xxx.x.xxx.x.x.XClass 类的。应用类加载器将拓展类加载器当成自己的父类加载器，当其尝试加载类的时候，首先尝试让其父加载器-拓展类加载器加载；如果拓展类加载器加载成功，则直接返回加载结果Class instance,加载失败，则会询问是否引导类加载器已经加载了该类；只有没有加载的时候，应用类加载器才会尝试自己加载。由于xxx.x.xxx.x.x.XClass是整个用户代码的入口，在Java虚拟机规范中，称其为 初始类(Initial Class)。 ​ 用户自定义类加载器（Customized Class Loader）：用户可以自己定义类加载器来加载类。所有的类加载器都要继承java.lang.ClassLoader类。 类加载器有如下特性： 委托机制是指将加载一个类的请求交给父类加载器，如果这个父类加载器不能够找到或者加载这个类，那么再加载它。 可见性的原理是子类的加载器可以看见所有的父类加载器加载的类，而父类加载器看不到子类加载器加载的类。 单一性原理是指仅加载一个类一次，这是由委托机制确保子类加载器不会再次加载父类加载器加载过的类。 2.双亲加载模型的逻辑和底层代码实现是怎样的？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//提供class类的二进制名称表示，加载对应class，加载成功，则返回表示该类对应的Class&lt;T&gt; instance 实例 public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false); &#125; protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先，检查是否已经被当前的类加载器记载过了，如果已经被加载，直接返回对应的Class&lt;T&gt;实例 Class&lt;?&gt; c = findLoadedClass(name); //初次加载 if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //如果有父类加载器，则先让父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; // 没有父加载器，则查看是否已经被引导类加载器加载，有则直接返回 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; // 父加载器加载失败，并且没有被引导类加载器加载，则尝试该类加载器自己尝试加载 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); // 自己尝试加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; //是否解析类 if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 3.什么是线程上下文加载器？（破坏双亲委派模型） 线程上下文类加载器是从线程的角度来看待类的加载，为每一个线程绑定一个类加载器，可以将类的加载从单纯的 双亲加载模型解放出来，进而实现特定的加载需求。 参考：http://blog.csdn.net/luanlouis/article/details/50529868 http://blog.csdn.net/zhangjg_blog/article/details/16102131]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java虚拟机之运行时数据区]]></title>
      <url>%2F2017%2F06%2F01%2F%E4%BD%A0%E6%87%82java%E5%90%97-12%2F</url>
      <content type="text"><![CDATA[修改内容 时间 初版 2017-06-01 内存泄漏和访问堆中对象 2017-07-06 Java运行时数据区，探秘虚拟机内存管理 ​ JVM就是一个特殊的进程， 我们执行的java程序， 都运行在一个JVM进程中， 这个进程的作用就是加载class文件， 并且执行class文件中的代码。既然虚拟机作为一个虚拟的计算机， 来执行我们的程序， 那么在执行的过程中， 必然要有地方存放我们的代码（class文件）； 在执行的过程中， 总会创建很多对象， 必须有地方存放这些对象； 在执行的过程中， 还需要保存一些执行的状态， 比如， 将要执行哪个方法， 当前方法执行完成之后， 要返回到哪个方法等信息， 所以， 必须有一个地方来保持执行的状态。 上面的描述中， “地方”指的当然就是内存区域， 程序运行起来之后， 就是一个动态的过程， 必须合理的划分内存区域， 来存放各种数据。 ​ JVM运行时数据区(JVM Runtime Area)其实就是指JVM在运行期间，其对计算机内存空间的划分和分配。 JVM的体系结构 类加载器子系统用于将class文件加载到虚拟机的运行时数据区中（准确的说应该是方法区） 。 可以认为执行引擎是字节码的执行机制， 一个线程可以看做是一个执行引擎的实例。 运行时数据区如何运转的？ 运行时数据区的OutOfMemoryError异常？这一块除了PC寄存器外，都有可能出现内存泄漏问题。我们可以做相关试验。 首先在Eclipse的Debug页签中设置虚拟机参数 1234-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8-Xms20M 设置JVM猝死内存为20M。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。-Xmx20M ，设置JVM最大可用内存为512M。-Xmn10m：设置年轻代大小为10M。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 java堆溢出在上述参数基础上加上-XX:+HeapDumpOnOutOfMemoryError让虚拟机在出现内存溢出异常时Dump出当前的内存堆转储快照以便事后进行分析。 1234567891011121314import java.util.ArrayList;import java.util.List;public class Main &#123; public static void main(String[] args) &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); while(true)&#123; list.add(new Object()); &#125; &#125;&#125;//输出java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid9212.hprof ...Heap dump file created [27960620 bytes in 0.073 secs] 分析思路 使用Memory Analyzer分析，eclipse安装地址：http://archive.eclipse.org/mat/1.2/update-site/ ​ 如果是内存泄露，可进一步通过工具查看泄露对象到GC Roots的引用链。 于是就能找到泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的。 掌握了泄露对象的类型信息及GC Roots引用链的信息，就可以比较准确地定位出泄露代码的位置。​ 如果不存在泄露，换句话说，就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、 持有状态时间过长的情况，尝试减少程序运行期的内存消耗。 虚拟机栈和本地方法栈溢出​ 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。这里把异常分成两种情况，看似更加严谨，但却存在着一些互相重叠的地方：当栈空间无法继续分配时，到底是内存太小，还是已使用的栈空间太大，其本质上只是对同一件事情的两种描述而已。下面这个代码演示的是在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是StackOverflowError异常。 12345678910111213141516171819202122public class JavaVMStackSOF &#123; private int stackLength=1; public void stackLeak()&#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF oom=new JavaVMStackSOF(); try&#123; oom.stackLeak(); &#125;catch(Throwable e)&#123; System.out.println("stack length："+oom.stackLength); throw e; &#125; &#125;&#125;//输出stack length：214238Exception in thread "main" java.lang.StackOverflowError at Concurrency.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:8) at Concurrency.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:8) at Concurrency.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:8) ​ 如果使用虚拟机默认参数，栈深度在大多数情况下（因为每个方法压入栈的帧大小并不是一样的，所以只能说在大多数情况下）达到1000～2000完全没有问题，对于正常的方法调用（包括递归），这个深度应该完全够用了。 但是，如果是建立过多线程导致的内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。 方法区和运行时常量池溢出​ String.intern()是一个Native方法，它的作用是：如果字符串常量池中已经包含一个等于此String对象的字符串，则返回代表池中这个字符串的String对象；否则，将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。通过-XX:PermSize和-XX:MaxPermSize限制方法区大小，从而间接限制其中常量池的容量。这两个命令java8已移除，不做讨论。 本机直接内存溢出略 运行时数据区之PC寄存器即程序计数器，用于存放一条指令的地址， 这条指令就是虚拟机要执行的下一条指令。如果是java,其PC记录的是正在执行的虚拟机字节码指令地址。如上图所示，pc寄存器和线程相关联， 每一个线程都有一个PC寄存器。 运行时数据区之Java栈如图所示，在线程创建的时候，都会为其创建一个私有的虚拟机栈，也就是说Java栈上的所有数据都是线程私有的， 也就是说， 每个线程都会有自己的Java栈， 不会相互访问其他Java栈中的数据。 ​ 栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。栈帧的存储空间分配在 Java 虚拟机栈之中，每一个栈帧都有自己的局部变量表（Local Variables）、操作数栈（Operand Stack）和指向当前方法所属的类的运行时常量池的引用。在一条线程之中，只有目前正在执行的那个方法的栈帧是活动的。这个栈帧就被称为是当前栈帧（Current Frame），这个栈帧对应的方法就被称为是当前方法（Current Method），定义这个方法的类就称作当前类（Current Class）。对局部变量表和操作数栈的各种操作，通常都指的是对当前栈帧的对局部变量表和操作数栈进行的操作。 ​ 如果当前方法调用了其他方法，或者当前方法执行结束，那这个方法的栈帧就不再是当前栈帧了。当一个新的方法被调用，一个新的栈帧也会随之而创建，并且随着程序控制权移交到新的方法而成为新的当前栈帧。当方法返回的之际，当前栈帧会传回此方法的执行结果给前一个栈帧，在方法返回之后，当前栈帧就随之被丢弃，前一个栈帧就重新成为当前栈帧了。 注意：栈帧是线程本地私有的数据，不可能在一个栈帧之中引用另外一条线程的栈帧。 局部变量表使用索引来进行定位访问，第一个局部变量的索引值为零，局部变量的索引值是从零至小于局部变量表最大容量的所有整数。 操作数栈所属的栈帧在刚刚被创建的时候，操作数栈是空的。 Java 虚拟机提供一些字节码指令来从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中，也提供了一些指令用于从操作数栈取走数据、操作数据和把操作结果重新入栈。在方法调用的时候，操作数栈也用来准备调用方法的参数以及接收方法返回结果。 Java 虚拟机栈可能发生如下异常情况： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量时， Java 虚拟机将会抛出一个 StackOverflowError 异常。 如果 Java 虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 运行时数据区之本地方法栈​ Java可以和C/C++互调。如果当前线程执行的代码是C/C++写的本地代码， 那么这些方法就在本地方法栈中执行，而不会在Java栈中执行， Java栈中只执行Java方法。 Java 虚拟机规范允许本地方法栈被实现成固定大小的或者是根据计算动态扩展和收缩的。如果采用固定大小的本地方法栈，那每一条线程的本地方法栈容量应当在栈创建的时候独立地选定。一般情况下， Java 虚拟机实现应当提供给程序员或者最终用户调节虚拟机栈初始容量的手段，对于长度可动态变化的本地方法栈来说，则应当提供调节其最大、最小容量的手段。 本地方法栈可能发生如下异常情况： 如果线程请求分配的栈容量超过本地方法栈允许的最大容量时， Java 虚拟机将会抛出一个StackOverflowError 异常。 如果本地方法栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的本地方法栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。 运行时数据区之方法区​ 在字面意思上， “方法区”这个词会让人产生误解。因为方法区存放的不只是方法， 它存放的是类型信息。我们在写程序的时候， 几乎总是在和类， 对象打交道， 我们知道根据一个类可以创建对象。 一般来说， 我们操纵的是对象， 访问对象的属性， 调用对象的方法等， 但是我们要思考这样一个问题， 虚拟机根据什么信息知道如何创建对象的呢？ 当然是根据这个对象的类型信息， 但是这个类型信息在哪里呢？现在我们知道是在方法区中。 那么类型信息是被谁加载到方法区中的呢？由上面的体系结构图， 我们可以知道是类加载器子系统。类加载器子系统提取class文件里面的类型信息，并将这些类型信息存放到方法区中。在 Java 虚拟机中，方法区（Method Area） 是可供各条线程共享的运行时内存区域。 方法区可能发生如下异常情况： 如果方法区的内存空间不能满足内存分配请求，那 Java 虚拟机将抛出一个OutOfMemoryError 异常。 运行时数据区之堆​ 方法区是存放类型数据的， 而堆则是存放运行时产生的对象的。 和C++不同的是， Java只能在堆中存放对象， 而不能在栈上分配对象， 所有运行时产生的对象全部都存放于堆中， 包括数组。 我们知道， 在Java中， 数组也是对象。一个JVM实例中只有一个堆， 所有线程共享堆中的数据（对象） 。 ​ 但是Java虚拟机的指令集中并不包含任何释放内存的指令， 因而我们也就不能手动释放内存。 所有被创建的对象都会被一个叫做垃圾收集器（GC）的模块自动回收， 垃圾收集器有不同的实现方式， 他们以 特定的方式判断对象是否过期， 并以特定的方式对对象进行回收。 ​ 所有创建的对象都存在堆中， 而垃圾收集器会自动回收过期的对象， 所以，JVM的堆区是垃圾收集器的“重点管理区” 。 如何访问堆中的对象？ ​ 建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象。 由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、 访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。 目前主流的访问方式有使用句柄和直接指针两种。 ​ 使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。​ 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。 Java 堆可能发生如下异常情况： 如果实际所需的堆超过了自动内存管理系统能提供的最大容量，那 Java 虚拟机将会抛出一个OutOfMemoryError 异常。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java虚拟机之理解Class文件]]></title>
      <url>%2F2017%2F05%2F26%2F%E4%BD%A0%E6%87%82java%E5%90%97-11%2F</url>
      <content type="text"><![CDATA[深入理解Java Class文件格式 Class文件的位置和作用​ JVM不会理解我们写的Java源文件， 我们必须把Java源文件编译成class文件， 才能被JVM识别， 对于JVM而言， class文件相当于一个接口， 理解了这个接口， 能帮助我们更好的理解JVM的行为；另一方面， class文件以另一种方式重新描述了我们在源文件中要表达的意思， 理解class文件如何重新描述我们编写的源文件， 对于深入理解Java语言和语法都是很有帮助的。 在整个Java技术体系结构中， class文件处于中间的位置， 对于理解整个体系有着承上启下的作用。 Class文件格式概述​ class文件是一种8位字节的二进制流文件， 各个数据项按顺序紧密的从前向后排列， 相邻的项之间没有间隙， 这样可以使得class文件非常紧凑， 体积轻巧， 可以被JVM快速的加载至内存， 并且占据较少的内存空间。 我们的Java源文件， 在被编译之后， 每个类（或者接口）都单独占据一个class文件， 并且类中的所有信息都会在class文件中有相应的描述， 由于class文件很灵活， 它甚至比Java源文件有着更强的描述能力。 ​ class文件中的信息是一项一项排列的， 每项数据都有它的固定长度， 有的占一个字节， 有的占两个字节， 还有的占四个字节或8个字节， 数据项的不同长度分别用u1, u2, u4, u8表示， 分别表示一种数据项在class文件中占据一个字节， 两个字节， 4个字节和8个字节。 可以把u1, u2, u3, u4看做class文件数据项的“类型” 。 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count class文件中的魔数和版本号​ 魔数(magic)​ 在class文件开头的四个字节， 存放着class文件的魔数， 这个魔数是class文件的标志，他是一个固定的值： 0XCAFEBABE 。 也就是说他是判断一个文件是不是class格式的文件的标准， 如果开头四个字节不是0XCAFEBABE， 那么就说明它不是class文件， 不能被JVM识别。 ​ 版本号(minor_version,major_version)​ 紧接着魔数的四个字节是class文件的此版本号和主版本号。 随着Java的发展， class文件的格式也会做相应的变动。 版本号标志着class文件在什么时候， 加入或改变了哪些特性。 举例来说， 不同版本的javac编译器编译的class文件， 版本号可能不同， 而不同版本的JVM能识别的class文件的版本号也可能不同， 一般情况下， 高版本的JVM能识别低版本的javac编译器编译的class文件， 而低版本的JVM不能识别高版本的javac编译器编译的class文件。 如果使用低版本的JVM执行高版本的class文件， JVM会抛出java.lang.UnsupportedClassVersionError 。 class文件中的常量池概述 ​ 常量池是class文件中的一项非常重要的数据。 常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。 字面量比较接近于Java语言层面的常量概念，如文本字符串、 声明为final的常量值等。 而符号引用则属于编译原理方面的概念，包括了下面三类常量：类和接口的全限定名（Fully Qualified Name），字段的名称和描述符（Descriptor），方法的名称和描述符。 ​ 常量池中几乎包含类中的所有信息的描述， class文件中的很多其他部分都是对常量池中的数据项的引用，比如this_class, super_class, field_info, attribute_info等， 另外字节码指令中也存在对常量池的引用， 这个对常量池的引用当做字节码指令的一个操作数。 此外， 常量池中各个项也会相互引用。 ​ 常量池计数器(constant_pool_count) ​ 常量池是class文件中非常重要的结构，它描述着整个class文件的字面量信息。 常量池是由一组constant_pool结构体数组组成的，而数组的大小则由常量池计数器指定。常量池计数器constant_pool_count 的值 =constant_pool表中的成员数+ 1。constant_pool表的索引值只有在大于 0 且小于constant_pool_count时才会被认为是有效的。 ​ 常量池数据区(constant_pool[contstant_pool_count-1]) ​ 常量池，constant_pool是一种表结构,它包含 Class 文件结构及其子结构中引用的所有字符串常量、 类或接口名、字段名和其它常量。 每个数据项叫做一个XXX_info项， 比如， 一个常量池中一个CONSTANT_Utf8类型的项， 就是一个CONSTANT_Utf8_info 。除此之外， 每个info项中都有一个标志值（tag）， 这个标志值表明了这个常量池中的info项的类型是什么， 从上面的表格中可以看出， 一个CONSTANT_Utf8_info中的tag值为1， 而一个CONSTANT_Fieldref_info中的tag值为9 。 常量池中数据项类型 类型标志 类型描述 CONSTANT_Utf8 1 UTF-8编码的Unicode字符串 CONSTANT_Integer 3 int类型字面值 CONSTANT_Float 4 float类型字面值 CONSTANT_Long 5 long类型字面值 CONSTANT_Double 6 double类型字面值 CONSTANT_Class 7 对一个类或接口的符号引用 CONSTANT_String 8 String类型字面值 CONSTANT_Fieldref 9 对一个字段的符号引用 CONSTANT_Methodref 10 对一个类中声明的方法的符号引用 CONSTANT_InterfaceMethodref 11 对一个接口中声明的方法的符号引用 CONSTANT_NameAndType 12 对一个字段或方法的部分符号引用 CONSTANT_MethodHandle 15 表示方法句柄 CONSTANT_MethodType 16 表示方法类型 CONSTANT_InvokeDynamic 18 表示用invokedynamic指令所使用的引导方法(Bootstrap Method),引导方法使用动态调用名称(Dynamic Invocation Name),参数和请求返回类型以及可以选择性的附加被称为静态参数(static arguments) 的常量序列。 class文件中的特殊字符串 类的全限定名 ​ 在常量池中， 一个类型的名字并不是我们在源文件中看到的那样， 也不是我们在源文件中使用的包名加类名的形式。 源文件中的全限定名和class文件中的全限定名不是相同的概念。 源文件中的全新定名是包名加类名， 包名的各个部分之间，包名和类名之间， 使用点号分割。 如Object类， 在源文件中的全限定名是java.lang.Object 。 而class文件中的全限定名是将点号替换成“/” 。 例如， Object类在class文件中的全限定名是 java/lang/Object 。 字段的名称和描述符 void和基本数据类型在描述符 基本数据类型和void类型 类型的对应字符 byte B char C double D float F int I long J short S boolean Z void V 引用类型（类和接口，枚举） 1“L” + 类型的全限定名 + “;” 如 Object在描述符中的对应字符串是： Ljava/lang/Object； ArrayList在描述符中的对应字符串是： Ljava/lang/ArrayList； ​ 自定义类型com.example.Person在描述符中的对应字符串是： Lcom/example/Person。 数组类型 1若干个“[” + 数组中元素类型的对应字符串 如 int[]类型的对应字符串是： [I ； ​ int[][]类型的对应字符串是： [[I ； ​ Object[]类型的对应字符串是： [Ljava/lang/Object ； ​ Object[][][]类型的对应字符串是： [[[Ljava/lang/Object。 方法的名称和描述符 1(参数1类型 参数2类型 参数3类型 ...)返回值类型 特殊方法的方法名,如类的构造方法的方法名使用字符串 &lt;init&gt; 表示， 而静态初始化方法的方法名使用字符串 &lt;clinit&gt; 表示。 除了这两种特殊的方法外， 其他普通方法的方法名， 和源文件中的方法名相同。 class文件中的访问标志信息访问标志（access_flags）紧接着常量池后，占有两个字节，总共16位 当JVM在编译某个类或者接口的源代码时，JVM会解析出这个类或者接口的访问标志信息，然后，将这些标志设置到访问标志（access_flags）这16个位上。 a. 我们知道，每个定义的类或者接口都会生成class文件（这里也包括内部类，在某个类中定义的静态内部类也会单独生成一个class文件）。 对于定义的类，JVM在将其编译成class文件时，会将class文件的访问标志的第11位设置为1 。第11位叫做ACC_SUPER标志位；对于定义的接口，JVM在将其编译成class文件时，会将class文件的访问标志的第8位 设置为 1 ，第8位叫做ACC_INTERFACE标志位； b. class文件表示的类或者接口的访问权限有public类型的和包package类型的。如果类或者接口被声明为public类型的，那么，JVM将其编译成class文件时，会将class文件的访问标志的第16位设置为1 。第16位叫做ACC_PUBLIC标志符； c. 类是否为抽象类型的，即我们定义的类有没有被abstract关键字修饰，即我们定义的类是否为抽象类。 如果我们形如： 1public abstract class MyClass&#123;......&#125; 定义某个类时，JVM将它编译成class文件的时候，会将class文件的访问标志的第7位设置为1 。第7位叫做ACC_ABSTRACT标志位。 另外值得注意的是，对于定义的接口，JVM在编译接口的时候也会对class文件的访问标志上的ACC_ABSTRACT标志位设置为 1； d. 该类是否被声明了final类型,即表示该类不能被继承。 此时JVM会在编译class文件的过程中，会将class文件的访问标志的第12位设置为 1 。第12位叫做ACC_FINAL标志位； e. 如果我们这个class文件不是JVM通过Java源代码文件编译而成的，而是用户自己通过class文件的组织规则生成的，那么，一般会对class文件的访问标志第4位设置为 1 。通过JVM编译源代码产生的class文件此标志位为 0，第4位叫做ACC_SYNTHETIC标志位； f. 枚举类，对于定义的枚举类如：public enum EnumTest{….}，JVM也会对此枚举类编译成class文件，这时，对于这样的class文件，JVM会对访问标志第2位设置为 1 ，以表示它是枚举类。第2位叫做ACC_ENUM标志位； g. 注解类，对于定义的注解类如：public @interface{…..},JVM会对此注解类编译成class文件，对于这样的class文件，JVM会将访问标志第3位设置为1，以表示这是个注解类，第3位叫做ACC_ANNOTATION标志位。 class文件中的this_class​ 一个Java类源文件经过JVM编译会生成一个class文件，也有可能一个Java类源文件中定义了其他类或者内部类，这样编译出来的class文件就不止一个，但每一个class文件表示某一个类，至于这个class表示哪一个类，便可以通过 类索引 这个数据项来确定。 class文件中的super_class​ Java支持单继承模式，除了java.lang.Object 类除外，每一个类都会有且只有一个父类。class文件中紧接着类索引(this_class)之后的两个字节区域表示父类索引，跟类索引一样，父类索引这两个字节中的值指向了常量池中的某个常量池项CONSTANT_Class_info，表示该class表示的类是继承自哪一个类。如果没有显式的继承一个，也就是说如果当前类是直接继承Object的， 那么super_class值为0 。 如果一个索引值为0， 那么就说明这个索引不引用任何常量池中的数据项， 因为常量池中的数据项是从1开始的。 也就是说， 如果一个类的class文件中的super_class为0 ， 那么就代表该类直接继承Object类。 class文件中的interfaces_count和interfaces​ 紧接着super_class的是interfaces_count， 表示当前类所实现的接口的数量或者当前接口所继承的超接口的数量。 注意， 只有当前类直接实现的接口才会被统计， 如果当前类继承了另一个类， 而另一个类又实现了一个接口， 那么这个接口不会统计在当前类的interfaces_count中。 在interfaces_count后面是interfaces， 他可以看做是一个数组， 其中的每个数组项是一个索引， 指向常量池中的一个CONSTANT_Class_info， 这个CONSTANT_Class_info又会引用常量池中的一个CONSTANT_Utf8_info ， 这个CONSTANT_Utf8_info 中存放着有当前类型直接实现或继承的接口的全限定名。 当前类型实现或继承了几个接口， 在interfaces数组中就会有几个数项与之相对应。 class文件中的fields_count和fields字段表（field_info）用于描述接口或者类中声明的变量。字段（field）包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。 Java中的一个Field字段应该包含信息如下： FIeld_info的组成元素：访问标志（access_flags）、名称索引（name_index）、描述索引（descriptor_index）、属性表集合 其中access_flags占两个字节， 描述的是字段的访问标志信息。 class文件中的methods_count和methods​ 方法表集合是指由若干个方法表（method_info）组成的集合。对于在类中定义的若干个，经过JVM编译成class文件后，会将相应的method方法信息组织到一个叫做方法表集合的结构中，字段表集合是一个类数组结构，如下图所示： 注意： ​ methods_count描述的是当前的类中定义的方法的个数，这里包括静态方法， 但不包括从父类继承的方法。 如果当前class文件是由一个接口生成的， 那么这里的methods_count描述的是接口中定义的抽象方法的数量， 我们知道， 接口中定义的方法默认都是公有的。此外需要说明的是， 编译器可能会在编译时向class文件增加额外的方法， 也就是说， class文件中的方法的数量可能多于源文件中由用户定义的方法。 举例来说： 如果当前类没有定义构造方法， 那么编译器会增加一个无参数的构造函数； 如果当前类或接口中定义了静态变量， 并且使用初始化表达式为其赋值， 或者定义了static静态代码块， 那么编译器在编译的时候会默认增加一个静态初始化方法 。 ​ 位于methods_count下面的数据叫做methods ， 可以把它看做一个数组， 数组中的每一项是一个method_info 。这个数组中一共有methods_count个method_info ， 每个method_info 都是对一个方法的描述。 ​ 上图中的method_info结构体的定义，该结构体的定义跟描述field字段 的field_info结构体的结构几乎完全一致方法表的结构体由：访问标志(access_flags)、名称索引(name_index)、描述索引(descriptor_index)、属性表(attribute_info)集合组成。 访问标志(access_flags)：​ method_info结构体最前面的两个字节表示的访问标志（access_flags），记录这这个方法的作用域、静态or非静态、可变性、是否可同步、是否本地方法、是否抽象等信息。 名称索引(name_index)：​ 紧跟在访问标志（access_flags）后面的两个字节称为名称索引，这两个字节中的值指向了常量池中的某一个常量池项，这个方法的名称以UTF-8格式的字符串存储在这个常量池项中。 描述索引(descriptor_index)：​ 描述索引表示的是这个方法的特征或者说是签名，一个方法会有若干个参数和返回值，而若干个参数的数据类型和返回值的数据类型构成了这个方法的描述，其基本格式为：(参数数据类型描述列表)返回值数据类型。所谓的方法描述符，实质上就是指用一个什么样的字符串来描述一个方法 属性表(attribute_info)集合： ​ 这个属性表集合非常重要，方法的实现被JVM编译成JVM的机器码指令，机器码指令就存放在一个Code类型的属性表中；如果方法声明要抛出异常，那么异常信息会在一个Exceptions类型的属性表中予以展现。这些信息包括：这个方法的代码实现，即方法的可执行的机器指令；这个方法声明的要抛出的异常信息；这个方法是否被@deprecated注解表示；这个方法是否是编译器自动生成的。 属性表之Code类型 ​ Java程序方法体中的代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性内。 Code属性出现在方法表的属性集合之中，但并非所有的方法表都必须存在这个属性，譬如接口或者抽象类中的方法就不存在Code属性。 Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码（Code，方法体里面的Java代码）和元数据（Metadata，包括类、 字段、 方法定义及其他信息）两部分，那么在整个Class文件中，Code属性用于描述代码，所有的其他数据项目都用于描述元数据。 1234567891011121. attribute_name_index,属性名称索引，占有2个字节，其内的值指向了常量池中的某一项，该项表示字符串“Code”;2. attribute_length,属性长度，占有 4个字节，其内的值表示后面有多少个字节是属于此Code属性表的；3. max_stack,操作数栈深度的最大值，占有 2 个字节，在方法执行的任意时刻，操作数栈都不应该超过这个值，虚拟机的运行的时候，会根据这个值来设置该方法对应的栈帧(Stack Frame)中的操作数栈的深度；4. max_locals,最大局部变量数目，占有 2个字节，其内的值表示局部变量表所需要的存储空间大小；5. code_length,机器指令长度，占有 4 个字节，表示跟在其后的多少个字节表示的是机器指令；6. code,机器指令区域，该区域占有的字节数目由 code_length中的值决定。JVM最底层的要执行的机器指令就存储在这里；7. exception_table_length,显式异常表长度，占有2个字节，如果在方法代码中出现了try&#123;&#125; catch()形式的结构，该值不会为空，紧跟其后会跟着若干个exception_table结构体，以表示异常捕获情况；8. exception_table，显式异常表，占有8 个字节，start_pc,end_pc,handler_pc中的值都表示的是PC计数器中的指令地址。exception_table表示的意思是：如果字节码从第start_pc行到第end_pc行之间出现了catch_type所描述的异常类型，那么将跳转到handler_pc行继续处理。9. attribute_count,属性计数器，占有 2 个字节，表示Code属性表的其他属性的数目。10. attribute_info,表示Code属性表具有的属性表，它主要分为两个类型的属性表：“LineNumberTable”类型和“LocalVariableTable”类型。 “LineNumberTable”类型的属性表记录着Java源码和机器指令之间的对应关系； “LocalVariableTable”类型的属性表记录着局部变量描述； ​ 机器指令(code)：JVM使用一个字节表示机器操作码，即对JVM底层而言，它能表示的机器操作码不多于2的 8 次方，即 256个。class文件中的机器指令部分是class文件中最重要的部分。 ​ 异常处理跳转信息：如果代码中出现了try{}catch{}块，那么try{}块内的机器指令的地址范围记录下来，并且记录对应的catch{}块中的起始机器指令地址，当运行时在try块中有异常抛出的话，JVM会将catch{}块对应懂得其实机器指令地址传递给PC寄存器，从而实现指令跳转。一个异常处理器（exception_info）的意思是： 如果偏移量从start_pc到end_pc之间的字节码出现了catch_type描述的类型的异常， 那么就跳转到偏移量为handler_pc的字节码处去执行。如果catch_type为0， 就代表不引用任何常量池项（常量池中的项是从1开始计的）， 那么这个exception_info用于实现finally子句。 exception_info中的各个字段： ​ start_pc是从字节码（Code属性中的code部分）起始处到当前异常处理器起始处的偏移量。 ​ end_pc是从字节码起始处到当前异常处理器末尾的偏移量。 ​ handler_pc是指当前异常处理器用来处理异常（即catch块）的第一条指令相对于字节码开始处的偏移量。 ​ catch_type是一个常量池索引， 指向常量池中的一个CONSTANT_Class_info数据项， 该数据项描述了catch块中的异常的类型信息。这个类型必须是java.lang.Throwable的或其子类。 ​ Java源码行号和机器指令的对应关系—LineNumberTable属性表：编译器在将java源码编译成class文件时，会将源码中的语句行号跟编译好的机器指令关联起来，这样的class文件加载到内存中并运行时，如果抛出异常，JVM可以根据这个对应关系，抛出异常信息，告诉我们的源码的多少行有问题，方便我们定位问题。这个信息不是运行时必不可少的信息，但是默认情况下，编译器会生成这一项信息，如果你项取消这一信息，你可以使用-g:none 或-g:lines来取消或者要求设置这一项信息。如果使用了-g:none来生成class文件，class文件中将不会有LineNumberTable属性表，造成的影响就是 将来如果代码报错，将无法定位错误信息报错的行，并且如果项调试代码，将不能在此类中打断点（因为没有指定行号。） ​ 局部变量表描述信息—-LocalVariableTable属性表：局部变量表信息会记录栈帧局部变量表中的变量和java源码中定义的变量之间的关系，这个信息不是运行时必须的属性，默认情况下不会生成到class文件中。你可以根据javac指令的-g:none或者-g:vars选项来取消或者设置这一项信息。它有什么作用呢？ 当我们使用IDE进行开发时，最喜欢的莫过于它们的代码提示功能了。如果在项目中引用到了第三方的jar包，而第三方的包中的class文件中有无LocalVariableTable属性表的区别如下： Exceptions类型 ​ Exceptions类型的属性表(attribute_info)结构体由一下元素组成：属性名称索引(attribute_name_index)：占有 2个字节，其中的值指向了常量池中的表示”Exceptions”字符串的常量池项；属性长度(attribute_length)：它比较特殊，占有4个字节，它的值表示跟在其后面多少个字节表示异常信息；异常数量(number_of_exceptions)：占有2 个字节，它的值表示方法声明抛出了多少个异常，即表示跟在其后有多少个异常名称索引；异常名称索引(exceptions_index_table)：占有2个字节，它的值指向了常量池中的某一项，该项是一个CONSTANT_Class_info类型的项，表示这个异常的完全限定名称； ​ 如果某个方法定义中，没有声明抛出异常，那么，表示该方法的方法表(method_info)结构体中的属性表集合中不会有Exceptions类型的属性表；换句话说，如果方法声明了要抛出的异常，方法表(method_info)结构体中的属性表集合中必然会有Exceptions类型的属性表，并且该属性表中的异常数量不小于1。 ​ 我们假设异常数量中的值为 N，那么后面的异常名称索引的数量就为N，它们总共占有的字节数为N*2，而异常数量占有2个字节，那么将有下面的这个关系式： 属性长度(attribute_length)中的值= 2 + 2*异常数量(number_of_exceptions)中的值 Exceptions类型的属性表（attribute_info）的长度=2 + 4 + 属性长度(attribute_length)中的值 Synthetic类型 Synthetic属性可以出现在filed_info中， method_info中和顶层的ClassFile中， 分别表示这个字段， 方法或类不是有用户代码生成的（即不存在与源文件中）， 而是由编译器自动添加的。 例如， 编译器会为内部类增加一个字段， 该字段是对外部类对象的引用； 如果一个不定义构造方法， 那么编译器会自动添加一个无参数的构造方法， 如果定义了静态字段或静态代码块， 还会根据具体情况， 增加静态初始化方法 。 此外， 有些机制， 如动态代理， 会在运行时自动生成字节码文件， 由于这些类不是由源文件中编译来的， 所以这些类的class文件中会有一个Synthetic属性。 Deprecated类型 Deprecated属性可以存在于filed_info中， method_info中和顶层的ClassFile中， 分别表示这个字段， 方法或类已经过时。 这个属性用来支持源文件中的@deprecated注解。 也就是说， 如果在源文件中为一个字段， 方法或类标注了@deprecated注解， 那么编译器就会在class文件中为这个字段， 方法或类生成一个Deprecated属性 。attribute_length永远为0 ， 因为这个属性只是一个标志信息， 用来表示字段， 方法， 类已经过时， 而不具有任何实质性的属性信息。 参考：http://blog.csdn.net/zhangjg_blog/article/details/21486985 http://blog.csdn.net/luanlouis/article/details/39892027]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之线程的理解]]></title>
      <url>%2F2017%2F05%2F26%2F%E4%BD%A0%E6%87%82java%E5%90%97-10%2F</url>
      <content type="text"><![CDATA[并发的理解​ 对于一个CPU来说，无论我创建多少个线程，所谓的“并发执行”、“同时”其实都不是真正意义上的“同时”。操作系统将进程线程进行管理，轮流（没有固定的顺序）分配每个进程很短的一段时间（不一定是均分），然后在每个线程内部，程序代码自己处理该进程内部线程的时间分配，多个线程之间相互的切换去执行，这个切换时间也是非常短的。因此多任务、多进程、多线程都是操作系统给人的一种宏观感受，从微观角度看，程序的运行是异步执行的。虽然操作系统是多线程的，但CPU每一时刻只能做一件事。另外上下文开销是多线程面临的主要问题，可以通过无锁并发编程、CAS算法、使用最少线程和使用协程的方式解决。 线程和进程的区别1，每个进程都有独立的代码和数据空间，进程间的切换会有较大的开销；2，线程可以看成是轻量级的进程，同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器，线程切换的开销小；3，多进程：在操作系统中能同时运行多个任务(程序)；4，多线程：在同一应用程序中有多个顺序流同时执行； 参考可见：线程与进程的区别 线程的实现实现线程主要有3种方式：使用内核线程实现、 使用用户线程实现和使用用户线程加轻量级进程混合实现。 使用内核线程实现 ​ 内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。 每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（MultiThreads Kernel）。由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限性：首先，由于是基于内核线程实现的，所以各种线程操作，如创建、 析构及同步，都需要进行系统调用。 而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（KernelMode）中来回切换。 其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。 使用用户线程实现 ​ 从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（User Thread,UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制。而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。 用户线程的建立、 同步、 销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。 ​ 使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。 线程的创建、 切换和调度都是需要考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、 “多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。 因而使用用户线程实现的程序一般都比较复杂，除了以前在不支持多线程的操作系统中（如DOS）的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java、Ruby等语言都曾经使用过用户线程，最终又都放弃使用它。 使用用户线程加轻量级进程混合实现 ​ 用户线程还是完全建立在用户空间中，因此用户线程的创建、 切换、 析构等操作依然廉价，并且可以支持大规模的用户线程并发。 而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。 线程的状态 线程的创建12345678910111213public class Calculator implements Runnable &#123; private int number; public Calculator(int number)&#123; this.number = number; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for (int i=1; i&lt;=10; i++)&#123; System.out.printf("%s: %d * %d = %d\n",Thread.currentThread().getName(),number,i,i*number); &#125; &#125;&#125; 123456789public class Main &#123; public static void main(String[] args) &#123; for (int i=1; i&lt;=2; i++)&#123; Calculator calculator=new Calculator(i); Thread thread=new Thread(calculator); thread.start(); &#125; &#125;&#125; ​ 每个Java程序最少有一个执行线程。当你运行程序的时候，JVM运行负责调用main（）方法的执行线程。当调用Thread对象的start()方法时，我们创建了另一个执行线程。在这些start（）方法调用之后，我们的程序就有了多个执行线程。当全部的线程执行结束时（更具体点，所有非守护线程结束时），Java程序就结束了。如果初始线程（执行main（）方法的主线程）运行结束，其他的线程还是会继续执行直到执行完成。但是如果某个线程调用System.exit()指示终结程序，那么全部的线程都会结束执行。创建一个Thread类的对象不会创建新的执行线程。同样，调用实现Runnable接口的run()方法也不会创建一个新的执行线程。只有调用start()方法才能创建一个新的执行线程。 获取和设置线程信息Thread类的对象中保存了一些属性信息能够帮助我们辨别每一个线程 ID：每个线程的独特标示； Name：线程的名称； Priority：线程对象的优先级。优先级别在1-10之间，1是最低级，10是最高级。 Status：线程状态。(new,runnable,blocked,waiting,time waiting 或terminated) 12345678910111213public class Calculator implements Runnable &#123; private int number; public Calculator(int number)&#123; this.number = number; &#125; @Override public void run() &#123; // TODO Auto-generated method stub for (int i=1; i&lt;=10; i++)&#123; System.out.printf(" %s: %d * %d = %d\n",Thread.currentThread().getName(),number,i,i*number); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.io.FileWriter;import java.io.PrintWriter;import java.lang.Thread.State;public class Main &#123; public static void main(String[] args) &#123; Thread[] threads = new Thread[10]; Thread.State[] status = new Thread.State[10]; for (int i = 0; i &lt; 10; i++) &#123; threads[i] = new Thread(new Calculator(i)); if((i%2) == 0) threads[i].setPriority(Thread.MAX_PRIORITY); else threads[i].setPriority(Thread.MIN_PRIORITY); threads[i].setName("Thread "+i); &#125; try&#123; FileWriter file = new FileWriter(".\\log.txt"); PrintWriter pw = new PrintWriter(file); for(int i =0;i&lt;10;i++)&#123; pw.println("main: status of thread "+i+": "+threads[i].getState()); status[i] = threads[i].getState(); &#125; for(int i =0;i&lt;10;i++)&#123; threads[i].start(); &#125; boolean finish = false; while(!finish)&#123; for (int i = 0; i &lt; 10; i++) &#123; if(threads[i].getState()!=status[i])&#123; writeThreadInfo(pw,threads[i],status[i]); &#125; &#125; finish = true; &#125; pw.close(); &#125;catch(Exception e)&#123; &#125; &#125; private static void writeThreadInfo(PrintWriter pw, Thread thread, State state) &#123; pw.printf("Main : %s\n",thread.getName()); pw.printf("Main : Priority: %d\n",thread.getPriority()); pw.printf("Main : Old State: %s\n",state); pw.printf("Main : New State: %s\n",thread.getState()); pw.printf("Main : ************************************\n"); &#125; &#125; 线程的中断​ 一个多个线程在执行的Java程序，只有当其全部的线程执行结束时（更具体的说，是所有非守护线程结束或者某个线程调用System.exit()方法的时候），它才会结束运行。有时，你需要为了终止程序而结束一个线程，或者当程序的用户想要取消某个Thread对象正在做的任务。​ Java提供中断机制来通知线程表明我们想要结束它。中断机制的特性是线程需要检查是否被中断，而且还可以决定是否相应结束的请求。所以，线程可以忽略中断请求并且继续运行。​ Thread类还有其他的可以检查线程是否被中断的方法。例如，静态方法interrupted()能检查正在运行的线程是否被中断。isInterrupted()和interrupted()方法有着很重要的区别。第一个测试线程是否被中断，第二个是用来中断线程。 12345678910111213141516171819202122232425public class Clocker extends Thread &#123; @Override public void run() &#123; // TODO Auto-generated method stub long number =1L; while(true)&#123; System.out.println("clock is "+number+" s"); if(isInterrupted())&#123; System.out.printf("The Clocker has been Interrupted"); return; &#125; number ++; &#125; &#125; public static void main(String[] args) &#123; Thread task = new Clocker(); task.start(); try &#123; sleep(5000); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; task.interrupt(); &#125;&#125; 操作线程的中断机制 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.io.File;public class FileSearch implements Runnable &#123; private String initPath; private String fileName; public FileSearch(String initPath, String fileName) &#123; this.initPath = initPath; this.fileName = fileName; &#125; @Override public void run() &#123; // TODO Auto-generated method stub File file = new File(initPath); if (file.isDirectory()) &#123; try &#123; directoryProcess(file); &#125; catch (InterruptedException e) &#123; System.out.printf("%s: The search has been interrupted",Thread.currentThread().getName()); &#125; &#125; &#125; private void directoryProcess(File file) throws InterruptedException &#123; File list[] = file.listFiles(); if (list != null) &#123; for (int i = 0; i &lt; list.length; i++) &#123; if (list[i].isDirectory()) &#123; directoryProcess(list[i]); &#125; else &#123; fileProcess(list[i]); &#125; &#125; &#125; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; &#125; private void fileProcess(File file) throws InterruptedException &#123; if (file.getName().equals(fileName)) &#123; System.out.printf("%s : %s\n",Thread.currentThread().getName() ,file.getAbsolutePath()); &#125; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; &#125; &#125; 123456789101112131415import java.util.concurrent.TimeUnit;public class Main &#123; public static void main(String[] args) &#123; FileSearch searcher=new FileSearch("D:\\","log.txt"); Thread thread=new Thread(searcher); thread.start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread.interrupt(); &#125; &#125; 1234567891011121314151617import java.util.Date;import java.util.concurrent.TimeUnit;public class FileClock implements Runnable&#123; @Override public void run() &#123; // TODO Auto-generated method stub for (int i = 0; i &lt; 10; i++) &#123; System.out.printf("%s\n", new Date()); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; System.out.printf("The FileClock has been interrupted"); &#125; &#125; &#125;&#125; 12345678910111213141516import java.util.concurrent.TimeUnit;public class Main &#123; public static void main(String[] args) &#123; FileClock clock = new FileClock(); Thread thread = new Thread(clock); thread.start(); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; thread.interrupt(); &#125; &#125; 线程的暂停，恢复和停止线程的暂停、恢复和停止操作为suspend()、resume()和stop()。这些API是过期的，也就是不建议使用的。 线程的睡眠​ Thread类的sleep方法或者使用TimeUnit列举元素的sleep方法。Thread离开CPU并在一段时间内停止运行。在这段时间内，它是不消耗CPU时间的，但它并不释放对象锁。例如有两个线程同时执行(没有synchronized)一个线程优先级为MAX_PRIORITY，另一个为MIN_PRIORITY，如果没有Sleep()方法，只有高优先级的线程执行完毕后，低优先级的线程才能够执行；但是高优先级的线程sleep(500)后，低优先级就有机会执行了。如果有synchronized，低优先级的线程也不会执行。 ​ Thread类使用yield()方法，它向JVM表示线程对象可以让CPU执行其他任务。JVM不保证遵守请求，通常它只是用来调试。只是不能由用户指定暂停多长时间，并且yield()方法只能让同优先级的线程有执行的机会。 等待线程的终结我们可能会遇到程序在执行前需要初始化资源。在执行剩下的代码之前，我们需要等待线程完成初始化任务。为了达到此目的，我们使用Thread类的join()方法。 123456789101112131415import java.util.Date;import java.util.concurrent.TimeUnit;public class DataSourcesLoader implements Runnable &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.printf("Beginning data sources loading : %s\n", new Date()); try &#123; TimeUnit.SECONDS.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.printf("Data sources loading has finished :%s\n",new Date()); &#125;&#125; 123456789101112131415161718192021import java.util.Date;import java.util.concurrent.TimeUnit;public class NetworkConnectionsLoader implements Runnable &#123; private Thread thread; public NetworkConnectionsLoader(Thread thread)&#123; this.thread = thread; &#125; @Override public void run() &#123; // TODO Auto-generated method stub System.out.printf("Beginning Net sources loading : %s\n", new Date()); try &#123; thread.start(); thread.join(); TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.printf("Net sources loading has finished :%s\n",new Date()); &#125;&#125; 1234567891011121314151617import java.util.Date;public class Main &#123; public static void main(String[] args) &#123; DataSourcesLoader dsLoader = new DataSourcesLoader(); Thread thread1 = new Thread(dsLoader,"DataSourcesLoader"); NetworkConnectionsLoader ncLoader = new NetworkConnectionsLoader(thread1); Thread thread2 = new Thread(ncLoader,"NetworkConnectionsLoader"); thread2.start(); try &#123; thread2.join(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.printf("Main: Configuration has been loaded: %s\n",new Date()); &#125; &#125; ThreadLocal的使用ThreadLocal，即线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值。可以通过set(T)方法来设置一个值，在当前线程下再通过get()方法获取到原先设置的值。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java虚拟机之理解Java虚拟机的含义]]></title>
      <url>%2F2017%2F05%2F26%2F%E4%BD%A0%E6%87%82java%E5%90%97-9%2F</url>
      <content type="text"><![CDATA[什么是Java虚拟机从外部行为和功能理解Java虚拟机：​ 虚拟机是一种抽象化的计算机，通过在实际的计算机上仿真模拟各种计算机功能来实现的。Java虚拟机有自己完善的硬体架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。JVM屏蔽了与具体操作系统平台相关的信息，使得Java程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。，简而言之，屏蔽底层操作系统平台的不同并且减少基于原生语言开发的复杂性，使java这门语言能够跨各种平台（只要虚拟机厂商在特定平台上实现了虚拟机），并且简单易用。 从操作系统进程理解Java虚拟机：​ 虚拟机是运行在操作系统之中的，那么什么东西才能在操作系统中运行呢？当然是进程，因为进程是操作系统中的执行单位。可以这样理解，当它在运行的时候，它就是一个操作系统中的进程实例，当它没有在运行时（作为可执行文件存放于文件系统中），可以把它叫做程序。 下面对比C语言和Java语言的HelloWorld程序来说明问题 C语言 1234567891011#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main(void) &#123; printf("hello world\n"); return 0; &#125; //编译gcc HelloWorld.c -o HelloWorld//运行./HelloWorld gcc编译器编译后的文件直接就是可被操作系统识别的二进制可执行文件，当我们在命令行中敲下 ./HelloWorld这条命令的时候， 直接创建一个进程， 并且将可执行文件加载到进程的地址空间中， 执行文件中的指令。 Java语言 12345678910public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println("HelloWorld"); &#125; &#125; //编译生成了HelloWorld.classjavac HelloWorld.java //运行java HelloWorld 我们在运行Java版的HelloWorld程序的时候， 敲入的命令并不是 ./HelloWorld.class 。 因为class文件并不是可以直接被操作系统识别的二进制可执行文件 。 我们敲入的是java这个命令。 这个命令说明， 我们首先启动的是一个叫做java的程序， 这个java程序在运行起来之后就是一个JVM进程实例。 上面的命令执行流程是这样的： java命令首先启动虚拟机进程，虚拟机进程成功启动后，读取参数“HelloWorld”，把他作为初始类加载到内存，对这个类进行初始化和动态链接，然后从这个类的main方法开始执行。也就是说我们的.class文件不是直接被系统加载后直接在cpu上执行的，而是被一个叫做虚拟机的进程托管的。首先必须虚拟机进程启动就绪，然后由虚拟机中的类加载器加载必要的class文件，包括jdk中的基础类（如String和Object等），然后由虚拟机进程解释class字节码指令，把这些字节码指令翻译成本机cpu能够识别的指令，才能在cpu上运行。 从这个层面上来看，在执行一个所谓的java程序的时候，真真正正在执行的是一个叫做Java虚拟机的进程，而不是我们写的一个个的class文件。这个叫做虚拟机的进程处理一些底层的操作，比如内存的分配和释放等等。我们编写的class文件只是虚拟机进程执行时需要的“原料”。这些“原料”在运行时被加载到虚拟机中，被虚拟机解释执行，以控制虚拟机实现我们java代码中所定义的一些相对高层的操作，比如创建一个文件等，可以将class文件中的信息看做对虚拟机的控制信息，也就是一种虚拟指令。 JVM体系结构 ​ 我们编译之后的class文件是作为Java虚拟机的原料被输入到Java虚拟机的内部的，那么具体由谁来做这一部分工作呢？其实在Java虚拟机内部，有一个叫做类加载器的子系统，这个子系统用来在运行时根据需要加载类。注意上面一句话中的“根据需要”四个字。在Java虚拟机执行过程中，只有他需要一个类的时候，才会调用类加载器来加载这个类，并不会在开始运行时加载所有的类。就像一个人，只有饿的时候才去吃饭，而不是一次把一年的饭都吃到肚子里。一般来说，虚拟机加载类的时机，在第一次使用一个新的类的时候。 ​ 由虚拟机加载的类，被加载到Java虚拟机内存中之后，虚拟机会读取并执行它里面存在的字节码指令。虚拟机中执行字节码指令的部分叫做执行引擎。就像一个人，不是把饭吃下去就完事了，还要进行消化，执行引擎就相当于人的肠胃系统。在执行的过程中还会把各个class文件动态的连接起来。 ​ 一个Java虚拟机实例在运行过程中有三个子系统来保障它的正常运行，分别是类加载器子系统， 执行引擎子系统和垃圾收集子系统。 虚拟机的运行，必须加载class文件，并且执行class文件中的字节码指令。它做这么多事情，必须需要自己的空间。就像人吃下去的东西首先要放在胃中。虚拟机也需要空间来存放个中数据。首先，加载的字节码，需要一个单独的内存空间来存放；一个线程的执行，也需要内存空间来维护方法的调用关系，存放方法中的数据和中间计算结果；在执行的过程中，无法避免的要创建对象，创建的对象需要一个专门的内存空间来存放。虚拟机的运行时内存区大概可以分成下图所示的几个部分。 总结：1 虚拟机并不神秘，在操作系统的角度看来，它只是一个普通进程。2 这个叫做虚拟机的进程比较特殊，它能够加载我们编写的class文件。如果把JVM比作一个人，那么class文件就是我们吃的食物。3 加载class文件的是一个叫做类加载器的子系统。就好比我们的嘴巴，把食物吃到肚子里。4 虚拟机中的执行引擎用来执行class文件中的字节码指令。就好比我们的肠胃，对吃进去的食物进行消化。5 虚拟机在执行过程中，要分配内存创建对象。当这些对象过时无用了，必须要自动清理这些无用的对象。清理对象回收内存的任务由垃圾收集器负责。就好比人吃进去的食物，在消化之后，必须把废物排出体外，腾出空间可以在下次饿的时候吃饭并消化食物。 参考：http://blog.csdn.net/zhangjg_blog/article/details/20380971]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之equals，== 和 hashcode理解]]></title>
      <url>%2F2017%2F05%2F24%2F%E4%BD%A0%E6%87%82java%E5%90%97-8%2F</url>
      <content type="text"><![CDATA[equals ，== 和 hashcode的理解 Object类是类继承结构的基础，所以是每一个类的父类。所有的对象，包括数组，都实现了在Object类中定义的方法。 java.lang.Object类中有两个非常重要的方法： public boolean equals(Object obj) public int hashCode() ==与equals的关系？== 是比较引用是否相等。上面我们说过equals是Object类的重要方法之一，是用来判断其他的对象是否和该对象相等。 equals()方法在object类中定义如下： 123public boolean equals(Object obj) &#123; return (this == obj); &#125; 很明显在object类中== 与equals是等价的，但是在很多类中，例如String 、Math、Integer、Double等这些封装类在使用equals()方法时，已经覆盖了object类的equals()方法。 hashcode和equals的关系？​ hashCode()方法给对象返回一个hash code值。为什么要使用hash code值，主要是出于提高效率。我们要比较两个个元素是否相等，会调用equals方法。假如一个集合里有1000个元素了，它就要调用1000次equals方法。这显然会大大降低效率。于是，Java采用了哈希表的原理。哈希（Hash）实际上是个人名，由于他提出一哈希算法的概念，所以就以他的名字命名了。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上，这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就一下子能定位到它应该放置的物理位置上。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址。所以这里存在一个冲突解决的问题。这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。 Java对象的eqauls方法和hashCode方法是这样规定的： 1234If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result.相等（相同）的对象必须具有相等的哈希码（或者散列码）。It is not required that if two objects are unequal according to the equals(java.lang.Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hash tables.两个对象的hashCode相同，它们并不一定相同。 相等（相同）的对象必须具有相等的哈希码（或者散列码） ​ 假如两个Java对象A和B，A和B相等（eqauls结果为true），但A和B的哈希码不同，则A和B存入HashMap时的哈希码计算得到的HashMap内部数组位置索引可能不同，那么A和B很有可能允许同时存入HashMap，显然相等/相同的元素是不允许同时存入HashMap，HashMap不允许存放重复元素。 两个对象的hashCode相同，它们并不一定相同 ​ 不同对象的hashCode可能相同；假如两个Java对象A和B，A和B不相等（eqauls结果为false），但A和B的哈希码相等，将A和B都存入HashMap时会发生哈希冲突，也就是A和B存放在HashMap内部数组的位置索引相同这时HashMap会在该位置建立一个链接表，将A和B串起来放在该位置，显然，该情况不违反HashMap的使用原则，是允许的。当然，哈希冲突越少越好，尽量采用好的哈希算法以避免哈希冲突。 为什么要同时重写equals和hashcode？首先我们知道在hashset中不允许出现重复对象，元素的位置也是不确定的。在hashset中又是怎样判定元素是否重复的呢？ 规则是： 1.判断两个对象的hashCode是否相等。如果不相等，认为两个对象也不相等，完毕；如果相等，转入2 2.判断两个对象用equals运算是否相等。如果不相等，认为两个对象也不相等； 如果相等，认为两个对象相等 示例代码一：由于没有重写equals和hashcode导致set存入重复元素。 1234567891011121314151617181920212223242526272829import java.util.HashSet;public class Demo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Book book1 = new Book("JAVA详解","Tom"); Book book2 = new Book("JAVA详解","Tom"); System.out.printf("book1.equals(book2) : %s; book1(%d) book2(%d)\n", book1.equals(book2), book1.hashCode(), book2.hashCode()); HashSet&lt;Book&gt; set = new HashSet&lt;Book&gt;(); set.add(book1); set.add(book2); System.out.printf("set:%s\n", set); &#125;&#125;class Book&#123; private String name; private String author; public Book(String name , String author )&#123; this.name = name ; this.author = author ; &#125; @Override public String toString() &#123; // TODO Auto-generated method stub return "(&lt;&lt;"+name+"&gt;&gt;," + author + ")"; &#125;&#125;//outputbook1.equals(book2) : false; book1(705927765) book2(366712642)set:[(&lt;&lt;JAVA详解&gt;&gt;,Tom), (&lt;&lt;JAVA详解&gt;&gt;,Tom)] 示例代码二：只是重写equals，不符合约束第一条，导致set存入重复元素 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.HashSet;public class Demo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Book book1 = new Book("JAVA详解","Tom"); Book book2 = new Book("JAVA详解","Tom"); System.out.printf("book1.equals(book2) : %s; book1(%d) book2(%d)\n", book1.equals(book2), book1.hashCode(), book2.hashCode()); HashSet&lt;Book&gt; set = new HashSet&lt;Book&gt;(); set.add(book1); set.add(book2); System.out.printf("set:%s\n", set); &#125;&#125;class Book&#123; private String name; private String author; public Book(String name , String author )&#123; this.name = name ; this.author = author ; &#125; @Override public String toString() &#123; // TODO Auto-generated method stub return "(&lt;&lt;"+name+"&gt;&gt;," + author + ")"; &#125; @Override public boolean equals(Object obj) &#123; // TODO Auto-generated method stub if ( obj == null )&#123; return false; &#125; if ( this == obj )&#123; return true; &#125; if( this.getClass() != obj.getClass())&#123; return false; &#125; Book book =(Book)obj; return this.name.equals(book.name) &amp;&amp; this.author.equals(book.author); &#125; &#125;//outputbook1.equals(book2) : true; book1(705927765) book2(366712642)set:[(&lt;&lt;JAVA详解&gt;&gt;,Tom), (&lt;&lt;JAVA详解&gt;&gt;,Tom)] 示例代码三：同时重写equals和hashcode，set没有存入重复元素 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.HashSet;public class Demo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Book book1 = new Book("JAVA详解","Tom"); Book book2 = new Book("JAVA详解","Tom"); System.out.printf("book1.equals(book2) : %s; book1(%d) book2(%d)\n", book1.equals(book2), book1.hashCode(), book2.hashCode()); HashSet&lt;Book&gt; set = new HashSet&lt;Book&gt;(); set.add(book1); set.add(book2); System.out.printf("set:%s\n", set); &#125;&#125;class Book&#123; private String name; private String author; public Book(String name , String author )&#123; this.name = name ; this.author = author ; &#125; @Override public String toString() &#123; // TODO Auto-generated method stub return "(&lt;&lt;"+name+"&gt;&gt;," + author + ")"; &#125; @Override public int hashCode() &#123; // TODO Auto-generated method stub int name = this.name.toUpperCase().hashCode(); int author =this.author.toUpperCase().hashCode(); return name *author; &#125; @Override public boolean equals(Object obj) &#123; // TODO Auto-generated method stub if ( obj == null )&#123; return false; &#125; if ( this == obj )&#123; return true; &#125; if( this.getClass() != obj.getClass())&#123; return false; &#125; Book book =(Book)obj; return this.name.equals(book.name) &amp;&amp; this.author.equals(book.author); &#125; &#125;book1.equals(book2) : true; book1(-269343346) book2(-269343346)set:[(&lt;&lt;JAVA详解&gt;&gt;,Tom)] 另外我们只重写hashcode时候，结果如下，hashset说明先后进行了hashcode和euqals比较，在两者均不相等才断定不是同一个元素。 12book1.equals(book2) : false; book1(-269343346) book2(-269343346)set:[(&lt;&lt;JAVA详解&gt;&gt;,Tom), (&lt;&lt;JAVA详解&gt;&gt;,Tom)]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之String分析]]></title>
      <url>%2F2017%2F05%2F19%2F%E4%BD%A0%E6%87%82java%E5%90%97-7%2F</url>
      <content type="text"><![CDATA[String的源码分析 从一段代码说起12345678910public class StringDemo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub String a = "abc"; String b = "a" + "b" + "c"; System.out.println(a == b); //true String c = new String("abc"); System.out.println(a == c); //false &#125;&#125; 下面我们从源码看String的具体实现（本文是jdk1.8）。 String的初始化String类的属性包含一个不可变的char数组用来存放字符串，一个int型的变量hash用来存放计算后的哈希值 12345678910public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = -6849794470754667710L; String构造函数 public String() public String(String original) public String(char value[]) public String(char value[], int offset, int count) public String(int[] codePoints, int offset, int count) public String(byte bytes[], int offset, int length, Charset charset) public String(byte bytes[], int offset, int length, String charsetName) public String(byte bytes[], int offset, int length, Charset charset) public String(byte bytes[], String charsetName) public String(byte bytes[], Charset charset) public String(byte bytes[], int offset, int length) public String(byte bytes[]) public String(StringBuffer buffer) public String(StringBuilder builder) String(char[] value, boolean share)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127 public String() &#123; this.value = "".value; &#125; public String(String original) &#123; this.value = original.value; this.hash = original.hash; &#125; public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length); &#125; public String(char value[], int offset, int count) &#123; if (offset &lt; 0) &#123; throw new StringIndexOutOfBoundsException(offset); &#125; if (count &lt;= 0) &#123; if (count &lt; 0) &#123; throw new StringIndexOutOfBoundsException(count); &#125; if (offset &lt;= value.length) &#123; this.value = "".value; return; &#125; &#125; // Note: offset or count might be near -1&gt;&gt;&gt;1. if (offset &gt; value.length - count) &#123; throw new StringIndexOutOfBoundsException(offset + count); &#125; this.value = Arrays.copyOfRange(value, offset, offset+count); &#125; public String(int[] codePoints, int offset, int count) &#123; if (offset &lt; 0) &#123; throw new StringIndexOutOfBoundsException(offset); &#125; if (count &lt;= 0) &#123; if (count &lt; 0) &#123; throw new StringIndexOutOfBoundsException(count); &#125; if (offset &lt;= codePoints.length) &#123; this.value = "".value; return; &#125; &#125; // Note: offset or count might be near -1&gt;&gt;&gt;1. if (offset &gt; codePoints.length - count) &#123; throw new StringIndexOutOfBoundsException(offset + count); &#125; final int end = offset + count; // Pass 1: Compute precise size of char[] int n = count; for (int i = offset; i &lt; end; i++) &#123; int c = codePoints[i]; //BmpCodePoint代码点是65535是2的16次方，刚好是两个字节（即一个字）的大小。在超出两个字节后只能算是有效的代码点，并非是 BmpCodePoint代码点。从代码中也可看出，BmpCodePoint代码点的整数是可以直接强转成char类型的。在java中char类型刚好占2个字节 在2个字节以内的整数都可以直接强转换成char类型！ if (Character.isBmpCodePoint(c)) continue; else if (Character.isValidCodePoint(c)) n++; else throw new IllegalArgumentException(Integer.toString(c)); &#125; // Pass 2: Allocate and fill in char[] final char[] v = new char[n]; for (int i = offset, j = 0; i &lt; end; i++, j++) &#123; int c = codePoints[i]; if (Character.isBmpCodePoint(c)) v[j] = (char)c; else Character.toSurrogates(c, v, j++); &#125; this.value = v; &#125;public String(byte bytes[], int offset, int length, Charset charset) &#123; if (charset == null) throw new NullPointerException("charset"); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charset, bytes, offset, length);&#125;public String(byte bytes[], int offset, int length, String charsetName) throws UnsupportedEncodingException &#123; if (charsetName == null) throw new NullPointerException("charsetName"); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charsetName, bytes, offset, length); &#125;public String(byte bytes[], int offset, int length, Charset charset) &#123; if (charset == null) throw new NullPointerException("charset"); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charset, bytes, offset, length); &#125;public String(byte bytes[], String charsetName) throws UnsupportedEncodingException &#123; this(bytes, 0, bytes.length, charsetName); &#125;public String(byte bytes[], Charset charset) &#123; this(bytes, 0, bytes.length, charset); &#125;public String(byte bytes[], int offset, int length) &#123; checkBounds(bytes, offset, length); this.value = StringCoding.decode(bytes, offset, length); &#125;public String(byte bytes[]) &#123; this(bytes, 0, bytes.length); &#125;public String(StringBuffer buffer) &#123; synchronized(buffer) &#123; this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); &#125; &#125;public String(StringBuilder builder) &#123; this.value = Arrays.copyOf(builder.getValue(), builder.length()); &#125;String(char[] value, boolean share) &#123; // assert share : "unshared not supported"; this.value = value; &#125;private static void checkBounds(byte[] bytes, int offset, int length) &#123; if (length &lt; 0) throw new StringIndexOutOfBoundsException(length); if (offset &lt; 0) throw new StringIndexOutOfBoundsException(offset); if (offset &gt; bytes.length - length) throw new StringIndexOutOfBoundsException(offset + length); &#125; String常用方法equals方法1234567891011121314151617181920212223242526public boolean equals(Object anObject) &#123; //如果引用的是同一个对象，返回真 if (this == anObject) &#123; return true; &#125; //如果不是String类型的数据，返回假 if (anObject instanceof String) &#123; String anotherString = (String) anObject; int n = value.length; //如果char数组长度不相等，返回假 if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; //从后往前单个字符判断，如果有不相等，返回假 while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; //每个字符都相等，返回真 return true; &#125; &#125; return false; &#125; equals的判断规则： 内存地址相同，则为真。 如果对象类型不是String类型，则为假。否则继续判断。 如果对象长度不相等，则为假。否则继续判断。 从后往前，判断String类中char数组value的单个字符是否相等，有不相等则为假。如果一直相等直到第一个数，则返回真。 compareTo 方法1234567891011121314151617181920212223public int compareTo(String anotherString) &#123; //自身对象字符串长度len1 int len1 = value.length; //被比较对象字符串长度len2 int len2 = anotherString.value.length; //取两个字符串长度的最小值lim int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; //从value的第一个字符开始到最小长度lim处为止，如果字符不相等，返回自身（对象不相等处字符-被比较对象不相等字符） while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; //如果前面都相等，则返回（自身长度-被比较对象长度） return len1 - len2;&#125; 先从0开始判断字符大小，如果两个对象能比较字符的地方比较完了还相等，就直接返回自身长度减被比较对象长度，如果两个字符串长度相等，则返回的是0，巧妙地判断了三种情况。 startsWith方法boolean startsWith(String prefix) boolean startsWith(String prefix, int toffset) boolean endsWith(String suffix) 1234567891011121314151617181920212223public boolean startsWith(String prefix) &#123; return startsWith(prefix, 0); &#125;public boolean startsWith(String prefix, int toffset) &#123; char ta[] = value; int to = toffset; char pa[] = prefix.value; int po = 0; int pc = prefix.value.length; // Note: toffset might be near -1&gt;&gt;&gt;1. if ((toffset &lt; 0) || (toffset &gt; value.length - pc)) &#123; return false; &#125; while (--pc &gt;= 0) &#123; if (ta[to++] != pa[po++]) &#123; return false; &#125; &#125; return true; &#125;public boolean endsWith(String suffix) &#123; return startsWith(suffix, value.length - suffix.value.length); &#125; hashCode方法123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; substring方法String substring(int beginIndex) String substring(int beginIndex, int endIndex) 12345678910111213141516171819202122232425public String substring(int beginIndex) &#123; if (beginIndex &lt; 0) &#123; throw new StringIndexOutOfBoundsException(beginIndex); &#125; int subLen = value.length - beginIndex; if (subLen &lt; 0) &#123; throw new StringIndexOutOfBoundsException(subLen); &#125; return (beginIndex == 0) ? this : new String(value, beginIndex, subLen); &#125;public String substring(int beginIndex, int endIndex) &#123; if (beginIndex &lt; 0) &#123; throw new StringIndexOutOfBoundsException(beginIndex); &#125; if (endIndex &gt; value.length) &#123; throw new StringIndexOutOfBoundsException(endIndex); &#125; int subLen = endIndex - beginIndex; if (subLen &lt; 0) &#123; throw new StringIndexOutOfBoundsException(subLen); &#125; return ((beginIndex == 0) &amp;&amp; (endIndex == value.length)) ? this : new String(value, beginIndex, subLen); &#125; concat方法12345678910111213public String concat(String str) &#123; int otherLen = str.length(); if (otherLen == 0) &#123; return this; &#125; int len = value.length; char buf[] = Arrays.copyOf(value, len + otherLen); str.getChars(buf, len); return new String(buf, true); &#125;void getChars(char dst[], int dstBegin) &#123; System.arraycopy(value, 0, dst, dstBegin, value.length); &#125; replace方法1234567891011121314151617181920212223242526272829public String replace(char oldChar, char newChar) &#123; //新旧值先对比 if (oldChar != newChar) &#123; int len = value.length; int i = -1; char[] val = value; /* avoid getfield opcode */ //找到旧值最开始出现的位置 while (++i &lt; len) &#123; if (val[i] == oldChar) &#123; break; &#125; &#125; //从那个位置开始，直到末尾，用新值代替出现的旧值 if (i &lt; len) &#123; char buf[] = new char[len]; for (int j = 0; j &lt; i; j++) &#123; buf[j] = val[j]; &#125; while (i &lt; len) &#123; char c = val[i]; buf[i] = (c == oldChar) ? newChar : c; i++; &#125; return new String(buf, true); &#125; &#125; return this;&#125; contains方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public boolean contains(CharSequence s) &#123; return indexOf(s.toString()) &gt; -1; &#125;public int indexOf(String str) &#123; return indexOf(str, 0); &#125;public int indexOf(String str, int fromIndex) &#123; return indexOf(value, 0, value.length, str.value, 0, str.value.length, fromIndex); &#125;static int indexOf(char[] source, int sourceOffset, int sourceCount, char[] target, int targetOffset, int targetCount, int fromIndex) &#123; if (fromIndex &gt;= sourceCount) &#123; return (targetCount == 0 ? sourceCount : -1); &#125; if (fromIndex &lt; 0) &#123; fromIndex = 0; &#125; if (targetCount == 0) &#123; return fromIndex; &#125; char first = target[targetOffset]; int max = sourceOffset + (sourceCount - targetCount); for (int i = sourceOffset + fromIndex; i &lt;= max; i++) &#123; /* Look for first character. */ if (source[i] != first) &#123; while (++i &lt;= max &amp;&amp; source[i] != first); &#125; /* Found first character, now look at the rest of v2 */ if (i &lt;= max) &#123; int j = i + 1; int end = j + targetCount - 1; for (int k = targetOffset + 1; j &lt; end &amp;&amp; source[j] == target[k]; j++, k++); if (j == end) &#123; /* Found whole string. */ return i - sourceOffset; &#125; &#125; &#125; return -1; &#125; split方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public String[] split(String regex) &#123; return split(regex, 0); &#125; public String[] split(String regex, int limit) &#123; /* fastpath if the regex is a (1)one-char String and this character is not one of the RegEx's meta characters ".$|()[&#123;^?*+\\", or (2)two-char String and the first char is the backslash and the second is not the ascii digit or ascii letter. */ char ch = 0; if (((regex.value.length == 1 &amp;&amp; ".$|()[&#123;^?*+\\".indexOf(ch = regex.charAt(0)) == -1) || (regex.length() == 2 &amp;&amp; regex.charAt(0) == '\\' &amp;&amp; (((ch = regex.charAt(1))-'0')|('9'-ch)) &lt; 0 &amp;&amp; ((ch-'a')|('z'-ch)) &lt; 0 &amp;&amp; ((ch-'A')|('Z'-ch)) &lt; 0)) &amp;&amp; (ch &lt; Character.MIN_HIGH_SURROGATE || ch &gt; Character.MAX_LOW_SURROGATE)) &#123; int off = 0; int next = 0; boolean limited = limit &gt; 0; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); while ((next = indexOf(ch, off)) != -1) &#123; if (!limited || list.size() &lt; limit - 1) &#123; list.add(substring(off, next)); off = next + 1; &#125; else &#123; // last one //assert (list.size() == limit - 1); list.add(substring(off, value.length)); off = value.length; break; &#125; &#125; // If no match was found, return this if (off == 0) return new String[]&#123;this&#125;; // Add remaining segment if (!limited || list.size() &lt; limit) list.add(substring(off, value.length)); // Construct result int resultSize = list.size(); if (limit == 0) &#123; while (resultSize &gt; 0 &amp;&amp; list.get(resultSize - 1).length() == 0) &#123; resultSize--; &#125; &#125; String[] result = new String[resultSize]; return list.subList(0, resultSize).toArray(result); &#125; return Pattern.compile(regex).split(this, limit); &#125; trim方法12345678910111213141516public String trim() &#123; int len = value.length; int st = 0; char[] val = value; /* avoid getfield opcode */ //找到字符串前段没有空格的位置 while ((st &lt; len) &amp;&amp; (val[st] &lt;= ' ')) &#123; st++; &#125; //找到字符串末尾没有空格的位置 while ((st &lt; len) &amp;&amp; (val[len - 1] &lt;= ' ')) &#123; len--; &#125; //如果前后都没有出现空格，返回字符串本身 return ((st &gt; 0) || (len &lt; value.length)) ? substring(st, len) : this;&#125; toCharArray方法123456public char[] toCharArray() &#123; // Cannot use Arrays.copyOf because of class initialization order issues char result[] = new char[value.length]; System.arraycopy(value, 0, result, 0, value.length); return result; &#125; valueOf方法12345678910111213141516171819202122232425public static String valueOf(Object obj) &#123; return (obj == null) ? "null" : obj.toString(); &#125;public static String valueOf(char data[]) &#123; return new String(data); &#125;public static String valueOf(char data[], int offset, int count) &#123; return new String(data, offset, count); &#125;public static String valueOf(char c) &#123; char data[] = &#123;c&#125;; return new String(data, true); &#125;public static String valueOf(int i) &#123; return Integer.toString(i); &#125;public static String valueOf(long l) &#123; return Long.toString(l); &#125;public static String valueOf(float f) &#123; return Float.toString(f); &#125;public static String valueOf(double d) &#123; return Double.toString(d); &#125; intern方法1public native String intern(); intern方法是Native调用，它的作用是在方法区中的常量池里通过equals方法寻找等值的对象，如果没有找到则在常量池中开辟一片空间存放字符串并返回该对应String的引用，否则直接返回常量池中已存在String对象的引用。 123456789101112public class StringDemo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub String a = "abc"; String b = "a" + "b" + "c"; System.out.println(a == b); String c = new String("abc"); System.out.println(a == c); String d = new String("abc").intern(); System.out.println(a == d); //true &#125;&#125; 其他方法123456789101112131415public int length() &#123; return value.length;&#125;public String toString() &#123; return this;&#125;public boolean isEmpty() &#123; return value.length == 0;&#125;public char charAt(int index) &#123; if ((index &lt; 0) || (index &gt;= value.length)) &#123; throw new StringIndexOutOfBoundsException(index); &#125; return value[index];&#125; String对象的三种比较方式： ==内存比较：直接对比两个引用所指向的内存值，精确简洁直接明了。 equals字符串值比较：比较两个引用所指对象字面值是否相等。 hashCode字符串数值化比较：将字符串数值化。两个引用的hashCode相同，不保证内存一定相同，不保证字面值一定相同。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之克隆机制]]></title>
      <url>%2F2017%2F05%2F19%2F%E4%BD%A0%E6%87%82java%E5%90%97-6%2F</url>
      <content type="text"><![CDATA[java的克隆机制 Java中对象的创建使用new操作符创建一个对象 ​ new操作符的本意是分配内存。程序执行到new操作符时， 首先去看new操作符后面的类型，因为知道了类型，才能知道要分配多大的内存空间。分配完内存之后，再调用构造函数，填充对象的各个域，这一步叫做对象的初始化，构造方法返回后，一个对象创建完毕，可以把他的引用（地址）发布到外部，在外部就可以使用这个引用操纵这个对象。 使用clone方法复制一个对象 ​ clone在第一步是和new相似的， 都是分配内存，调用clone方法时，分配的内存和源对象（即调用clone方法的对象）相同，然后再使用原对象中对应的各个域，填充新对象的域， 填充完成之后，clone方法返回，一个新的相同的对象被创建，同样可以把这个新对象的引用发布到外部。 使用序列化的方式克隆一个对象 ​ 把母对象写入到一个字节流中，再从字节流中将其读出来，这样就可以创建一个新的对象了，并且该新对象与母对象之间并不存在引用共享的问题，真正实现对象的深拷贝。 Clone()方法的延伸思考复制对象 or 复制引用 123456789101112131415161718192021222324252627282930313233343536package Demo;public class Test &#123; public static void main(String[] args) throws Exception &#123; Person p = new Person(23, "luckylau"); Person p1 = p; Person p2 = (Person) p.clone(); System.out.println(p); System.out.println(p1); System.out.println(p2); System.out.println(p.getName() == p2.getName()); &#125;&#125;class Person implements Cloneable&#123; private int age; private String name; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125; public int getAge() &#123; return age; &#125; public String getName() &#123; return name; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; // TODO Auto-generated method stub return (Person)super.clone(); &#125; &#125;//outputDemo.Person@2a139a55Demo.Person@2a139a55Demo.Person@15db9742 有结果可看出，p1只是复制引用，p2才是复制对象。 string 在clone()中的特殊性我们来分析一下上面的String类型的拷贝。 首先string源码分析如下地址： https://luckylau.github.io/2017/05/19/%E4%BD%A0%E6%87%82java%E5%90%97-7/ String不是基本数据类型，但是在深复制的时候并没有进行单独的复制，也就是说违反了深复制，仅仅复制了引用，而String没有实现cloneable接口，也就是说只能复制引用。 在修改克隆之后的对象之后，会不会将原来的值也改变了？ 当然是NO。因为String是在内存中不可以被改变的对象，所以克隆相当于1个String内存空间有两个引用，当修改其中的一个值的时候，会新分配一块内存用来保存新的值，这个引用指向新的内存空间，原来的String因为还存在指向他的引用，所以不会被回收，这样，虽然是复制的引用，但是修改值的时候，并没有改变被复制对象的值。 String对象真的不可变吗？ 用反射， 可以反射出String对象中的value属性， 进而改变通过获得的value引用改变数组的结构。 1234567891011121314151617import java.lang.reflect.Field;public class StringDemo &#123; public static void main(String[] args) throws Exception&#123; //创建字符串"Hello World"， 并赋给引用s String s = "Hello World"; System.out.println("s = " + s); //Hello World //获取String类中的value字段 Field valueFieldOfString = String.class.getDeclaredField("value"); //改变value属性的访问权限 valueFieldOfString.setAccessible(true); //获取s对象上的value属性的值 char[] value = (char[]) valueFieldOfString.get(s); //改变value所引用的数组中的第5个字符 value[5] = '_'; System.out.println("s = " + s); //Hello_World &#125;&#125; 如何实现深拷贝如果在拷贝一个对象时，要想让这个拷贝的对象和源对象完全彼此独立，那么在引用链上的每一级对象都要实现Cloneable接口来被显式的拷贝。下面的实例就是完全深拷贝。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class TestClone &#123; public static void main(String[] args) throws Exception &#123; // TODO Auto-generated method stub Body a = new Body(new Head(new Face())); Body b =(Body) a.clone(); System.out.println(a.head == b.head); System.out.println(a.head.face == b.head.face); &#125;&#125;class Body implements Cloneable&#123; public Head head; public Body() &#123;&#125; public Body(Head head) &#123;this.head = head;&#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Body newBody = (Body) super.clone(); newBody.head = (Head) head.clone(); return newBody; &#125; &#125; class Head implements Cloneable&#123; public Face face; public Head() &#123; &#125; public Head(Face face)&#123; this.face = face; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; // TODO Auto-generated method stub Head newHead = (Head) super.clone(); newHead.face = (Face)this.face.clone(); return newHead; &#125; &#125;class Face implements Cloneable&#123; @Override protected Object clone() throws CloneNotSupportedException &#123; // TODO Auto-generated method stub return super.clone(); &#125; &#125; 假如face不实现Cloneable，虽然对Body对象内所引用的其他对象（目前只有Head）都进行了拷贝，也就是说两个独立的Body对象内的head引用已经指向了独立的两个Head对象。但是，这对于两个Head对象来说，他们指向了同一个Face对象，是一种不彻底的拷贝。 但是实现完全深拷贝在引用关系非常复杂的情况下， 是很困难的，比如某一级上引用了一个第三方的对象， 而这个对象没有实现clone方法， 那么在它之后的所有引用的对象都是被共享的。 假如下面实例被Head引用的Face类是第三方库中的类，并且没有实现Cloneable接口，那么在Face之后的所有对象都会被拷贝前后的两个Body对象共同引用。假设Face对象内部组合了Mouth对象，并且Mouth对象内部组合了Tooth对象， 内存结构如下图： 序列化方法的延伸思考1234567891011121314151617181920212223242526272829import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;public class CloneUtils &#123; @SuppressWarnings("unchecked") public static &lt;T extends Serializable&gt; T clone(T obj)&#123; T cloneObj = null; try &#123; //写入字节流 ByteArrayOutputStream out = new ByteArrayOutputStream(); ObjectOutputStream obs = new ObjectOutputStream(out); obs.writeObject(obj); obs.close(); //分配内存，写入原始对象，生成新对象 ByteArrayInputStream ios = new ByteArrayInputStream(out.toByteArray()); ObjectInputStream ois = new ObjectInputStream(ios); //返回生成的新对象 cloneObj = (T) ois.readObject(); ois.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return cloneObj; &#125; &#125; 参考：http://blog.csdn.net/zhangjg_blog/article/details/18369201 http://www.cnblogs.com/carbs/archive/2012/06/26/2564373.html http://blog.csdn.net/chenssy/article/details/12952063]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之集合框架]]></title>
      <url>%2F2017%2F05%2F16%2F%E4%BD%A0%E6%87%82java%E5%90%97-5%2F</url>
      <content type="text"><![CDATA[java的集合框架详细解读(基于jdk1.8） java集合框架java集合框架需要掌握的是六大接口（Collection、Set、List、Map、Iterator和Comparable）和两个工具类Arrays和Collections。 Collection接口继承了Iterable接口，是最基本集合接口,由于Iterable接口依赖Iterator接口，所以所有实现Collection接口的容器类都有iterator方法，用于返回一个实现了Iterator接口的对象。Iterator对象称作迭代器，Iterator接口方法能以迭代方式逐个访问集合中各个元素，并可以从Collection中除去适当的元素。另外由Collection接口派生出3个主要接口，分别是List ,Set,Queue。 Map也是接口，但没有继承Collection接口。该接口描述了从不重复的键到值的映射。Map接口用于维护键/值对（key/value pairs）。 Comparable可以用于比较的实现，实现了Comparable接口的类可以通过实现comparaTo方法从而确定该类对象的排序方式。 另外就是两个重要的工具类，分别是用来操作数组、集合的Arrays和Collections，例如在ArrayList和Vector中大量调用了Arrays.Copyof()方法，而Collections中有很多静态方法可以返回各集合类的synchronized版本，即线程安全的版本，当然了，如果要用线程安全的结合类，首选Concurrent并发包下的对应的集合类。 Collection接口概览Collection接口12345678910111213141516171819202122232425262728293031323334353637383940414243 public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); Iterator&lt;E&gt; iterator(); Object[] toArray(); boolean add(E e); boolean remove(Object o); boolean containsAll(Collection&lt;?&gt; c); boolean addAll(Collection&lt;? extends E&gt; c); boolean removeAll(Collection&lt;?&gt; c); //@since 1.8 default boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; Objects.requireNonNull(filter); boolean removed = false; final Iterator&lt;E&gt; each = iterator(); while (each.hasNext()) &#123; if (filter.test(each.next())) &#123; each.remove(); removed = true; &#125; &#125; return removed; &#125; boolean retainAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); //@since 1.8 @Override default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0); &#125; //@since 1.8 default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false); &#125; //@since 1.8 default Stream&lt;E&gt; parallelStream() &#123; return StreamSupport.stream(spliterator(), true); &#125;&#125; 在Java8的新特性中有一个新特性为接口默认方法，该新特性允许我们在接口中添加一个非抽象的方法实现，而这样做的方法只需要使用关键字default修饰该默认实现方法即可。该特性又叫扩展方法。 List接口概览​ List是一个继承Collection接口的接口，当然间接的继承了Iterable接口，实现类包括：ArrayList、LinkedList、Vector等。List是有序的Collection可以对每个元素的插入位置进行精准控制，可以根据索引访问元素，允许重复元素，有自己的迭代器 ListIterator。Java8有28个方法，我们只列举常见方法，也是后面会主要分析其实现的方法。 12345678910boolean add(E e);void add(int index, E e);E set(int index, E e);get(int index);boolean remove(Object o);Iterator iterator();int indexOf(E e);int lastIndexOf(E e);void clear();List subList(int fromIndex, int toIndex); ArrayList​ ArrayList是一个可改变大小的数组，当更多的元素加入到ArrayList中时，其大小将会动态的增长。内部的元素可以直接通过get与set方法进行访问，因为ArrayList本质上就是一个数组。ArrayList不是线程安全的，只能在单线程环境下，多线程环境下可以考虑用 collections.synchronizedList(List l)函数返回一个线程安全的ArrayList类，也可以使用concurrent并发包下的CopyOnWriteArrayList类。ArrayList实现了Serializable接口，因此它支持序列化，能够通过序列化传输，实现了RandomAccess接口，支持快速随机访问，实际上就是通过下标序号进行快速访问，实现了Cloneable接口，能被克隆。 初始化代码123456789public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; private static final int DEFAULT_CAPACITY = 10; private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; transient Object[] elementData; // non-private to simplify nested class access private int size; 涉及知识点： transient 123456789101112131415161718192021222324252627282930313233343536373839404142434445package test1;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;class UserInfo implements Serializable &#123; private static final long serialVersionUID = 996890129747019948L; private String name; private transient String psw; public UserInfo(String name, String psw) &#123; this.name = name; this.psw = psw; &#125; public String toString() &#123; return "name=" + name + ", psw=" + psw; &#125; &#125; public class TestTransient &#123; public static void main(String[] args) &#123; UserInfo userInfo = new UserInfo("张三", "123456"); System.out.println(userInfo); try &#123; // 序列化，被设置为transient的属性没有被序列化 ObjectOutputStream o = new ObjectOutputStream(new FileOutputStream( "UserInfo.out")); o.writeObject(userInfo); o.close(); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; try &#123; // 重新读取内容 ObjectInputStream in = new ObjectInputStream(new FileInputStream( "UserInfo.out")); UserInfo readUserInfo = (UserInfo) in.readObject(); //读取后psw的内容为null System.out.println(readUserInfo.toString()); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125; &#125; &#125; 三种构建方法第一个构造方法使用提供的initialCapacity来初始化elementData数组的大小。 第二个构造方法调用第一个构造方法并传入参数10，即默认elementData数组的大小为10。 第三个构造方法则将提供的集合转成数组返回给elementData（返回若不是Object[]将调用Arrays.copyOf方法将其转为Object[]）。 123456789101112131415161718192021222324252627// ArrayList带容量大小的构造函数。 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125;// ArrayList无参构造函数。默认容量是10。 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; // 创建一个包含collection的ArrayList public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; add方法代码boolean add(E e) void add(int index, E element) boolean addAll(Collection&lt;? extends E&gt; c) boolean addAll(int index,Collection&lt;? extends E&gt; c) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 // 将e添加到ArrayList中 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; // 将e添加到ArrayList的指定位置 public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size+1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; // 将集合c追加到ArrayList中 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; // 从index位置开始，将集合c添加到ArrayList public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; // 确定ArrarList的容量。 // 若ArrayList的容量不足以容纳当前的全部元素，设置 新的容量=“(原始容量x3)/2 + 1”private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 若当前容量不足以容纳当前的元素个数，设置 新的容量=“(原始容量x3)/2 + 1” int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; remove方法代码E remove(int index) boolean remove(Object o) void removeRange(int fromIndex, int toIndex) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 // 删除ArrayList指定位置的元素 public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; &#125;private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; // 删除元素 public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; // 便利ArrayList，找到“元素o”，则删除，并返回true。 for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; // 删除fromIndex到toIndex之间的全部元素。 protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; // 快速删除第index个元素 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; // 从"index+1"开始，用后面的元素替换前面的元素。 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); // 将最后一个元素设为null elementData[--size] = null; // Let gc do its work &#125; get方法代码E get(int index) E set(int index, E element) 123456789101112// 获取index位置的元素值 public E get(int index) &#123; rangeCheck(index); return elementData(index); &#125;// 设置index位置的值为elementpublic E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; clear方法代码1234567// 清空ArrayList，将全部的元素设为null public void clear() &#123; modCount++; for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; clone方法代码调用父类的clone方法返回一个对象的副本，将返回对象的elementData数组的内容赋值为原对象elementData数组的内容，将副本的modCount设置为0。 123456789101112// 克隆函数 public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; &#125; indexOf(Object o)方法代码123456789101112public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; lastIndexOf(Object o)方法代码123456789101112public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; writeObject和readObject方法代码void writeObject(java.io.ObjectOutputStream s) void readObject(java.io.ObjectInputStream s) 123456789101112131415161718192021222324252627282930 // java.io.Serializable的写入函数 // 将ArrayList的“容量，所有的元素值”都写入到输出流中 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // 写入“数组的容量” s.writeInt(elementData.length); // 写入“数组的每一个元素” for (int i=0; i&lt;size; i++) s.writeObject(elementData[i]); if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; // java.io.Serializable的读取函数：根据写入方式读出 // 先将ArrayList的“容量”读出，然后将“所有的元素值”读出 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in size, and any hidden stuff s.defaultReadObject(); // 从输入流中读取ArrayList的“容量” int arrayLength = s.readInt(); Object[] a = elementData = new Object[arrayLength]; // 从输入流中将“所有的元素值”读出 for (int i=0; i&lt;size; i++) a[i] = s.readObject(); &#125; &#125; 其他方法boolean contains(Object o) boolean isEmpty() int size() Object[] toArray() T[] toArray(T[] a) void trimToSize() 12345678910111213141516171819202122232425262728293031323334353637// ArrayList是否包含Object(o) public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0; &#125; // 返回ArrayList是否为空 public boolean isEmpty() &#123; return size == 0; &#125; // 返回ArrayList的实际大小 public int size() &#123; return size; &#125; // 返回ArrayList的Object数组 public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; // 返回ArrayList元素组成的数组 public &lt;T&gt; T[] toArray(T[] a) &#123; // 若数组a的大小 &lt; ArrayList的元素个数； // 则新建一个T[]数组，数组大小是“ArrayList的元素个数”，并将“ArrayList”全部拷贝到新数组中 if (a.length &lt; size) return (T[]) Arrays.copyOf(elementData, size, a.getClass()); // 若数组a的大小 &gt;= ArrayList的元素个数； // 则将ArrayList的全部元素都拷贝到数组a中。 System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; 几点说明： ArrayList的实现中大量地调用了Arrays.copyof()和System.arraycopy()方法 Arrays.copyof()方法 1234567891011public static &lt;T&gt; T[] copyOf(T[] original, int newLength) &#123; return (T[]) copyOf(original, newLength, original.getClass()); &#125; public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; &#125; //该方法实际上是在其内部又创建了一个长度为newlength的数组，调用System.arraycopy()方法，将原来数组中的元素复制到了新的数组中。 System.arraycopy()方法 ​ 该方法被标记了native，调用了系统的C/C++代码，在JDK中是看不到的，但在openJDK中可以看到其源码。该函数实际上最终调用了C语言的memmove()函数，因此它可以保证同一个数组内元素的正确复制和移动，比一般的复制方法的实现效率要高很多，很适合用来批量处理数组。Java强烈推荐在复制大量数组元素时用该方法，以取得更高的效率。 LinkedList​ LinkedList 是一个双向循环链表,在添加和删除元素时具有比ArrayList更好的性能。但在get与set方面弱于ArrayList。当然这些对比都是指数据量很大或者操作很频繁的情况下的对比，如果数据和运算量很小，那么对比将失去意义。 LinkedList还实现了Queue接口，该接口比List提供了更多的方法，包括offer()，peek()，poll()等。所以除了可以当作链表来操作外，它还可以当作栈，队列和双端队列来使用。LinkedList同样是非线程安全的，只在单线程下适合使用。LinkedList实现了Serializable接口，因此它支持序列化，能够通过序列化传输，实现了Cloneable接口，能被克隆。 初始化代码123456789101112131415public class LinkedList&lt;E&gt;extends AbstractSequentialList&lt;E&gt;implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; transient int size = 0; /** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; 两种构建方法无参构造方法和Collection的构造方法，先调用无参构造方法建立一个空链表，然后将Collection中的数据加入到链表的尾部后面。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 默认构造函数 public LinkedList() &#123; &#125;// 包含“集合”的构造函数:创建一个包含“集合”的LinkedList public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; // 将“集合(c)”添加到LinkedList中。 // 实际上，是从双向链表的末尾开始，将“集合(c)”添加到双向链表中。 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c); &#125; // 从双向链表的index开始，将“集合(c)”添加到双向链表中。 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125;private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; add方法代码boolean add(E e) void add(int index, E element) void addFirst(E e) void addLast(E e) void push(E e) boolean offer(E e) boolean offerLast(E e) boolean offerFirst(E e) E set( int index, E element) boolean addAll(Collection&lt;? extends E&gt; c) boolean addAll(int index, Collection&lt;? extends E&gt; c) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//将元素(E)添加到LinkedList中 public boolean add(E e) &#123; linkLast(e); return true; &#125; void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; // 在index前添加节点，且节点的值为element public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); &#125; private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; &#125;// 将元素添加到LinkedList的起始位置 public void addFirst(E e) &#123; linkFirst(e); &#125;// 将元素添加到LinkedList的结束位置 public void addLast(E e) &#123; linkLast(e); &#125;// 将e插入到双向链表开头 public void push(E e) &#123; addFirst(e); &#125; public void addFirst(E e) &#123; linkFirst(e); &#125; private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++; &#125;// 将e添加双向链表末尾 public boolean offer(E e) &#123; return add(e); &#125;// 将e添加双向链表开头 public boolean offerFirst(E e) &#123; addFirst(e); return true; &#125; // 将e添加双向链表末尾 public boolean offerLast(E e) &#123; addLast(e); return true; &#125; // 设置index位置对应的节点的值为element public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal; &#125; get方法代码E get(int index) E getFirst() E getLast() E peekFirst() E peekLast() E peek() E element() 12345678910111213141516171819202122232425262728293031323334353637383940414243// 返回LinkedList指定位置的元素 public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125;// 获取LinkedList的第一个元素 public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item; &#125;// 获取LinkedList的最后一个元素 public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item; &#125; // 返回第一个节点 // 若LinkedList的大小为0,则返回null public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; // 返回最后一个节点 // 若LinkedList的大小为0,则返回null public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item; &#125; // 返回第一个节点 public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125; // 返回第一个节点 // 若LinkedList的大小为0,则抛出异常 public E element() &#123; return getFirst(); &#125; remove方法代码 E poll() E removeFirst() E removeLast() E pollFirst() E pollLast() E pop() boolean removeLastOccurrence(Object o) boolean removeLastOccurrence(Object o) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122// 删除LinkedList的最后一个元素 public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125;private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125;// 删除index位置的节点 public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index)); &#125;E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125; // 删除并返回第一个节点 // 若LinkedList的大小为0,则返回null public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; &#125; // 删除并返回第一个节点 public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f); &#125; // 删除并返回最后一个节点 public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l); &#125;// 删除并返回第一个节点 public E pop() &#123; return removeFirst(); &#125;// 删除LinkedList的第一个元素 public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125; // 从LinkedList开始向后查找，删除第一个值为元素(o)的节点 // 从链表开始查找，如存在节点的值为元素(o)的节点，则删除该节点 public boolean removeFirstOccurrence(Object o) &#123; return remove(o); &#125; // 从LinkedList末尾向前查找，删除第一个值为元素(o)的节点 // 从链表开始查找，如存在节点的值为元素(o)的节点，则删除该节点 public boolean removeLastOccurrence(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; clear方法代码1234567891011121314151617// 清空双向链表 public void clear() &#123; // Clearing all of the links between nodes is "unnecessary", but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++; &#125; lastIndexOf(Object o)方法代码12345678910111213141516171819// 从后向前查找，返回“值为对象(o)的节点对应的索引” // 不存在就返回-1 public int lastIndexOf(Object o) &#123; int index = size; if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (x.item == null) return index; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1; &#125; listIterator(int index)方法代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// 返回“index到末尾的全部节点”对应的ListIterator对象(List迭代器) public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index); &#125;// List迭代器 private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; public boolean hasPrevious() &#123; return nextIndex &gt; 0; &#125; public E previous() &#123; checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; &#125; public int nextIndex() &#123; return nextIndex; &#125; public int previousIndex() &#123; return nextIndex - 1; &#125; public void remove() &#123; checkForComodification(); if (lastReturned == null) throw new IllegalStateException(); Node&lt;E&gt; lastNext = lastReturned.next; unlink(lastReturned); if (next == lastReturned) next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; &#125; public void set(E e) &#123; if (lastReturned == null) throw new IllegalStateException(); checkForComodification(); lastReturned.item = e; &#125; public void add(E e) &#123; checkForComodification(); lastReturned = null; if (next == null) linkLast(e); else linkBefore(e, next); nextIndex++; expectedModCount++; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &#123; action.accept(next.item); lastReturned = next; next = next.next; nextIndex++; &#125; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; 其他方法boolean contains(Object o) int size() 123456789101112131415161718192021222324252627// 判断LinkedList是否包含元素(o) public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; // 返回LinkedList的大小 public int size() &#123; return size; &#125; // 从前向后查找，返回“值为对象(o)的节点对应的索引” // 不存在就返回-1 public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; Vector​ Vector 和ArrayList类似,但属于强同步类。如果你的程序本身是线程安全的(thread-safe，没有在多个线程之间共享同一个集合/对象)，那么使用ArrayList是更好的选择。 Vector和ArrayList在更多元素添加进来时会请求更大的空间。Vector每次请求其大小的双倍空间，而ArrayList每次对size增长50%。 Vector的API源码显的比较臃肿、基本现在已经不再推荐使用Vector了、可以使用经过处理后的ArrayList来代替多线程环境中的Vector。 初始化代码Vector是JDK1.0引入了，它的很多实现方法都加入了同步语句，因此是线程安全的，可以用于多线程环境。 Vector实现了Serializable接口，因此它支持序列化，同时实现了Cloneable接口，能被克隆，实现了RandomAccess接口，支持快速随机访问。 Vector继承了AbstractList，实现了List，它是一个队列，因此实现了相应的添加、删除、修改、遍历等功能。 源码基于jdk1.8 123456789public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; protected Object[] elementData; protected int elementCount; // 容量增长系数 protected int capacityIncrement; private static final long serialVersionUID = -2767605614048989439L; 四种构建方法123456789101112131415161718192021public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement; &#125;public Vector(int initialCapacity) &#123; this(initialCapacity, 0); &#125;public Vector() &#123; this(10); &#125; public Vector(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, elementCount, Object[].class); &#125; add方法代码synchronized boolean add(E e) void add(int index, E element) synchronized boolean addAll(Collection&lt;? extends E&gt; c) synchronized boolean addAll(int index, Collection&lt;? extends E&gt; c) synchronized void addElement(E obj) synchronized E set(int index, E element) synchronized void insertElementAt(E obj, int index) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true; &#125;public void add(int index, E element) &#123; insertElementAt(element, index); &#125;public synchronized void insertElementAt(E obj, int index) &#123; modCount++; if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt; " + elementCount); &#125; ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++; &#125;public synchronized boolean addAll(Collection&lt;? extends E&gt; c) &#123; modCount++; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityHelper(elementCount + numNew); System.arraycopy(a, 0, elementData, elementCount, numNew); elementCount += numNew; return numNew != 0; &#125;public synchronized boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; modCount++; if (index &lt; 0 || index &gt; elementCount) throw new ArrayIndexOutOfBoundsException(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityHelper(elementCount + numNew); int numMoved = elementCount - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); elementCount += numNew; return numNew != 0; &#125;public synchronized void addElement(E obj) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = obj; &#125;private void ensureCapacityHelper(int minCapacity) &#123; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125;private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125;public synchronized E set(int index, E element) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125;public synchronized void setElementAt(E obj, int index) &#123; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt;= " + elementCount); &#125; elementData[index] = obj; &#125;public synchronized void insertElementAt(E obj, int index) &#123; modCount++; if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt; " + elementCount); &#125; ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++; &#125; get方法代码synchronized E get(int index) synchronized E elementAt(int index) 12345678910111213public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index); &#125;public synchronized E elementAt(int index) &#123; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt;= " + elementCount); &#125; return elementData(index); &#125; remove方法代码boolean remove(Object o) synchronized E remove(int index) synchronized boolean removeElement(Object obj) synchronized void removeElementAt(int index) synchronized void removeAllElements() boolean removeAll(Collection&lt;?&gt; c) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public boolean remove(Object o) &#123; return removeElement(o); &#125;public synchronized E remove(int index) &#123; modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return oldValue; &#125;public synchronized boolean removeElement(Object obj) &#123; modCount++; int i = indexOf(obj); if (i &gt;= 0) &#123; removeElementAt(i); return true; &#125; return false; &#125;public synchronized void removeElementAt(int index) &#123; modCount++; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + " &gt;= " + elementCount); &#125; else if (index &lt; 0) &#123; throw new ArrayIndexOutOfBoundsException(index); &#125; int j = elementCount - index - 1; if (j &gt; 0) &#123; System.arraycopy(elementData, index + 1, elementData, index, j); &#125; elementCount--; elementData[elementCount] = null; /* to let gc do its work */&#125;public synchronized void removeAllElements() &#123; modCount++; // Let gc do its work for (int i = 0; i &lt; elementCount; i++) elementData[i] = null; elementCount = 0; &#125;public synchronized boolean removeAll(Collection&lt;?&gt; c) &#123; return super.removeAll(c); &#125;//AbstractCollectionpublic boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); boolean modified = false; Iterator&lt;?&gt; it = iterator(); while (it.hasNext()) &#123; if (c.contains(it.next())) &#123; it.remove(); modified = true; &#125; &#125; return modified; &#125; clear方法代码void clear() 1234567891011121314public void clear() &#123; removeRange(0, size()); &#125;protected synchronized void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = elementCount - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // Let gc do its work int newElementCount = elementCount - (toIndex-fromIndex); while (elementCount != newElementCount) elementData[--elementCount] = null;&#125; indexOf方法int indexOf(Object o) synchronized int indexOf(Object o, int index) 123456789101112131415public int indexOf(Object o) &#123; return indexOf(o, 0); &#125;public synchronized int indexOf(Object o, int index) &#123; if (o == null) &#123; for (int i = index ; i &lt; elementCount ; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = index ; i &lt; elementCount ; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; lastIndexOf方法代码synchronized int lastIndexOf(Object o) synchronized int lastIndexOf(Object o, int index) 123456789101112131415161718public synchronized int lastIndexOf(Object o) &#123; return lastIndexOf(o, elementCount-1); &#125;public synchronized int lastIndexOf(Object o, int index) &#123; if (index &gt;= elementCount) throw new IndexOutOfBoundsException(index + " &gt;= "+ elementCount); if (o == null) &#123; for (int i = index; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = index; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; clone方法代码123456789101112public synchronized Object clone() &#123; try &#123; @SuppressWarnings("unchecked") Vector&lt;E&gt; v = (Vector&lt;E&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, elementCount); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; &#125; hashcode方法代码12345678910public synchronized int hashCode() &#123; return super.hashCode(); &#125;//AbstractList&lt;E&gt; public int hashCode() &#123; int hashCode = 1; for (E e : this) hashCode = 31*hashCode + (e==null ? 0 : e.hashCode()); return hashCode; &#125; equals方法代码1234567891011121314151617181920public synchronized boolean equals(Object o) &#123; return super.equals(o); &#125;//AbstractList&lt;E&gt; public boolean equals(Object o) &#123; if (o == this) return true; if (!(o instanceof List)) return false; ListIterator&lt;E&gt; e1 = listIterator(); ListIterator&lt;?&gt; e2 = ((List&lt;?&gt;) o).listIterator(); while (e1.hasNext() &amp;&amp; e2.hasNext()) &#123; E o1 = e1.next(); Object o2 = e2.next(); if (!(o1==null ? o2==null : o1.equals(o2))) return false; &#125; return !(e1.hasNext() || e2.hasNext()); &#125; listIterator(int index)方法代码synchronized ListIterator listIterator() synchronized ListIterator listIterator(int index) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public synchronized ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125;public synchronized ListIterator&lt;E&gt; listIterator(int index) &#123; if (index &lt; 0 || index &gt; elementCount) throw new IndexOutOfBoundsException("Index: "+index); return new ListItr(index); &#125;final class ListItr extends Itr implements ListIterator&lt;E&gt; &#123; ListItr(int index) &#123; super(); cursor = index; &#125; public boolean hasPrevious() &#123; return cursor != 0; &#125; public int nextIndex() &#123; return cursor; &#125; public int previousIndex() &#123; return cursor - 1; &#125; public E previous() &#123; synchronized (Vector.this) &#123; checkForComodification(); int i = cursor - 1; if (i &lt; 0) throw new NoSuchElementException(); cursor = i; return elementData(lastRet = i); &#125; &#125; public void set(E e) &#123; if (lastRet == -1) throw new IllegalStateException(); synchronized (Vector.this) &#123; checkForComodification(); Vector.this.set(lastRet, e); &#125; &#125; public void add(E e) &#123; int i = cursor; synchronized (Vector.this) &#123; checkForComodification(); Vector.this.add(i, e); expectedModCount = modCount; &#125; cursor = i + 1; lastRet = -1; &#125;&#125; synchronized Iterator iterator() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public synchronized Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125;private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; // Racy but within spec, since modifications are checked // within or after synchronization in next/previous return cursor != elementCount; &#125; public E next() &#123; synchronized (Vector.this) &#123; checkForComodification(); int i = cursor; if (i &gt;= elementCount) throw new NoSuchElementException(); cursor = i + 1; return elementData(lastRet = i); &#125; &#125; public void remove() &#123; if (lastRet == -1) throw new IllegalStateException(); synchronized (Vector.this) &#123; checkForComodification(); Vector.this.remove(lastRet); expectedModCount = modCount; &#125; cursor = lastRet; lastRet = -1; &#125; @Override public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); synchronized (Vector.this) &#123; final int size = elementCount; int i = cursor; if (i &gt;= size) &#123; return; &#125; @SuppressWarnings("unchecked") final E[] elementData = (E[]) Vector.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; action.accept(elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; 其他方法synchronized int capacity() boolean contains(Object object) synchronized boolean containsAll(Collection&lt;?&gt; collection) synchronized void copyInto(Object[] elements) Enumeration elements() synchronized void ensureCapacity(int minimumCapacity) synchronized E firstElement() synchronized boolean isEmpty() synchronized E lastElement() synchronized boolean retainAll(Collection&lt;?&gt; collection) synchronized void setSize(int length) synchronized int size() synchronized List subList(int start, int end) synchronized T[] toArray(T[] contents) synchronized Object[] toArray() synchronized String toString() synchronized void trimToSize() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139public synchronized int capacity() &#123; return elementData.length; &#125;public boolean contains(Object o) &#123; return indexOf(o, 0) &gt;= 0; &#125;public synchronized boolean containsAll(Collection&lt;?&gt; c) &#123; return super.containsAll(c); &#125;//AbstractCollection&lt;E&gt;public boolean containsAll(Collection&lt;?&gt; c) &#123; for (Object e : c) if (!contains(e)) return false; return true; &#125;public synchronized void copyInto(Object[] anArray) &#123; System.arraycopy(elementData, 0, anArray, 0, elementCount); &#125; public Enumeration&lt;E&gt; elements() &#123; return new Enumeration&lt;E&gt;() &#123; int count = 0; public boolean hasMoreElements() &#123; return count &lt; elementCount; &#125; public E nextElement() &#123; synchronized (Vector.this) &#123; if (count &lt; elementCount) &#123; return elementData(count++); &#125; &#125; throw new NoSuchElementException("Vector Enumeration"); &#125; &#125;; &#125;public synchronized void ensureCapacity(int minCapacity) &#123; if (minCapacity &gt; 0) &#123; modCount++; ensureCapacityHelper(minCapacity); &#125; &#125;public synchronized E firstElement() &#123; if (elementCount == 0) &#123; throw new NoSuchElementException(); &#125; return elementData(0); &#125; public synchronized boolean isEmpty() &#123; return elementCount == 0; &#125;public synchronized E lastElement() &#123; if (elementCount == 0) &#123; throw new NoSuchElementException(); &#125; return elementData(elementCount - 1); &#125;public synchronized boolean retainAll(Collection&lt;?&gt; c) &#123; return super.retainAll(c); &#125;//AbstractCollection&lt;E&gt;public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); boolean modified = false; Iterator&lt;E&gt; it = iterator(); while (it.hasNext()) &#123; if (!c.contains(it.next())) &#123; it.remove(); modified = true; &#125; &#125; return modified; &#125;public synchronized void setSize(int newSize) &#123; modCount++; if (newSize &gt; elementCount) &#123; ensureCapacityHelper(newSize); &#125; else &#123; for (int i = newSize ; i &lt; elementCount ; i++) &#123; elementData[i] = null; &#125; &#125; elementCount = newSize; &#125;public synchronized int size() &#123; return elementCount; &#125;public synchronized List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; return Collections.synchronizedList(super.subList(fromIndex, toIndex), this); &#125;//AbstractList&lt;E&gt;public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; return (this instanceof RandomAccess ? new RandomAccessSubList&lt;&gt;(this, fromIndex, toIndex) : new SubList&lt;&gt;(this, fromIndex, toIndex)); &#125;public synchronized Object[] toArray() &#123; return Arrays.copyOf(elementData, elementCount); &#125;@SuppressWarnings("unchecked")public synchronized &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; elementCount) return (T[]) Arrays.copyOf(elementData, elementCount, a.getClass()); System.arraycopy(elementData, 0, a, 0, elementCount); if (a.length &gt; elementCount) a[elementCount] = null; return a; &#125; public synchronized String toString() &#123; return super.toString(); &#125;//AbstractCollection&lt;E&gt; public String toString() &#123; Iterator&lt;E&gt; it = iterator(); if (! it.hasNext()) return "[]"; StringBuilder sb = new StringBuilder(); sb.append('['); for (;;) &#123; E e = it.next(); sb.append(e == this ? "(this Collection)" : e); if (! it.hasNext()) return sb.append(']').toString(); sb.append(',').append(' '); &#125; &#125;public synchronized void trimToSize() &#123; modCount++; int oldCapacity = elementData.length; if (elementCount &lt; oldCapacity) &#123; elementData = Arrays.copyOf(elementData, elementCount); &#125; &#125; Stack​ Stack（栈）是以栈的形式来存储数据，其特点是先进后出（FILO），同时Stack继承与Vector，所以如果把Stack内部的实现也是通过动态数组来实现的、而不是其他的数据结构。在List体系中有个LinkedList是以双向链表的数据结构来存储数据的，使用LinkedList完全可以达到Stack的效果、但是Stack不能作为双向链表来使用，并且LinkedList不是线程安全的、而Stack是线程安全的。 1234567891011121314151617181920212223242526272829303132333435363738publicclass Stack&lt;E&gt; extends Vector&lt;E&gt; public Stack() &#123; &#125; public E push(E item) &#123; addElement(item); return item; &#125; public synchronized E pop() &#123; E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj; &#125; public synchronized E peek() &#123; int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); &#125; public boolean empty() &#123; return size() == 0; &#125; public synchronized int search(Object o) &#123; int i = lastIndexOf(o); if (i &gt;= 0) &#123; return size() - i; &#125; return -1; &#125; /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = 1224463164541339165L;&#125; Queue接口概览是一个泛型接口，父接口：Collection，子接口：Deque。 12345678public interface Queue&lt;E&gt; extends Collection&lt;E&gt; &#123; boolean add(E e); boolean offer(E e); E remove(); E poll(); E element(); E peek();&#125; boolean add(E e)和 boolean offer(E e)调用相同。 E element()和E peek()获取但不移除失败时，element抛出异常，peek()返回null E remove()和E poll()获取并移除失败时，remove()抛出异常，poll()返回null Deque 双端队列，可以实现队列，也可以用作栈。 Set接口概览​ 存入Set的每个元素必须是惟一的，因为Set不保存重复元素。加入Set的元素重新必须定义equals()方法和hashcode()方法以确保对象的唯一性。Set不保证维护元素的次序，Set与Collection有完全一样的接口。 HashSet初始化代码​ HashSet继承了AbstractSet，实现了Set接口。其实AbstractSet已经实现Set接口了。AbstractSet继承自AbstractCollection，而AbstractCollection实现了Collection接口的部分方法，而Set接口和Collection接口完全一致，所以AbstractSet只是实现了AbstractCollection没有实现的Set接口的方法和重写了部分AbstractCollection已经实现的方法。对于HashSet中保存的对象，请注意正确重写其equals和hashCode方法，以保证放入的对象的唯一性。 12345678public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable&#123; static final long serialVersionUID = -5024744406713321676L; private transient HashMap&lt;E,Object&gt; map;//底层使用HashMap来保存HashSet中所有元素。 // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object();//定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final 五种构建方法12345678910111213141516171819public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125;public HashSet(Collection&lt;? extends E&gt; c) &#123; //实际底层使用默认的加载因子0.75和足以包含指定collection中所有元素的初始容量来创建一个HashMap。 map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125;public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125;//以指定的initialCapacity和loadFactor构造一个新的空链接哈希集合。//此构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet的支持。HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; add方法代码boolean add(E e) 12345678910111213 /** * 底层实际将将该元素作为key放入HashMap。 * 由于HashMap的put()方法添加key-value对时，当新放入HashMap的Entry中key * 与集合中原有Entry的key相同（hashCode()返回值相等，通过equals比较也返回true）， * 新添加的Entry的value会将覆盖原来Entry的value，但key不会有任何改变， * 因此如果向HashSet中添加一个已经存在的元素时，新添加的集合元素将不会被放入HashMap中， * 原来的元素也不会有任何改变，这也就满足了Set中元素不重复的特性。 * @param e 将添加到此set中的元素。 * @return 如果此set尚未包含指定元素，则返回true。 */ public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; get方法代码 通过Iterator遍历HashSet 123public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125; 123456789101112public class test1 &#123; public static void main(String[] args) &#123; Set&lt;String&gt; set = new HashSet&lt;String&gt;(12,1); set.add("a"); set.add("b"); set.add("c"); Iterator&lt;String&gt; iterator = set.iterator(); while(iterator.hasNext())&#123; System.out.println(iterator.next()); &#125; &#125;&#125; remove方法代码123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125; clear方法代码1234567/** * Removes all of the elements from this set. * The set will be empty after this call returns. */ public void clear() &#123; map.clear(); &#125; clone()方法代码12345678910@SuppressWarnings("unchecked") public Object clone() &#123; try &#123; HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); return newSet; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(e); &#125; &#125; writeObject和readObject方法代码void writeObject(java.io.ObjectOutputStream s) void readObject(java.io.ObjectInputStream s) 12345678910111213141516171819202122232425262728293031323334353637383940414243private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in any hidden serialization magic s.defaultReadObject(); // Read capacity and verify non-negative. int capacity = s.readInt(); if (capacity &lt; 0) &#123; throw new InvalidObjectException("Illegal capacity: " + capacity); &#125; // Read load factor and verify positive and non NaN. float loadFactor = s.readFloat(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) &#123; throw new InvalidObjectException("Illegal load factor: " + loadFactor); &#125; // Read size and verify non-negative. int size = s.readInt(); if (size &lt; 0) &#123; throw new InvalidObjectException("Illegal size: " + size); &#125; // Set the capacity according to the size and load factor ensuring that // the HashMap is at least 25% full but clamping to maximum capacity. capacity = (int) Math.min(size * Math.min(1 / loadFactor, 4.0f), HashMap.MAXIMUM_CAPACITY); // Create backing HashMap map = (((HashSet&lt;?&gt;)this) instanceof LinkedHashSet ? new LinkedHashMap&lt;E,Object&gt;(capacity, loadFactor) : new HashMap&lt;E,Object&gt;(capacity, loadFactor)); // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; @SuppressWarnings("unchecked") E e = (E) s.readObject(); map.put(e, PRESENT); &#125; &#125; 其他方法size()方法 123public int size() &#123; return map.size(); &#125; isEmpty()方法 123public boolean isEmpty() &#123; return map.isEmpty(); &#125; contains(Object)方法 123public boolean contains(Object o) &#123; return map.containsKey(o); &#125; LinkedHashSetLinkedHashSet会调用HashSet的父类构造函数，让其底层实现为LinkedHashMap，这样就很好的实现了LinkedHashSet所需要的功能。 初始化代码12345public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = -2851667679971038690L; 四种构建方法1234567891011121314151617 public LinkedHashSet(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor, true); &#125; public LinkedHashSet(int initialCapacity) &#123; super(initialCapacity, .75f, true); &#125; public LinkedHashSet() &#123; super(16, .75f, true); &#125; public LinkedHashSet(Collection&lt;? extends E&gt; c) &#123; super(Math.max(2*c.size(), 11), .75f, true); addAll(c); &#125;//super调用的是LinkedHashMapHashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; TreeSetTreeSet底层实现严重依赖于TreeMap。 未完待续Collections与Arrays工具类Collection是一个接口，它是Set、List等容器的父接口；Collections是一个工具类，提供了一系列的静态方法来辅助容器操作，这些方法包括对容器的搜索、排序、线程安全化等等。 Collections的常用方法sort排序12public static &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List&lt;T&gt; list)public static &lt;T&gt; void sort(List&lt;T&gt; list,Comparator&lt;? super T&gt; c) 由此可以看出我们有两种方式排序，list中的对象实现Comparable接口以及根据Collections.sort重载方法来实现。 list中的对象实现Comparable接口 1234567891011121314151617import java.util.ArrayList;import java.util.Collections;import java.util.List;//String 本身含有compareTo方法，所以可以直接调用sort方法public class SortTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub List&lt;String&gt; listS = new ArrayList&lt;String&gt;(); listS.add("abd"); listS.add("abc"); System.out.println(listS.toString()); Collections.sort(listS); System.out.println(listS.toString()); &#125;&#125;//[abd, abc]//[abc, abd] 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.ArrayList;import java.util.Collections;import java.util.List;public class SortTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Student st1 =new Student("mm",29); Student st2 =new Student("tt",24); List&lt;Student&gt; listS = new ArrayList&lt;Student&gt;(); listS.add(st1); listS.add(st2); System.out.println(listS.toString()); Collections.sort(listS); System.out.println(listS.toString()); &#125;&#125;class Student implements Comparable&lt;Student&gt;&#123; private String name; private Integer age; public Student(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; @Override public String toString()&#123; return "name: " + this.name +" age: " + this.age; &#125; @Override public int compareTo(Student o) &#123; // TODO Auto-generated method stub return this.age.compareTo(o.getAge()); &#125; &#125;//[name: mm age: 29, name: tt age: 24]//[name: tt age: 24, name: mm age: 29] 根据Collections.sort重载方法来实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.List;public class SortTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Student st1 =new Student("mm",29); Student st2 =new Student("tt",24); List&lt;Student&gt; listS = new ArrayList&lt;Student&gt;(); listS.add(st1); listS.add(st2); System.out.println(listS.toString()); Collections.sort(listS,new Mycompare()); System.out.println(listS.toString()); &#125;&#125;class Student&#123; private String name; private Integer age; public Student(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; @Override public String toString()&#123; return "name: " + this.name +" age: " + this.age; &#125; &#125;class Mycompare implements Comparator&lt;Student&gt; &#123; @Override public int compare(Student arg0, Student arg1) &#123; // TODO Auto-generated method stub return arg0.getAge().compareTo(arg1.getAge()); &#125; &#125;//[name: mm age: 29, name: tt age: 24]//[name: tt age: 24, name: mm age: 29] 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.List;public class SortTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Student st1 =new Student("mm",29); Student st2 =new Student("tt",24); List&lt;Student&gt; listS = new ArrayList&lt;Student&gt;(); listS.add(st1); listS.add(st2); System.out.println(listS.toString()); Collections.sort(listS,new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; // TODO Auto-generated method stub return o1.getAge().compareTo(o2.getAge()); &#125; &#125;); System.out.println(listS.toString()); &#125;&#125;class Student&#123; private String name; private Integer age; public Student(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125; @Override public String toString()&#123; return "name: " + this.name +" age: " + this.age; &#125; &#125;//[name: mm age: 29, name: tt age: 24]//[name: tt age: 24, name: mm age: 29] shuffle 随机排序12public static void shuffle(List&lt;?&gt; list)public static void shuffle(List&lt;?&gt; list, Random rnd) binarySearch查找指定集合中的元素，返回所查找元素的索引 123456public static &lt;T&gt; int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key)public static &lt;T&gt; int binarySearch(List&lt;? extends T&gt; list, T key, Comparator&lt;? super T&gt; c) max12public static &lt;T extends Object &amp; Comparable&lt;? super T&gt;&gt; T max(Collection&lt;? extends T&gt; coll)public static &lt;T&gt; T max(Collection&lt;? extends T&gt; coll,Comparator&lt;? super T&gt; comp) min12public static &lt;T extends Object &amp; Comparable&lt;? super T&gt;&gt; T min(Collection&lt;? extends T&gt; coll)public static &lt;T&gt; T min(Collection&lt;? extends T&gt; coll,Comparator&lt;? super T&gt; comp) indexOfSubList查找subList在list中首次出现位置的索引 1public static int indexOfSubList(List&lt;?&gt; source,List&lt;?&gt; target) lastIndexOfSubList同上 replaceAll替换批定元素为某元素,若要替换的值存在刚返回true,反之返回false 1public static &lt;T&gt; boolean replaceAll(List&lt;T&gt; list,T oldVal,T newVal) reverse反转集合中元素的顺序 1public static void reverse(List&lt;?&gt; list) rotate集合中的元素向后移m个位置，在后面被遮盖的元素循环到前面来 1public static void rotate(List&lt;?&gt; list, int distance) copy将集合n中的元素全部复制到m中,并且覆盖相应索引的元素 1public static &lt;T&gt; void copy(List&lt;? super T&gt; dest, List&lt;? extends T&gt; src) swap交换集合中指定元素索引的位置 1public static void swap(List&lt;?&gt; list,int i,int j) fill1public static &lt;T&gt; void fill(List&lt;? super T&gt; list, T obj) nCopies返回大小为n的List，List不可改变,其中的所有引用都指向o 1public static &lt;T&gt; List&lt;T&gt; nCopies(int n, T o) Arrays常用方法asList方法12345@SafeVarargs@SuppressWarnings("varargs")public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; binarySearch方法binarySearch方法支持在整个数组中查找 1int index = Arrays.binarySearch(new int[] &#123; 1, 2, 3, 4, 5, 6, 7 &#125;, 6); 在某个区间范围内查找 123456public static int binarySearch(int[] a, int fromIndex, int toIndex, int key) &#123; rangeCheck(a.length, fromIndex, toIndex); return binarySearch0(a, fromIndex, toIndex, key); &#125;int index = Arrays.binarySearch(new int[] &#123; 1, 2, 3, 4, 5, 6, 7 &#125;, 1, 6, 6); copyOf及copyOfRange方法sort方法toString方法deepToString方法12345678910111213141516171819202122232425262728293031import java.util.Arrays;public class test8 &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int[][] stuGrades = &#123; &#123; 80, 81, 82 &#125;, &#123; 84, 85, 86 &#125;, &#123; 87, 88, 89 &#125; &#125;; System.out.println(Arrays.toString(stuGrades)); System.out.println(Arrays.deepToString(stuGrades)); Stu stu1 = new Stu("aa",20); Stu stu2 = new Stu("bb",24); Stu[][] stus =&#123;&#123;stu1,stu2&#125;,&#123;stu1,stu1&#125;&#125;; System.out.println(Arrays.toString(stus)); System.out.println(Arrays.deepToString(stus)); &#125;&#125;class Stu&#123; private String name; private int age; public Stu(String name , int age) &#123; this.name = name; this.age = age; &#125; @Override public String toString()&#123; return "&#123;name: " + name + " age: " + age+"&#125;"; &#125; &#125;//output[[I@2a139a55, [I@15db9742, [I@6d06d69c][[80, 81, 82], [84, 85, 86], [87, 88, 89]][[Ltest1.Stu;@4e25154f, [Ltest1.Stu;@70dea4e][[&#123;name: aa age: 20&#125;, &#123;name: bb age: 24&#125;], [&#123;name: aa age: 20&#125;, &#123;name: aa age: 20&#125;]] equals方法deepEquals方法1234567891011121314import java.util.Arrays;public class test8 &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub String[][] name1 = &#123;&#123; "G","a","o" &#125;,&#123; "H","u","a","n"&#125;,&#123; "j","i","e"&#125;&#125;; String[][] name2 = &#123;&#123; "G","a","o" &#125;,&#123; "H","u","a","n"&#125;,&#123; "j","i","e"&#125;&#125;; System.out.println(Arrays.equals(name1, name2)); // false System.out.println(Arrays.deepEquals(name1, name2));// true String[] name3 = &#123;"G","a","o","H","u","a","n","j","i","e"&#125;; String[] name4 = &#123;"G","a","o","H","u","a","n","j","i","e"&#125;; System.out.println(Arrays.equals(name3, name4)); // true System.out.println(Arrays.deepEquals(name3, name4)); // true &#125;&#125; fill方法123456789public class test8 &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int [] stu = new int [8]; System.out.println(Arrays.toString(stu));//[0, 0, 0, 0, 0, 0, 0, 0] Arrays.fill(stu,1); System.out.println(Arrays.toString(stu));//[1, 1, 1, 1, 1, 1, 1, 1] &#125;&#125; Map接口概览​ Map一次存一对元素, Collection 一次存一个。Map 的键不能重复，保证唯一。Map 一次存入一对元素，是以键值对的形式存在。键与值存在映射关系，一定要保证键的唯一性。 Map接口常用方法1、添加： 12put(K key, V value) //可以相同的key值，但是添加的value值会覆盖前面的，返回值是前一个，如果没有就返回null。 putAll(Map&lt;? extends K,? extends V&gt; m) // 从指定映射中将所有映射关系复制到此映射中（可选操作）。 2、删除 12remove(Object key) //删除关联对象，指定key对象clear() //清空集合对象 3、获取 1get(key) //可以用于判断键是否存在的情况。当指定的键不存在的时候，返回的是null。 3、判断： 123boolean isEmpty()//长度为0返回true否则falseboolean containsKey(Object key)//判断集合中是否包含指定的keyboolean containsValue(Object value)//判断集合中是否包含指定的value 4、长度： 1int size() 5、遍历Map的方式： 1234567//1、将map集合中所有的键取出存入set集合。Set&lt;K&gt; keySet() //返回所有的key对象的Set集合，再通过get方法获取键对应的值。//2、values()，获取所有的值。Collection&lt;V&gt; values() //不能获取到key对象//3、Map.Entry对象(推荐使用)重点Set&lt;Map.Entry&lt;k,v&gt;&gt; entrySet()//将map 集合中的键值映射关系打包成一个对象。Map.Entry//对象通过Map.Entry 对象的getKey，getValue获取其键和值。 HashMap​ Java8的HashMap对之前做了较大的优化，其中最重要的一个优化就是桶中的元素不再唯一按照链表组合，也可以使用红黑树进行存储，总之，目标只有一个，那就是在安全和功能性完备的情况下让其速度更快，提升性能。 初始化代码123456789101112131415161718192021222324252627public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的填充因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树 static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表 static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍 transient Node&lt;k,v&gt;[] table; // 存放具体元素的集 transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet; // 存放元素的个数，注意这个不等于数组的长度。 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容 int threshold; // 填充因子 final float loadFactor; 四种构建方法HashMap(int, float) HashMap(int) HashMap() HashMap(Map&lt;? extends K&gt;) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public HashMap(int initialCapacity, float loadFactor) &#123; // 初始容量不能小于0，否则报错 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); // 初始容量不能大于最大值，否则为最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 填充因子不能小于或等于0，不能为非数字 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); // 初始化填充因子 this.loadFactor = loadFactor; // 初始化threshold大小 this.threshold = tableSizeFor(initialCapacity); &#125;//返回大于initialCapacity的最小的二次幂数值static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;public HashMap(int initialCapacity) &#123; // 调用HashMap(int, float)型构造函数 this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; // 初始化填充因子 this.loadFactor = DEFAULT_LOAD_FACTOR; &#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125;//putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict)函数将m的所有元素存入本HashMap实例中final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; // 判断table是否已经初始化 if (table == null) &#123; // pre-size // 未初始化，s为m的实际元素个数 float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 计算得到的t大于阈值，则初始化阈值 if (t &gt; threshold) threshold = tableSizeFor(t); &#125; // 已初始化，并且m元素个数大于阈值，进行扩容处理 else if (s &gt; threshold) resize(); // 将m中的所有元素添加至HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; put方法代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // hash值不相等，即key不相等；为红黑树结点 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 结点数量达到阈值，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 跳出循环 break; &#125; //判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; //onlyIfAbsent为false或者旧值为null,用新值替换旧值 if (!onlyIfAbsent || oldValue == null) e.value = value; // 访问后回调 afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125;//通过hashCode()的高16位异或低16位实现,这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125;//扩容机制final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 容量翻倍，使用左移，效率更高 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // oldCap = 0并且oldThr = 0，使用缺省值（如使用HashMap()构造函数，之后再插入一个元素会调用resize函数，会进入这一步） else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 新阈值为0 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 复制元素，重新进行hash for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 将同一桶中的元素根据(e.hash &amp; oldCap)是否为0进行分割，分成两个不同的链表，完成rehash do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; get方法代码12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 桶中第一项(数组元素)相等 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 桶中不止一个结点 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) // 为红黑树结点 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 否则，在链表中查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; remove方法代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; // table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; clear方法代码123456789public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; clone方法代码123456789101112public Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // this shouldn&apos;t happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); return result; &#125; 其他方法略 LinkedHashMap​ 我们需要按照元素插入的顺序来访问元素，此时，LinkedHashMap就派上用场了。LinkedHashMap是HashMap的直接子类，二者唯一的区别是LinkedHashMap在HashMap的基础上，采用双向链表（doubly-linked list）的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同。除了可以保迭代历顺序，这种结构还有一个好处：迭代LinkedHashMap时不需要像HashMap那样遍历整个table，而只需要直接遍历header指向的双向链表即可，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。 初始化代码12345678910111213141516public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125; &#125; // 版本序列号 private static final long serialVersionUID = 3801124242820219131L; // 链表头结点 transient LinkedHashMap.Entry&lt;K,V&gt; head; // 链表尾结点 transient LinkedHashMap.Entry&lt;K,V&gt; tail; // 访问顺序 final boolean accessOrder;&#125; 五种构建方法LinkedHashMap(int, float) LinkedHashMap(int) LinkedHashMap() LinkedHashMap(Map&lt;? extends K, ? extends V&gt;) LinkedHashMap(int, float, boolean) 1234567891011121314151617181920212223public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false;&#125;public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false;&#125;public LinkedHashMap() &#123; super(); accessOrder = false;&#125;public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; putMapEntries(m, false);&#125;public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125;//可以指定accessOrder的值，从而控制访问顺序 未完待续HashTable初始化代码123456789public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable &#123; private transient Entry&lt;?,?&gt;[] table; private transient int count; private int threshold;// 阈值，用于判断是否需要调整Hashtable的容量 private float loadFactor;// 加载因子 private transient int modCount = 0; private static final long serialVersionUID = 1421746759512286392L; 四种构建方法123456789101112131415161718192021222324252627public Hashtable(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal Load: "+loadFactor); if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry&lt;?,?&gt;[initialCapacity]; threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1); &#125; public Hashtable(int initialCapacity) &#123; this(initialCapacity, 0.75f); &#125; public Hashtable() &#123; this(11, 0.75f); &#125; public Hashtable(Map&lt;? extends K, ? extends V&gt; t) &#123; this(Math.max(2*t.size(), 11), 0.75f); putAll(t); &#125; public synchronized void putAll(Map&lt;? extends K, ? extends V&gt; t) &#123; for (Map.Entry&lt;? extends K, ? extends V&gt; e : t.entrySet()) put(e.getKey(), e.getValue()); &#125; put方法代码12345678910111213141516171819202122232425262728293031323334353637public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; // Makes sure the key is not already in the hashtable. Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode();// //在此处计算key的hash值，如果此处key为null，则直接抛出空指针异常。 int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings("unchecked") Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; for(; entry != null ; entry = entry.next) &#123; if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; entry.value = value; return old; &#125; &#125; addEntry(hash, key, value, index); return null; &#125;private void addEntry(int hash, K key, V value, int index) &#123; modCount++; Entry&lt;?,?&gt; tab[] = table; if (count &gt;= threshold) &#123; // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; // Creates the new entry. @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++; &#125; get方法代码1234567891011public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return (V)e.value; &#125; &#125; return null;&#125; remove方法代码12345678910111213141516171819202122public synchronized V remove(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)tab[index]; for(Entry&lt;K,V&gt; prev = null ; e != null ; prev = e, e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; modCount++; if (prev != null) &#123; prev.next = e.next; &#125; else &#123; tab[index] = e.next; &#125; count--; V oldValue = e.value; e.value = null; return oldValue; &#125; &#125; return null; &#125; clear方法代码1234567public synchronized void clear() &#123; Entry&lt;?,?&gt; tab[] = table; modCount++; for (int index = tab.length; --index &gt;= 0; ) tab[index] = null; count = 0; &#125; clone方法代码123456789101112131415161718public synchronized Object clone() &#123; try &#123; Hashtable&lt;?,?&gt; t = (Hashtable&lt;?,?&gt;)super.clone(); t.table = new Entry&lt;?,?&gt;[table.length]; for (int i = table.length ; i-- &gt; 0 ; ) &#123; t.table[i] = (table[i] != null) ? (Entry&lt;?,?&gt;) table[i].clone() : null; &#125; t.keySet = null; t.entrySet = null; t.values = null; t.modCount = 0; return t; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; &#125; TreeMapTreeMap底层使用的数据结构是红黑树，HashMap在达到一定阈值时候会使用红黑树。 未完待续Iterator接口概览Iterator接口也是Java集合框架的成员，主要用于遍历（即迭代访问）Collection集合中的元素，Iterator对象也被称为迭代器。 123456789101112public interface Iterator&lt;E&gt; &#123; boolean hasNext(); E next(); default void remove() &#123; throw new UnsupportedOperationException("remove"); &#125; default void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); while (hasNext()) action.accept(next()); &#125;//这是Java 8为Iterator新增的默认方法，该方法可使用Lambda表达式来遍历集合元素&#125; Comparable接口概览在Java集合框架里面，各种集合的操作很大程度上都离不开Comparable和Comparator，虽然它们与集合没有显示的关系，但是它们只有在集合里面的时候才能发挥最大的威力。 Comparable 123public interface Comparable&lt;T&gt;&#123; public int compareTo(T o);&#125; Comparator 12345public interface Comparator&lt;T&gt;&#123; int compare(T o1, T o2); boolean equals(Object obj); .....//其他是1.8扩展的&#125; 示例： 1234567891011121314151617181920212223242526272829303132333435363738public class Person implements Comparable &#123; String name; int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public int compareTo(Object o) &#123; // TODO Auto-generated method stub Person another =(Person)o; int i = this.name.compareTo(another.name); if(i== 0)&#123; return age - another.age; &#125;else&#123; return i; &#125; &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + "]"; &#125; @SuppressWarnings("unchecked") public static void main(String[] args) &#123; // TODO Auto-generated method stub Person p1 =new Person("a",20); Person p2 =new Person("a",12); List&lt;Person&gt; list = new ArrayList&lt;Person&gt;(); list.add(p1); list.add(p2); Collections.sort(list); System.out.println(Arrays.deepToString(list.toArray())); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839public class Person &#123; String name; int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + "]"; &#125; @SuppressWarnings("unchecked") public static void main(String[] args) &#123; // TODO Auto-generated method stub Person p1 =new Person("a",20); Person p2 =new Person("a",12); List&lt;Person&gt; list = new ArrayList&lt;Person&gt;(); list.add(p1); list.add(p2); Collections.sort(list,new MyComparator()); System.out.println(Arrays.deepToString(list.toArray())); &#125;&#125;class MyComparator implements Comparator&lt;Person&gt; &#123; // TODO Auto-generated method stub @Override public int compare(Person o1, Person o2) &#123; // TODO Auto-generated method stub int i = o1.name.compareTo(o2.name); if(i== 0)&#123; return o1.age - o2.age; &#125;else&#123; return i; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗?]]></title>
      <url>%2F2017%2F05%2F15%2F%E4%BD%A0%E6%87%82python%E5%90%97%2F</url>
      <content type="text"><![CDATA[Python的函数参数传递 深刻理解Python中的元类(metaclass) @staticmethod和@classmethod的区别 Python 的类的下划线命名 python的format函数使用 args和 *kwargs python的新式类和旧式类 init与new的区别 python的单例模式 Python的闭包和装饰器 lambda函数 python的拷贝 Python垃圾回收机制]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[maven父子项目创建]]></title>
      <url>%2F2017%2F05%2F12%2Fmaven%E7%88%B6%E5%AD%90%E9%A1%B9%E7%9B%AE%E5%88%9B%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[使用SpringToolSuite 下一步之后得到如下图，我们可以把src文件删除了。 pom.xml文件如下内容： 1234567891011121314151617181920&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;A&lt;/groupId&gt; &lt;artifactId&gt;B&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;distributionManagement&gt; &lt;site&gt; &lt;id&gt;website&lt;/id&gt; &lt;url&gt;scp://webhost.company.com/www/website&lt;/url&gt; &lt;/site&gt; &lt;/distributionManagement&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt;&lt;/project&gt; 我们可以删除不用的保留如下： 123456789101112&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;A&lt;/groupId&gt; &lt;artifactId&gt;B&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt;&lt;/project&gt; pom.xml文件内容如下： 123456789101112131415&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;A&lt;/groupId&gt; &lt;artifactId&gt;B&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;modules&gt; &lt;module&gt;C&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 其他子项目类似。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java框架之SpringBoot(2)]]></title>
      <url>%2F2017%2F05%2F11%2Fjava%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBoot-2%2F</url>
      <content type="text"><![CDATA[java框架之SpringBoot(2)主要是简略列举SpringBoot常用模块，详解部分侧重于实际开发需求 详解部分：SpringBoot的pom.xml Spring Boot属性配置文件 模板引擎Thymeleaf Swagger2 Spring-data-jpa(包括多数据源使用) Spring Boot整合MyBatis Spring Boot中使用Redis，MongoDB数据库 Spring Boot日志管理 Spring Boot中使用AOP Spring Boot中的事务管理 Spring Security Spring Boot中使用RabbitMQ 基础依赖如下： spring-boot-starter：核心模块，包括自动配置支持、日志和YAML spring-boot-starter-test：测试模块，包括JUnit、Hamcrest、Mockito spring-boot-starter-web：引用web模块 123456789101112131415161718192021&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 静态资源访问Spring Boot默认提供静态资源目录位置需置于classpath下，目录名需符合如下规则： /static/public/resources/META-INF/resources 渲染Web页面模板引擎Spring Boot提供了默认配置的模板引擎主要有以下几种： Thymeleaf 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; FreeMarkerVelocityGroovyMustache 支持JSP的配置https://github.com/spring-projects/spring-boot/tree/v1.3.2.RELEASE/spring-boot-samples/spring-boot-sample-web-jsp 工程结构（最佳实践）root package结构：com.example.myproject应用主类Application.java置于root package下，通常我们会在应用主类中做一些框架配置扫描等配置，我们放在root package下可以帮助程序减少手工配置来加载到我们希望被Spring加载的内容实体（Entity）与数据访问层（Repository）置于com.example.myproject.domain包下逻辑层（Service）置于com.example.myproject.service包下Web层（web）置于com.example.myproject.web包下 123456789101112131415com +- example +- myproject +- Application.java | +- domain | +- Customer.java | +- CustomerRepository.java | +- service | +- CustomerService.java | +- web | +- CustomerController.java | Swagger2之Swagger2我们构建RESTful API的目的通常都是由于多终端的原因，这些终端会共用很多底层业务逻辑，因此我们会抽象出这样一层来同时服务于多个移动端或者Web前端。 这样一来，我们的RESTful API就有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等。为了减少与其他团队平时开发期间的频繁沟通成本，传统做法我们会创建一份RESTful API文档来记录所有接口细节，然而这样的做法有以下几个问题： 由于接口众多，并且细节复杂（需要考虑不同的HTTP请求类型、HTTP头部信息、HTTP请求内容等），高质量地创建这份文档本身就是件非常吃力的事，下游的抱怨声不绝于耳。随着时间推移，不断修改接口实现的时候都必须同步修改接口文档，而文档与代码又处于两个不同的媒介，除非有严格的管理机制，不然很容易导致不一致现象。 1234567891011&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt; Demo地址： https://github.com/Luckylau/UsefulTools/tree/master/SpringBootDemo 详情地址： http://luckylau.tech/2017/08/05/SpringBoot%E4%B9%8BSwagger2/ 具体开发看提交日志 演示如下结果如下 http://localhost:8080/swagger-ui.html#/ SpringBoot之访问数据库JdbcTemplate访问数据库JdbcTemplateAPI 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt; 在src/main/resources/application.properties配置 1234spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=dbuserspring.datasource.password=dbpassspring.datasource.driver-class-name=com.mysql.jdbc.Driver Spring-data-jpa访问数据库123456789&lt;dependency &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt; 在src/main/resources/application.properties配置 12345spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.jpa.properties.hibernate.hbm2ddl.auto= spring.jpa.properties.hibernate.hbm2ddl.auto是hibernate的配置属性，其主要作用是：自动创建、更新、验证数据库表结构。该参数的几种配置如下： create：每次加载hibernate时都会删除上一次的生成的表，然后根据你的model类再重新来生成新表，哪怕两次没有任何改变也要这样执行，这就是导致数据库表数据丢失的一个重要原因。create-drop：每次加载hibernate时根据model类生成表，但是sessionFactory一关闭,表就自动删除。update：最常用的属性，第一次加载hibernate时根据model类会自动建立起表的结构（前提是先建立好数据库），以后加载hibernate时根据。 model类自动更新表结构，即使表结构改变了但表中的行仍然存在不会删除以前的行。要注意的是当部署到服务器后，表结构是不会被马上建立起来的，是要等应用第一次运行起来后才会。validate：每次加载hibernate时，验证创建数据库表结构，只会和数据库中的表进行比较，不会创建新表，但是会插入新值。 详情地址：http://luckylau.tech/2017/06/12/SpringBoot%E4%B9%8BSpring-data-jpa/ SpringBoot之redis访问NoSQL数据库SpringBoot之MongoDB访问NoSQL数据库Spring Boot整合MyBatis详情详见：http://luckylau.tech/2017/11/12/SpringBoot%E4%B9%8BMyBatis/ Spring Boot日志管理默认的日志输出如下： 111:06:59.250 [main] DEBUG o.s.t.c.j.SpringJUnit4ClassRunner - SpringJUnit4ClassRunner constructor called with [class com.didispace.ApplicationTests] 时间日期 — 精确到毫秒日志级别 — ERROR, WARN, INFO, DEBUG or TRACE进程ID分隔符 — — 标识实际日志的开始线程名 — 方括号括起来（可能会截断控制台输出）Logger名 — 通常使用源代码的类名日志内容 可以在application.properties中配置 常见是使用log4j，详细地址http://luckylau.tech/2017/12/28/SpringBoot%E4%B9%8Blog4j/ Spring Boot中使用AOP1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; Spring Security1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; Spring Boot整合MyBatis12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; application.properties中配置mysql的连接配置 1234spring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver Spring Boot中使用RabbitMQ1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 在application.properties中配置 12345spring.application.name=rabbitmq-hellospring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=springspring.rabbitmq.password=123456 参考：http://blog.didispace.com/Spring-Boot%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/ 陈绍健《深入实践SpringBoot》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[三人行，必有我师]]></title>
      <url>%2F2017%2F05%2F08%2F%E4%B8%89%E4%BA%BA%E8%A1%8C%EF%BC%8C%E5%BF%85%E6%9C%89%E6%88%91%E5%B8%88%2F</url>
      <content type="text"><![CDATA[云计算相关关于生活点滴，linux系统，openstack的博客 http://fishcried.com/archive/ 每天5分钟学习openstack http://blog.csdn.net/cloudman6?viewmode=contents 算法相关关于美国的生活点滴，算法，语言的博客 http://yansu.org/ 基础算法学习 http://www.cnblogs.com/yuzhangcmu/ http://www.csie.ntnu.edu.tw/~u91029/DynamicProgramming.html leecode算法 https://segmentfault.com/t/leetcode/blogs 结构之法算法之道 http://blog.csdn.net/v_july_v http://blog.csdn.net/v_july_v/article/details/6543438 python相关关于python，网络的学习 http://www.cnblogs.com/vamei/ http://www.cnblogs.com/zxqstrong/tag/python/ Java相关springboot学习 http://blog.didispace.com/ java深入学习，包括一些源码解读 http://blog.csdn.net/jzhf2012/article/category/1314885 http://blog.csdn.net/column/details/zhangjg-java-blog.html http://www.cnblogs.com/swiftma/p/?page=9 http://www.cnblogs.com/peida/archive/2013/04/23/3036035.html http://blog.csdn.net/luoweifu/article/category/887395 http://www.cnblogs.com/leesf456/tag/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/ http://jinnianshilongnian.iteye.com/blog/2018936/ springcloud学习 http://blog.didispace.com/springcloud2/ dubbo学习 https://github.com/dubbo/ http://shiyanjun.cn/archives/325.html http://blog.csdn.net/hzzhoushaoyu/article/details/43273099 http://www.cnblogs.com/xrq730/category/750525.html http://www.ityouknow.com/ 数据库优化http://blog.51yip.com/mysql/949.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之泛型]]></title>
      <url>%2F2017%2F05%2F04%2F%E4%BD%A0%E6%87%82java%E5%90%97-4%2F</url>
      <content type="text"><![CDATA[概述泛型在java中有很重要的地位，在面向对象编程及各种设计模式中有非常广泛的应用。 什么是泛型？​ 泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 ​ 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。 为什么要使用泛型？​ Java语言引入泛型的好处是安全简单。可以将运行时错误提前到编译时错误。在Java SE 1.5之前，没有泛型的情况的下，通过对类型Object的引用来实现参数的“任意化”，“任意化”带来的缺点是要做显式的强制类型转换，而这种转换是要求开发者对实际参数类型可以预知的情况下进行的。对于强制类型转换错误的情况，编译器可能不提示错误，在运行的时候才出现异常，这是一个安全隐患。泛型的好处是在编译的时候检查类型安全，并且所有的强制转换都是自动和隐式的，提高代码的重用率。 泛型的特性泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。 12345678910111213141516171819202122public class Generics&lt;T&gt; &#123; private T key; public Generics(T key) &#123; this.key = key; &#125; public T getKey()&#123; return key; &#125; public static void main(String[] args) &#123; Class genericInteger = new Generics&lt;Integer&gt;(123456).getClass(); Class genericNumber = new Generics&lt;Number&gt;(456).getClass(); Class genericString = new Generics&lt;String&gt;("key_vlaue").getClass(); System.out.println(genericInteger==genericString); System.out.println(genericInteger==genericNumber);//outputtrue,true //在泛型内部，无法获得任何有关泛型参数类型的信息。Generics&lt;String&gt;和Generics&lt;Integer&gt;是相同的类型 泛型通配符我们知道Ingeter是Number的一个子类，上述代码也验证过Generic&lt;Ingeter&gt;与Generic&lt;Number&gt;实际上是相同的一种基本类型。那么问题来了，在使用Generic&lt;Number&gt;作为形参的方法中，能否使用Generic&lt;Ingeter&gt;的实例传入呢？在逻辑上类似于Generic&lt;Number&gt;和Generic&lt;Ingeter&gt;是否可以看成具有父子关系的泛型类型呢？ 1234567891011121314151617181920public class Generics&lt;T&gt; &#123; private T key; public Generics(T key) &#123; this.key = key; &#125; public T getKey()&#123; return key; &#125; public static void showKeyValue(Generics&lt;Number&gt; obj)&#123; System.out.println("key is " + obj.getKey()); &#125; public static void main(String[] args) &#123; Generics&lt;Integer&gt; genericInteger = new Generics&lt;Integer&gt;(123456); Generics&lt;Number&gt; genericNumber = new Generics&lt;Number&gt;(456); showKeyValue(genericInteger);// showKeyValue这个方法编译器会为我们报错：Generic&lt;java.lang.Integer&gt; // cannot be applied to Generic&lt;java.lang.Number&gt; showKeyValue(genericNumber); &#125;&#125; 我们可以将上面的方法改一下： 123public static void showKeyValue(Generics&lt;?&gt; obj)&#123; System.out.println("key is " + obj.getKey());&#125; 此处’？’是类型实参，而不是类型形参 。再直白点的意思就是，此处的？和Number、String、Integer一样都是一种实际的类型，可以把？看成所有类型的父类。是一种真实的类型。 泛型的上界在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。 普通法的上界 上述例子 123456public static void showKeyValue(Generics&lt;?&gt; obj)&#123; System.out.println("key is " + obj.getKey());&#125;....Generics&lt;String&gt; genericString = new Generics&lt;String&gt;("abc");showKeyValue(genericString); //没问题 修改成 123456public static void showKeyValue(Generics&lt;? extends Number&gt; obj)&#123; System.out.println("key is " + obj.getKey());&#125;....Generics&lt;String&gt; genericString = new Generics&lt;String&gt;("abc");showKeyValue(genericString); //报错 类的上界 上述例子 123public class Generics&lt;T&gt; &#123; &#125; 修改成 1234public class Generics&lt;T extends number&gt; &#123;&#125;Generics&lt;String&gt; genericString = new Generics&lt;String&gt;("abc"); //报错 泛型方法的上界 1234567//在泛型方法中添加上下边界限制的时候，必须在权限声明与返回值之间的&lt;T&gt;上添加上下边界，即在泛型声明的时候添加//public &lt;T&gt; T showKeyName(Generic&lt;T extends Number&gt; container)，编译器会报错："Unexpected bound"public &lt;T extends Number&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println("container key :" + container.getKey()); T test = container.getKey(); return test;&#125; 泛型的下界既然有了通配符的上界，自然有着通配符的下界。使用（? super ），类的父类都可以，子类不行，我们知道Integer是Number的一个子类，如果 123456789101112public static void showKeyValue(Generics&lt;? extends Number&gt; obj)&#123; System.out.println("key is " + obj.getKey());&#125;Generics&lt;Integer&gt; genericInteger = new Generics&lt;Integer&gt;(123456);showKeyValue(genericInteger);//没问题public static void showKeyValue(Generics&lt;? super Number&gt; obj)&#123; System.out.println("key is " + obj.getKey());&#125;Generics&lt;Integer&gt; genericInteger = new Generics&lt;Integer&gt;(123456);showKeyValue(genericInteger);//报错 泛型的使用泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法。 泛型类泛型类型用于类的定义中，被称为泛型类。通过泛型可以完成对一组类的操作对外开放相同的接口。最典型的就是各种容器类，如：List、Set、Map。 注意：泛型的类型参数只能是类类型，不能是简单类型；不能对确切的泛型类型使用instanceof操作。 123456789101112131415161718192021222324252627282930313233//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generics&lt;T&gt; &#123; private T key; //key这个成员变量的类型为T,T的类型由外部指定 public Generics(T key) &#123; //泛型构造方法形参key的类型也为T，T的类型由外部指定 this.key = key; &#125; public T getKey()&#123; //泛型方法getKey的返回值类型为T，T的类型由外部指定 return key; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub //泛型的类型参数只能是类类型（包括自定义类），不能是简单类型 //传入的实参类型需与泛型的类型参数类型相同，即为Integer. Generics&lt;Integer&gt; genericInteger = new Generics&lt;Integer&gt;(123456); //传入的实参类型需与泛型的类型参数类型相同，即为String. Generics&lt;String&gt; genericString = new Generics&lt;String&gt;("key_vlaue"); System.out.println("泛型测试 , key is " + genericInteger.getKey()); System.out.println("泛型测试 , key is " + genericString.getKey()); //如果不传入泛型类型实参的话，在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型 Generics generic = new Generics(67890); System.out.println("泛型测试 , key is " + generic.getKey()); &#125;&#125;//output泛型测试 , key is 123456泛型测试 , key is key_vlaue泛型测试 , key is 67890 泛型接口123456789101112131415161718192021222324252627282930313233343536373839import java.util.Random; interface Generator&lt;T&gt; &#123; public T next(); &#125; //定义一个泛型接口class Coffee&#123; public String toString()&#123; return getClass().getSimpleName(); &#125; &#125; class Mocha extends Coffee&#123;&#125; class Cappuccino extends Coffee&#123;&#125; class Breve extends Coffee&#123;&#125; class Latte extends Coffee&#123;&#125; /** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class CoffeeGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; * 如果不声明泛型，如：class CoffeeGenerator implements Generator&lt;T&gt;，编译器会报错："Unknown class" */class CoffeeGenerator implements Generator&lt;Coffee&gt;&#123; //T为Coffee private static Random rand = new Random(); private Class[] types = &#123;Latte.class, Mocha.class, Cappuccino.class, Breve.class&#125;; @Override public Coffee next() &#123;//T为Coffee try &#123; return (Coffee) types[rand.nextInt(types.length)].newInstance(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; public class Genericstest &#123; public static void main(String[] args) &#123; CoffeeGenerator gen = new CoffeeGenerator(); for(int i=0; i&lt;4; i++)&#123; System.out.println(gen.next()); &#125; &#125;&#125; 泛型方法​ 泛型方法使得该方法能独立于类而产生变化。以下是一个基本的指导原则：无论何时，只要你能做到，你就应该尽量使用泛型方法。也就是说，如果使用泛型方法可以取代将整个类泛型化，那么就应该只使用泛型方法，因为它可以使事情更清楚明白。另外，对于一个static的方法而言，无法访问泛型类的类型参数。所以，如果static方法需要使用泛型能力，就必须使其成为泛型方法。 123456789101112131415/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： * 1）public 与 返回值中间&lt;T&gt;非常重要，可以理解为声明此方法为泛型方法。 * 2）只有声明了&lt;T&gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 * 3）&lt;T&gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 * 4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */public &lt;T&gt; T genericMethod(Class&lt;T&gt; tClass)throws InstantiationException , IllegalAccessException&#123; T instance = tClass.newInstance(); return instance;&#125; 示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Genericsmethod &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Apple apple = new Apple(); Person person = new Person(); GenerateTest&lt;Fruit&gt; generateTest = new GenerateTest&lt;Fruit&gt;(); //apple是Fruit的子类，所以这里可以 generateTest.show_1(apple); //编译器会报错，因为泛型类型实参指定的是Fruit，而传入的实参类是Person //generateTest.show_1(person); //使用这两个方法都可以成功 generateTest.show_2(apple); generateTest.show_2(person); //使用这两个方法也都可以成功 generateTest.show_3(apple); generateTest.show_3(person); &#125;&#125;class Fruit&#123; @Override public String toString() &#123; return "fruit"; &#125;&#125;class Apple extends Fruit&#123; @Override public String toString() &#123; return "apple"; &#125;&#125;class Person&#123; @Override public String toString() &#123; return "Person"; &#125;&#125;class GenerateTest&lt;T&gt;&#123; public void show_1(T t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。 //由于泛型方法在声明的时候会声明泛型&lt;E&gt;，因此即使在泛型类中并未声明泛型，编译器也能够正确识别泛型方法中识别的泛型。 public &lt;E&gt; void show_2(E t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型，可以与泛型类中声明的T不是同一种类型。 public &lt;T&gt; void show_3(T t)&#123; System.out.println(t.toString()); &#125;&#125; 如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法如下： 123456public static void show_1(T t)&#123; System.out.println(t.toString()); &#125; // 错误public static &lt;T&gt;void show_1(T t)&#123; System.out.println(t.toString()); &#125; // 正确 泛型的示例泛型数组123List&lt;?&gt;[] ls = new ArrayList&lt;?&gt;[10]; //正确List&lt;String&gt;[] ls = new ArrayList[10];//正确List&lt;String&gt;[] ls = new ArrayList&lt;String&gt;[10];//错误 元组的使用1234567891011121314151617181920212223242526272829303132333435/** * 容纳两个对象 * @param &lt;A&gt; * @param &lt;B&gt; */public class TwoTuple&lt;A,B&gt; &#123;//定义成final,返回后不可修改 public final A first; public final B second; public TwoTuple(A a,B b) &#123; first=a; second=b; &#125; @Override public String toString() &#123; // TODO Auto-generated method stub return first.toString()+second.toString(); &#125; public static TwoTuple&lt;String,Integer&gt; f() &#123; TwoTuple&lt;String,Integer&gt; two=new TwoTuple&lt;String,Integer&gt;("asfdsaf", 55535); return two; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub TwoTuple&lt;String,Integer&gt; two=f(); System.out.println(two); System.out.println(two.first); System.out.println(two.second); &#125;&#125; 123456789101112131415161718192021/** * * 容纳三个对象 * * @param &lt;A&gt; * @param &lt;B&gt; * @param &lt;C&gt; */class ThreeTuple&lt;A,B,C&gt; extends TwoTuple&lt;A, B&gt;&#123; public final C third; public ThreeTuple(A a,B b,C c) &#123; super(a, b); third=c; &#125; @Override public String toString() &#123; // TODO Auto-generated method stub return super.toString()+third.toString(); &#125;&#125; 普通泛型1234567891011121314151617181920212223242526272829303132333435363738394041424344class Point&lt;T&gt;&#123; // 此处可以随便写标识符号，T是type的简称 private T var ; // var的类型由T指定，即：由外部指定 public T getVar()&#123; // 返回值的类型由外部决定 return var ; &#125; public void setVar(T var)&#123; // 设置的类型也由外部决定 this.var = var ; &#125; &#125;; public class GenericsDemo06&#123; public static void main(String args[])&#123; Point&lt;String&gt; p = new Point&lt;String&gt;() ; // 里面的var类型为String类型 p.setVar("it") ; // 设置字符串 System.out.println(p.getVar().length()) ; // 取得字符串的长度 &#125; &#125;; ---------------------------------------------------------- class Notepad&lt;K,V&gt;&#123; // 此处指定了两个泛型类型 private K key ; // 此变量的类型由外部决定 private V value ; // 此变量的类型由外部决定 public K getKey()&#123; return this.key ; &#125; public V getValue()&#123; return this.value ; &#125; public void setKey(K key)&#123; this.key = key ; &#125; public void setValue(V value)&#123; this.value = value ; &#125; &#125;; public class GenericsDemo09&#123; public static void main(String args[])&#123; Notepad&lt;String,Integer&gt; t = null ; // 定义两个泛型类型的对象 t = new Notepad&lt;String,Integer&gt;() ; // 里面的key为String，value为Integer t.setKey("汤姆") ; // 设置第一个内容 t.setValue(20) ; // 设置第二个内容 System.out.print("姓名；" + t.getKey()) ; // 取得信息 System.out.print("，年龄；" + t.getValue()) ; // 取得信息 &#125; &#125;; 通配符12345678910111213141516171819202122class Info&lt;T&gt;&#123; private T var ; // 定义泛型变量 public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; public String toString()&#123; // 直接打印 return this.var.toString() ; &#125; &#125;; public class GenericsDemo14&#123; public static void main(String args[])&#123; Info&lt;String&gt; i = new Info&lt;String&gt;() ; // 使用String为泛型类型 i.setVar("it") ; // 设置内容 fun(i) ; &#125; public static void fun(Info&lt;?&gt; temp)&#123; // 可以接收任意的泛型对象 System.out.println("内容：" + temp) ; &#125; &#125;; 受限泛型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Info&lt;T&gt;&#123; private T var ; // 定义泛型变量 public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; public String toString()&#123; // 直接打印 return this.var.toString() ; &#125; &#125;; public class GenericsDemo17&#123; public static void main(String args[])&#123; Info&lt;Integer&gt; i1 = new Info&lt;Integer&gt;() ; // 声明Integer的泛型对象 Info&lt;Float&gt; i2 = new Info&lt;Float&gt;() ; // 声明Float的泛型对象 i1.setVar(30) ; // 设置整数，自动装箱 i2.setVar(30.1f) ; // 设置小数，自动装箱 fun(i1) ; fun(i2) ; &#125; public static void fun(Info&lt;? extends Number&gt; temp)&#123; // 只能接收Number及其Number的子类 System.out.print(temp + "、") ; &#125; &#125;; ---------------------------------------------------------- class Info&lt;T&gt;&#123; private T var ; // 定义泛型变量 public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; public String toString()&#123; // 直接打印 return this.var.toString() ; &#125; &#125;; public class GenericsDemo21&#123; public static void main(String args[])&#123; Info&lt;String&gt; i1 = new Info&lt;String&gt;() ; // 声明String的泛型对象 Info&lt;Object&gt; i2 = new Info&lt;Object&gt;() ; // 声明Object的泛型对象 i1.setVar("hello") ; i2.setVar(new Object()) ; fun(i1) ; fun(i2) ; &#125; public static void fun(Info&lt;? super String&gt; temp)&#123; // 只能接收String或Object类型的泛型 System.out.print(temp + "、") ; &#125; &#125;; 泛型无法向上转型12345678910111213141516171819class Info&lt;T&gt;&#123; private T var ; // 定义泛型变量 public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; public String toString()&#123; // 直接打印 return this.var.toString() ; &#125; &#125;; public class GenericsDemo23&#123; public static void main(String args[])&#123; Info&lt;String&gt; i1 = new Info&lt;String&gt;() ; // 泛型类型为String Info&lt;Object&gt; i2 = null ; i2 = i1 ; //这句会出错 incompatible types &#125; &#125;; 泛型接口123456789101112131415161718192021222324252627282930313233343536373839404142434445interface Info&lt;T&gt;&#123; // 在接口上定义泛型 public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型 &#125; class InfoImpl&lt;T&gt; implements Info&lt;T&gt;&#123; // 定义泛型接口的子类 private T var ; // 定义属性 public InfoImpl(T var)&#123; // 通过构造方法设置属性内容 this.setVar(var) ; &#125; public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; &#125;; public class GenericsDemo24&#123; public static void main(String arsg[])&#123; Info&lt;String&gt; i = null; // 声明接口对象 i = new InfoImpl&lt;String&gt;("汤姆") ; // 通过子类实例化对象 System.out.println("内容：" + i.getVar()) ; &#125; &#125;; ---------------------------------------------------------- interface Info&lt;T&gt;&#123; // 在接口上定义泛型 public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型 &#125; class InfoImpl implements Info&lt;String&gt;&#123; // 定义泛型接口的子类 private String var ; // 定义属性 public InfoImpl(String var)&#123; // 通过构造方法设置属性内容 this.setVar(var) ; &#125; public void setVar(String var)&#123; this.var = var ; &#125; public String getVar()&#123; return this.var ; &#125; &#125;; public class GenericsDemo25&#123; public static void main(String arsg[])&#123; Info i = null; // 声明接口对象 i = new InfoImpl("汤姆") ; // 通过子类实例化对象 System.out.println("内容：" + i.getVar()) ; &#125; &#125;; 泛型方法1234567891011121314class Demo&#123; public &lt;T&gt; T fun(T t)&#123; // 可以接收任意类型的数据 return t ; // 直接把参数返回 &#125; &#125;; public class GenericsDemo26&#123; public static void main(String args[])&#123; Demo d = new Demo() ; // 实例化Demo对象 String str = d.fun("汤姆") ; // 传递字符串 int i = d.fun(30) ; // 传递数字，自动装箱 System.out.println(str) ; // 输出内容 System.out.println(i) ; // 输出内容 &#125; &#125;; 通过泛型方法返回泛型类型实例1234567891011121314151617181920212223class Info&lt;T extends Number&gt;&#123; // 指定上限，只能是数字类型 private T var ; // 此类型由外部决定 public T getVar()&#123; return this.var ; &#125; public void setVar(T var)&#123; this.var = var ; &#125; public String toString()&#123; // 覆写Object类中的toString()方法 return this.var.toString() ; &#125; &#125;; public class GenericsDemo27&#123; public static void main(String args[])&#123; Info&lt;Integer&gt; i = fun(30) ; System.out.println(i.getVar()) ; &#125; public static &lt;T extends Number&gt; Info&lt;T&gt; fun(T param)&#123;//方法中传入或返回的泛型类型由调用方法时所设置的参数类型决定 Info&lt;T&gt; temp = new Info&lt;T&gt;() ; // 根据传入的数据类型实例化Info temp.setVar(param) ; // 将传递的内容设置到Info对象的var属性之中 return temp ; // 返回实例化对象 &#125; &#125;; 使用泛型统一传入的参数类型123456789101112131415161718192021222324class Info&lt;T&gt;&#123; // 指定上限，只能是数字类型 private T var ; // 此类型由外部决定 public T getVar()&#123; return this.var ; &#125; public void setVar(T var)&#123; this.var = var ; &#125; public String toString()&#123; // 覆写Object类中的toString()方法 return this.var.toString() ; &#125; &#125;; public class GenericsDemo28&#123; public static void main(String args[])&#123; Info&lt;String&gt; i1 = new Info&lt;String&gt;() ; Info&lt;String&gt; i2 = new Info&lt;String&gt;() ; i1.setVar("HELLO") ; // 设置内容 i2.setVar("汤姆") ; // 设置内容 add(i1,i2) ; &#125; public static &lt;T&gt; void add(Info&lt;T&gt; i1,Info&lt;T&gt; i2)&#123; System.out.println(i1.getVar() + " " + i2.getVar()) ; &#125; &#125;; 泛型数组123456789101112131415public class GenericsDemo30&#123; public static void main(String args[])&#123; Integer i[] = fun1(1,2,3,4,5,6) ; // 返回泛型数组 fun2(i) ; &#125; public static &lt;T&gt; T[] fun1(T...arg)&#123; // 接收可变参数 return arg ; // 返回泛型数组 &#125; public static &lt;T&gt; void fun2(T param[])&#123; // 输出 System.out.print("接收泛型数组：") ; for(T t:param)&#123; System.out.print(t + "、") ; &#125; &#125; &#125;; 泛型的嵌套设置123456789101112131415161718192021222324252627282930313233343536373839404142class Info&lt;T,V&gt;&#123; // 接收两个泛型类型 private T var ; private V value ; public Info(T var,V value)&#123; this.setVar(var) ; this.setValue(value) ; &#125; public void setVar(T var)&#123; this.var = var ; &#125; public void setValue(V value)&#123; this.value = value ; &#125; public T getVar()&#123; return this.var ; &#125; public V getValue()&#123; return this.value ; &#125; &#125;; class Demo&lt;S&gt;&#123; private S info ; public Demo(S info)&#123; this.setInfo(info) ; &#125; public void setInfo(S info)&#123; this.info = info ; &#125; public S getInfo()&#123; return this.info ; &#125; &#125;; public class GenericsDemo31&#123; public static void main(String args[])&#123; Demo&lt;Info&lt;String,Integer&gt;&gt; d = null ; // 将Info作为Demo的泛型类型 Info&lt;String,Integer&gt; i = null ; // Info指定两个泛型类型 i = new Info&lt;String,Integer&gt;("汤姆",30) ; // 实例化Info对象 d = new Demo&lt;Info&lt;String,Integer&gt;&gt;(i) ; // 在Demo类中设置Info类的对象 System.out.println("内容一：" + d.getInfo().getVar()) ; System.out.println("内容二：" + d.getInfo().getValue()) ; &#125; &#125;; 参考：http://blog.csdn.net/caihuangshi/article/details/51278793 http://www.cnblogs.com/sunwei2012/archive/2010/10/08/1845938.html http://www.cnblogs.com/iyangyuan/archive/2013/04/09/3011274.html http://blog.csdn.net/androidstudio/article/details/18567239]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之异常处理]]></title>
      <url>%2F2017%2F05%2F02%2F%E4%BD%A0%E6%87%82java%E5%90%97-3%2F</url>
      <content type="text"><![CDATA[我们主要讲解一下exception的处理。 异常的示例 try…catch…finally恐怕是大家再熟悉不过了，但是看下面这个例子，不同的处理输出就不一样。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class TestException &#123; public TestException() &#123; &#125; boolean testEx() throws Exception &#123; boolean ret = true; try &#123; ret = testEx1(); &#125; catch (Exception e) &#123; System.out.println("testEx, catch exception"); ret = false; throw e; &#125; finally &#123; System.out.println("testEx, finally; return value=" + ret); return ret; &#125; &#125; boolean testEx1() throws Exception &#123; boolean ret = true; try &#123; ret = testEx2(); if (!ret) &#123; return false; &#125; System.out.println("testEx1, at the end of try"); return ret; &#125; catch (Exception e) &#123; System.out.println("testEx1, catch exception"); ret = false; throw e; &#125; finally &#123; System.out.println("testEx1, finally; return value=" + ret); //return ret; &#125; &#125; boolean testEx2() throws Exception &#123; boolean ret = true; try &#123; int b = 12; int c; for (int i = 2; i &gt;= -2; i--) &#123; c = b / i; System.out.println("i=" + i); &#125; return true; &#125; catch (Exception e) &#123; System.out.println("testEx2, catch exception" + e.getMessage()); ret = false; throw e; &#125; finally &#123; System.out.println("testEx2, finally; return value=" + ret); //return ret; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub TestException testException = new TestException(); try &#123; testException.testEx(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;//outputi=2i=1testEx2, catch exception/ by zerotestEx2, finally; return value=falsetestEx1, catch exceptiontestEx1, finally; return value=falsetestEx, catch exceptiontestEx, finally; return value=false//假设不注销return的话//outputi=2i=1testEx2, catch exception/ by zerotestEx2, finally; return value=falsetestEx1, finally; return value=falsetestEx, finally; return value=false 异常的分类​ 异常指不期而至的各种状况，如：文件找不到、网络连接失败、除0操作、非法参数等。异常是一个事件，它发生在程序运行期间，干扰了正常的指令流程。 ​ Java语言在设计的当初就考虑到这些问题，提出异常处理的框架的方案，所有的异常都可以用一个异常类来表示，不同类型的异常对应不同的子类异常（目前我们所说的异常包括错误概念），定义异常处理的规范，在JDK1.4版本以后增加了异常链机制，从而便于跟踪异常。 按类别分类 Throwable： 有两个重要的子类：Exception（异常）和 Error（错误），二者都是 Java 异常处理的重要子类，各自都包含大量子类。 Error（错误）：是程序无法处理的错误，表示运行应用程序中较严重问题。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。AWTError不是很常用了，主要与Swing有关。 Exception（异常）：是程序本身可以处理的异常。 Exception 类有一个重要的子类 RuntimeException。RuntimeException 类及其子类表示“JVM 常用操作”引发的错误。 按可查分类Java的异常(包括Exception和Error)分为可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）。Java的异常(包括Exception和Error)分为可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）。 可查异常（编译器要求必须处置的异常）：正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常，包括 IOException（IO错误）及其子类EOFExcption(文件已结束异常)、FileNotFound（文件未找到异常）。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。 不可查异常(编译器不要求强制处置的异常):包括运行时异常（RuntimeException与其子类）和错误（Error）。 按运行分类Exception 这种异常分两大类运行时异常和非运行时异常(编译异常)。程序中应当尽可能去处理这些异常。 运行时异常：都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。 非运行时异常 （编译异常）：是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。 常见异常集算术异常类：ArithmeticExecption 空指针异常类：NullPointerException 类型强制转换异常：ClassCastException 数组负下标异常：NegativeArrayException 数组下标越界异常：ArrayIndexOutOfBoundsException 违背安全原则异常：SecturityException 文件已结束异常：EOFException 文件未找到异常：FileNotFoundException 字符串转换为数字异常：NumberFormatException 操作数据库异常：SQLException 输入输出异常：IOException 方法未找到异常：NoSuchMethodException java.lang.AbstractMethodError 抽象方法错误。当应用试图调用抽象方法时抛出。 java.lang.AssertionError 断言错。用来指示一个断言失败的情况。 java.lang.ClassCircularityError 类循环依赖错误。在初始化一个类时，若检测到类之间循环依赖则抛出该异常。 java.lang.ClassFormatError 类格式错误。当Java虚拟机试图从一个文件中读取Java类，而检测到该文件的内容不符合类的有效格式时抛出。 java.lang.Error 错误。是所有错误的基类，用于标识严重的程序运行问题。这些问题通常描述一些不应被应用程序捕获的反常情况。 java.lang.ExceptionInInitializerError 初始化程序错误。当执行一个类的静态初始化程序的过程中，发生了异常时抛出。静态初始化程序是指直接包含于类中的static语句段。 java.lang.IllegalAccessError 违法访问错误。当一个应用试图访问、修改某个类的域（Field）或者调用其方法，但是又违反域或方法的可见性声明，则抛出该异常。 java.lang.IncompatibleClassChangeError 不兼容的类变化错误。当正在执行的方法所依赖的类定义发生了不兼容的改变时，抛出该异常。一般在修改了应用中的某些类的声明定义而没有对整个应用重新编译而直接运行的情况下，容易引发该错误。 java.lang.InstantiationError 实例化错误。当一个应用试图通过Java的new操作符构造一个抽象类或者接口时抛出该异常. java.lang.InternalError 内部错误。用于指示Java虚拟机发生了内部错误。 java.lang.LinkageError 链接错误。该错误及其所有子类指示某个类依赖于另外一些类，在该类编译之后，被依赖的类改变了其类定义而没有重新编译所有的类，进而引发错误的情况。 java.lang.NoClassDefFoundError 未找到类定义错误。当Java虚拟机或者类装载器试图实例化某个类，而找不到该类的定义时抛出该错误。 java.lang.NoSuchFieldError 域不存在错误。当应用试图访问或者修改某类的某个域，而该类的定义中没有该域的定义时抛出该错误。 java.lang.NoSuchMethodError 方法不存在错误。当应用试图调用某类的某个方法，而该类的定义中没有该方法的定义时抛出该错误。 java.lang.OutOfMemoryError 内存不足错误。当可用内存不足以让Java虚拟机分配给一个对象时抛出该错误。 java.lang.StackOverflowError 堆栈溢出错误。当一个应用递归调用的层次太深而导致堆栈溢出时抛出该错误。 java.lang.ThreadDeath 线程结束。当调用Thread类的stop方法时抛出该错误，用于指示线程结束。 java.lang.UnknownError 未知错误。用于指示Java虚拟机发生了未知严重错误的情况。 java.lang.UnsatisfiedLinkError 未满足的链接错误。当Java虚拟机未找到某个类的声明为native方法的本机语言定义时抛出。 java.lang.UnsupportedClassVersionError 不支持的类版本错误。当Java虚拟机试图从读取某个类文件，但是发现该文件的主、次版本号不被当前Java虚拟机支持的时候，抛出该错误。 java.lang.VerifyError 验证错误。当验证器检测到某个类文件中存在内部不兼容或者安全问题时抛出该错误。 java.lang.VirtualMachineError 虚拟机错误。用于指示虚拟机被破坏或者继续执行操作所需的资源不足的情况。 java.lang.ArithmeticException 算术条件异常。譬如：整数除零等。 java.lang.ArrayIndexOutOfBoundsException 数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。 java.lang.ArrayStoreException 数组存储异常。当向数组中存放非数组声明类型对象时抛出。 java.lang.ClassCastException 类造型异常。假设有类A和B（A不是B的父类或子类），O是A的实例，那么当强制将O构造为类B的实例时抛出该异常。该异常经常被称为强制类型转换异常。 java.lang.ClassNotFoundException 找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。 java.lang.CloneNotSupportedException 不支持克隆异常。当没有实现Cloneable接口或者不支持克隆方法时,调用其clone()方法则抛出该异常。 java.lang.EnumConstantNotPresentException 枚举常量不存在异常。当应用试图通过名称和枚举类型访问一个枚举对象，但该枚举对象并不包含常量时，抛出该异常。 java.lang.Exception 根异常。用以描述应用程序希望捕获的情况。 java.lang.IllegalAccessException 违法的访问异常。当应用试图通过反射方式创建某个类的实例、访问该类属性、调用该类方法，而当时又无法访问类的、属性的、方法的或构造方法的定义时抛出该异常。 java.lang.IllegalMonitorStateException 违法的监控状态异常。当某个线程试图等待一个自己并不拥有的对象（O）的监控器或者通知其他线程等待该对象（O）的监控器时，抛出该异常。 java.lang.IllegalStateException 违法的状态异常。当在Java环境和应用尚未处于某个方法的合法调用状态，而调用了该方法时，抛出该异常。 java.lang.IllegalThreadStateException 违法的线程状态异常。当县城尚未处于某个方法的合法调用状态，而调用了该方法时，抛出异常。 java.lang.IndexOutOfBoundsException 索引越界异常。当访问某个序列的索引值小于0或大于等于序列大小时，抛出该异常。 java.lang.InstantiationException 实例化异常。当试图通过newInstance()方法创建某个类的实例，而该类是一个抽象类或接口时，抛出该异常。 java.lang.InterruptedException 被中止异常。当某个线程处于长时间的等待、休眠或其他暂停状态，而此时其他的线程通过Thread的interrupt方法终止该线程时抛出该异常。 java.lang.NegativeArraySizeException 数组大小为负值异常。当使用负数大小值创建数组时抛出该异常。 java.lang.NoSuchFieldException 属性不存在异常。当访问某个类的不存在的属性时抛出该异常。 java.lang.NoSuchMethodException 方法不存在异常。当访问某个类的不存在的方法时抛出该异常。 java.lang.NullPointerException 空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等。 java.lang.NumberFormatException 数字格式异常。当试图将一个String转换为指定的数字类型，而该字符串确不满足数字类型要求的格式时，抛出该异常。 java.lang.RuntimeException 运行时异常。是所有Java虚拟机正常操作期间可以被抛出的异常的父类。 java.lang.SecurityException 安全异常。由安全管理器抛出，用于指示违反安全情况的异常。 java.lang.StringIndexOutOfBoundsException 字符串索引越界异常。当使用索引值访问某个字符串中的字符，而该索引值小于0或大于等于序列大小时，抛出该异常。 java.lang.TypeNotPresentException 类型不存在异常。当应用试图以某个类型名称的字符串表达方式访问该类型，但是根据给定的名称又找不到该类型是抛出该异常。该异常与ClassNotFoundException的区别在于该异常是unchecked（不被检查）异常，而ClassNotFoundException是checked（被检查）异常。 java.lang.UnsupportedOperationException 不支持的方法异常。指明请求的方法不被支持情况的异常。 异常捕获与处理Java的异常处理本质上是抛出异常和捕获异常。 异常的捕获和展示异常类型获取 通过getClass().getName()方式 出错点获取 123456String regEx = "Caused by:(.*)"; Pattern pat = Pattern.compile(regEx); Matcher mat = pat.matcher(content); boolean rs = mat.find(); System.out.println("found?" + rs); System.out.println(mat.group(1)); 或者 12e.getCause().getClass() //获取类型e.getCause().getMessage() //获取信息 异常信息的获取 1234ByteArrayOutputStream baos = new ByteArrayOutputStream(); e.printStackTrace(new PrintStream(baos)); String exception = baos.toString(); System.out.println("baos:" + exception); 异常处理的基本语法​ Java异常处理涉及到五个关键字，分别是：try、catch、finally、throw、throws。下面将骤一介绍，通过认识这五个关键字，掌握基本异常处理知识。 • try — 用于监听。将要被监听的代码(可能抛出异常的代码)放在try语句块之内，当try语句块内发生异常时，异常就被抛出。 • catch — 用于捕获异常。catch用来捕获try语句块中发生的异常。 • finally — finally语句块总是会被执行。它主要用于回收在try块里打开的物力资源(如数据库连接、网络连接和磁盘文件)。只有finally块，执行完成之后，才会回来执行try或者catch块中的return或者throw语句，如果finally中使用了return或者throw等终止方法的语句，则就不会跳回执行，直接停止。 • throw — 用于抛出异常。 • throws — 用在方法签名中，用于声明该方法可能抛出的异常。 ​ try-catch ​ 如下try-catch所描述的即是监控区域，关键词try后的一对大括号将一块可能发生异常的代码包起来，即为监控区域。Java方法在运行过程中发生了异常，则创建异常对象。将异常抛出监控区域之外，由Java运行时系统负责寻找匹配的catch子句来捕获异常。若有一个catch语句匹配到了，则执行该catch块中的异常处理代码，就不再尝试匹配别的catch块了。 使用多重的catch语句：很多情况下，由单个的代码段可能引起多个异常。处理这种情况，我们需要定义两个或者更多的catch子句，每个子句捕获一种类型的异常，当异常被引发时，每个catch子句被依次检查，第一个匹配异常类型的子句执行，当一个catch子句执行以后，其他的子句将被旁路。 总之顺序是 先小后大，即先子类后父类。对于有多个catch子句的异常程序而言，应该尽量将捕获底层异常类的catch子句放在前面，同时尽量将捕获相对高层的异常类的catch子句放在后面。否则，捕获底层异常类的catch子句将可能会被屏蔽。 1234567try&#123; //code that might generate exceptions &#125;catch(Exception e)&#123; //the code of handling exception1&#125;catch(Exception e)&#123; //the code of handling exception2&#125; ​ try-catch-finally ​ try-catch语句还可以包括第三部分，就是finally子句。它表示无论是否出现异常，都应当执行的内容。try-catch-finally语句的一般语法形式为： 123456789try &#123; // 可能会发生异常的程序代码 &#125; catch (Type1 id1) &#123; // 捕获并处理try抛出的异常类型Type1 &#125; catch (Type2 id2) &#123; // 捕获并处理try抛出的异常类型Type2 &#125; finally &#123; // 无论是否发生异常，都将执行的语句块 &#125; ​ 除了下列情况，总将执行 finally 做为结束：JVM 过早终止（调用 System.exit(int)）；在 finally 块中抛出一个未处理的异常；计算机断电、失火、或遭遇病毒攻击。 ​ throws抛出异常 ​ 如果一个方法可能会出现异常，但没有能力处理这种异常，可以在方法声明处用throws子句来声明抛出异常。 Throws抛出异常的规则：如果是不受检查异常（unchecked exception），即Error、RuntimeException 或它们的子类，那么可以不使用throws关键字来声明要抛出的异常，编译仍能顺利通过，但在运行时会被系统抛出。必须声明方法可抛出的任何检查异常（checked exception）。即如果一个方法可能出现受可查异常，要么用try-catch语句捕获，要么用throws子句声明将它抛出，否则会导致编译错误仅当抛出了异常，该方法的调用者才必须处理或者重新抛出该异常。当方法的调用者无力处理该异常的时候，应该继续抛出，而不是囫囵吞枣。调用方法必须遵循任何可查异常的处理和声明规则。若覆盖一个方法，则不能声明与覆盖方法不同的异常。声明的任何异常必须是被覆盖方法所声明异常的同类或子类。 ​ 使用throw抛出异常 ​ throw总是出现在函数体中，用来抛出一个Throwable类型的异常。程序会在throw语句后立即终止，它后面的语句执行不到，然后在包含它的所有try块中（可能在上层调用函数中）从里向外寻找含有与其匹配的catch子句的try块。我们知道，异常是异常类的实例对象，我们可以创建异常类的实例对象通过throw语句抛出。该语句的语法格式为： throw new exceptionname; 自定义异常用户自定义异常类，只需继承Exception类即可。 参考：http://blog.csdn.net/hguisu/article/details/6155636 http://blog.csdn.net/hongweigg/article/details/18313461 http://blog.csdn.net/beidou321/article/details/6499288/ http://www.cnblogs.com/Qian123/p/5715402.html http://swiftlet.net/archives/998]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SDN和NFV的区别？]]></title>
      <url>%2F2017%2F05%2F02%2FSDN%E5%92%8CNFV%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[SDN诞生于高校，成熟于数据中心SDN初始于园区网络，一群研究者在进行科研时发现，每次进行新的协议部署尝试时，都需要改变网络设备的软件，这让他们灰常郁闷，于是乎，他们开始考虑让这些网络硬件设备可编程化，并且可以被集中的一个盒子所管理和控制，就这样，诞生了当今SDN的基本定义和元素: 分离控制和转发的功能 控制集中化 使用广泛定义的(软件)接口使得网络可以执行程序化行为 另一个SDN成功的环境就是云数据中心，这些数据中心的规模不断的扩展，如何控制虚拟机的爆炸式增长，如何用更好的方式连接和控制这些虚拟机，成为数据中心明确需求。而SDN的思想，恰恰提供了一个希望：数据中心如何可以更可控。 NFV由服务供应商创建和SDN始于研究者和数据中心不同，NFV则是由运营商的联盟提出，解决以下问题： 网络运营商的网络是通过大型的不断增长的专属硬件设备来部署。一项新网络服务的推出，不仅能耗在增加，资本投入存在挑战，又缺少必要的技巧来设计，整合和操作日趋复杂的硬件设备。 SDN vs NFV ​ 网络功能虚拟化和软件定义网络(SDN)有很强的互补性，但是并不相互依赖(反之亦然)，网络功能虚拟化可以不依赖于SDN部署，尽管两个概念和解决方案可以融合，并且潜在形成更大的价值。依赖于应用在大量数据中心内的现有技术，网络功能虚拟化的目标可以基于非SDN的机制而实现。但是，如果可以逐渐接近SDN所提出的将控制平面和数据平面的思路，那么就能进一步使现有的部署性能增强且简化互操作性，减轻运营和维护流程的负担。网络功能虚拟化为SDN软件的运行提供基础架构的支持，未来，网络功能虚拟化可以和SDN的目标紧密联系在一起——使用商业性服务器和交换机。 SDN和NFV—协同工作下图展示了当今路由器服务部署典型案例，在每个客户站点使用均使用一台路由器(提供服务)。 下图展示了使用虚拟路由器的功能，NFV就可以在这个场景中展现作用，所有的用户站点左侧都是一个网络接口设备(NID)–—-虚拟路由器，提供网络的分界点，并且测量性能。 下图是SDN被引入进来，将控制平面和转发平面分割，数据包将会根据更优化的数据平面被转发，路由功能被提取到控制平面作为控制策略的一部分。所以sdn与nfv结合，会使得一个昂贵的专业设备被通用硬件和高级软件替代；软件控制平面被转移到了更优化的位置，从专用设备硬件中剥离，放置在数据中心或者POP位置，可能以服务器或者虚拟机的形式存在；数据平面的控制被从专有设备上提取出来，并且标准化，使得网络和应用的革新无需网络设备硬件升级。 总结： 分类 SDN NFV Reason for Being Separation of control and data, centralization of control and programmability of network Relocation of network functions from dedicated appliances to generic servers Target Location Campus, data center / cloud Service provider network Target Devices Commodity servers and switches Commodity servers and switches Initial Applications Cloud orchestration and networking Routers, firewalls, gateways, CDN, WAN accelerators, SLA assurance New Protocols OpenFlow None yet Formalization Open Networking Forum (ONF) ETSI NFV Working Group 参考：http://network.51cto.com/art/201306/398240.htm https://www.sdxcentral.com/articles/contributed/nfv-and-sdn-whats-the-difference/2013/03/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之final,static,finalize的区别]]></title>
      <url>%2F2017%2F04%2F27%2F%E4%BD%A0%E6%87%82java%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[更新时间 更新内容 2017-04-27 原文初始化 2017-05-08 static方法初始化的过程 final关键字 ​ Java关键字final有“这是无法改变的”或者“终态的”含义，它可以修饰非抽象类、非抽象类成员方法和变量。你可能出于两种理解而需要阻止改变：设计或效率。 final类不能被继承，没有子类，final类中的方法默认是final的。 final方法不能被子类的方法覆盖，但可以被继承。 final成员变量表示常量，只能被赋值一次，赋值后值不再改变。 final不能用于修饰构造方法。 注意：父类的private成员方法是不能被子类方法覆盖的，因此private类型的方法默认是final类型的。 final的使用定义变量，包括静态的和非静态的。 用final修饰的成员变量表示常量，值一旦给定就无法改变。 final修饰的变量有三种：静态变量、实例变量和局部变量，分别表示三种类型的常量。 定义方法的参数。 斯坦福教授说的好，方法可以比喻成一台机器(面包机)，没错，在我的机器（方法）里面，我要的参数加了final(要原料)，你给我传过来的参数，机器里面就无法改了，也就是说在机器里的这个参数，一直指向的都是你传进来的参数。 一句话概括是不允许将引用变量进行重定向。 1234567891011public void setLength( int length) &#123; if(length &lt; 8) &#123; length = 8; &#125;&#125;//下面就会出现编译错误public void setLength( final int length) &#123; if(length &lt; 8) &#123; length = 8; &#125;&#125; 定义方法。 如果一个类不允许其子类覆盖某个方法，则可以把这个方法声明为final方法。 使用final修饰，可以把方法锁定，防止任何继承类修改它的意义和实现；其次是高效，编译器在遇到调用final方法时候会转入内嵌机制，大大提高执行效率。 1234567891011class PersonalLoan&#123; public final String getName()&#123; return "personal loan"; &#125; &#125;class CheapPersonalLoan extends PersonalLoan&#123; @Override public final String getName()&#123; return "cheap personal loan"; //compilation error: overridden method is final &#125; &#125; 定义类。 ​ final类不能被继承，因此final类的成员方法没有机会被覆盖，默认都是final的。在设计类时候，如果这个类不需要有子类，类的实现细节不允许改变，并且确信这个类不会载被扩展，那么就设计为final类。 final与static的区别static表示“全局”或者“静态”的意思，用来修饰成员变量和成员方法，也可以形成静态static代码块，但是Java语言中没有全局变量的概念。 static变量按照是否静态的对类成员变量进行分类可分两种：一种是被static修饰的变量，叫静态变量或类变量；另一种是没有被static修饰的变量，叫实例变量。两者的区别是：对于静态变量在内存中只有一个拷贝（节省内存），JVM只为静态分配一次内存，在加载类的过程中完成静态变量的内存分配，可用类名直接访问（方便），当然也可以通过对象来访问（但是这是不推荐的）。 静态方法静态方法可以直接通过类名调用，任何的实例也都可以调用，因此静态方法中不能用this和super关键字，不能直接访问所属类的实例变量和实例方法(就是不带static的成员变量和成员成员方法)，只能访问所属类的静态成员变量和成员方法。因为实例成员与特定的对象关联！这个需要去理解，想明白其中的道理，不是记忆！！！ 因为static方法独立于任何实例，因此static方法必须被实现，而不能是抽象的abstract。 static代码块static代码块也叫静态代码块，是在类中独立于类成员的static语句块，可以有多个，位置可以随便放，它不在任何的方法体内，JVM加载类时会执行这些静态的代码块，如果static代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。 12345678910111213141516171819202122232425262728public class staitcTest &#123; private static int B; private int b; static &#123; B = 1; System.out.println(" B : " +B); staitcTest t = new staitcTest(); t.printTest(); t.B=2; t.b=1; System.out.println(" B : " + B); System.out.println(" b : " +t.b); &#125; public void printTest()&#123; System.out.println(".... test ...."); &#125; public static void main(String[] args) &#123; &#125; static &#123; B = 3; System.out.println(" B : " + B); &#125; &#125;//output B : 1 B : 2 b : 1 B : 3 解释static代码块如何加载（static块到底在什么时候运行的）： 一个类的运行包括以下步骤：装载—-连接—-初始化 装载阶段又三个基本动作组成： 通过类型的完全限定名，产生一个代表该类型的二进制数据流；解析这个二进制数据流为方法区内的内部数据结构；创建一个表示该类型的java.lang.Class类的实例；另外如果一个类装载器在预先装载的时遇到缺失或错误的class文件，它需要等到程序首次主动使用该类时才报告错误。 连接阶段又分为三部分： 验证，确认类型符合Java语言的语义，检查各个类之间的二进制兼容性(比如final的类不用拥有子类等)，另外还需要进行符号引用的验证。准备，Java虚拟机为类变量分配内存，设置默认初始值。解析(可选的) ，在类型的常量池中寻找类，接口，字段和方法的符号引用，把这些符号引用替换成直接引用的过程。 当一个类被主动使用时，Java虚拟就会对其初始化，如下六种情况为主动使用： 当创建某个类的新实例时（如通过new或者反射，克隆，反序列化等）当调用某个类的静态方法时当使用某个类或接口的静态字段时当调用Java API中的某些反射方法时，比如类Class中的方法，或者java.lang.reflect中的类的方法时当初始化某个子类时当虚拟机启动某个被标明为启动类的类（即包含main方法的那个类） Java编译器会收集所有的类变量初始化语句和类型的静态初始化器，将这些放到一个特殊的方法中：clinit。 实际上，static块的执行发生在“初始化”的阶段。初始化阶段，jvm主要完成对静态变量的初始化，静态块执行等工作。 执行static块的几种情况： 第一次new A()的过程会打印””；因为这个过程包括了初始化； 第一次Class.forName(“A”)的过程会打印；因为这个过程相当于Class.forName(“A”,true,this.getClass().getClassLoader())； 第一次Class.forName(“A”,false,this.getClass().getClassLoader())的过程则不会打印。因为false指明了装载类的过程中，不进行初始化。不初始化则不会执行static块。 重要的几点说明1.被static修饰的成员变量和成员方法独立于该类的任何对象。也就是说，它不依赖类特定的实例，被类的所有实例共享。只要这个类被加载，Java虚拟机就能根据类名在运行时数据区的方法区内定找到他们。因此，static对象可以在它的任何对象创建之前访问，无需引用任何对象。 2.用public修饰的static成员变量和成员方法本质是全局变量和全局方法，当声明它类的对象时，不生成static变量的副本，而是类的所有实例共享同一个static变量。 3.static变量前可以有private修饰，表示这个变量可以在类的静态代码块中，或者类的其他静态成员方法中使用（当然也可以在非静态成员方法中使用–废话），但是不能在其他类中通过类名来直接引用，这一点很重要。实际上你需要搞明白，private是访问权限限定，static表示不要实例化就可以使用，这样就容易理解多了。static前面加上其它访问权限关键字的效果也以此类推。 4.static修饰的成员变量和成员方法习惯上称为静态变量和静态方法，可以直接通过类名来访问，访问语法为： ​ 类名.静态方法名(参数列表…)​ 类名.静态变量名 5.用static修饰的代码块表示静态代码块，当Java虚拟机（JVM）加载类时，就会执行该代码块。 static和final合纵连横static 和final用来修饰成员变量和成员方法，可简单理解为“全局常量”！对于变量，表示一旦给值就不可修改，并且通过类名可以访问。对于方法，表示不可覆盖，并且可以通过类名直接访问。 特别要注意一个问题： 对于被static和final修饰过的实例常量，实例本身不能再改变了，但对于一些容器类型（比如，ArrayList、HashMap）的实例变量，不可以改变容器变量本身，但可以修改容器中存放的对象，这一点在编程中用到很多。 final与static的联合使用： 1234567891011121314151617181920212223242526272829303132333435363738public class FinalTest &#123; public final int A = 10; // 在定义时初始化 public final int B; &#123; B = 20; // 在初始化块中初始化 &#125; // 非静态final变量不能在静态初始化块中初始化 // public final int C; // static &#123; // C = 30; // &#125; public static final int STATIC_D = 40; //静态常量，在定义时初始化 public static final int STATIC_E; static &#123; STATIC_E = 50; // 静态常量，在静态初始化块中初始化 &#125; // 静态变量不能在初始化块中初始化 // public static final int STATIC_F; // &#123; // STATIC_F = 60; // &#125; public final int G; // 静态final变量不可以在构造器中初始化 // public static final int STATIC_H; // 在构造器中初始化 public FinalTest() &#123; G = 70; // 静态final变量不可以在构造器中初始化 // STATIC_H = 80; // 给final的变量第二次赋值时，编译会报错 // A = 99; // STATIC_D = 99; &#125; // final变量未被初始化，编译时就会报错 // public final int I; // 静态final变量未被初始化，编译时就会报错 // public static final int STATIC_J;&#125; final、finally和finalize的区别finallyfinally 它只能用在try/catch语句中，并且附带着一个语句块，表示这段语句最终总是被执行。 123456789101112public class FinallyTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub try &#123; throw new NullPointerException(); &#125; catch (NullPointerException e) &#123; System.out.println("程序抛出了异常"); &#125; finally &#123; System.out.println("执行了finally语句块"); &#125; &#125;&#125; 那么，有没有一种情况使finally语句块得不到执行呢？我们测试一下return、continue、break，代码示例如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class FinallyTest &#123; // 测试return语句 public ReturnClass testReturn() &#123; try &#123; return new ReturnClass(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println("执行了finally语句"); &#125; return null; &#125; // 测试continue语句 public void testContinue() &#123; for (int i = 0; i &lt; 3; i++) &#123; try &#123; System.out.println(i); if (i == 1) &#123; continue; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println("执行了finally语句"); &#125; &#125; &#125; // 测试break语句 public void testBreak() &#123; for (int i = 0; i &lt; 3; i++) &#123; try &#123; System.out.println(i); if (i == 1) &#123; break; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println("执行了finally语句"); &#125; &#125; &#125; class ReturnClass &#123; public ReturnClass() &#123; System.out.println("执行了return语句"); &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub FinallyTest ft = new FinallyTest(); // 测试return语句 ft.testReturn(); System.out.println("================"); // 测试continue语句 ft.testContinue(); System.out.println("================"); // 测试break语句 ft.testBreak(); &#125;&#125;//output执行了return语句执行了finally语句================0执行了finally语句1执行了finally语句2执行了finally语句================0执行了finally语句1执行了finally语句 从输出的结果来看，return语句似乎在finally语句块之前执行了，事实真的如此吗？ 分析如下： ​ 我们来想想看，return语句的作用是什么呢？是退出当前的方法，并将值或对象返回。如果finally语句块是在return语句之后执行的，那么return语句被执行后就已经退出当前方法了，finally语句块又如何能被执行呢？因此，正确的执行顺序应该是这样的：编译器在编译return new ReturnClass();时，将它分成了两个步骤，new ReturnClass()和return，前一个创建对象的语句是在finally语句块之前被执行的，而后一个return语句是在finally语句块之后执行的，也就是说finally语句块是在程序退出方法之前被执行的。同样，finally语句块是在循环被跳过（continue）和中断（break）之前被执行的。 finalize它是一个方法，属于java.lang.Object类，它的定义如下：​ protected void finalize() throws Throwable { }​ 众所周知，finalize()方法是GC(garbage collector)运行机制的一部分，finalize()方法是在GC清理它所从属的对象时被调用的，如果执行它的过程中抛出了无法捕获的异常(uncaught exception)，GC将终止对改对象的清理，并且该异常会被忽略；直到下一次GC开始清理这个对象时，它的finalize()会被再次调用。 以后在java垃圾回收详细分析。 参考http://lavasoft.blog.51cto.com/62575/18771/ http://www.cnblogs.com/ivanfu/archive/2012/02/12/2347817.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[netstat命令]]></title>
      <url>%2F2017%2F04%2F25%2Fnetstat%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[​ netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。 -a (all)显示所有选项，默认不显示LISTEN相关 -t (tcp)仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化成数字 -l 仅列出有在 Listen (监听) 的服务状态 -p 显示建立相关链接的程序名 -r 显示路由信息，路由表 -e 显示扩展信息，例如uid等 -s 按各个协议进行统计 -c 每隔一个固定时间，执行该netstat命令 示例如下： 123456789101112131415161718192021222324root@localhost:~# netstat -tunlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1532/sshd tcp 0 0 0.0.0.0:6653 0.0.0.0:* LISTEN 1600/ovs-testcontrotcp6 0 0 :::22 :::* LISTEN 1532/sshd udp 0 0 127.0.0.1:4500 0.0.0.0:* 1623/racoon udp 0 0 127.0.0.0:4500 0.0.0.0:* 1623/racoon udp 0 0 12.12.99.8:4500 0.0.0.0:* 1623/racoon udp 0 0 10.0.38.222:4500 0.0.0.0:* 1623/racoon udp 0 0 127.0.0.1:500 0.0.0.0:* 1623/racoon udp 0 0 127.0.0.0:500 0.0.0.0:* 1623/racoon udp 0 0 12.12.99.8:500 0.0.0.0:* 1623/racoon udp 0 0 10.0.38.222:500 0.0.0.0:* 1623/racoon udp 0 0 0.0.0.0:4789 0.0.0.0:* - udp6 0 0 fe80::9406:4dff:fe:4500 :::* 1623/racoon udp6 0 0 fe80::250:56ff:fe8:4500 :::* 1623/racoon udp6 0 0 fe80::250:56ff:fe8:4500 :::* 1623/racoon udp6 0 0 ::1:4500 :::* 1623/racoon udp6 0 0 fe80::9406:4dff:fe9:500 :::* 1623/racoon udp6 0 0 fe80::250:56ff:fe8d:500 :::* 1623/racoon udp6 0 0 fe80::250:56ff:fe8d:500 :::* 1623/racoon udp6 0 0 ::1:500 :::* 1623/racoon udp6 0 0 :::4789 :::* -]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron中的LoadBalancerv2的Haproxy]]></title>
      <url>%2F2017%2F04%2F24%2FNeutron%E4%B8%AD%E7%9A%84LoadBalancerv2%E7%9A%84Haproxy%2F</url>
      <content type="text"><![CDATA[Haproxy的介绍​ Haproxy提供高可用性、负载均衡以及基于TCP(第四层)和HTTP（第七层）应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。 ​ haproxy特别适用于那些负载特别大的web站点，这些站点通常又需要会话保持或七层处理。haproxy运行在时下的硬件上，完全可以支持数以万计的并发连接，并且它的运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的web服务器不被暴露到网络上。 ​ haproxy实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space)实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以使每个CPU时间片(Cycle)做更多的工作。 haproxy的优点 （1）免费开源，稳定性也是非常好。单haproxy也跑得不错，稳定性可以与硬件级的F5相媲美。 （2）根据官方文档，haproxy可以跑满10Gbps，这个数值作为软件级负载均衡器是相当惊人的。 （3）haproxy支持连接拒绝:因为维护一个连接的打开的开销是很低的，有时我们很需要限制攻击蠕虫（attack bots），也就是说限制它们的连接打开从而限制它们的危害。这个已经为一个陷于小型DDoS攻击的网站开发了而且已经拯救了很多站点，这个优点也是其它负载均衡器没有的。 （4）haproxy支持全透明代理（已具备硬件防火墙的典型特点）:可以用客户端IP地址或者任何其他地址来连接后端服务器。这个特性仅在Linux 2.4/2.6内核打了tcp proxy补丁后才可以使用。这个特性也使得为某特殊服务器处理部分流量同时又不修改服务器的地址成为可能。 （5）haproxy现多于线上的Mysql集群环境，我们常用于它作为MySQL（读）负载均衡。 （6）自带强大的监控服务器状态的页面，实际环境中我们结合Nagios进行邮件或短信报警。 （7）HAProxy支持虚拟主机，许多朋友说它不支持虚拟主机是错误的，通过测试我们知道，HAProxy是支持虚拟主机的。 Haproxy的安装以在ubantu-16.04操作系统为例 1apt-get -y install haproxy 常用命令如下： 123ps -ef |grep haproxyhaproxy -vcat /etc/haproxy/haproxy.cfg Haproxy的配置启动监控界面123456789listen statsmode httpbind 0.0.0.0:1080stats enablestats hide-versionstats uri /statsstats realm Haproxy\ Statisticsstats auth admin:admin123stats admin if TRUE #启用管理功能 关键词解析balance balance用于定义负载均衡的算法，可用于defaults、listen和backend中。 balance使用方法如下： balance &lt;algorithm&gt; [ &lt;arguments&gt; ] balance url_param [check_post [&lt;max_wait&gt;]] 用于在负载均衡场景中挑选一个server，其仅应用于持久信息不可用的条件下或需要将一个连接重新派发至另一个服务器时。 balance支持的算法有： roundrobin：基于权重进行轮询，在服务器的处理时间保持均匀分布时，这是最平衡、最公平的算法。此算法是动态的，这表示其权重可以在运行时进行调整。不过在设计上，每个后端服务器仅能最多接受4128个连接。 source：将请求的源地址进行hash运算，并由后端服务器的权重总数相除后派发至某匹配的服务器。这可以使得同一个客户端IP的请求始终被派发至某特定的服务器；不过，当服务器权重总数发生变化时，如某服务器宕机或添加了新的服务器，许多客户端的请求可能会被派发至与此前请求不同的服务器；常用于负载均衡无cookie功能的基于TCP的协议；其默认为静态，不过也可以使用hash-type修改此特性。 static-rr：基于权重进行轮询，与roundrobin类似，但是为静态方法，在运行时调整其服务器权重不会生效；不过，其在后端服务器连接数上没有限制。 leastconn：新的连接请求被派发至具有最少连接数目的后端服务器；在有着较长时间会话的场景中推荐使用此算法，如LDAP、SQL等，其并不太适用于较短会话的应用层协议，如HTTP；此算法是动态的，可以在运行时调整其权重。 uri：对URI的左半部分(“问题”标记之前的部分)或整个URI进行hash运算，并由服务器的总权重相除后派发至某匹配的服务器；这可以使得对同一个URI的请求总是被派发至某特定的服务器，除非服务器的权重总数发生了变化；此算法常用于代理缓存或反病毒代理以提高缓存的命中率；需要注意的是，此算法仅应用于HTTP后端服务器场景；其默认为静态算法，不过也可以使用hash-type修改此特性。 url_param：通过为URL指定的参数在每个HTTP GET请求中将会被检索；如果找到了指定的参数且其通过等于号“=”被赋予了一个值，那么此值将被执行hash运算并被服务器的总权重相除后派发至某匹配的服务器；此算法可以通过追踪请求中的用户标识进而确保同一个用户ID的请求将被送往同一个特定的服务器，除非服务器的总权重发生了变化；如果某请求中没有出现指定的参数或其没有有效值，则使用轮叫算法对相应请求进行调度；此算法默认为静态的，不过其也可以使用hash-type修改此特性。 hdr()：对于每个HTTP请求，通过指定的HTTP首部将会被检索；如果相应的首部没有出现或其没有有效值，则使用轮叫算法对相应请求进行调度；其有一个可选选项“use_domain_only”，可在指定检索类似Host类的首部时仅计算域名部分以降低hash算法的运算量；此算法默认为静态的，不过其也可以使用hash-type修改此特性； bind bind仅能用于frontend和listen区段，用于定义一个或几个监听的套接词。 bind使用方法如下： bind []: [, …] bind []: [, …] interface ：可选选项，其可以为主机名、IPv4地址、IPv6地址或*。省略此选项、将其指定为*或0.0.0.0时，将监听当前系统的所有IPv4地址。 ：可以是一个特定的TCP端口，也可是一个端口范围(如 5005-5010)，代理服务器将通过指定的端口来接收客户端请求。 需要注意的是，每组监听的套接词在同一个实例上只能使用一次，而且小于1024的端口需要有特定权限的用户才能使用，这可能需要通过uid参数来定义。 ：指定物理接口的名称，仅能在Linux系统上使用。其不能使用接口别名，而仅能使用物理接口名称，而且只有管理有权限指定绑定的物理接口。 mode mode用于设定实例的运行模式或协议。当实现内容交换时，前端和后端必须工作于同一种模式(一般说来都是HTTP模式)，否则将无法启动实例。 mode可被用与listen、defaults、frontend、backend区段。 mode使用方法如下： mode { tcp|http|health } tcp：实例运行于纯TCP模式（即4层），在客户端和服务器端之间将建立一个全双工的连接，且不会对7层报文做任何类型的检查；此为默认模式，通常用于SSL、SSH、SMTP等应用。 http：实例运行于HTTP模式（即7层），客户端请求在转发至后端服务器之前将被深度分析，所有不与RFC格式兼容的请求都会被拒绝。 health：实例工作于health模式，其对入站请求仅响应“OK”信息并关闭连接，且不会记录任何日志信息；此模式将用于响应外部组件的健康状态检查请求；目前此模式已经废弃，因为tcp或http模式中的monitor关键词可完成类似功能； hash-type hash-type定义用于将hash码映射至后端服务器的方法；其不能用于frontend区段；可用方法有map-based和consistent，在大多数场景下推荐使用默认的map-based方法。 hash-type使用方法如下： hash-type map-based：hash表是一个包含了所有在线服务器的静态数组。其hash值将会非常平滑，会将权重考虑在列，但其为静态方法，对在线服务器的权重进行调整将不会生效，这意味着其不支持慢速启动。此外，挑选服务器是根据其在数组中的位置进行的，因此，当一台服务器宕机或添加了一台新的服务器时，大多数连接将会被重新派发至一个与此前不同的服务器上，对于缓存服务器的工作场景来说，此方法不甚适用。 consistent：hash表是一个由各服务器填充而成的树状结构；基于hash键在hash树中查找相应的服务器时，最近的服务器将被选中。此方法是动态的，支持在运行时修改服务器权重，因此兼容慢速启动的特性。添加一个新的服务器时，仅会对一小部分请求产生影响，因此，尤其适用于后端服务器为cache的场景。不过，此算法不甚平滑，派发至各服务器的请求未必能达到理想的均衡效果，因此，可能需要不时的调整服务器的权重以获得更好的均衡性。 log log为每个实例启用事件和流量日志，因此可用于所有区段。每个实例最多可以指定两个log参数，不过，如果使用了“log global”且”global”段已经定了两个log参数时，多余了log参数将被忽略。 log global log [ []] global：当前实例的日志系统参数同”global”段中的定义时，将使用此格式；每个实例仅能定义一次“log global”语句，且其没有任何额外参数。 ：定义日志发往的位置，其格式之一可以为，其中的port为UDP协议端口，默认为514；格式之二为Unix套接词文件路径，但需要留心chroot应用及用户的读写权限。 ：可以为syslog系统的标准facility之一。 ：定义日志级别，即输出信息过滤器，默认为所有信息；指定级别时，所有等于或高于此级别的日志信息将会被发送。 maxconn maxconn设定一个前端的最大并发连接数，因此，其不能用于backend区段。 maxconn使用方法如下： maxconn 对于大型站点来说，可以尽可能提高此值以便让haproxy管理连接队列，从而避免无法应答用户请求。当然，此最大值不能超出“global”段中的定义。此外，需要留心的是，haproxy会为每个连接维持两个缓冲，每个缓冲的大小为8KB，再加上其它的数据，每个连接将大约占用17KB的RAM空间。这意味着经过适当优化后，有着1GB的可用RAM空间时将能维护40000-50000并发连接。 如果为指定了一个过大值，极端场景下，其最终占据的空间可能会超出当前主机的可用内存，这可能会带来意想不到的结果；因此，将其设定了一个可接受值方为明智决定。其默认为2000。 default_backend default_backend定义在没有匹配的use_backend规则时为实例指定使用的默认后端服务器，因此，其不可应用于backend区段。在frontend和backend之间进行内容交换时，通常使用use-backend定义其匹配规则；而没有被规则匹配到的请求将由此参数指定的后端服务器接收。 default_backend使用方法如下： default_backend ：指定使用的后端的名称。 server server为后端声明一个server，因此，不能用于defaults和frontend区段。 server使用方法如下： server &lt;name&gt; &lt;address&gt;[:port][param *] &lt;name&gt;：为此服务器指定的内部名称，其将出现在日志及警告信息中；如果设定了http-send-server-name，它还将被添加至发往此服务器的请求首部中。 &lt;address&gt;：为此服务器的的IPv4地址，支持使用可解析的主机名，同时也支持域名，只不过在启动时需要解析主机名至相应的IPv4地址。 [:port]：指定将连接请求所发往的此服务器时的目标端口，其为可选项；未设定时，将使用客户端请求时的同一相端口。 [param*]：为此服务器设定的一系参数；其可用的参数非常多，具体请参考官方文档中的说明，下面仅说明几个常用的参数； 服务器或默认服务器参数： backup：设定为备用服务器，仅在负载均衡场景中的其它server均不可用于启用此server。 check：启动对此server执行健康状态检查，其可以借助于额外的其它参数完成更精细的设定，如： inter ：设定健康状态检查的时间间隔，单位为毫秒，默认为2000；也可以使用fastinter和downinter来根据服务器端状态优化此时间延迟； rise ：设定健康状态检查中，某离线的server从离线状态转换至正常状态需要成功检查的次数； fall ：确认server从正常状态转换为不可用状态需要检查的次数； cookie ：为指定server设定cookie值，此处指定的值将在请求入站时被检查，第一次为此值挑选的server将在后续的请求中被选中，其目的在于实现持久连接的功能； maxconn ：指定此服务器接受的最大并发连接数；如果发往此服务器的连接数目高于此处指定的值，其将被放置于请求队列，以等待其它连接被释放； maxqueue ：设定请求队列的最大长度； observe ：通过观察服务器的通信状况来判定其健康状态，默认为禁用，其支持的类型有“layer4”和“layer7”，“layer7”仅能用于http代理场景； redir ：启用重定向功能，将发往此服务器的GET和HEAD请求均以302状态码响应；需要注意的是，在prefix后面不能使用/，且不能使用相对地址，以免造成循环；例如： server srv1 192.168.5.174:80 redir http://www.baidu.com check weight ：权重，默认为1，最大值为256，0表示不参与负载均衡。 stats enable stats enable启用基于程序编译时默认设置的统计报告，stats enable不能用于frontend区段。只要没有另外的其它设定，它们就会使用如下的配置： stats uri : /stats stats realm : “HAProxy Statistics” stats auth : no authentication stats scope : no restriction 尽管stats enable一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期望的后果。 stats hide-version stats hide-version隐藏统计报告中haproxy版本号，不能用于frontend区段。默认情况下，统计页面会显示一些有用信息，包括haproxy的版本号。然而，向所有人公开haproxy的精确版本号是非常有风险的，因为它能帮助恶意用户快速定位版本的缺陷和漏洞。 stats realm stats realm启用统计报告并高精认证领域，不能用于“frontend”区段。 stats realm haproxy在读取realm时会将其视作一个单词，因此，中间的任何空白词符都必须使用反斜线进行转义。此参数仅在与“stats auth”配置使用时有意义。 ：实现HTTP基本认证时显示在浏览器中的领域名称，用于提示用户输入一个用户名和密码。 stats scope stats scope启用统计报告并限定报告的区段，不能用于frontend区段。 当指定此语句时，统计报告将仅显示其列举出区段的报告信息，所有其它区段的信息将被隐藏。如果需要显示多个区段的统计报告，此语句可以定义多次。需要注意的是，区段名称检测仅仅是以词符串比较的方式进行，它不会真检测指定的区段是否真正存在。 stats scope { | “.” } ：可以是一个listen、frontend或backend区段的名称，而“.”则表示stats scope语句所定义的当前区段。 stats auth stats auth启用带认证的统计报告功能并授权一个用户帐号，其不能用于frontend区段。 stats auth : ：授权进行访问的用户名； ：此用户的访问密码，明文格式； 此语句将基于默认设定启用统计报告功能，并仅允许其定义的用户访问，其也可以定义多次以授权多个用户帐号。可以结合“stats realm”参数在提示用户认证时给出一个领域说明信息。在使用非法用户访问统计功能时，其将会响应一个“401 Forbidden”页面。其认证方式为HTTP Basic认证，密码传输会以明文方式进行，因此，配置文件中也使用明文方式存储以说明其非保密信息故此不能相同于其它关键性帐号的密码。 stats admin stats admin在指定的条件满足时启用统计报告页面的管理级别功能，它允许通过web接口启用或禁用服务器，不过，基于安全的角度考虑，统计报告页面应该尽可能为只读的。此外，如果启用了HAProxy的多进程模式，启用此管理级别将有可能导致异常行为。 stats admin { if | unless } 目前来说，POST请求方法被限制于仅能使用缓冲区减去保留部分之外的空间，因此，服务器列表不能过长，否则，此请求将无法正常工作。因此，建议一次仅调整少数几个服务器。下面是两个案例，第一个限制了仅能在本机打开报告页面时启用管理级别功能，第二个定义了仅允许通过认证的用户使用管理级别功能。 backend stats_localhost stats enable stats admin if LOCALHOST backend stats_auth stats enable stats auth admin:password stats admin if TRUE option httplog option httplog启用记录HTTP请求、会话状态和计时器的功能。 option httplog [ clf ] clf：使用CLF格式来代替HAProxy默认的HTTP格式，通常在使用仅支持CLF格式的特定日志分析器时才需要使用此格式。 默认情况下，日志输入格式非常简陋，因为其仅包括源地址、目标地址和实例名称，而“option httplog”参数将会使得日志格式变得丰富许多，其通常包括但不限于HTTP请求、连接计时器、会话状态、连接数、捕获的首部及cookie、“frontend”、“backend”及服务器名称，当然也包括源地址和端口号等。 option logasap option logasap 启用提前将HTTP请求记入日志，不能用于backend区段。 默认情况下，HTTP请求是在请求结束时进行记录以便能将其整体传输时长和词节数记入日志，由此，传较大的对象时，其记入日志的时长可能会略有延迟。option logasap参数能够在服务器发送complete首部时即时记录日志，只不过，此时将不记录整体传输时长和词节数。此情形下，捕获Content-Length响应首部来记录传输的词节数是一个较好选择。 option forwardfor option forwardfor允许在发往服务器的请求首部中插入“X-Forwarded-For”首部。即启用获取客户端真实IP功能。 option forwardfor [ except ][ header ] [ if-none ] ：可选参数，当指定时，源地址为匹配至此网络中的请求都禁用此功能。 ：可选参数，可使用一个自定义的首部，如“X-Client”来替代“X-Forwarded-For”。有些独特的web服务器的确需要用于一个独特的首部。 if-none：仅在此首部不存在时才将其添加至请求报文问道中。 haproxy工作于反向代理模式，其发往服务器的请求中的客户端IP均为haproxy主机的地址而非真正客户端的地址，这会使得服务器端的日志信息记录不了真正的请求来源，“X-Forwarded-For”首部则可用于解决此问题。haproxy可以向每个发往服务器的请求上添加此首部，并以客户端IP为其value。 需要注意的是，haproxy工作于隧道模式，其仅检查每一个连接的第一个请求，因此，仅第一个请求报文被附加此首部。如果想为每一个请求都附加此首部，请确保同时使用了“option httpclose”、“option forceclose”和“option http-server-close”几个option。 errorfile errorfile在用户请求不存在的页面时，返回一个页面文件给客户端而非由haproxy生成的错误代码；可用于所有段中。 errorfile ：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504。 ：指定用于响应的页面文件。 例如： errorfile 400 /etc/haproxy/errorpages/400badreq.http errorfile 403 /etc/haproxy/errorpages/403forbid.http errorfile 503 /etc/haproxy/errorpages/503sorry.http rrorloc和errorloc302 errorloc errorloc302 请求错误时，返回一个HTTP重定向至某URL的信息；可用于所有配置段中。 ：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504； ：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向； 需要留意的是，这两个关键词都会返回302状态吗，这将使得客户端使用同样的HTTP方法获取指定的URL，对于非GET法的场景(如POST)来说会产生问题，因为返回客户的URL是不允许使用GET以外的其它方法的。如果的确有这种问题，可以使用errorloc303来返回303状态码给客户端。 errorloc303 errorloc303 请求错误时，返回一个HTTP重定向至某URL的信息给客户端，可用于所有配置段中。 ：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有400、403、408、500、502、503和504； ：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向； 例如： backend webserver server 172.16.100.6 172.16.100.6:80 check maxconn 3000 cookie srv01 server 172.16.100.7 172.16.100.7:80 check maxconn 3000 cookie srv02 errorloc 403 /etc/haproxy/errorpages/sorry.htm errorloc 503 /etc/haproxy/errorpages/sorry.htm 配置文件解析haproxy的配置文件主要包含以下几个部分： global全局配置、defaults默认配置、监控页面配置、frontend配置、backend配置。 global：全局配置参数，进程级的，用来控制Haproxy启动前的一些进程及系统设置。 defaults：配置一些默认的参数，可以被frontend，backend，listen段继承使用。 frontend：用来匹配接收客户所请求的域名，uri等，并针对不同的匹配，做不同的请求处理。 backend：定义后端服务器集群，以及对后端服务器的一些权重、队列、连接数等选项的设置。 listen：我将其理解为frontend和backend的组合体。 global全局配置全局配置的标志参数为global，全局配置主要用于设定义全局参数，属于进程级的配置，通常和操作系统配置有关。 进程管理及安全相关的参数: chroot ：修改haproxy的工作目录至指定的目录并在放弃权限之前执行chroot()操作，可以提升haproxy的安全级别，不过需要注意的是要确保指定的目录为空目录且任何用户均不能有写权限。 使用方法为： chroot /var/lib/haproxy daemon：让haproxy以守护进程的方式工作于后台，其等同于“-D”选项的功能。当然，也可以在命令行中以“-db”选项将其禁用。 uid：以指定的uid身份运行haproxy进程。 user：同uid参数，但使用的是用户名。 gid ：以指定的gid运行haproxy，建议使用专用于运行haproxy的gid，以免因权限问题带来风险。 group ：同gid参数，不过指定的组名。 log [max level [min level]]：定义全局的syslog服务器，最多可以定义两个。 log-send-hostname []：在syslog信息的首部添加当前主机名，可以为“string”指定的名称，也可以缺省使用当前主机名。 nbproc ：指定启动的haproxy进程个数，只能用于守护进程模式的haproxy。默认只启动一个进程，鉴于调试困难等多方面的原因，一般只在单进程仅能打开少数文件描述符的场景中才使用多进程模式。 pidfile：将haproxy的进程写入pid文件。 ulimit-n：设定每进程所能够打开的最大文件描述符数目，默认情况下其会自动进行计算，因此不推荐修改此选项。 stats socket ：定义统计信息保存位置。 性能调整相关的参数： maxconn ：设定每个haproxy进程所接受的最大并发连接数，其等同于命令行选项“-n”；“ulimit -n”自动计算的结果正是参照此参数设定的。 maxpipes ：haproxy使用pipe完成基于内核的tcp报文重组，此选项则用于设定每进程所允许使用的最大pipe个数。每个pipe会打开两个文件描述符，因此，“ulimit -n”自动计算时会根据需要调大此值；默认为maxconn/4，其通常会显得过大。 noepoll：在Linux系统上禁用epoll机制。 nokqueue：在BSE系统上禁用kqueue机制。 nopoll：禁用poll机制。 nosepoll：在Linux禁用启发式epoll机制。 nosplice：禁止在Linux套接字上使用内核tcp重组，这会导致更多的recv/send系统调用；不过，在Linux 2.6.25-28系列的内核上，tcp重组功能有bug存在。 spread-checks ：在haproxy后端有着众多服务器的场景中，在精确的时间间隔后统一对众服务器进行健康状况检查可能会带来意外问题；此选项用于将其检查的时间间隔长度上增加或减小一定的随机时长。 tune.bufsize ：设定buffer的大小，同样的内存条件下，较小的值可以让haproxy有能力接受更多的并发连接，较大的值可以让某些应用程序使用较大的cookie信息；默认为16384，其可以在编译时修改，不过强烈建议使用默认值。 tune.chksize ：设定检查缓冲区的大小，单位为字节；更大的值有助于在较大的页面中完成基于字符串或模式的文本查找，但也会占用更多的系统资源；不建议修改。 tune.maxaccept ：设定haproxy进程内核调度运行时一次性可以接受的连接的个数，较大的值可以带来较大的吞吐率，默认在单进程模式下为100，多进程模式下为8，设定为-1可以禁止此限制；一般不建议修改。 tune.maxpollevents ：设定一次系统调用可以处理的事件最大数，默认值取决于OS。其值小于200时可节约带宽，但会略微增大网络延迟，而大于200时会降低延迟，但会稍稍增加网络带宽的占用量。 tune.maxrewrite ：设定为首部重写或追加而预留的缓冲空间，建议使用1024左右的大小。在需要使用更大的空间时，haproxy会自动增加其值。 tune.rcvbuf.client ：定义在客户端内核套接字接收缓冲区的大小，单位为字节，建议不要调整此值。 tune.rcvbuf.server ：设定内核套接字中服务端或客户端接收缓冲的大小，单位为字节；强烈推荐使用默认值。 tune.sndbuf.client：定义在客户端内核套接字发送缓冲区的大小，单位为字节，建议不要调整此值。 tune.sndbuf.server：定义在服务端内核套接字发送缓冲区的大小，单位为字节，建议不要调整此值。 上边的这些指令大多也是作为了解即可，在实际中并不常会调整这些参数。 debug相关的参数： debug：在调度haproxy时可以启用此参数，但在生产环境不应该启用。 quiet：haproxy启动后不会显示任何相关信息，这与在命令行启动haproxy时加上参数“-q”相同。 defaults默认配置defaults段用于为所有其它配置段提供默认参数，这配置默认配置参数可由下一个defaults所重新设定。 下面提供一个defaults模版配置，如下： defaults mode http 设置haproxy的运行模式，有三种｛http|tcp|health｝。注意：如果haproxy中还要使用4层的应用（mode tcp）的话，不建议在此定义haproxy的运行模式。 log global 设置日志继承全局配置段的设置。 option httplog 表示开始打开记录http请求的日志功能。 option dontlognull 如果产生了一个空连接，那这个空连接的日志将不会记录。 option http-server-close 打开http协议中服务器端关闭功能，使得支持长连接，使得会话可以被重用，使得每一个日志记录都会被记录。 option forwardfor except 127.0.0.0/8 如果上游服务器上的应用程序想记录客户端的真实IP地址，haproxy会把客户端的IP信息发送给上游服务器，在HTTP请求中添加”X-Forwarded-For”字段,但当是haproxy自身的健康检测机制去访问上游服务器时是不应该把这样的访问日志记录到日志中的，所以用except来排除127.0.0.0，即haproxy身。 option redispatch 当与上游服务器的会话失败(服务器故障或其他原因)时，把会话重新分发到其他健康的服务器上,当原来故障的服务器恢复时，会话又被定向到已恢复的服务器上。还可以用”retries”关键字来设定在判定会话失败时的尝试连接的次数。 retries 3 向上游服务器尝试连接的最大次数，超过此值就认为后端服务器不可用。 option abortonclose 当haproxy负载很高时，自动结束掉当前队列处理比较久的链接。 timeout http-request 10s 客户端发送http请求的超时时间。 timeout queue 1m 当上游服务器在高负载响应haproxy时，会把haproxy发送来的请求放进一个队列中，timeout queue定义放入这个队列的超时时间。 timeout connect 5s haproxy与后端服务器连接超时时间，如果在同一个局域网可设置较小的时间。 timeout client 1m 定义客户端与haproxy连接后，数据传输完毕，不再有数据传输，即非活动连接的超时时间。 timeout server 1m 定义haproxy与上游服务器非活动连接的超时时间。 timeout http-keep-alive 10s 设置新的http请求连接建立的最大超时时间，时间较短时可以尽快释放出资源，节约资源。 timeout check 10s 健康检测的时间的最大超时时间。 maxconn 3000 最大并发连接数。 contimeout 5000 设置成功连接到一台服务器的最长等待时间，默认单位是毫秒，新版本的haproxy使用timeout connect替代，该参数向后兼容。 clitimeout 3000 设置连接客户端发送数据时的成功连接最长等待时间，默认单位是毫秒，新版本haproxy使用timeout client替代。该参数向后兼容。 srvtimeout 3000 设置服务器端回应客户度数据发送的最长等待时间，默认单位是毫秒，新版本haproxy使用timeout server替代。该参数向后兼容。 监控页面配置listen admin_status frontend和backend的组合体,监控组的名称，按需自定义名称。 bind 0.0.0.0:1080 配置监听端口。 mode http 配置监控运行的模式，在这为http模式。 log 127.0.0.1 local3 err 配置错误日志记录。 stats refresh 5s 配置每隔5秒自动刷新监控页面。 stats uri /stats 配置监控页面的url。 stats realm Haproxy\ Statistics 配置监控页面的提示信息。 stats auth admin:admin 配置监控页面的用户和密码admin,可以设置多个用户名。如下： stats auth admin1:admin1 配置监控页面的用户和密码admin1。 stats hide-version 配置隐藏统计页面上的HAproxy版本信息。 stats admin if TRUE 配置手工启用/禁用,后端服务器(haproxy-1.4.9以后版本)。 frontend配置frontend web_demo 定义一个名为 web_demo的frontend。 bind 0.0.0.0:80 定义haproxy前端部分监听的端口。 mode http 定义为http模式。 log global 继承global中log的定义。 option forwardfor 使后端server获取到客户端的真实IP。 acl php_web path_end .php 定义一个名叫php_web的acl，当请求的url末尾是以.php结尾的，将会被匹配到。 use_backend php_server if php_web 如果满足策略php_web时，就将请求交予backend php_server处理。 default_backend backend_default 如果以上策略都不满足时，就将请求交予default_backend处理。 12345678910111213141516171819202122232425262728293031323334353637383940acl使用如下：acl 自定义acl名称 acl方法 -i [匹配的路径或者方法]hdr_reg(host),hdr_dom(host),hdr_beg(host),url_sub,url_dir,path_beg,path_end-i 表示不区分大小写,后边跟上匹配的路径或文件或正则表达式与ACL一起使用的参数还有use_backend,usebackend后面需要跟上一个backend实例名,表示在满足ACL规则后去请求哪个backend实例,与use_backend对应的还有default_backend参数,表示在没有满足ACL条件的时候默认使用哪个backend后端例如：acl static_down nbsrv(static_server) lt 1定义一个名叫static_down的acl，当backend static_sever中存活机器数小于1时会被匹配到。#acl php_web url_reg /*.phpacl php_web path_end .php定义一个名叫php_web的acl，当请求的url末尾是以.php结尾的，将会被匹配到，上面两种写法任选其一。#acl static_web url_reg /*.(css|jpg|png|jpeg|js|gif)$acl static_web path_end .gif .png .jpg .css .js .jpeg定义一个名叫static_web的acl，当请求的url末尾是以.css、.jpg、.png、.jpeg、.js、.gif结尾的，将会被匹配到，上面两种写法任选其一。acl is_ilanni hdr_beg(host) -i ilanni.test.com定义一个名叫is_ilanni的acl，当请求的是以ilanni.test.com开头的主机的话，将会被匹配到。其中-i表示忽略大小写。acl is_dg hdr_beg(host) dg.test.com定义一个名叫is_dg的acl，当请求的是以dg.test.com开头的主机的话，将会被匹配到。acl is_171 hdr_beg(host) 192.168.5.171定义一个名叫is_171的acl，当请求的是以192.168.5.171开头的主机的话，将会被匹配到。acl is_ip src 192.168.5.140定义一个名叫is_ip的acl，当客户端的IP是192.168.5.140的话，将会被匹配到。use_backend php_server if static_down如果满足策略static_down时，就将请求交予backend php_server处理。use_backend php_server if php_web如果满足策略php_web时，就将请求交予backend php_server处理。use_backend static_server if static_web如果满足策略static_web时，就将请求交予backend static_server处理。use_backend acl if is_171 is_ip如果同时满足is_171和is_ip这两条策略时，就将请求交予backend acl处理。use_backend mui_acl if is_171 is_ip is_port如果同时满足is_171、is_ip和is_port这三条策略时，就将请求交予backend mui_acl处理。use_backend dgserver if is_dg如果满足策略is_dg时，就将请求交予backend dgserver处理。use_backend ilanni if is_ilanni如果满足策略is_ilanni时，就将请求交予backend ilanni处理。use_backend 171server if is_171如果满足策略is_171时，就将请求交予backend 171server处理。default_backend backend_default如果以上策略都不满足时，就将请求交予default_backend处理。 backend配置backend dgserver 定义dgserver服务器组 balance source 定义负载均衡方式，roundrobin平均方式 mode http option httpchk GET /index.html 心跳检测的文件 server web1 192.168.5.171:8080 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 服务器定义，maxconn 1024 表示该服务器的最大连接数，check inter 2000是检测心跳频率，rise 2是2次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重 Haproxy的使用示例haproxy 的ssl 配置（处理https）方式一：haproxy 本身提供ssl 证书，后面的web 服务器走正常的http配置示例如下： 12345678910111213141516frontend https_frontend bind *:443 ssl crt /etc/ssl/certs/servername.pem ####关键##### mode http option httpclose option forwardfor reqadd X-Forwarded-Proto:\ https default_backend web_serverbackend web_server mode http balance roundrobin cookie SERVERID insert indirect nocache server s1 192.168.250.47:80 check cookie s1 server s2 192.168.250.49:80 check cookie s2 注意：这里的pem 文件是下面两个文件合并而成： cat servername.crt servername.key |tee servername.pem 附录：简单地演示生成自签名证书的方式 123456789101112131415$ sudo mkdir /etc/ssl/xip.io$ sudo openssl genrsa -out /etc/ssl/xip.io/xip.io.key 1024$ sudo openssl req -new -key /etc/ssl/xip.io/xip.io.key -out /etc/ssl/xip.io/xip.io.csr&gt; Country Name (2 letter code) [AU]:US&gt; State or Province Name (full name) [Some-State]:Connecticut&gt; Locality Name (eg, city) []:New Haven&gt; Organization Name (eg, company) [Internet Widgits Pty Ltd]:SFH&gt; Organizational Unit Name (eg, section) []:&gt; Common Name (e.g. server FQDN or YOUR name) []:*.xip.io&gt; Email Address []:&gt; Please enter the following &apos;extra&apos; attributes to be sent with your certificate request&gt; A challenge password []:&gt; An optional company name []:$ sudo openssl x509 -req -days 365 -in /etc/ssl/xip.io/xip.io.csr -signkey /etc/ssl/xip.io/xip.io.key -out /etc/ssl/xip.io/xip.io.crt$ sudo cat /etc/ssl/xip.io/xip.io.crt /etc/ssl/xip.io/xip.io.key | sudo tee /etc/ssl/xip.io/xip.io.pem 当购买真正的证书 时，你不一定会获取拼接后的文件。你可以要自己拼接它们。然而，很多机构也会提供一份拼接好的文件给你。如果你没有获取到拼接后的文件，则它可能不是一个 pem 文件，而是 bundle、cert、cert、key文件或一些相同概念但名称类似的文件。 方式二：haproxy 本身只提供代理，后面的web服务器https又称SSL穿透，不需要重新编译支持ssl，简单方便。需要后面的web服务器配置好ssl 即可。 配置示例如下： 123456789101112frontend https_frontend bind *:443 mode tcp default_backend web_serverbackend web_server mode tcp balance roundrobin stick-table type ip size 200k expire 30m stick on src server s1 192.168.250.47:443 server s2 192.168.250.49:443#注意，这种模式下mode 必须是tcp 模式 haproxy的tcp应用haproxy代理ssh为了安全起见，要求所有业务服务器都关闭公网的连接，只开放haproxy所在的服务器，并且其他业务服务器的ssh连接通过haproxy来实现。 实际业务，访问192.168.5.171的8098端口就是访问192.168.5.174的ssh端口。 haproxy代理mysql为了安全起见，要求mysql数据库的连接只能通过内网IP，但是因为使用的是云数据库，所以如果公司内部要连接数据库的话要通过haproxy来实现。实际业务，访问192.168.5.171的8099端口就是访问192.168.7.7的3306端口。 以上两个需求的配置如下： 因为是haproxy的7层和4层混合使用，所以在defaults中，我们不定义haproxy的运行模式。 注意：有关http模式的相关配置参数不要出现在default中。 123456789.....listen 8099bind 0.0.0.0:8099mode tcpserver 174_22 192.168.5.174:22 maxconn 1024 weight 5 check inter 2000 rise 2 fall 3listen 8098bind 0.0.0.0:8098mode tcpserver 77_3306 192.168.7.7:3306 maxconn 1024 weight 5 check inter 2000 rise 2 fall 3 参考：http://www.ilanni.com/?s=haproxy http://cbonte.github.io/haproxy-dconv/1.6/intro.html#3 https://www.oschina.net/translate/haproxy-ssl-termation-pass-through?lang=chs&amp;page=2# http://virtuallyhyper.com/2013/05/configure-haproxy-to-load-balance-sites-with-ssl/ http://www.rackspace.com/knowledge_center/article/setting-up-haproxy http://www.cnblogs.com/MacoLee/p/5853413.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GNS3的安装部署]]></title>
      <url>%2F2017%2F04%2F19%2FGNS3%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%2F</url>
      <content type="text"><![CDATA[GNS3下载首先我提供了自己的GNS3的下载地址如下： 链接：http://pan.baidu.com/s/1jIl0UH4 密码：7s5e GNS3的安装配置然后我们安装GNS3 ，双击GNS3-1.4.6-all-in-one，运行到如下图全选。 GNS3 的使用基于Local server的GNS使用首次进入会有向导，我们选择如下，然后下一步下一步，基于Local server导入ISO image，中间过程出现一些提示框，都选择是。 基于GNS3 VM的使用首先我们部署GNS3.VM虚拟机，解压VMware.Workstation1.4.6.zip，并将虚拟机导入vmware中。导入后启动虚拟机。 待续 。。。。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(6)]]></title>
      <url>%2F2017%2F04%2F17%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-6%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》和《史上最“牛”的 Cisco 路由器配置与管理手册》总结网络必备的知识。 本篇章涉及以下内容： OSPF协议 OSPF 术语链路 链路就是一个网络或者一个被指定给任一给定网络的路由器接口。当一个接口被添加到 OSPF 进程时，它就被 OSPF 认定是一个链路。这个链路或接口都将有一个与它关联的状态信息( up 或 down)，以及一个或多个 IP 地址。 路由器 ID 路由器 ID( RID) 是一个用来标识此路由器的 IP 地址。 邻居 邻居可以是两个或更多的路由器，这些路由器的某个接口是连接在同一个公共网络上，比如两个通过点到点串行链路连接在一起的路由器。 邻接 邻接是指两个 OSPF 路由器之间的关系，这两个路由器之间允许直接交换路由更新数据。 Hello协议 OSPF 的 Hello 协议能够动态地发现邻居，并维护邻居关系。 Hello 数据包和链路状态通告 (LSA) 共同用于建立并维护拓扑数据库。 Hello 数据包使用的是组播地址 224.0.0.5 0。 邻居关系数据库 邻居关系数据库是一个 OSPF 路出器的列表，这些路由器的 Hello 数据包相互可见 。 拓扑数据库 拓扑数据库中包含有来自为同一区域接收的所有链路状态通告数据包中的信息。 链路状态通告 链路状态通告 (LSA) 是一个 OSPF 数据包，它包含着 OSPF 路由器中共享的链路状态和路由选择信息。 指定路由器 无论什么时候，当 OSPF 路由器被连接到同一多路访问网络时，都需要选择一个指定路由器 (DR) 。 一个 DR ，它负责将路由选择信息分发到广播网络或链路中其他路由器上，或收集其他路由器的路由选择信息。这样就可以确保所有路由器上的拓扑表是完全同步的。 备用指定路由器 备用指定路由器 (BDR) 是在多路访问链路上随时准备着的待命的 DR。BDR从 OSPF 邻接路由器上接收所有的路由更新，但并不泛发 LSA 更新。 OSPF 区域 一个 OSPF 区域是一组相邻的网络和路由器。 广播(多路访问) 广播(多路访问)网络允许多个设备连接(或者是访问)到同一个网络上，并通过将单一数据包投递到网络中所有的结点来提供广播能力，如以太网。在 OSPF 中，每个广播多路访问网络都必须选出一个 DR 和一个 BDR。 非广播多路访问 非广播多路访问 (NBMA) 网络是那些诸如帧中继、 X.25 和异步传输模式(ATM) 等类型的网络。这些网络允许多路访问，但不具备以太网那样的广播能力。因此，要实现恰当的功能， NBMA 网络需要特殊的 OSPF 配置，并且邻居关系必须详细定义。 点到点 点到点被定义为一种由两个路由器间的直接连接组成的网络拓扑类型，这一连接为路由器提供单一的通信路径。 点到多点 点到多点也被定义为一种网络拓扑类型，这种拓扑中包含单个路由器上的单一接口与多个目的路由器间的一系列连接。所有位于不同路由器上的接口都共享属于同一网络的点到多点的连接。与点到点一样，这里不需要 DR 或 BDR。 OSPF协议介绍​ 每个 OSPF 路由器维护相同 AS 拓扑结构的数据库。从这个数据库里，构造出最短路径树来计算出路由表。当拓扑结构发生变化时， OSPF 协议能迅速重新计算出路径，而只产生少量的路由协议流量。此外，所有的 OSPF 路由选择分组的交换都是经过验证的。 OSPF 与 RIP采用链路状态路由算法。RIP 采用的相对简单的“距离矢量”路由算法，仅以“距离”（ Distance）作为度量； 而 OSPF采用的是更加复杂的“链路状态”路由算法包括线路带宽、 端口状态、端口带宽、端口优先级、链路稳定性等方面，是以“开销”（ cost）作为其度量的。 可划分不同区域。在一个 OSPF 网络中，只能有一个 AS，但在这个 AS 中可以划分多个区域（ Area），同一个区域的不同 OSPF 路由器进程可以一样，也可以不一样。 在 OSPF 路由协议中，每一个区域中的路由器都按照该区域中定义的链路状态算法来计算网络拓扑结构，这意味着每一个区域都有着该区域独立的网络拓扑数据库及网络拓扑图。对于每一个区域， 其网络拓扑结构在区域外是不可见的，同样，在每一个区域中的路由器对其域外的其余网络结构也不了解。这样做有利于减少网络中链路状态数据包在全网范围内的广播，也是 OSPF 将其路由域或一个 AS 划分成很多个区域的重要原因。 有不同路由器角色。OSPF 可以划分不同的多个区域，所以就涉及相同区域内部，以及不同区域间的路由问题。这也就决定了在 OSPF 网络中存在多种不同类型的路由器， 担当不同角色。如区域内部路由器、区域边界路由器、 AS 边界路由器。 收敛性能更高。RIP 协议中，所有的路由都由跳数来描述，到达目的地的路由最大不超过 15 跳，这就限制了 RIP 的服务半径，同时需要定期（默认为 30 秒）在网络邻居路由器上通告自己的整个路由表信息，以便及时对网络拓扑结构的改变进行收敛。OSPF 是基于链路状态的路由协议不再交换整个路由表，而是同步各路由器对网络状态的认识，即链路状态数据库，然后通过 Dijkstra 最短路径算法计算出网络中各目的地址的最优路由。这样 OSPF 路由器间不需要定期地交换大量路由数据，而只是保持着一种连接，仅在链路状态发生变化时，才通过组播方式对进行触发式路由更新。 无环路。从OSPF 网络的两层结构来说， OSPF 网络中包括唯一的骨干区域和许多普通的非骨干区域。在普通区域内部的路由采用的是 SPF 链路状态路由算法，而在区域之间的路由采用的是 DV（距离矢量）路由算法。同时要求所有非骨干区域必须与骨干区域连接（可以是直接连接，也可以是通过虚拟链路进行间的接连接），非骨干区域之间的通信也必须通过骨干区域，形成了一种 Hub-Spoken 星状结构。 这样所有非骨干区域没有了直连，不具备形成环路的条件。 而在同一个区域内部， OSPF 所采用的 SPF（Shortest Path First，最短路径优先）路由算法所生成的单向 SPT（Shortest Path Tree， 最短路径树）又保证了区域内部没有路由环路。 两者结合就决定了整个 OSPF 网络不会出现路由环路了。 AS和Area​ AS 是一组使用相同路由协议交换路由信息的路由器， 也称路由域（Routing Domain）。在 OSPF 网络中，只有在同一 AS 中的路由器才会相互交换链路状态信息；在同一个 AS 中，所有的 OSPF 路由器都维护一个相同 AS 结构描述的数据库。该数据库中存放的是路由域中相应链路的状态信息。 OSPF 路由器正是通过这个数据库计算出其 OSPF 路由表的。而且 OSPF 可以将个 AS 分割成多个小的区域，便于网络的拓展，而且每个 OSPF 路由器只在区域内部学习完整的链路状态信息，便于路由更新管理。 ​ 为了减小 LSDB 的大小，降低 SPF 运算的系统资源开销，减少路由表项数， OSPF 允许 AS被划分成多个连续网络群组，这就是“域”（Area）。在 OSPF 路由协议中，每一个区域中的路由器都独立计算网络拓扑结构，区域间的网络结构情况是互不可见的。在每一个区域中的路由器也不会了解外部区域的网络结构，可谓是“各自为政，互不干涉”。这就意味着每一个区域都有着该区域独立的网络拓扑数据库及网络拓扑图。这样做的好处就是有利于减少网络中 LSA 报文在整个 OSPF 网络范围内的通告。 OSPF 网络路由器类型​ 内部路由器（Internal Router， IR）当一个 OSPF 路由器上所有直连的链路（也就是路由器上所有接口）都处于同一个区域（不直接与其他区域相连）时，我们称这种路由器为“内部路由器”。 内部路由器上仅仅运行其所属区域的 OSPF 运算法则，仅生成区域内部的路由表项。​ 区域边界路由器（Area Border Router， ABR）当一个路由器有多个接口，其中至少有一个接口与其他区域相连时，我们称之为“区域边界路由器”。区域边界路由器的各对应接口运行与其相连区域定义的 OSPF 运算法则，具有相连的每一个区域的网络结构数据，并且了解如何将该区域的链路状态信息通告至骨干区域，再由骨干区域转发至其余区域。​ AS 边界路由器（Autonomous System Boundary Router， ASBR）AS 边界路由器是与 AS 外部的路由器互相交换路由信息的 OSPF 路由器。该路由器在 AS 内部通告其所得到的 AS 外部路由信息，这样 AS 内部的所有路由器都知道 AS 边界路由器的路由信息。 AS 边界路由器的定义是与前面几种路由器的定义相独立的，一个 AS 边界路由器可以是一个区域内部路由器，或是一个区域边界路由器。​ 骨干路由器（Backbone Router）骨干路由器是指至少有一个接口定义为属于骨干区域的路由器。任何一个与骨干区域互联的ABR 或者 ASBR 也将成为骨干路由器。 DR 和 BDR​ DR 就是集中负责一个区域内各路由器间的 LSU 交换和邻接关系建立，相当于这个区域的负责人一样。这个负责人负责其他成员的信息反馈、 转发和广播（他保存有所有成员之间的联系信息），其他每个成员也都与这个负责人建立单线联系，而其他成员之间彼此不建立联系。这样就不需要每个成员都保存整个团体会员的联系信息，也不必每个成员都与其他成员建立联系，管理更加简单。 ​ BDR 是用于在 DR 失效后接替 DR 的工作（也可不选举 BDR），在 DR 正常工作时，它不担当 DR 的职责。在同一个OSPF 区域中，每个路由器都和 DR， BDR 相连。当区域中的路由器有路由更新时， DR Other 路由器不会向其他 DR Other 路由器发送自己的LSU，而只会向 224.0.0.6 这个组播地址发送，然后由 224.0.0.6 这个地址会把 DR Other 发上来的LSU 组播给 DR/BDR， 之后 DR/BDR 都会收到这个 DR Other 的路由更新。在 DR/BDR 收到从224.0.0.6 发过来的 LSU 后又会把这些 LSU 发给 224.0.0.5 这个组播地址，这时 224.0.0.5 会把 LSU泛洪到区域内的所有 DR Other 路由器上。 对于DR 和 BDR 的选举是这样的： DR 是通过接口优先级（Interface Priority）进行选举，最高优先级的路由器被选为DR，次高者被选为 BDR； 如果接口优先级相同，就按 router-id 进行选举，由最大到次大选举DR、 BDR。但 DR、 BDR的选举不支持抢占（Preemption）， 也就是一旦选举完成，即使新加一个优先级更高的设备也不会进行重新的选择，相反只有在 DR 或者 BDR 出问题的时候才会发生重选。 OSPF 路由计算基本过程整个 OSPF 路由计算过程可分为：邻接关系建立→DR/BDR 选举→发送 LSA→创建路由表→维护路由表这五大基本步骤。 邻接关系建立​ 路由器首先发送拥有自身 ID 信息（Loopback 端口或最大的 IP 地址）的 Hello 报文。与之相邻的路由器如果收到这个 Hello 报文，就将这个报文内的 ID 信息加入到自己的 Hello 报文内。然后在后面发送的 Hello 报文中就包括了原来所接收到的邻居路由器的 ID 信息。如果路由器的某端口收到从其他路由器发送的含有自身 ID 信息的 Hello 报文，则它根据该端口所在网络类型确定是否可以与对端路由器建立邻接关系。 DR/BDR 选举​ DR 和 BDR 是由同一网段中所有的路由器根据路由器优先级、 Router ID 通过 Hello 报文选举出来的，只有优先级大于 0 的路由器才具有选举资格。 具体的选举过程如下：（1）在与一个或多个邻居之间的双向通信建立起来之后，本地路由器对每个邻居发送来的 Hello包中的优先级、 DR 和 BDR 域进行检查。此时所有路由器都宣称自己为 DR（将它们自己的接口地址置于 Hello 包的 DR 域中）；而且所有路由器都宣称自己为 BDR（将它们自己的接口地址置于Hello 包的 BDR 域中）。（2）如果一或多个备选路由器将它（们）自身的接口地址置于 DR 域中，拥有最高优先级的邻居将被宣告为 DR。如果路由器优先级一样，拥有最高 Router ID 的邻居将被选举出来。（3）然后再将自身的接口地址置于 BDR 域中的路由器中选择拥有最高优先级的路由器作为BDR。如果这些宣称自己为 BDR 路由器的优先级相等，则拥有最高 Router ID 的邻居将被选举作为 BDR。（4）如果没有任何路由器被宣告为 BDR，拥有最高优先级的非 DR 邻居路由器将被宣告为BDR；如果多个优先级相同的这样的路由器，则拥有最高 Router ID 的邻居将被选举作为 BDR。 发送 LSA​ 路由器与路由器之间首先利用 Hello 报文的 ID 信息确认主从关系，然后主从路由器相互交换部分链路状态信息。每个路由器对信息进行分析比较，如果收到的信息有新的内容，路由器将要求对方发送完整的链路状态信息。这个状态完成后，路由器之间建立完全邻接关系，同时各邻接路由器拥有自己独立的、完整的链路状态数据库。 ​ 在多路访问网络内， DR 与 BDR 互换信息，并同时与本子网内其他路由器交换链路状态信息。在 Point-to-Point（点对点）或 Point-to-MultiPoint（点对多点）网络中，相邻路由器之间会直接交换链路状态信息。 创建路由表​ 当网络重新稳定下来，也可以说 OSPF 路由协议收敛下来时，所有的路由器会根据其各自的链路状态信息数据库，采用 SPF（最短路径优先）算法计算并创建路由表。 OSPF 路由器依据链路状态数据库的内容，独立地用 SPF 算法计算出到每一个目的网络的路径，并将路径存入路由表中。该路由表中包含路由器到每一个可到达目的地的开销以及到达该目的地所要转发的下一个路由器（next-hop）。 ​ OSPF 利用开销来计算路由路径性能的， 开销最小者即为最短路径。在配置 OSPF 路由器时可根据实际情况，如链路带宽、时延等设置链路的开销大小；开销越小，则该链路被选为路由的可能性越大。这里的开销是根据链路类型来计算的，不同的链路类型对应的开销值不一样。 维护路由表​ 当链路状态发生变化时， OSPF 通过泛洪过程广播网络上的其他路由器。 OSPF 路由器接收到包含有新信息的链路状态更新报文，将更新自己的链路状态数据库，然后用 SPF 算法重新计算路由表。在重新计算过程中，路由器继续使用旧路由表，直到 SPF 完成新的路由表计算。新的链路状态信息将发送给其他路由器。值得注意的是，即使链路状态没有发生改变， OSPF 路由信息也会自动更新，默认时间为 30 分钟。 OSPF 报头​ OSPF 报文直接封装为 IP 协议报文，因为 OSPF 是专为 TCP/IP 网络而设计的路由协议。 OSPF报文主要有 5 种： Hello 报文、 DD（Database Description， 数据库描述） 报文、 LSR（LinkStateRequest， 链路状态请求） 报文、 LSU（LinkState Update， 链路状态更新） 报文和 LSAck（LinkStateAcknowledgment， 链路状态应答） 报文，它们使用相同的 OSPF 报头格式。 Version： 版本字段， 占 1 个字节，指出所采用的 OSPF 协议版本号，目前最高版本为 OSPFv4，即值为 4（对应二进制就是 0100）。Packet Type： 报文类型字段，标识对应报文的类型。 前面说了 OSPF 有 5 种报文，分别是：Hello 报文、 DD 报文、 LSR 报文、 LSU 报文、 LSAck 报文。Packet Length：包长度字段， 占 2 个字节。它是指整个报文（包括 OSPF 报头部分和后面各报文内容部分）的字节长度。Router ID： 路由器 ID 字段，占 4 个字节，指定发送报文的源路由器 ID。Area ID：区域 ID 字段，占 4 个字节，指定发送报文的路由器所对应的 OSPF 区域号。Checksum：校验和字段， 占 2 个字节， 是对整个报文（包括 OSPF 报头和各报文具体内容，但不包括下面的 Authentication 字段）的校验和， 用于对端路由器校验报文的完整性和正确性。AuType：认证类型字段， 占 2 个字节，指定所采用的认证类型， 0 为不认证， 1 为进行简单认证， 2 采用 MD5 方式认证。Authentication：认证字段， 占 8 个字节，具体值根据不同认证类型而定：认证类型为不认证时，此字段没有数据， 认证类型为简单认证时，此字段为认证密码，认证类型为 MD5 认证时，此字段为 MD5 摘要消息。 Quagga实现OSPF路由器​ quagga是一个主要部署在linux上的开源路由软件，是软路由的一种。 大部分企业的数据中心，在不同的网络里传输数据主要是依靠硬件路由器，在Linux系统部署上quagga也可以实现路由功能。 Quagga覆盖了所有重要的路由协议：OSPFv2和V3；RIP版本1，2和NG；甚至BGP。Quagga不止支持unix，也同样支持Linux，Solaris和FreeBSD，NetBSD等系统。 在CentOS上安装Quagga： yum install quagga Quagga包括了几个协同工作的守护进程。Zebra: 核心守护进程，负责内核接口和静态路由。Ospfd: IPv4 OSPF 守护进程。 常见问题]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(5)]]></title>
      <url>%2F2017%2F04%2F17%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-5%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： IP路由 路由选择基础 ​ 路由选择是指将分组从一个设备通过互联网络发往位于不同网络上的另一个设备的操作。路由器不关注网络中的主机，而只关注互联起来的网络以及通往各个网络的最佳路径。目标主机的逻辑网络地址用来获取通过可路由网络传送到指定网络中的分组，主机的硬件地址用来将分组从路由器投递到正确的目标主机上。 要实现对分组的路由，路由器至少必须了解以下内容: 目的地址;借以获取远程网络信息的相邻路由器;到达所有远程网络的可能路由;到达每个远程网络的最佳路由;维护并验证路由选择信息的方式。 IP 路由选择过程 Host_A 上的某个用户对 Host_B 的 IP 地址执行了 ping 操作。 (1) 因特网控制报文协议 (ICMP )将创建一个回应请求数据包(此数据包的数据域中只包含字母)。 (2) ICMP 会将这一有效负荷递交给因特网协议 (IP )，IP协议会用它创建一个分组 。 至少，源 IP地址、目标 IP 地址和值为 01h 的协议字段)将被封装到此分组中。当此分组到达目的方时，这些内容就会告诉接收方主机应该将这个有效负荷交付给哪个协议来处理。 (3) 一旦这个分组被创建， IP 协议就需要判断目标 IP 地址的位置，判断此目的方位于本地网络还是某个远程网络。 (4) 由于 IP 协议判定这是一个远程的跨网络请求，而要将这一分组路由到远程网络，就必须将它发送给默认网关。 (5) 主机 172.16.10.2 (Host_A) 的默认网关被配置为 172.16.10.1 。要将这一分组发送给此默认网关，我们就必须知道路由器的 Ethemet 0 ( 172.16.10.1 就是配置给它的 IP 地址)接口的硬件地址。为什么要这样?这是因为只有知道了接口的硬件地址，分组才可以向下递交给数据链路层，并在那里完成帧的组建，然后再将帧发送给与 172.16.10.0 网络相连接的路由器接口。 (6) 接下来，需要检查主机的 ARP 缓存，查看此默认网关的 IP 地址是否已被解析为一个硬件地址。 ​ 如果已被解析，此分组就可被传送到数据链路层以组建成帧。 ​ 如果在主机的 ARP 缓存中没有被解析的硬件地址，那么用于查找 172.16.10.1 硬件地址的 ARP广播将被发送到本地网络上。这时，示例中的路由器会响应这个请求，并提供 Ethemet0 的硬件地址，此后主机会接收并缓存这个地址。 (7) 一旦分组和目的方的硬件地址被交付给数据链路层，局域网驱动程序负责选用适合所在局域网类型(本例中为以太网)的介质访问方式。通过将控制信息封装到此分组上帧就被创建了。在这个帧中，附加有目的方硬件地址和源硬件地址，以及以太网类型字段，这个字段用于描述给数据链路层交付帧中分组的网络层协议，在本示例中，这个协议为IP。在帧的尾部是 FCS (Frame CheckSequence ，帧校验序列)字段，这个部分装载了 CRC (循环冗余校验)的计算结果。 (8) 一旦帧创建完成，这个帧将被交付给物理层，物理层会以一次一比特的方式将帧发送到物理介质上。 (9) 这时，此冲突域中的每台设备都会接收这些比特，并将它们重新组建成帧。每个设备都会对接收到的内容进行 CRC 运算，并与帧中 FCS 字段的内容进行比对。如果值不匹配，接收到的帧将被丢弃。 ​ 如果这个 CRC 计算机结果与帧中 FCS 字段的内容匹配，接着将检查目的方的硬件地址与自己( 本示例中指的是路由器的 Ethemet 0 接口 )是否匹配。 ​ 如果匹配，则接下来查看以太网类型字段，以获悉完成数据后续处理的网络层协议。 (10) 将分组从帧中取出，并将其他部分丢弃。然后分组被递交给以太网类型字段中列出的协议一示例中是 IP 。 (11) IP 将接收这个分组，并检查它的 IP 目的地址。由于分组的目的地址与配置到此接收路由器上的各个地址均不匹配，此路由器会在其路由选择表中查找目的方的 IP 网络的地址。 (12) 在此路由选择表中需要包含网络 172.16 .2 0.0 的相关表项，否则路由器会立即将收到的分组丢弃，并同时向发送数据源方设备回送一个携带有目标网络不可达信息的 ICMP 报文。(13) 如果路由器在路由选择表中查找到了关于目的方网络的内容，则分组将被交换到指定的输出接口一在本示例中为接口 Ethernet 1 。(14) 路由器将此分组交换到 Ethernet 1 的缓冲区内。(15) 此 Ethernet 1 的缓冲需要获得目的方主机的硬件地址，因此会首先查看 ARP 缓存。 ​ 如果 Host-B 的硬件地址已经被解析并保存在路由器的 ARP 缓存中，那么此分组和硬件地址将被递交到数据链路层，用于帧的组建。 ​ 如果此硬件地址没有被解析，则路由器将从 Ethernet 1 发出一个 ARP 请求，用以查找 172.16.20.2 的硬件地址。Host-B 将用它的硬件地址进行响应，随后此分组和目的方的硬件地址都会被传递给数据链路层，用以组装成帧。(16) 数据链路层将使用目标硬件地址和源硬件地址、以太网类型字段及帧尾部的 FCS 字段创建帧。随后这个帧将被递交到物理层，并由物理层以逐比特发送的方式发送到物理介质上。(17) Host_B 将接收此帧，并立即运行 CRC。如果运算的结果与 FCS 字段中的内容匹配，则检查帧中的目标硬件地址。如果主机认定地址也是匹配的，则检查帧中以太网类型字段的值，判断将分组向上递交的网络层协议一一本示例中为 IP 。(18) 在网络层，IP会接收这个分组，并对 IP 报头运行 CRC 。如果校验通过， IP 随后将检查分组中目标地址。由于它们最终是匹配的，接下来要检查的就是分组的协议字段，并据此了解分组有效负荷的交付对象。(19) 此有效负荷将被递交给 ICMP ，后者知道这是一个回应请求数据。 ICMP 将负责应答这个请求，它首先立即丢弃这个接收到的分组然后产生一个新的有效负荷作为回应应答数据。(20) 这样一个包含有源方地址、目的方地址、协议字段和有效负荷的一个新分组就被创建出来了。而该分组的目的方设备就是 Host A。(21) 在递交给 IP 后，它将对这个目的方 IP 地址的位置进行判断，判断这一地址指向的是一个本地局域网中的设备，还是一个位于远程网络上的设备。由于示例中的目的方设备位于远程网络，此分组将首先被发送给默认网关。(22) 默认网关的 IP 地址可以在 Windows 主机的注册表中找到。此外，为了实现 IP 地址到硬件地址的解析还需要查看 ARP 的缓存。(23) 一旦找到默认网关的硬件地址，则目的方的硬件地址会随分组一起被递交给数据链路层，以便完成帧的创建。(24) 数据链路层会将收到的分组内容封装起来，并在帧头中包含下列内容:​ 目的方硬件地址和源方的硬件地址;​ 值为 Ox0800 (IP) 的以太网类型字段;​ 值为 CRC 运算结果的 FCS 字段。(25) 之后，帧将向下递交给物理层，以逐比特的方式发送到网络介质上。(26) 路由器的 Ethemet 1 接口将接收这些比特位，并将它们重新组建为帧。然后进行 CRC 运算，帧中的 FCS 字段被用于验证计算结果是否匹配。(27) 当 CRC 通过后，路由器将检查帧中携带的硬件目的地址。由于路由器的接口地址与这一地址是匹配的，于是帧中封装的分组将被取出，随后路由器会查看帧的以太网类型字段，以确定应接收此数据包的网络层协议。(28) 由于以太网类型字段中指定的是 IP ，于是分组被递交给了网络层的 IP。 IP 将首先对其 IP报头运行 CRC ，然后检查帧中的目的方 IP 地址。 IP 并不会像数据链珞层那样对分组运行完全的 CRC ，它只对 IP 报头进行校验，只关注报头可能出现的错误。 ​ 由于分组中携带的 IP 目的方地址与该路由器各个接口的 IP 地址不匹配，于是路由器需要查看路由选择表，以找出一条通往 172.16.10.0 网络的路由。如果表中没有关于目的网络的路由，则路由器会将该分组立即丢弃。​ 有一点需要简要说明，当(如果)分组是在返回源主机的途中被丢弃，由于这是一个不知原因的错误，我们通常看到的会是请求超时这样的信息。如果出现的错误是由某种已知原因导致的，比如在前往目的主机的途中，某路由器的路由选择表里没有可用的路由，这时得到的信息将会是目标主机不可达一类的信息。根据这些提示内容，我们就可以判断问题是发生在前往目的主机的途中，还是出现在返回源主机的过程中。(29) 在这里，路由器是知道如何到达网络 172.16.10.0 的，用于输出的接口就是 Ethernet 0 ，于是分组被交换到接口 Ethernet 0 上。(30) 路由器将检查 ARP 缓存，以确定 172.16.10.2 的硬件地址是否已经被解析。(31) 由于在完成将分组发送给 Host B 的过程中， 172.16.10.2 的硬件地址已经被缓存起来，因此这一硬件地址将随分组一起被递交给数据链路层。(32) 数据链路层将使用这个目的方的硬件地址和源方的硬件地址以及类型为 IP的以太网类型字段完成帧的创建。随后对这个帧进行 CRC 运算，并将运算结果放入 FCS 字段中。(33) 接下来这个帧将被递交给物理层，以逐比特的方式发送到本地网络中。(34) 目标主机将会接收这个帧，然后运行 CRC ，验证目的方的硬件地址，并查看以太网类型字段中的内容，以认定处理这个分组的上层协议。(35) IP 是指定的接收者，随后这个分组将被递交给网络层的 IP ，它将检查帧中的协议字段，以确定下一步的操作。 IP 发现需要将此有效负荷交给 ICMP ，之后 ICMP 将确定此分组是一个 ICMP 应答回复。(36) ICMP 通过向用户界面发送一个惊叹号( ! )表明已经接收到一个回复。随后， ICMP 将尝试继续发送后续的 4 个应答请求给目的方的主机。 ​ 这里的 36 个简单步骤可以帮助我们理解整个IP路由选择过程。这里的关键性问题是，即使对于大型的网络，路由选择的实现过程也是如此。只是在非常大的互联网络中，分组在到达目标主机之前需要经过更多的路由转发。需要重点记忆的是，当 Host A 向 Host B 发送分组时，所采用的目标硬件地址是默认网关的以太网接口地址。之所以会这样，是因为数据帧只在本地网络中有效，它不可以被直接发送到远程网络中。因此，发往远程网络的分组必须通过默认网关进行转发。 测试认知： 在主机 4 发出的数据帧中，目的地址字段中应该放置哪个地址? 主机 4 将使用的目标地址是 Lab B 路由器的 Fa0/0 接口的 MAC 地址。 当分组到达主机 1 时，在分组报头中的 OSI 第 3 层协议的源地址可能是什么? 在第 3 层，源 IP地址就是主机 4 的地址，并且分组中的目标地址就是主机1 的IP地址。 主机 4 正在向连接到 Lab A 路由器上的电子邮件服务器传输文件。由主机 4 发出的数据中所携带的第 2 层目的方地址应该是什么? 主机 4 发出的数据中携带的第 2 层目的方地址将是 Lab B 路由器 Fa0/0接口的 MAC 地址。 当数据帧被电子邮件服务器接收时，它所携带的源 MAC 地址将会是什么? 电子邮件服务器接收的数据帧携带的源 MAC 地址将是 Lab A 路由器的 Fa0/0接口地址。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron的防火墙原理]]></title>
      <url>%2F2017%2F04%2F10%2Fneutron%E7%9A%84%E9%98%B2%E7%81%AB%E5%A2%99%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[确切的说这是fwaas，即防火墙即是服务。 防火墙与安全组区别防火墙一般放在网关上，用来隔离子网之间的访问。因此，防火墙即服务也是在网络节点上（具体说来是在路由器命名空间中）来实现。 安全组的对象是虚拟网卡，由L2 Agent来实现，比如neutron_openvswitch_agent 和 neutron_linuxbridge_agent，会在计算节点上通过配置 iptables 规则来限制虚拟网卡的进出访问。防火墙可以在安全组之前隔离外部过来的恶意流量，但是对于同个子网内部不同虚拟网卡间的通讯不能过滤（除非它要跨子网）。 部署防火墙我部署的是metaka版本 在控制节点和网络节点： yum install openstack-neutron-fwaas python-neutron-fwaas 控制节点： 修改配置文件 /etc/neutron/neutron.conf 1service_plugins = router,neutron.services.firewall.fwaas_plugin.FirewallPlugin 配置数据库 1neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini --service fwaas upgrade 配置dashboard 12vim /usr/share/openstack-dashboard/openstack_dashboard/local/local_settings.py&apos;enable_firewall&apos; = True 网络节点： 修改配置文件/etc/neutron/fwaas_driver.ini 1234567[DEFAULT][fwaas]driver = neutron.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriverenabled = True[service_providers]service_provider= FIREWALL:Iptables:neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver:default 然后重启服务 123systemctl restart neutron-server #控制节点systemctl restart httpd.service memcached.service #控制节点systemctl restart neutron-l3-agent.service # 网络节点 防火墙的使用示例创建防火墙规则 创建防火墙策略 创建防火墙并应用的router路由器 防火墙分析流程我事先在防火墙上下了2个规则，’icmp source 10.0.0.0/24 drop ‘, ‘tcp source 2.2.2.0/24 des 3.3.3.0/24 drop’,并应用到路由器。 INPUT iptables –line-numbers -vnL INPUT 1234ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL INPUTChain INPUT (policy ACCEPT 489 packets, 19560 bytes)num pkts bytes target prot opt in out source destination 1 749 29960 neutron-l3-agent-INPUT all -- * * 0.0.0.0/0 0.0.0.0/0 iptables –line-numbers -vnL neutron-l3-agent-INPUT 12345ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-INPUTChain neutron-l3-agent-INPUT (1 references)num pkts bytes target prot opt in out source destination 1 0 0 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 mark match 0x1/0xffff2 0 0 DROP tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:9697 可见在INPUT接受所有的数据包 OUTPUT iptables –line-numbers -vnL OUTPUT 123456789101112131415ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL OUTPUTChain OUTPUT (policy ACCEPT 3 packets, 120 bytes)num pkts bytes target prot opt in out source destination 1 14 560 neutron-filter-top all -- * * 0.0.0.0/0 0.0.0.0/0 2 14 560 neutron-l3-agent-OUTPUT all -- * * 0.0.0.0/0 0.0.0.0/0ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-filter-topChain neutron-filter-top (2 references)num pkts bytes target prot opt in out source destination 1 14 560 neutron-l3-agent-local all -- * * 0.0.0.0/0 0.0.0.0/0 ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-localChain neutron-l3-agent-local (1 references)num pkts bytes target prot opt in out source destination ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-OUTPUTChain neutron-l3-agent-OUTPUT (1 references)num pkts bytes target prot opt in out source destination 可见在OUTPUT链没有什么规则 FORWARD 1234567891011121314151617181920ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL FORWARDChain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination 1 0 0 neutron-filter-top all -- * * 0.0.0.0/0 0.0.0.0/0 2 0 0 neutron-l3-agent-FORWARD all -- * * 0.0.0.0/0 0.0.0.0/0 ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-filter-topChain neutron-filter-top (2 references)num pkts bytes target prot opt in out source destination 1 14 560 neutron-l3-agent-local all -- * * 0.0.0.0/0 0.0.0.0/0 ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-localChain neutron-l3-agent-local (1 references)num pkts bytes target prot opt in out source destination ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-FORWARDChain neutron-l3-agent-FORWARD (1 references)num pkts bytes target prot opt in out source destination 1 0 0 neutron-l3-agent-scope all -- * * 0.0.0.0/0 0.0.0.0/0 2 0 0 neutron-l3-agent-iv45e26bf33 all -- * qr-+ 0.0.0.0/0 0.0.0.0/0 3 0 0 neutron-l3-agent-ov45e26bf33 all -- qr-+ * 0.0.0.0/0 0.0.0.0/0 4 0 0 neutron-l3-agent-fwaas-defau all -- * qr-+ 0.0.0.0/0 0.0.0.0/0 5 0 0 neutron-l3-agent-fwaas-defau all -- qr-+ * 0.0.0.0/0 0.0.0.0/0 neutron-l3-agent-FORWARD很重要，在没有防火墙应用到路由之前，只有条目1，应用防火墙之后，生成了2，3，4，5 我们分别看一下它们具体的内容。 12345678910111213141516171819ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-iv45e26bf33Chain neutron-l3-agent-iv45e26bf33 (1 references)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 state INVALID2 0 0 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED3 0 0 DROP tcp -- * * 2.2.2.0/24 3.3.3.0/24 tcp spt:30 dpt:304 0 0 DROP icmp -- * * 10.0.0.0/24 0.0.0.0/0ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-ov45e26bf33Chain neutron-l3-agent-ov45e26bf33 (1 references)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 state INVALID2 0 0 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED3 0 0 DROP tcp -- * * 2.2.2.0/24 3.3.3.0/24 tcp spt:30 dpt:304 0 0 DROP icmp -- * * 10.0.0.0/24 0.0.0.0/0 ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-fwaas-defauChain neutron-l3-agent-fwaas-defau (2 references)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 这正是我在前面提到的规则，我们发现一条规则下发后分别存在进出两条规则在router中，即neutron-l3-agent-iv45e26bf33 ，neutron-l3-agent-ov45e26bf33 ，用于进数据网络的包的默认处理和出数据网络的包的默认处理。 neutron-l3-agent-fwaas-defau用于默认丢弃没有被以上规则处理的所有包。 我们在此基础上又添加一条规则’‘udp source 7.7.0.0/16 des 8.8.8.0/24 REJECT’’，默认新加的规则在前两者之前，当然我们可以控制这条规则的位置，加入我们把它放在前面两个规则之间，查看如下： 12345678910111213141516ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-ov45e26bf33Chain neutron-l3-agent-ov45e26bf33 (1 references)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 state INVALID2 0 0 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED3 0 0 DROP tcp -- * * 2.2.2.0/24 3.3.3.0/24 tcp spt:30 dpt:304 0 0 REJECT udp -- * * 7.7.0.0/16 8.8.8.0/24 udp spt:89 dpt:900 reject-with icmp-port-unreachable5 0 0 DROP icmp -- * * 10.0.0.0/24 0.0.0.0/0 ip netns exec qrouter-6d975099-f0d9-49a8-bae8-8bf936c95e1c iptables --line-numbers -vnL neutron-l3-agent-iv45e26bf33Chain neutron-l3-agent-iv45e26bf33 (1 references)num pkts bytes target prot opt in out source destination 1 0 0 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 state INVALID2 0 0 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED3 0 0 DROP tcp -- * * 2.2.2.0/24 3.3.3.0/24 tcp spt:30 dpt:304 0 0 REJECT udp -- * * 7.7.0.0/16 8.8.8.0/24 udp spt:89 dpt:900 reject-with icmp-port-unreachable5 0 0 DROP icmp -- * * 10.0.0.0/24 0.0.0.0/0 防火墙有一定顺序，一条一条匹配的，所以规则的顺序也是值得关注的。 参考：http://www.cnblogs.com/sammyliu/p/4658746.html http://blog.csdn.net/wylfengyujiancheng/article/details/53540816]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron的安全组原理]]></title>
      <url>%2F2017%2F04%2F09%2FNeutron%E7%9A%84%E5%AE%89%E5%85%A8%E7%BB%84%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[​ Security group通过Linux IPtables来实现，为此，在Compute节点上引入了qbr*这样的Linux传统bridge（iptables规则目前无法加载到直接挂在到ovs的tap设备上）。 安全组的INPUT、OUTPUT、FORWARD ​ 其中id的前10位数字被用作虚机对外连接的qbr（同时也是tap口）的id。i或o加上前9位数字被用作安全组chain的id。所有的规则默认都在Compute节点上的filter表（默认表）中实现，分别来查看filter表的INPUT、OUTPUT、FORWARD三条链上的规则。 INPUTiptables –line-numbers -vnL INPUT 可以看到，跟安全组相关的规则被重定向到neutron-openvswi-INPUT。 查看其规则，只有一条。 iptables –line-numbers -vnL neutron-openvswi-INPUT iptables –line-numbers -vnL neutron-openvswi-o46364368-5 iptables –line-numbers -vnL neutron-openvswi-s46364368-5 这条chain主要检查从vm发出来的网包，是否是openstack所分配的IP和MAC，如果不匹配，则禁止通过。这将防止利用vm上进行一些伪装地址的攻击。 OUTPUT iptables –line-numbers -vnL OUTPUT 分别跳转到neutron-filter-top和neutron-openvswi-OUTPUT iptables –line-numbers -vnL neutron-filter-top 该chain目前无规则。 iptables –line-numbers -vnL neutron-openvswi-OUTPUT 该chain目前无规则。 FORWARD iptables –line-numbers -vnL FORWARD 同样跳转到neutron-filter-top，无规则。跳转到neutron-openvswi-FORWARD。 iptables –line-numbers -vnL neutron-openvswi-FORWARD iptables –line-numbers -vnL neutron-openvswi-sg-chain 如果是网桥从tap-XXX端口发出到VM的流量，则跳转到neutron-openvswi-i9LETTERID，例如i46364368-5；如果是从tap-XXX端口进入到网桥的（即vm发出来的）流量，则跳转到neutron-openvswi-o9LETTERID，例如o46364368-5。 neutron-openvswi-i9LETTERID允许安全组中配置的策略（允许ssh、ping等）和dhcp reply通过。默认的neutron-openvswi-sg-fallback将drop所有流量。 iptables –line-numbers -vnL neutron-openvswi-i46364368-5 iptables –line-numbers -vnL neutron-openvswi-o46364368-5 neutron-openvswi-o9LETTERID将跳转到 neutron-openvswi-s46364368-5，允许DHCP Request和匹配VM的源IP和源MAC的流量通过,同时允许安全组中配置的策略（允许ssh、ping等）通过。 iptables –line-numbers -vnL neutron-openvswi-s46364368-5 整体逻辑 快速查找安全组规则从前面分析可以看出，某个vm的安全组相关规则的chain的名字，跟vm的id的前9个字符有关。 因此，要快速查找qbr-XXX上相关的iptables规则，可以用iptables -S列出（默认是filter表）所有链上的规则，其中含有id的链即为虚拟机相关的安全组规则。其中–physdev-in表示即将进入某个网桥的端口，–physdev-out表示即将从某个网桥端口发出。 iptables -S | grep tap4ca9818f-53 可以看出，进出tap-XXX口的FORWARD链上的流量都被扔到了neutron-openvswi-sg-chain这个链，neutron-openvswi-sg-chain上是security group具体的实现（两条规则，访问虚拟机的流量扔给neutron-openvswi-i583c7038-d；从虚拟机出来的扔给neutron-openvswi-o583c7038-d）。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron三层网络服务实现原理]]></title>
      <url>%2F2017%2F04%2F06%2FNeutron%E4%B8%89%E5%B1%82%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[​ Neutron 对虚拟三层网络的实现是通过其 L3 Agent （neutron-l3-agent）。该 Agent 利用 Linux IP 栈、route 和 iptables 来实现内网内不同网络内的虚机之间的网络流量，以及虚机和外网之间网络流量的路由和转发。为了在同一个Linux 系统上支持可能的 IP 地址空间重叠，它使用了 Linux network namespace 来提供隔离的转发上下文。 NameSpace技术​ 在二层网络上，VLAN 可以将一个物理交换机分割成几个独立的虚拟交换机。类似地，在三层网络上，Linux network namespace（netns） 可以将一个物理三层网络分割成几个独立的虚拟三层网络。 ​ Network namespace （netns）从 Linux 2.6.24 版本开始添加，直到 2.6.29 添加完成。每个 netns 拥有独立的 （virtual）network devices, IP addresses, IP routing tables, /proc/net directory, ports 等等。新创建的 netns 默认只包含 loopback device。除了这个设备，每个 network device，不管是物理的还是虚拟的网卡还是网桥等，都只能存在于一个 netns。而且，连接物理硬件的物理设备只能存在于 root netns。其它普通的网络设备可以被创建和添加到某个 netns。 添加 network namespace ​ ip netnas add &lt;network namespace name&gt; ​ Example: ​ ip netns add nstest 列表所有 netns ​ ip netns list 删除某 netns ​ ip netns delete &lt;network namespace name&gt; 在 network namespace 中运行命令 ​ ip netns exec &lt;network namespace name&gt; &lt;command&gt; ​ Example using the namespace from above: ​ ip netns exec nstest ip addr 添加 virtual interfaces 到 network namespace ​ ip link add veth-a type veth peer name veth-b #创建一对虚拟网卡veth-a 和 veth-b，两者由一根虚拟网线连接 将 veth-b 添加到 network namespace ​ ip link set veth-b netns nstest 设置 vi 的 IP 地址 ​ ip netns exec nstest ip addr add 10.0.0.2/24 dev veth-b ​ ip netns exec nstest ip link set dev veth-b up 设置默认namespace的vi地址 ​ ip addr add 10.0.0.1/24 dev veth-a​ ip link set dev veth-a up ping ​ ip netns exec nstest ping 10.0.0.1 ​ PING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. ​ bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=0.054 ms 查看路由表和 iptbales ​ ip netns exec nstest route ​ ip netns exec nstest iptables -L Iptables​ Neutron 主要用到 filter 表和 nat 表，其中， filter 用来实现安全组（Security Group）和 防火墙（FWaas）；nat 主要用来实现 router。 ​ iptables其实是个client，供用户去管理防火墙。相关的请求最后会发送相关内核模块，如ip_tables。ip_tables内核模块主要用于组织iptables使用的表，链，规则。netfilter是一套技术框架，ip_tables依托于netfilter来注册各种hooks实现对数据包的具体控制。一些厂商的防火墙，入侵检测，入侵防御系统什么的基本依托于Netfilter来实现(从事过相关开发)。 NEW,ESTABLISHED,RELATED,INVALID状态 NEW: conntrack模块看到的某个连接第一个包，它即将被匹配了。比如，我们看到一个SYN包，是我们所留意的连接的第一个包，就要匹配它。第一个包也可能不是SYN包，但它仍会被认为是NEW状态。ESTABLISHED: 已经注意到两个方向上的数据传输，而且会继续匹配这个连接的包。处于ESTABLISHED状态的连接是非常容易理解的。只要发送并接到应答，连接就是ESTABLISHED的了。一个连接要从NEW变为ESTABLISHED，只需要接到应答包即可，不管这个包是发往防火墙的，还是要由防火墙转发的。ICMP的错误和重定向等信息包也被看作是ESTABLISHED，只要它们是我们所发出的信息的应答。RELATED 当一个连接和某个已处于ESTABLISHED状态的连接有关系时，就被认为是RELATED的了。换句话说，一个连接要想是RELATED的，首先要有一个ESTABLISHED的连接。这个ESTABLISHED连接再产生一个主连接之外的连接，这个新的连接就是RELATED的了，比如ftp的父子链接。INVALID 非以上状态的包。 iptables自定义连 如果想自行定义规则链,可以通过-N参数,然后通过-j/–jump跳转过来就可以了。 12iptables -N 链名iptables ... -j 链名 下面我们查看openstack中的router是如何使用iptables的。 首先当路由器创建完成并加入网络（9.9.9.0/24）之后，我们查看一下它iptable信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# Generated by iptables-save v1.6.0 on Tue Jul 18 21:49:49 2017*nat:PREROUTING ACCEPT [0:0]:INPUT ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-snat - [0:0]:neutron-postrouting-bottom - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A POSTROUTING -j neutron-postrouting-bottom-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697-A neutron-l3-agent-snat -j neutron-l3-agent-float-snat-A neutron-postrouting-bottom -m comment --comment &quot;Perform source NAT on outgoing traffic.&quot; -j neutron-l3-agent-snatCOMMIT# Completed on Tue Jul 18 21:49:49 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 21:49:49 2017*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:neutron-filter-top - [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-local - [0:0]:neutron-l3-agent-scope - [0:0]-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-filter-top-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-filter-top-A OUTPUT -j neutron-l3-agent-OUTPUT-A neutron-filter-top -j neutron-l3-agent-local-A neutron-l3-agent-FORWARD -j neutron-l3-agent-scope-A neutron-l3-agent-INPUT -m mark --mark 0x1/0xffff -j ACCEPT-A neutron-l3-agent-INPUT -p tcp -m tcp --dport 9697 -j DROP-A neutron-l3-agent-scope -o qr-b111bb2e-84 -m mark ! --mark 0x4000000/0xffff0000 -j DROPCOMMIT# Completed on Tue Jul 18 21:49:49 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 21:49:49 2017*raw:PREROUTING ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-PREROUTING - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUTCOMMIT# Completed on Tue Jul 18 21:49:49 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 21:49:49 2017*mangle:PREROUTING ACCEPT [0:0]:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-floatingip - [0:0]:neutron-l3-agent-mark - [0:0]:neutron-l3-agent-scope - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-mark-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-scope-A neutron-l3-agent-PREROUTING -m connmark ! --mark 0x0/0xffff0000 -j CONNMARK --restore-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-floatingip-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j MARK --set-xmark 0x1/0xffff-A neutron-l3-agent-float-snat -m connmark --mark 0x0/0xffff0000 -j CONNMARK --save-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-scope -i qr-b111bb2e-84 -j MARK --set-xmark 0x4000000/0xffff0000COMMIT# Completed on Tue Jul 18 21:49:49 2017 输出是分段的,每个段落一个表,*开头后面跟着表名。:开头的行是对链匹配次数的总结,后面跟着统计信息,[数据包:字节数]。后面跟着的是具体规则。最后跟着COMMIT表示一个表的结束。 然后我们将该路由器关联一个外部网络(10.0.99.0/24),我们发现该网络的所有虚拟机访问外网时候，会将凡是到达外网络的数据都进行SNAT为其外部地址10.0.99.2，但是没有相应的表项导致外网中的虚拟机是无法访问内部虚拟机的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091root@netagent:~# ip netns exec qrouter-71d8932f-3782-470f-b3a2-f80203f96885 iptables-save# Generated by iptables-save v1.6.0 on Tue Jul 18 22:14:04 2017*nat:PREROUTING ACCEPT [98:22227]:INPUT ACCEPT [1:325]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-snat - [0:0]:neutron-postrouting-bottom - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A POSTROUTING -j neutron-postrouting-bottom-A neutron-l3-agent-POSTROUTING ! -i qg-37790cfc-43 ! -o qg-37790cfc-43 -m conntrack ! --ctstate DNAT -j ACCEPT-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697-A neutron-l3-agent-snat -j neutron-l3-agent-float-snat-A neutron-l3-agent-snat -o qg-37790cfc-43 -j SNAT --to-source 10.0.99.2-A neutron-l3-agent-snat -m mark ! --mark 0x2/0xffff -m conntrack --ctstate DNAT -j SNAT --to-source 10.0.99.2-A neutron-postrouting-bottom -m comment --comment &quot;Perform source NAT on outgoing traffic.&quot; -j neutron-l3-agent-snatCOMMIT# Completed on Tue Jul 18 22:14:04 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 22:14:04 2017*filter:INPUT ACCEPT [26:8892]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:neutron-filter-top - [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-local - [0:0]:neutron-l3-agent-scope - [0:0]-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-filter-top-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-filter-top-A OUTPUT -j neutron-l3-agent-OUTPUT-A neutron-filter-top -j neutron-l3-agent-local-A neutron-l3-agent-FORWARD -j neutron-l3-agent-scope-A neutron-l3-agent-INPUT -m mark --mark 0x1/0xffff -j ACCEPT-A neutron-l3-agent-INPUT -p tcp -m tcp --dport 9697 -j DROP-A neutron-l3-agent-scope -o qr-b111bb2e-84 -m mark ! --mark 0x4000000/0xffff0000 -j DROPCOMMIT# Completed on Tue Jul 18 22:14:04 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 22:14:04 2017*raw:PREROUTING ACCEPT [123:30794]:OUTPUT ACCEPT [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-PREROUTING - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUTCOMMIT# Completed on Tue Jul 18 22:14:04 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 22:14:04 2017*mangle:PREROUTING ACCEPT [118:29354]:INPUT ACCEPT [23:7908]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-floatingip - [0:0]:neutron-l3-agent-mark - [0:0]:neutron-l3-agent-scope - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A neutron-l3-agent-POSTROUTING -o qg-37790cfc-43 -m connmark --mark 0x0/0xffff0000 -j CONNMARK --save-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-mark-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-scope-A neutron-l3-agent-PREROUTING -m connmark ! --mark 0x0/0xffff0000 -j CONNMARK --restore-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-floatingip-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j MARK --set-xmark 0x1/0xffff-A neutron-l3-agent-float-snat -m connmark --mark 0x0/0xffff0000 -j CONNMARK --save-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-mark -i qg-37790cfc-43 -j MARK --set-xmark 0x2/0xffff-A neutron-l3-agent-scope -i qg-37790cfc-43 -j MARK --set-xmark 0x4000000/0xffff0000-A neutron-l3-agent-scope -i qr-b111bb2e-84 -j MARK --set-xmark 0x4000000/0xffff0000COMMIT# Completed on Tue Jul 18 22:14:04 2017 Floating Ip我们将9.9.9.0/24网络中的虚拟机（9.9.9.3）分配一个floatingIP（10.0.99.3），查看router的iptables-save。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394root@netagent:~# ip netns exec qrouter-71d8932f-3782-470f-b3a2-f80203f96885 iptables-save# Generated by iptables-save v1.6.0 on Tue Jul 18 22:23:42 2017*nat:PREROUTING ACCEPT [48:12000]:INPUT ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-snat - [0:0]:neutron-postrouting-bottom - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A POSTROUTING -j neutron-postrouting-bottom-A neutron-l3-agent-OUTPUT -d 10.0.99.3/32 -j DNAT --to-destination 9.9.9.3-A neutron-l3-agent-POSTROUTING ! -i qg-37790cfc-43 ! -o qg-37790cfc-43 -m conntrack ! --ctstate DNAT -j ACCEPT-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697-A neutron-l3-agent-PREROUTING -d 10.0.99.3/32 -j DNAT --to-destination 9.9.9.3-A neutron-l3-agent-float-snat -s 9.9.9.3/32 -j SNAT --to-source 10.0.99.3-A neutron-l3-agent-snat -j neutron-l3-agent-float-snat-A neutron-l3-agent-snat -o qg-37790cfc-43 -j SNAT --to-source 10.0.99.2-A neutron-l3-agent-snat -m mark ! --mark 0x2/0xffff -m conntrack --ctstate DNAT -j SNAT --to-source 10.0.99.2-A neutron-postrouting-bottom -m comment --comment &quot;Perform source NAT on outgoing traffic.&quot; -j neutron-l3-agent-snatCOMMIT# Completed on Tue Jul 18 22:23:42 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 22:23:42 2017*filter:INPUT ACCEPT [608:211608]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:neutron-filter-top - [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-local - [0:0]:neutron-l3-agent-scope - [0:0]-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-filter-top-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-filter-top-A OUTPUT -j neutron-l3-agent-OUTPUT-A neutron-filter-top -j neutron-l3-agent-local-A neutron-l3-agent-FORWARD -j neutron-l3-agent-scope-A neutron-l3-agent-INPUT -m mark --mark 0x1/0xffff -j ACCEPT-A neutron-l3-agent-INPUT -p tcp -m tcp --dport 9697 -j DROP-A neutron-l3-agent-scope -o qr-b111bb2e-84 -m mark ! --mark 0x4000000/0xffff0000 -j DROPCOMMIT# Completed on Tue Jul 18 22:23:42 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 22:23:42 2017*raw:PREROUTING ACCEPT [3155:832499]:OUTPUT ACCEPT [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-PREROUTING - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A OUTPUT -j neutron-l3-agent-OUTPUTCOMMIT# Completed on Tue Jul 18 22:23:42 2017# Generated by iptables-save v1.6.0 on Tue Jul 18 22:23:42 2017*mangle:PREROUTING ACCEPT [3150:831059]:INPUT ACCEPT [605:210624]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:neutron-l3-agent-FORWARD - [0:0]:neutron-l3-agent-INPUT - [0:0]:neutron-l3-agent-OUTPUT - [0:0]:neutron-l3-agent-POSTROUTING - [0:0]:neutron-l3-agent-PREROUTING - [0:0]:neutron-l3-agent-float-snat - [0:0]:neutron-l3-agent-floatingip - [0:0]:neutron-l3-agent-mark - [0:0]:neutron-l3-agent-scope - [0:0]-A PREROUTING -j neutron-l3-agent-PREROUTING-A INPUT -j neutron-l3-agent-INPUT-A FORWARD -j neutron-l3-agent-FORWARD-A OUTPUT -j neutron-l3-agent-OUTPUT-A POSTROUTING -j neutron-l3-agent-POSTROUTING-A neutron-l3-agent-POSTROUTING -o qg-37790cfc-43 -m connmark --mark 0x0/0xffff0000 -j CONNMARK --save-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-mark-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-scope-A neutron-l3-agent-PREROUTING -m connmark ! --mark 0x0/0xffff0000 -j CONNMARK --restore-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-PREROUTING -j neutron-l3-agent-floatingip-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j MARK --set-xmark 0x1/0xffff-A neutron-l3-agent-float-snat -m connmark --mark 0x0/0xffff0000 -j CONNMARK --save-mark --nfmask 0xffff0000 --ctmask 0xffff0000-A neutron-l3-agent-mark -i qg-37790cfc-43 -j MARK --set-xmark 0x2/0xffff-A neutron-l3-agent-scope -i qg-37790cfc-43 -j MARK --set-xmark 0x4000000/0xffff0000-A neutron-l3-agent-scope -i qr-b111bb2e-84 -j MARK --set-xmark 0x4000000/0xffff0000COMMIT# Completed on Tue Jul 18 22:23:42 2017 -A neutron-l3-agent-float-snat -s 9.9.9.3/32 -j SNAT –to-source 10.0.99.3，决定了该虚拟机访问外网会做SNAT为10.0.99.3，而其他虚拟机依然按照原来方式访问外网。 -A neutron-l3-agent-PREROUTING -d 10.0.99.3/32 -j DNAT –to-destination 9.9.9.3 Linux IP 栈Secondary IP我们看一个路由器的ip信息qg-37790cfc-43接口绑定了浮动ip。 123456789101112131415161718ip netns exec qrouter-71d8932f-3782-470f-b3a2-f80203f96885 ip addr16: qg-37790cfc-43: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:51:15:05 brd ff:ff:ff:ff:ff:ff inet 10.0.99.2/24 brd 10.0.99.255 scope global qg-37790cfc-43 valid_lft forever preferred_lft forever inet 10.0.99.3/32 brd 10.0.99.3 scope global qg-37790cfc-43 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe51:1505/64 scope link valid_lft forever preferred_lft forever#解释&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;：端口的各种状态BROADCAST： device can send traffic to all hosts on the link （能够发广播）MULTICAST： device can perform and receive multicast packets （能够发多播）UP： device is functioning （enabled 状态，可通过 ip * up/down 设置。）LOWER_UP：the state of the Ethernet link（表示线已接上）inet/brd/scope：IP 地址及子网掩码，广播地址，作用域scope：global：valid everywhere ​ 这个interface有两个静态 IP 地址。第一个是主要的（primary）IP，第二个是辅助的（ secondary） 的 IP。当一个网卡配置了静态IP后，你可以添加secondary IP 给它。这样它就拥有了多个 IP 地址了。Secondary IP 不可以通过 DHCP 分配。它所有的IP 地址都关联到它唯一的一个 MAC 地址上。那为什么需要 secondary IP 地址呢？ 路由器有个 Secondary IP 的概念，这个特性可以创建逻辑子网，也就是说在一个物理网口上连接两个子网，比如这个网口接到一台交换机上，如果这个网口没有配置Secondary IP的话，那么这台交换机只能连接一个网段的主机，比如 192.168.1.1/24，但是，如果它配置了Secondary IP，那么就可以连接两个网段的主机，比如 192.168.1.1/24 和 10.0.0.1/24。 Gratuitous ARP​ 众所周知，ARP的基本功能就是在以太网环境中，通过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。但由于ARP的广播、动态学习等特性注定了它不是一种安全的协议，所以在实际应用中，会由于各种各样的原因使ARP学习失败，从而影响网络的互通性，并进而影响用户的业务稳定运行。整个ARP的体系里基本上就是由ARP Request和Response组成的,Request就是告知对方“我要什么”，而Response是回答“我是什么”。但有些时候也会例外，他们虽然从形式上还是Request和Response的，但它们通常不会不是一问一答的，而是只有其中的一部分，所以通常被称为免费ARP或无为ARP（Gratuitous ARP）。 Gratuitous ARP在主机启动的时候，请求自己的IP地址对应的MAC地址。 它常用于三个用途： ​ Change of L2 address：通告自己改变了 MAC 地址。以 ARP Response 的形式发送广播，它通常只是为了把自己的ARP信息通告/更新给局域网全体，这种Response不需要别人请求，是自己主动发送的通告。当一个网络设备的 MAC 地址发生改变时，发送该设备的 Gratuitous ARP，通知所在广播域内的已经包含该 IP 地址在其 ARP 表中的机器去更新它的 ARP 条目。 ​ Duplicate address detection：重复 MAC 地址检测。以 ARP Request的形式发送广播，请求自己的MAC地址，目的是探测局域网中是否有跟自己IP地址相同的主机，也就是常说的IP冲突。发送主机并不需要一定收到此请求的回答。如果收到一个回答，表示网络中存在与自身IP相同的主机。如果没有收到应答，则表示本机所使用的IP与网络中其它主机并不冲突。 Virtual IP：用于一组服务器做 failover 时通知周围的机器新生效的 IP 地址的 MAC. Route （Linux 路由表）​ route命令用来显示并设置Linux内核中的网络路由表，route命令设置的路由主要是静态路由。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。 route add -net 10.0.0.0 netmask 255.0.0.0 dev eth0 #增加一条经过 eth0 到达 10.0.0.0 的路由route add -net 10.0.0.0 netmask 255.0.0.0 reject #增加一条屏蔽的路由，目的地址为10.X.X.X将被拒绝。route del -net 10.0.0.0 netmask 255.0.0.0route del -net 10.0.0.0 netmask 255.0.0 rejectroute del default gw 10.0.36.254route add default gw 10.0.36.254 基于VRRP的路由高可用什么是VRRP？​ Virtual Redundent Routing Protocol 虚拟冗余路由协议，是一种可以解决这种问题的容错协议。VRRP协议的目的就是为了解决路由单点故障问题，VRRP通过竞选(election)协议来动态的将路由任务交给LAN中虚拟路由器中的某台VRRP路由器。它的原理如下： 在这之前我们先了解一下相关术语： 虚拟路由器：由一个 Master 路由器和多个 Backup 路由器组成。主机将虚拟路由器当作默认网关。VRID：虚拟路由器的标识，有相同 VRID 的一组路由器构成一个虚拟路由器。通常用（0-255）标识Master路由器：虚拟路由器中承担报文转发任务的路由器。Backup路由器： Master路由器出现故障时能够代替 Master路由器工作的路由器。虚拟 IP：地址虚拟路由器的 IP 地址，一个虚拟路由器可以拥有一个或多个IP 地址。IP 地址拥有者：接口IP地址与虚拟IP地址相同的路由器被称为 IP 地址拥有者。虚拟 MAC 地址：一个虚拟路由器拥有一个虚拟 MAC 地址。虚拟 MAC 地址的格式为 00-00-5E-00-01-{VRID}。通常情况下虚拟路由器回应 ARP 请求使用的是虚拟 MAC 地址，只有虚拟路由器做特殊配置的时候才回应接口的真实 MAC 地址。priority优先级：VRRP 根据优先级来确定虚拟路由器中每台路由器的地位。用0-255来表示，数字越小优先级越低。VRRP优先级的取值范围为0到255（数值越大表明优先级越高），可配置的范围是1到254，优先级0为系统保留给路由器放弃Master位置时候使用，255则是系统保留给IP地址拥有者使用。当路由器为IP地址拥有者时，其优先级始终为255。因此，当虚拟路由器内存在IP地址拥有者时，只要其工作正常，则为Master路由器。抢占方式：默认，如果 Backup 路由器工作在抢占方式下，当它收到 VRRP 报文后会将自己的优先级与通告报文中的优先级进行比较。如果自己的优先级比当前的 Master 路由器的优先级高就会主动抢占成为 Master 路由器否则将保持 Backup 状态。非抢占方式：如果 Backup 路由器工作在非抢占方式下则只要 Master 路由器没有出现故障Backup 路由器即使随后被配置了更高的优先级也不会成为Master 路由器。 VRRP协议报文：封装在IP报文中，发送到分配给 VRRP 的 IP 组播地址。在IP报文头中，源地址为发送报文接口的主 IP 地址（不是虚拟IP地址），目的地址是224.0.0.18，TTL是255，协议号是112。目前，VRRP协议包括两个版本：VRRPv2和VRRPv3，VRRPv2仅适用于IPv4网路，VRRPv3适用于IPv4和IPv6两种网络。 VRRP 节点三种状态：初始状态（Initialize）、活动状态（Master）、备份状态（Backup）。其中，只有处于Master状态的设备才可以转发那些发送到虚拟IP地址的报文。 然后我们结合上图来描述一下VRRP的机制。 ​ Device A 和 B 组成一个 VRRP 组，它的虚拟 IP（VIP） 为 10.0.0.3/24。其中，通过选举机制，A 是 Master Router，B 是 Backup Router。一个 VRRP 组内可以由多个设备，但是只有一个是 Master 设备。注意 Device A 和 B 可以由自己的 IP 地址，VIP 可以和其中的某 IP 相同，也可以不同。 ​ 当前，Router A 作为 Master router 向局域网内的机器提供路由服务，Router B 作为 Backup router。它的任务是周期性地接受 A 发出的心跳。在规定的时间段内，如果都没有收到 A 发出的心跳，则启动一个选举过程，重新选出 Master。 ​ 局域网内的机器将虚拟路由器当作默认网关，它们仅仅知道这个虚拟路由器的IP 地址 10.0.0.3，而并不知道具体的 Master 路由器的 IP 地址以及 Backup 路由器的IP 地址。它们将自己的缺省路由下一跳地址设置为10.0.0.3。于是，网络内的主机就通过这个虚拟的路由器来与其它网络进行通信。如果 Master 路由器坏掉，Backup 路由器将会通过选举策略选出一个新的 Master 路由器，继续向网络内的主机提供路由服务。从而实现网络内的主机不间断地与外部网络进行通信。 它的优势： ​ 操作简单：它不需要改变组网情况，也不需要在主机上做任何配置，只需要在相关路由器上配置极少的几条命令，就能实现下一跳网关的备份，并且不会给主机带来任何负担。和其他方法比较起来，VRRP更加能够满足用户的需求。​ 简化网络管理：在具有多播或广播能力的局域网（如以太网）中，借助 VRRP 能在某台设备出现故障时仍然提供高可靠的缺省链路，有效避免单一链路发生故障后网络中断的问题，而无需修改动态路由协议、路由发现协议等配置信息，也无需修改主机的默认网关配置。​ 适应性强：VRRP报文封装在IP报文中，支持各种上层协议。​ 网络开销小：VRRP只定义了一种报文——VRRP通告报文，并且只有处于Master状态的路由器可以发送VRRP报文。 什么是keepalived ？​ Keepalived 是 VRRP 的一个非常好的开源实现，它是一个基于 VRRP 协议来实现的 WEB 服务高可用方案，可以利用其来避免单点故障。在neutron的路由高可用中，需要安装keepalived 即可。 Keepalived组件如下：​ keepalived是模块化设计，不同模块负责不同的功能：​ core：keepalived的核心；负责主进程的启动和维护全局配置文件的加载解析等​ check：负责healthchecker(健康检查)包括了各种健康检查方式以及对应的配置文件的解析​ vrrp VRRPD：子进程用来实现VRRP协议​ libipfwc iptables(ipchains)库配置LVS​ libipvs*：配置LVS keepalived进程如下： ​ Keepalived 使用三个进程，其中 Watchdog 是控制进程，VRRP Stack and Checkers 是它的两个子进程。 ​ Watchdog 通过心跳机制来确保子进程处于运行状态。 ​ Checkers：负责真实服务器的健康检测，用于负载均衡。 ​ VRRP Stack：实现 VRRP 协议，提供 HA。 neutron如何实现？Neutron L3 HA 的提出就是为了保证 OpenStack 环境三层网络的高可用性。 ​ QR 和 QG 分别连接内网和外网，这是 router 本来就有的端口；HA 端口是 HA router 才特有的。一个非 HA router，只会存在于一个 Neutron L3 agent 所在的 Network node 中。而一个 HA router 会在多个 Neutron L3 agent 所在的 Network node 里创建 instance，这包括创建相应的 namespace 和端口。每个 HA router instance 里面的 QR 和 QG 都有相同的设备名和 MAC 地址(Media Access Control Address)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#Master的信息root@netagent10038219:~# ip netns exec qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever28: ha-65bc01fe-af: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:1f:d2:bd brd ff:ff:ff:ff:ff:ff inet 169.254.192.1/18 brd 169.254.255.255 scope global ha-65bc01fe-af valid_lft forever preferred_lft forever inet 169.254.0.1/24 scope global ha-65bc01fe-af valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe1f:d2bd/64 scope link valid_lft forever preferred_lft forever30: qr-fe09d52e-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:58:13:ad brd ff:ff:ff:ff:ff:ff inet 1.1.1.1/24 scope global qr-fe09d52e-c6 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe58:13ad/64 scope link nodad valid_lft forever preferred_lft forever32: qg-21bed7aa-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:a9:28:e7 brd ff:ff:ff:ff:ff:ff inet 10.99.1.101/32 scope global qg-21bed7aa-c6 valid_lft forever preferred_lft forever inet 10.99.1.102/32 scope global qg-21bed7aa-c6 valid_lft forever preferred_lft forever inet 10.99.1.103/24 scope global qg-21bed7aa-c6 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fea9:28e7/64 scope link nodad valid_lft forever preferred_lft forever#Slave信息root@netagent10038220:~# ip netns exec qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever26: ha-557abd6c-48: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:3f:75:8d brd ff:ff:ff:ff:ff:ff inet 169.254.192.2/18 brd 169.254.255.255 scope global ha-557abd6c-48 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe3f:758d/64 scope link valid_lft forever preferred_lft forever29: qr-fe09d52e-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 8950 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:58:13:ad brd ff:ff:ff:ff:ff:ff32: qg-21bed7aa-c6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:a9:28:e7 brd ff:ff:ff:ff:ff:ff Slave 和 Master router instance 的区别在于 Master router instance 的网络端口上是有 IP 地址的。这些 IP 实际上是 VIP，它们只会存在于 Master router instance 上。每个 router instance 上都有一个 HA 端口，这些端口都有不同的 IP。这些端口是用来进行 VRRP 广播通信的。每个 router instance 里面都运行着一个 keepalived 进程。Keepalived 是一个实现了 VRRP 的软件工具，Neutron 利用 keepalived 实现的 L3 HA的。 对于Master 我们查看一下它发的VRRP广播 123456root@netagent10038219:~# ip netns exec qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b tcpdump -i ha-65bc01fe-aftcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ha-65bc01fe-af, link-type EN10MB (Ethernet), capture size 262144 bytes05:01:11.336576 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 2005:01:13.337818 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 2005:01:15.339083 IP 169.254.192.1 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 1, prio 50, authtype none, intvl 2s, length 20 HA 端口向广播地址 224.0.0.18 发送信息。这是由 VRRP 协议规定的。如果 Master router instance 出现故障，不能发出广播信息，导致 Slave router instance 未在一定的时间内收到广播信息。剩下的 Slave router instance 会选取出一个来作为新的 Master router instance。这个 instance 会获取 VIP，从而为 OpenStack 提供三层网络。虽然提供服务的 router instance 变了，但是 IP 没有改变，所以从使用者的角度来看，网络服务没有发生改变。 vrid 是 HA router 对应的 id，每个 tenant 下面，不同的 router 对应不同的 vrid。需要注意的是，由于 VRRP 协议的限制，vrid 是一个 8 bit 数据。因此每个 tenant 下面，最多只能创建 255 个 HA router。prio 是 instance 的优先级，这个目前是不可配置的，每个 instance 的优先级一样。authtype 是 instance 之间通信的认证方式，默认是不需要认证。intvl 是广播之间的间隔时间，默认是 2 秒，这个可以配置。 每个 HA router 一旦被创建，Neutron L3 agent 会为每个 router instance 创建一个 keepalived 进程，在这之前会生成一个 keepalived 的配置文件供 keepalived 的进程使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869root@netagent10038219:~# ps -aux | grep &apos;23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b&apos;root 4310 0.0 0.8 155892 73080 ? S Mar17 0:05 /usr/bin/python /usr/local/bin/neutron-keepalived-state-change --router_id=23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --namespace=qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --conf_dir=/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --monitor_interface=ha-65bc01fe-af --monitor_cidr=169.254.0.1/24 --pid_file=/var/lib/neutron/external/pids/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.monitor.pid --state_path=/var/lib/neutron --user=0 --group=0root 4810 0.0 0.0 54252 564 ? Ss Mar17 0:59 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 4811 0.0 0.0 56496 3856 ? S Mar17 2:31 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 6330 0.0 0.8 140156 71188 ? S Mar28 0:02 /usr/bin/python /usr/local/bin/neutron-ns-metadata-proxy --pid_file=/var/lib/neutron/external/pids/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid --metadata_proxy_socket=/var/lib/neutron/metadata_proxy --router_id=23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --state_path=/var/lib/neutron --metadata_port=9697 --metadata_proxy_user=0 --metadata_proxy_group=0 --log-file=neutron-ns-metadata-proxy-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.log --log-dir=/var/log/neutronroot 28706 0.0 0.0 13080 2544 pts/1 S+ 05:47 0:00 grep --color=auto 23d7334d-a55f-4b4b-9dfa-4d1ee4b3080broot@netagent10038219:/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b# lskeepalived.conf neutron-keepalived-state-change.log statevrrp_instance VR_1 &#123; state BACKUP interface ha-65bc01fe-af virtual_router_id 1 priority 50 garp_master_delay 60 nopreempt advert_int 2 track_interface &#123; ha-65bc01fe-af &#125; virtual_ipaddress &#123; 169.254.0.1/24 dev ha-65bc01fe-af &#125; virtual_ipaddress_excluded &#123; 1.1.1.1/24 dev qr-fe09d52e-c6 10.99.1.101/32 dev qg-21bed7aa-c6 10.99.1.102/32 dev qg-21bed7aa-c6 10.99.1.103/24 dev qg-21bed7aa-c6 fe80::f816:3eff:fe58:13ad/64 dev qr-fe09d52e-c6 scope link fe80::f816:3eff:fea9:28e7/64 dev qg-21bed7aa-c6 scope link &#125; virtual_routes &#123; 0.0.0.0/0 via 10.99.1.1 dev qg-21bed7aa-c6 &#125;&#125;========================================================================================root@netagent10038220:~# ps -aux | grep &apos;23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b&apos;root 4330 0.0 0.8 155896 72840 ? S Mar17 0:04 /usr/bin/python /usr/local/bin/neutron-keepalived-state-change --router_id=23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --namespace=qrouter-23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --conf_dir=/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b --monitor_interface=ha-557abd6c-48 --monitor_cidr=169.254.0.1/24 --pid_file=/var/lib/neutron/external/pids/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.monitor.pid --state_path=/var/lib/neutron --user=0 --group=0root 4882 0.0 0.0 54252 568 ? Ss Mar17 0:59 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 4883 0.0 0.0 56540 4304 ? S Mar17 1:46 keepalived -P -f /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b/keepalived.conf -p /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid -r /var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b.pid-vrrproot 25801 0.0 0.0 13080 2548 pts/0 S+ 05:48 0:00 grep --color=auto 23d7334d-a55f-4b4b-9dfa-4d1ee4b3080broot@netagent10038220:/var/lib/neutron/ha_confs/23d7334d-a55f-4b4b-9dfa-4d1ee4b3080b# lskeepalived.conf neutron-keepalived-state-change.log statevrrp_instance VR_1 &#123; state BACKUP interface ha-557abd6c-48 virtual_router_id 1 priority 50 garp_master_delay 60 nopreempt advert_int 2 track_interface &#123; ha-557abd6c-48 &#125; virtual_ipaddress &#123; 169.254.0.1/24 dev ha-557abd6c-48 &#125; virtual_ipaddress_excluded &#123; 1.1.1.1/24 dev qr-fe09d52e-c6 10.99.1.101/32 dev qg-21bed7aa-c6 10.99.1.102/32 dev qg-21bed7aa-c6 10.99.1.103/24 dev qg-21bed7aa-c6 fe80::f816:3eff:fe58:13ad/64 dev qr-fe09d52e-c6 scope link fe80::f816:3eff:fea9:28e7/64 dev qg-21bed7aa-c6 scope link &#125; virtual_routes &#123; 0.0.0.0/0 via 10.99.1.1 dev qg-21bed7aa-c6 &#125;&#125; ​ 总的来说，要使用 HA router，首先必须有多个 Neutron L3 agent 在不同的 Network node 上运行。一旦创建了一个 HA router，Neutron 会通过多个 L3 agent 创建相应的 namespace 和端口，这样就有了这个 HA router 的多个 instance。同时，L3 agent 还会创建 keepalived 进程，每个 keepalived 进程都有 router 的全部信息。这样，每个 Network node 上都有 HA router 的一个 instance 和管理这个 router instance 的 keepalived 进程。​ 当一切就绪之后，这些 router instance 会进行一次选举，胜出的作为 Master instance，剩下的作为 Slave instance。由于所有的 router instance 的优先级都是一样的，选举的结果是随机的。也就是说，如果创建多个 HA router，这些 router 的 Master instance 可能分布在多个 Network node 上。​ 选举结束后，Master router instance 负责提供 L3 网络服务，并同时向其他的 Slave router instance 发广播报告自身的状况。一旦由于各种原因，广播中断，Slave router instance 会重新选举出新的 Master router instance，继续提供 L3 网络服务，并同时发送广播报告自身的状况。 DVR分布式路由的实现DVR的架构网络层： 服务层： 架构： DVR的配置与试验 上图是我搭建的部署环境（你可以将Network Server与Controller Node放在一起），对于DVR来说我们需要操作如下： 控制节点： 123neutron.conf [DEFAULT]router_distributed = True 网络节点： 123456openvswitch_agent.ini[agent]enable_distributed_routing = Truel3_agent.ini[DEFAULT]agent_mode = dvr_snat 计算节点： 123456789yum install openstack-neutronsystemctl enable neutron-l3-agent.serviceopenvswitch_agent.ini[agent]enable_distributed_routing = Truel3_agent.ini[DEFAULT]interface_driver = neutron.agent.linux.interface.OVSInterfaceDriveragent_mode = dvr 然后重启以下服务： 12345控制节点：systemctl restart neutron-server计算节点：systemctl restart neutron-openvswitch-agent systemctl start neutron-l3-agent网络节点：systemctl restart neutron-openvswitch-agent systemctl restart neutron-l3-agent 为了演示DVR我们创建外部网络 123[root@controller ~]# neutron net-create --shared --provider:physical_network external --provider:network_type flat external_net[root@controller ~]# neutron subnet-create --name external_net --allocation-pool start=123.4.4.10,end=123.4.4.50 --dns-nameserver 123.4.4.1 --gateway 123.4.4.1 external_net 123.4.4.0/24[root@controller ~]# neutron net-update external_net --router:external 在下面实现之前要注意： 当虚拟机创建落在计算机点后，才会在该计算机节点出现qrouter的namespace 当router设置网关后，才会出现snat namespace 当关联floating ip 才会在计算机点出现fixed ip 的namespace 创建路由器 如果我们选择了外部网络后，在网络节点就会出现snat namespace 1234567891011121314151617181920[root@netagent ~]# ip netns listsnat-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a[root@netagent ~]# ip netns exec snat-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ifconfiglo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0qg-b683d547-5f: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 123.4.4.14 netmask 255.255.255.0 broadcast 123.4.4.255 inet6 fe80::f816:3eff:fe88:bdc7 prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:88:bd:c7 txqueuelen 1000 (Ethernet) RX packets 5 bytes 332 (332.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 13 bytes 1074 (1.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 fixed IP的南北向流量创建内部网络6.6.6.0/24和虚拟机6.6.6.5，虚拟机落在计算节点2，我们看到在这个节点出现了qrouter-namespace,同时网络节点也出现了qrouter-namespace，这两个网络接口信息一样，同时snat-namespace也多了一个网口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@com2 ~]# ip netns listqrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a[root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ifconfiglo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0qr-b452f7b9-bc: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 6.6.6.1 netmask 255.255.255.0 broadcast 6.6.6.255 inet6 fe80::f816:3eff:fe99:3c29 prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:99:3c:29 txqueuelen 1000 (Ethernet) RX packets 10 bytes 1076 (1.0 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 10 bytes 864 (864.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@netagent ~]# ip netns listsnat-851e3ae1-1b10-41ed-b215-f0e5dfd7a46aqrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a[root@netagent ~]# ip netns exec snat-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ifconfiglo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0qg-b683d547-5f: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 123.4.4.14 netmask 255.255.255.0 broadcast 123.4.4.255 inet6 fe80::f816:3eff:fe88:bdc7 prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:88:bd:c7 txqueuelen 1000 (Ethernet) RX packets 19 bytes 1324 (1.2 KiB) RX errors 0 dropped 1 overruns 0 frame 0 TX packets 13 bytes 1074 (1.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0sg-d722c249-c5: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 6.6.6.3 netmask 255.255.255.0 broadcast 6.6.6.255 inet6 fe80::f816:3eff:fef5:93ba prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:f5:93:ba txqueuelen 1000 (Ethernet) RX packets 22 bytes 1500 (1.4 KiB) RX errors 0 dropped 2 overruns 0 frame 0 TX packets 15 bytes 1210 (1.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 在虚机没有floating ip的情况下访问外网，从虚机发出的包会首先到计算节点的qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a，丢给网关6.6.6.1/24，然后匹配table 101058049，我们看到会交给6.6.6.3的地址，它正是snat-namespace新出现的网口sg-d722c249-c5地址。 1234567891011[root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip rule0: from all lookup local 32766: from all lookup main 32767: from all lookup default 101058049: from 6.6.6.1/24 lookup 101058049 [root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip route list table 101058049default via 6.6.6.3 dev qr-b452f7b9-bc [root@netagent ~]# ip netns exec snat-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a iptables -nvL -t natChain neutron-l3-agent-snat (1 references) pkts bytes target prot opt in out source destination 0 0 SNAT all -- * qg-b683d547-5f 0.0.0.0/0 0.0.0.0/0 to:123.4.4.14 总之，虚拟机通过计算节点的qrouter-namespace再到网络节点的snat-namespace，而外网返回的数据会通过网络节点的snat-namespace和qrouter-namespace到计算节点的虚拟机。 整个流程如下所示： floatingip的南北向流量我们对虚拟机6.6.6.5绑定一个floatingip如下： 我们看到虚拟机所在的节点多出了fip-namespace，同时我们看到qrouter-namespace有很多变化。虚拟机6.6.6.5ping外网时候，它的数据的首先查找主表main，没有匹配项后，就会匹配from 6.6.6.5 lookup 16，而不会匹配from 6.6.6.1/24 lookup 101058049 。在table16，我们看到数据想通过qrouter-namespace的rfp-851e3ae1-1到达169.254.106.115，数据转发到rfp-851e3ae1-1接口后，qrouter-namespace对其作了SNAT,neutron-l3-agent-float-snat -s 6.6.6.5/32 -j SNAT –to-source 123.4.4.16,也就是数据从rfp-851e3ae1-1发出后的源地址为123.4.4.16。qrouter-namespace的rfp-851e3ae1-1与fip-namespace的fpr-851e3ae1-1是veth对，此时数据就到达了fip-namespace。我们看一下fip-namespace路由表，数据会转发到fg-9b5bb134-fa接口到达外网。 外网数据返回时候，以 123.4.4.16/32作为目的地址发给fip-namespace的fg-9b5bb134-fa，根据路由表会通过fpr-851e3ae1-1发给网关169.254.106.114，也就是qrouter-namespace的rfp-851e3ae1-1接口地址，到达该接口，qrouter-namespace作DNAT，将123.4.4.16/32变为6.6.6.5/32。neutron-l3-agent-PREROUTING -d 123.4.4.16/32 -j DNAT –to-destination 6.6.6.5，然后查主表如何到达6.6.6.5,根据路由表，我们发现数据到达了 qr-b452f7b9-bc发出，之后就会转发到br-int再到虚机。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[root@com2 ~]# ip netns listfip-49ca86bb-afe9-4c6f-a67f-5399f57b851dqrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a[root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: rfp-851e3ae1-1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether ce:61:44:bd:66:1e brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 169.254.106.114/31 scope global rfp-851e3ae1-1 valid_lft forever preferred_lft forever inet 123.4.4.16/32 brd 123.4.4.16 scope global rfp-851e3ae1-1 valid_lft forever preferred_lft forever inet6 fe80::cc61:44ff:febd:661e/64 scope link valid_lft forever preferred_lft forever15: qr-b452f7b9-bc: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UNKNOWN qlen 1000 link/ether fa:16:3e:99:3c:29 brd ff:ff:ff:ff:ff:ff inet 6.6.6.1/24 brd 6.6.6.255 scope global qr-b452f7b9-bc valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe99:3c29/64 scope link valid_lft forever preferred_lft forever[root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip rule0: from all lookup local 32766: from all lookup main 32767: from all lookup default 57481: from 6.6.6.5 lookup 16 101058049: from 6.6.6.1/24 lookup 101058049 [root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip route list table main6.6.6.0/24 dev qr-b452f7b9-bc proto kernel scope link src 6.6.6.1 169.254.106.114/31 dev rfp-851e3ae1-1 proto kernel scope link src 169.254.106.114 [root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface6.6.6.0 0.0.0.0 255.255.255.0 U 0 0 0 qr-b452f7b9-bc169.254.106.114 0.0.0.0 255.255.255.254 U 0 0 0 rfp-851e3ae1-1[root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip route list table 16default via 169.254.106.115 dev rfp-851e3ae1-1 [root@com2 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a iptables-save.....-A neutron-l3-agent-OUTPUT -d 123.4.4.16/32 -j DNAT --to-destination 6.6.6.5-A neutron-l3-agent-POSTROUTING ! -i rfp-851e3ae1-1 ! -o rfp-851e3ae1-1 -m conntrack ! --ctstate DNAT -j ACCEPT-A neutron-l3-agent-PREROUTING -d 169.254.169.254/32 -i qr-+ -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 9697-A neutron-l3-agent-PREROUTING -d 123.4.4.16/32 -j DNAT --to-destination 6.6.6.5-A neutron-l3-agent-float-snat -s 6.6.6.5/32 -j SNAT --to-source 123.4.4.16-A neutron-l3-agent-snat -j neutron-l3-agent-float-snat-A neutron-postrouting-bottom -m comment --comment &quot;Perform source NAT on outgoing traffic.&quot; -j neutron-l3-agent-snatCOMMIT[root@com2 ~]# ip netns exec fip-49ca86bb-afe9-4c6f-a67f-5399f57b851d ifconfigfg-9b5bb134-fa: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 123.4.4.17 netmask 255.255.255.0 broadcast 123.4.4.255 inet6 fe80::f816:3eff:fe5d:43b7 prefixlen 64 scopeid 0x20&lt;link&gt; ether fa:16:3e:5d:43:b7 txqueuelen 1000 (Ethernet) RX packets 3 bytes 84 (84.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 10 bytes 864 (864.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0fpr-851e3ae1-1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 169.254.106.115 netmask 255.255.255.254 broadcast 0.0.0.0 inet6 fe80::b8fe:64ff:fe79:1608 prefixlen 64 scopeid 0x20&lt;link&gt; ether ba:fe:64:79:16:08 txqueuelen 1000 (Ethernet) RX packets 7 bytes 738 (738.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 7 bytes 738 (738.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 [root@com2 ~]# ip netns exec fip-49ca86bb-afe9-4c6f-a67f-5399f57b851d route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 123.4.4.1 0.0.0.0 UG 0 0 0 fg-9b5bb134-fa123.4.4.0 0.0.0.0 255.255.255.0 U 0 0 0 fg-9b5bb134-fa123.4.4.16 169.254.106.114 255.255.255.255 UGH 0 0 0 fpr-851e3ae1-1169.254.106.114 0.0.0.0 255.255.255.254 U 0 0 0 fpr-851e3ae1-1[root@com2 ~]# ip netns exec fip-49ca86bb-afe9-4c6f-a67f-5399f57b851d ip route list table maindefault via 123.4.4.1 dev fg-9b5bb134-fa 123.4.4.0/24 dev fg-9b5bb134-fa proto kernel scope link src 123.4.4.17 123.4.4.16 via 169.254.106.114 dev fpr-851e3ae1-1 169.254.106.114/31 dev fpr-851e3ae1-1 proto kernel scope link src 169.254.106.115 东西流量我们又创建了一个子网192.168.1.0/24，虚拟机192.168.1.5在计算节点1，在计算机点1也会出现qrouter-namespace 123456789101112131415161718192021[root@com1 ~]# ip netns listqrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a[root@com1 ~]# ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever15: qr-b452f7b9-bc: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UNKNOWN qlen 1000 link/ether fa:16:3e:99:3c:29 brd ff:ff:ff:ff:ff:ff inet 6.6.6.1/24 brd 6.6.6.255 scope global qr-b452f7b9-bc valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fe99:3c29/64 scope link valid_lft forever preferred_lft forever18: qr-ff78f72b-98: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UNKNOWN qlen 1000 link/ether fa:16:3e:a8:f8:fa brd ff:ff:ff:ff:ff:ff inet 192.168.1.1/24 brd 192.168.1.255 scope global qr-ff78f72b-98 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fea8:f8fa/64 scope link valid_lft forever preferred_lft forever 我们用虚拟机192.168.1.5 ping 6.6.6.5。首先会查询路由表，将包发送到网关192.168.1.1。那么会首先会发送192.168.1.1的arp请求。arp请求会发送到br-int上，192.168.1.5 的portid为b452f7b9-bc4d-464d-8dca-fa2396bfba85，对应的br-int上是Port “qvob452f7b9-bc” 而端口qvo45b153f7-40是属于vlan 2的，qr-b452f7b9-bc也是属于vlan2的，arp广播包会转发到”qr-b452f7b9-bc”和”patch-tun”。而”qr-b452f7b9-bc”是com2的qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a路由接口，拥有网关地址“192.168.1.1” 对于”patch-tun”，之后会发送到“br-tun”，我们看看“br-tun” cookie=0xbe2941571871a27c, duration=13079.754s, table=1, n_packets=1, n_bytes=42, idle_age=13078, priority=3,arp,dl_vlan=2,arp_tpa=192.168.1.1 actions=drop cookie=0xbe2941571871a27c, duration=13079.552s, table=1, n_packets=1, n_bytes=42, idle_age=13078, priority=3,arp,dl_vlan=5,arp_tpa=6.6.6.1 actions=drop 发现数据包会由table=0，转给table=1,对于arp采取丢弃的方式。 虚拟机192.168.1..5 ，当获取到了192.168.1.1的MAC地址后，会发出如下的包： Dest IP: 6.6.6.5Souce IP: 192.168.1.5Dest MAC: MAC of 192.168.1.1Source MAC: MAC of 192.168.1.5 执行命令查看ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip rule0: from all lookup local32766: from all lookup main32767: from all lookup default查看mainip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip route list table main 6.6.6.0/24 dev qr-b452f7b9-bc proto kernel scope link src 6.6.6.1192.168.1.0/24 dev qr-ff78f72b-98 proto kernel scope link src 192.168.1.1 在main表中满足以下路由:6.6.6.0/24 dev qr-b452f7b9-bc proto kernel scope link src 6.6.6.1因此会从qr-b452f7b9-bc 转发出去。 之后需要去查询6.6.6.5 的MAC地址， MAC是由neutron使用静态ARP的方式设定的：ip netns exec qrouter-851e3ae1-1b10-41ed-b215-f0e5dfd7a46a ip nei6.6.6.5 dev qr-ff78f72b-98 lladdr fa:16:3e:23:77:1c PERMANENT由于Neutron知道所有虚机的信息，因此他可以事先设定好静态ARP。至此，我们的ICMP包会变成以下形式从qr-b452f7b9-bc 转发出去：Dest IP: 6.6.6.5Souce IP: 192.168.1.5Dest MAC: MAC of 6.6.6.5Source MAC: MAC of 192.168.1.5 当包转发到”br-tun”后，开始查询openflow表。ovs-ofctl show br-tun 可以查看端口状态首先我们看一下br-tun的flowtable，首先会进入table 0，由于包是从br-int发过来的，因此in_port是patch-int(1)，之后会查询表1，这张表中会丢弃目标地址是interface_distributed接口的ARP和目的MAC是interface_distributed的包。以防止虚机发送给本地路由器的包被转发到网络中。我们的ICMP包会命中一下flow，它会把源MAC地址改为全局唯一和计算节点绑定的MAC(fa:16:3f:88:30:58): cookie=0xbe2941571871a27c, duration=13079.754s, table=1, n_packets=1, n_bytes=42, idle_age=13078, priority=3,arp,dl_vlan=2,arp_tpa=192.168.1.1 actions=drop cookie=0xbe2941571871a27c, duration=13079.552s, table=1, n_packets=1, n_bytes=42, idle_age=13078, priority=3,arp,dl_vlan=5,arp_tpa=6.6.6.1 actions=drop cookie=0xbae18ea66f2bd595, duration=69678.476s, table=1, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=2,dl_vlan=2,dl_dst=fa:16:3e:99:3c:29 actions=drop cookie=0xbae18ea66f2bd595, duration=16219.966s, table=1, n_packets=0, n_bytes=0, idle_age=16219, priority=2,dl_vlan=5,dl_dst=fa:16:3e:a8:f8:fa actions=drop cookie=0xbae18ea66f2bd595, duration=69678.454s, table=1, n_packets=4, n_bytes=440, idle_age=65534, hard_age=65534, priority=1,dl_vlan=2,dl_src=fa:16:3e:99:3c:29 actions=mod_dl_src:fa:16:3f:88:30:58,resubmit(,2) cookie=0xbae18ea66f2bd595, duration=16219.961s, table=1, n_packets=4, n_bytes=440, idle_age=16218, priority=1,dl_vlan=5,dl_src=fa:16:3e:a8:f8:fa actions=mod_dl_src:fa:16:3f:88:30:58,resubmit(,2) 继续查询流表2，表2是VXLAN表，如果是广播包就会查询表22，如果是单播包就查询表20： cookie=0xbae18ea66f2bd595, duration=79697.638s, table=2, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,20) cookie=0xbae18ea66f2bd595, duration=79697.637s, table=2, n_packets=120088, n_bytes=5057540, idle_age=1, hard_age=65534, priority=0,dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,22) ICMP包是单播包，因此会查询表20，由于开启了L2 pop功能，在表20中会事先学习到应该转发到哪个VTEP cookie=0xbae18ea66f2bd595, duration=15286.730s, table=20, n_packets=0, n_bytes=0, idle_age=15286, priority=2,dl_vlan=2,dl_dst= fa:16:3e:23:77:1c actions=strip_vlan,set_tunnel:0x62,output:2 此时包会变成如下形式： Dest IP: 6.6.6.5 Souce IP: 192.168.1.5 Dest MAC: MAC of 6.6.6.5 Source MAC: 16:3f:88:30:58 之后包会从port 2发出。 数据包到达com2上查询br-tun的流表:ovs-ofctl show br-tun 可以查看端口状态在table0中可以看到，如果包是从外部发来的就会去查询表4： ovs-ofctl dump-flows br-tun | grep “table=0” cookie=0x83d99e19c90a76fc, duration=10376.919s, table=0, n_packets=6, n_bytes=580, idle_age=6185, priority=1,in_port=2 actions=resubmit(,4) 在表4中，会将tun_id对应的改为本地vlan id，之后查询表9: cookie=0x83d99e19c90a76fc, duration=5190.158s, table=4, n_packets=0, n_bytes=0, idle_age=5190, priority=1,tun_id=0x42 actions=mod_vlan_vid:5,resubmit(,9) 在表9中，如果发现包的源地址是全局唯一并与计算节点绑定的MAC地址，就将其转发到br-int: cookie=0x83d99e19c90a76fc, duration=21043.043s, table=9, n_packets=0, n_bytes=0, idle_age=21043, priority=1,dl_src=16:3f:88:30:58 actions=output:1 由于我们的源MAC为16:3f:88:30:58，我们的ICMP包就被转发到了br-int，之后查询br-int的流表： ovs-ofctl dump-flows br-intcookie=0xa0e2bd57839cefda, duration=21258.165s, table=0, n_packets=0, n_bytes=0, idle_age=21258, priority=2,in_port=1,dl_src=16:3f:88:30:58 actions=resubmit(,1)在表1中，事先设定好了flow，如果目的MAC是发送给虚拟机6.6.6.5，就将源MAC改为network 2的网关MAC地址： cookie=0xa0e2bd57839cefda, duration=5401.439s, table=1, n_packets=0, n_bytes=0, idle_age=5401, priority=4,dl_vlan=3,dl_dst=16:3f:88:30:58 actions=strip_vlan,mod_dl_src:fa:16:3e:99:3c:29,output:15经过br-int的流表后，包会变成如下形式：Dest IP: 6.6.6.5Souce IP: 192.168.1.5Dest MAC: MAC of 6.6.6.5Source MAC:fa:16:3e:99:3c:29（6.6.6.0/24的网关MAC地址） DHCP服务neutron dhcp为租户网络提供DHCP服务，即IP地址动态分配，另外还会提供metadata请求服务。3个主要的部件：DHCP agent scheduler：负责DHCP agent与network的调度。DHCP agent：为租户网络提供DHCP的功能，提供metadata request服务。DHCP driver：即dnsmasq，用于管理DHCP server。 Dnsmasq 是被 Neutron 用来提供 DHCP 和 DNS 服务的一个开源程序，即DHCP driver部分。它提供 DNS 缓存和 DHCP 服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。作为DHCP 服务器，dnsmasq 可以为局域网电脑提供内网ip地址和路由。DNS和DHCP两个功能可以同时或分别单独实现。dnsmasq轻量且易配置，适用于主机较少的网络。 根据整个dhcp处理的流程，dhcp模块主要由Neutron api、core plugin（如linux bridge plugin，ovs plugin等）、dhcp agent scheduler、dhcp agent、dhcp driver（dnsmasq）构成。 对应架构图中数字，有以下几个接口：1.network/subnet/port的操作2.agent management/agent scheduler的操作3.network/subnet/port操作会发送rpc请求到dhcp agent。4.agentscheduler db发送rpc请求到dhcp agent。5.dhcp agent通过DhcpPluginApi发送rpc请求到core plugin，操作相应的数据库。6.dhcp agent调用dhcp driver进行dhcp相关操作。 虚机获取固定IP （Fixed IP）主要分为两个步骤： ​ 在创建虚机过程中，Neutron 随机生成 MAC 和 从配置数据中分配一个固定IP 地址，并保存到 Dnsmasq 的 hosts 文件中，让 Dnsmasq 做好准备。 ​ 虚机在启动时向 Dnsmasq 获取 IP 地址 红色为创建虚拟机的数据流 绿色为虚拟机启动的数据流 创建虚机时的数据流 Controller 节点上的 Neutron Server 接到该请求后，会开始下面的过程： 步骤 2 ~ 6：Neutron Server 生成 MAC 和 IP。 其中 MAC 是由任意数组成的；Fixed IP 是从保存在数据库中的管理员配置的网络和地址数据生成的。 步骤 7 ~ 10： 调用 L3 Agent 和 OVS 执行一些操作。 步骤 12 ~ 14：通过 AMQP 的 cast 消息给 Neutron 节点上的 DHCP Agent，告诉它 Port 创建结束以及 新分配的 Port 的数据。 步骤 13：返回Port 给 nova-compute。 步骤 15：Neturon 节点上的 DHCP Agent 根据接收到的 Port 创建完成通知，重新生成 Dnsmasq 的 hosts 文件，然后让 Dnsmasq 重新加载该文件。Nova 拿到 Port 的数据后，会写入虚机的 libvirt.xml 文件。 参考：http://man.linuxde.net/route http://fishcried.com/2016-02-19/iptables/ http://www.cnblogs.com/sammyliu/p/4636091.html http://www.embeddedlinux.org.cn/linux_net/0596002556/understandlni-CHP-28-SECT-3.html https://www.ibm.com/developerworks/cn/cloud/library/1506_xiaohh_openstackl3/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux的iptables原理]]></title>
      <url>%2F2017%2F04%2F06%2FLinux%E7%9A%84iptables%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[​ 在Linux系统中，对于防火墙的实现一般分为包过滤防火墙，TCP-Wrapper即程序管控，代理服务器等几种方式。其中，iptables作为一种基于包过滤方式的防火墙工具，在实际中应用非常广泛，是非常重要的一个安全工具。真正实现防火墙功能的是 netfilter，它是一个 linux 内核模块，做实际的包过滤。实际上，除了 iptables 以外，还有很多类似的用户空间工具。 iptables的“链”与“表”netfilter 使用表（table）和 链（chain）来组织网络包的处理规则（rule）。它默认定义了以下表和链： 表 表功能 链 链功能 raw PREROUTING OUTPUT RAW 拥有最高的优先级，它使用PREROUTING和OUTPUT两个链，因此 RAW 可以覆盖所有包。在raw表中支持一个特殊的目标:TRACE，使内核记录下每条匹配该包的对应iptables规则信息。使用raw表内的TRACE target 即可实现对iptables规则的跟踪调试。比如：# iptables -t raw -A OUTPUT -p icmp -j TRACE # ipt ables -t raw -A PREROUTING -p icmp -j TRACE Filter 包过滤 FORWARD 过滤目的地址和源地址都不是本机的包 INPUT 过滤目的地址是本机的包 OUTPUT 过滤源地址是本机的包 Nat 网络地址转换 PREROUTING 在路由前做地址转换，使得目的地址能够匹配上防火墙的路由表，常用于转换目的地址。 POSTROUTING 在路由后做地址转换。这意味着不需要在路由前修改目的地址。常用于转换源地址。 OUTPUT 对防火墙产生的包做地址转换（很少量地用于 SOHO 环境中） Mangle TCP 头修改 PREROUTING POSTROUTING OUTPUT INPUT FORWARD 在路由器修改 TCP 包的 QoS（很少量地用在 SOHO 环境中） 先是透过路由判断， 决定了输出的路径后，再透过 filter 的 OUTPUT 链来传送的， mangle 这个表格很少被使用，如果将上图的mangle 拿掉的话，那就容易看的多了： 如果你的防火墙事实上是用来管制 LAN 内的其他主机的话，那么你就必须要再针对 filter 的 FORWARD 这条链，还有 nat 的 PREROUTING, POSTROUTING 以及 OUTPUT 进行额外的规则订定才行。 iptables实现SNAT与DNATNAT 服务器的重点就在于上面流程NAT table 的两条重要的链：PREROUTING 与 POSTROUTING。 举例如下： SNAT封包传送和封包接收 ​ 客户端所发出的封包表头中，来源会是 192.168.1.100 ，然后传送到 NAT 这部主机；NAT 这部主机的内部接口 (192.168.1.2) 接收到这个封包后，会主动分析表头数据， 因为表头数据显示目的并非 Linux 本机，所以开始经过路由， 将此封包转到可以连接到 Internet 的 Public IP 处；由于 private IP 与 public IP 不能互通，所以 Linux 主机透过 iptables 的 NAT table 内的 Postrouting 链将封包表头的来源伪装成为 Linux 的 Public IP ，并且将两个不同来源 (192.168.1.100 及 public IP) 的封包对应写入暂存内存当中， 然后将此封包传送出去了；​ 此时 Internet 上面看到这个封包时，都只会知道这个封包来自那个 Public IP 而不知道其实是来自内部啦。 好了，那么如果 Internet 回传封包呢？又会怎么作？ ​ 在 Internet 上面的主机接到这个封包时，会将响应数据传送给那个 Public IP 的主机；当 Linux NAT 服务器收到来自 Internet 的回应封包后，会分析该封包的序号，并比对刚刚记录到内存当中的数据， 由于发现该封包为后端主机之前传送出去的，因此在 NAT Prerouting 链中，会将目标 IP 修改成为后端主机，亦即那部 192.168.1.100，然后发现目标已经不是本机 (public IP)， 所以开始透过路由分析封包流向；封包会传送到 192.168.1.2 这个内部接口，然后再传送到最终目标 192.168.1.100 机器上去！ SNAT 主要是应付内部 LAN 连接到 Internet 的使用方式，至于 DNAT 则主要用在内部主机想要架设可以让 Internet 存取的服务器啦！ DNAT封包传送 ​ 假设我的内部主机 192.168.1.210 启动了 WWW 服务，这个服务的 port 开启在 port 80 ， 那么 Internet 上面的主机 (61.xx.xx.xx) 要如何连接到我的内部服务器呢？当然啦， 还是得要透过 Linux NAT 服务器嘛！所以这部 Internet 上面的机器必须要连接到我们的 NAT 的 public IP 才行。外部主机想要连接到目的端的 WWW 服务，则必须要连接到我们的 NAT 服务器上头；我们的 NAT 服务器已经设定好要分析出 port 80 的封包，所以当 NAT 服务器接到这个封包后， 会将目标 IP 由 public IP 改成 192.168.1.210 ，且将该封包相关信息记录下来，等待内部服务器的响应；上述的封包在经过路由后，来到 private 接口处，然后透过内部的 LAN 传送到 192.168.1.210 上头！ ​ 192.186.1.210 会响应数据给 61.xx.xx.xx ，这个回应当然会传送到 192.168.1.2 上头去；经过路由判断后，来到 NAT Postrouting 的链，然后透过刚刚的记录，将来源 IP 由 192.168.1.210 改为 public IP 后，就可以传送出去了！ iptables常用命令 注释： 如果想查看特别的表时使用-t指定,如果查看单独的链需要在操作后面指定. 如果是查看规则定义,使用-S. -S比-L查看规则时更加清晰. 如果查看匹配状况使用-nvL.配合watch使用. --line-number用于查看规则号. iptables [-t tables][-L] [-nv] 选项与参数： -t ：后面接 table ，例如 nat 或 filter ，若省略此项目，则使用默认的 filter -L ：列出目前的 table 的规则 -n ：不进行 IP 与 HOSTNAME 的反查，显示讯息的速度会快很多！ -v ：列出更多的信息，包括通过该规则的封包总位数、相关的网络接口等 iptables-save [-t table] （列出完整的防火墙规则） 选项与参数： -t ：可以仅针对某些表格来输出，例如仅针对 nat 或 filter 等等 ​ 这个命令主要是把内存态的规则保存到文件,然后下次启动的时候用iptables-restore来载入规则. 但是这个命令常常用来查看防火墙规则。比iptables用得都多, 主要是输出结果的格式比较紧凑直观.而且能方便的能看到所有表的规则. iptables [-t tables][-FXZ] 选项与参数：-F ：清除所有的已订定的规则；-X ：杀掉所有使用者 “自定义” 的 chain (应该说的是 tables ）啰；-Z ：将所有的 chain 的计数与流量统计都归零 iptables命令举例清空当前的所有规则和计数 123iptables -F #清空所有的防火墙规则iptables -X #删除用户自定义的空链iptables -Z #清空计数 配置允许ssh端口连接 12iptables -A INPUT -s 192.168.1.0/24 -p tcp --dport 22 -j ACCEPT #22为你的ssh端口， -s 192.168.1.0/24表示允许这个网段的机器来连接，其它网段的ip地址是登陆不了你的机器的。 -j ACCEPT表示接受这样的请求 允许本地回环地址可以正常使用 123iptables -A INPUT -i lo -j ACCEPT #本地圆环地址就是那个127.0.0.1，是本机上使用的,它进与出都设置为允许iptables -A OUTPUT -o lo -j ACCEPT 设置默认的规则 123iptables -P INPUT DROP #配置默认的不让进iptables -P FORWARD DROP #默认的不允许转发iptables -P OUTPUT ACCEPT #默认的可以出去 一些例子 123456789iptables -A INPUT -s 10.10.10.10 -j DROP #丢弃从 10.10.10.10 主机来的所有包iptables -A INPUT -s 10.10.10.0/24 -j DROP #丢弃从 10.10.10.0/24 网段进来所有包iptables -A INPUT -p tcp --dport ssh -s 10.10.10.10 -j DROP # 如果协议是 tcp，目标端口是 ssh 端口，源IP 为 10.10.10.10，那么丢弃它iptables -A INPUT -i virbr0 -p udp -m udp --dport 53 -j ACCEPT #接受从 virbr0 进来的所有目标端口 53 的 udp 包iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT #接受 RELEASED 和 ESTABLISHED 状态的连接。Linux 3.7 以后，--state 被替换成了 --conntrackiptables -A FORWARD -d 192.168.122.0/24 -o virbr0 -m state --state RELATED,ESTABLISHED -j ACCEPT #转发时接受这些包iptables -A FORWARD -p icmp -j ACCEPT #转发时接受所有 ICMP 路由包。iptables -A INPUT -i lo -j ACCEPT #使用 -i 过滤从 lo 设备进来的包iptables -A INPUT -i eth0 -j ACCEPT #使用 -i 过滤从网卡 eth0 进来的包。不指定网卡的话表示所有网卡。 iptables的常见问题1.你听说过Linux下面的iptables和Firewalld么？知不知道它们是什么，是用来干什么的？ ​ iptables通常被用作类UNIX系统中的防火墙，更准确的说，可以称为iptables/netfilter。管理员通过终端/GUI工具与iptables打交道，来添加和定义防火墙规则到预定义的表中。Netfilter是内核中的一个模块，它执行包过滤的任务。 ​ Firewalld是RHEL/CentOS 7中最新的过滤规则的实现。它已经取代了iptables接口，并与netfilter相连接。 2.请在iptables中添加一条规则，接受所有从一个信任的IP地址（例如，192.168.0.7）过来的包。 ​ iptables -A INPUT -s 192.168.0.7 -j ACCEPT 3.假如有一台电脑的本地IP地址是192.168.0.6。你需要封锁在21、22、23和80号端口上的连接，你会怎么做？ ​ iptables -A INPUT -s 192.168.0.6 -p tcp -m multiport –dport 22,23,80,8080 -j DROP 参考：http://fishcried.com/2016-02-19/iptables/ http://cn.linux.vbird.org/linux_server/0250simple_firewall_3.php https://linux.cn/article-5948-1.html#3_10137]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是openstack?]]></title>
      <url>%2F2017%2F04%2F05%2F%E4%BB%80%E4%B9%88%E6%98%AFopenstack%2F</url>
      <content type="text"><![CDATA[​ OpenStack是一个旨在为公共及私有云的建设与管理提供软件的开源项目。它不是一个软件，而是由几个主要的组件组合起来完成一些具体的工作。可以搭建公有云，私有云，企业云。​ OpenStack基本上是一个软件项目，有近55万行代码。分解成核心项目、孵化项目，以及支持项目和相关项目。​ OpenStack是一个框架，一个可以建立公有云和私有云的基础架构。它并不是一个现成的产品，要想开展基础架构方面的工作，企业需要顾问和开发人员。很多时候还需要第三方的集成工具。KVM(Kernel-based Virtual Machine)是一个开源的系统虚拟化模块，它需要硬件支持，如Intel VT技术或者AMD V技术，是基于硬件的完全虚拟化，完全内置于Linux。 ​ OpenStack几乎支持所有的虚拟化管理程序，不论是开源的(Xen与KVM)还是厂商的(Hyper-V与VMware)。但在以前，OpenStack是基于KVM开发的，KVM常常成为默认的虚拟机管理程序。两者都使用相同的开放源理念与开发方法。 OpenStack组件 Compute (Nova) 计算服务 Identity Service (Keystone) 认证服务 Image Service (Glance) 镜像服务 Networking (Neutron/Quantum) 网络服务 Dashboard (Horizon) 仪表板 Object Storage (Swift) 对象存储 Block Storage (Cinder) 块存储 Orchestration (Heat) 编排 Telemetry (Ceilometer) 监控 Database Service (Trove) 数据库服务 Data Processing (Sahara) 数据处理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron二层网络服务实现原理]]></title>
      <url>%2F2017%2F04%2F05%2FNeutron%E4%BA%8C%E5%B1%82%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[网络​ 网络（network）是一个隔离的二层网段，类似于物理网络世界中的虚拟 LAN (VLAN)。更具体来讲，它是为创建它的租户而保留的一个广播域，或者被显式配置为共享网段。端口和子网始终被分配给某个特定的网络。根据网络的类型，Neutron network 可以分为： ​ VLAN network（虚拟局域网） ：基于物理 VLAN 网络实现的虚拟网络。共享同一个物理网络的多个 VLAN 网络是相互隔离的，甚至可以使用重叠的 IP 地址空间。每个支持 VLAN network 的物理网络可以被视为一个分离的 VLAN trunk，它使用一组独占的 VLAN ID。有效的 VLAN ID 范围是 1 到 4094。 ​ Flat network：基于不使用 VLAN 的物理网络实现的虚拟网络。每个物理网络最多只能实现一个虚拟网络。local network（本地网络）：一个只允许在本服务器内通信的虚拟网络，不知道跨服务器的通信。主要用于单节点上测试。​ GRE network （通用路由封装网络）：一个使用 GRE 封装网络包的虚拟网络。GRE 封装的数据包基于 IP 路由表来进行路由，因此 GRE network 不和具体的物理网络绑定。​ VXLAN network（虚拟可扩展网络）：基于 VXLAN 实现的虚拟网络。同 GRE network 一样， VXLAN network 中 IP 包的路由也基于 IP 路由表，也不和具体的物理网络绑定。 关系： （1）tenant —- 1:n —– network ——- 1：n ——- subnet （一个 tenant 可以拥有多个 network，一个 network 可以包含多个 subnet） （2）network ——- 1: n ——- port —— 1:1 — subnet（一个network 可以有多个 port， 每个 port 连接一个 subnet）（若创建虚机时指定的是 net-id，那么虚机将随机地从该 network 包含的 subnet 中分配 IP） （3）VM —– 1 : n —- NIC —– 1:1 — port（一个 VM 可以有多个 NIC，每个 NIC 连接一个 port）（可以在创建虚机时指定一个或者多个 port） （4）Tenant —– 1 : n —- Router —– 1 : n —— subnet/ext-network （一个 tenant 可以拥有多个 router，每个 router 在 Neutron network 节点上使用一个 Linux network namespace，其 ID 就是 neutron router-list 得到的 router 的 ID； 一个 router 连接一个通向外网的 gateway 和多个该 tenant 的 subnet） （5）network —- 1 : 1 —- Dnamasq —– 1: n —– subnet （一个 network 有一个 Dnsmasq 进程，该进程为多个启动了 DHCP 的 subnet 服务，分配它们拥有的 IP 给虚机） Neutron 管理的实体如下： 网络： 隔离的 L2 域，可以是虚拟、逻辑或交换，同一个网络中的主机彼此 L2 可见。 子网： IP 地址块，其中每个虚拟机有一个 IP，同一个子网的主机彼此 L3 可见。 端口： 网络上虚拟、逻辑或交换端口。 Linux相关技术​ Neutron 的设计目标是实现“网络即服务”，为了达到这一目标，在设计上遵循了基于“软件定义网络”实现网络虚拟化的原则，在实现上充分利用了 Linux 系统上的各种网络相关的技术。​ 理解了 Linux 系统上的这些概念将有利于快速理解 Neutron 的原理和实现。 涉及的 Linux 网络技术bridge：网桥，Linux中用于表示一个能连接不同网络设备的虚拟设备，linux中传统实现的网桥类似一个hub设备，而ovs管理的网桥一般类似交换机。br-int：bridge-integration，综合网桥，常用于表示实现主要内部网络功能的网桥。br-ex：bridge-external，外部网桥，通常表示负责跟外部网络通信的网桥。GRE：General Routing Encapsulation，一种通过封装来实现隧道的方式。在openstack中一般是基于L3的gre，即original pkt/GRE/IP/EthernetVETH：虚拟ethernet接口，通常以pair的方式出现，一端发出的网包，会被另一端接收，可以形成两个网桥之间的通道。qvb：neutron veth, Linux Bridge-sideqvo：neutron veth, OVS-sideTAP设备：模拟一个二层的网络设备，可以接受和发送二层网包。TUN设备：模拟一个三层的网络设备，可以接受和发送三层网包。iptables：Linux 上常见的实现安全策略的防火墙软件。Vlan：虚拟 Lan，同一个物理 Lan 下用标签实现隔离，可用标号为1-4094。VXLAN：一套利用 UDP 协议作为底层传输协议的 Overlay 实现。一般认为作为 VLan 技术的延伸或替代者。namespace：用来实现隔离的一套机制，不同 namespace 中的资源之间彼此不可见。 GRE网络, Vlan网络, Vxlan网络举例GRE网络 ​ 在 VM1 中，虚拟机的网卡实际上连接到了物理机的一个 TAP 设备（即 A，常见名称如 tap-XXX）上，A 则进一步通过 VETH pair（A-B）连接到网桥 qbr-XXX 的端口 vnet0（端口 B）上，之后再通过 VETH pair（C-D）连到 br-int 网桥上。一般 C 的名字格式为 qvb-XXX，而 D的名字格式为 qvo-XXX。注意它们的名称除了前缀外，后面的 id 都是一样的，表示位于同一个虚拟机网络到物理机网络的连接上。 br-tun转发逻辑： ​ 表 10 负责学习。有一条规则，基于 learn 行动来创建反向（内部网包从 gre 端口发出去）的规则。如下所示： learn 行动并非标准的 openflow 行动，是 openvswitch 自身的扩展行动，这个行动可以根据流内容动态来修改流表内容。这条规则首先创建了一条新的流（该流对应 vm 从 br-tun 的 gre 端口发出的规则）： 其中 table=20 表示规则添加在表 20； NXM_OF_VLAN_TCI[0..11] 表示匹配包自带的vlan id； NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[] 表示 L2 目标地址需要匹配当前包的 L2 源地址； load:0-&gt;NXM_OF_VLAN_TCI[]，去掉vlan； load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[]，添加 tunnel 号为原始 tunnel 号； output:NXM_OF_IN_PORT[]，发出端口为原始包抵达的端口。向表 20 添加完规则后，最后将匹配的当前网包从端口 1（即 patch-int）发出。 举例VLAN网络： ​ 路由是L3 agent来实现，每个子网在br-int上有一个端口（qr-YYY和qr-ZZZ，已配置IP，分别是各自内部子网的网关），L3 agent绑定到上面。要访问外部的公共网络，需要通过L3 agent发出，而不是经过int-br-ex到phy-br-ex（实际上并没有网包从这个veth pair传输）。如果要使用外部可见的floating IP，L3 agent仍然需要通过iptables来进行NAT。 在多租户情况下 举例VXLAN网络：（详细分析） 当我们部署环境之后（一个网络节点和两个计算节点）我们查看计算机节点的状态如下，此时并没有vxlan隧道的建立。我们同时发现当创建完成网络和子网的时候（创建了7.7.7.0/24子网），依然没有vxlan隧道。 1234567891011121314151617181920root@com2:~# ovs-vsctl showf4a15348-e3a9-4834-82ee-fa0beb4e9420 Bridge br-tun fail_mode: secure Port br-tun Interface br-tun type: internal Port patch-int Interface patch-int type: patch options: &#123;peer=patch-tun&#125; Bridge br-int fail_mode: secure Port patch-tun Interface patch-tun type: patch options: &#123;peer=patch-int&#125; Port br-int Interface br-int type: internal 只有当有虚拟机接入该子网时候，我们发现虚拟机所在的计算节点会和网络节点建立vxlan隧道。 123456789101112131415161718192021222324252627282930313233343536root@com2:~# ovs-vsctl showf4a15348-e3a9-4834-82ee-fa0beb4e9420 Bridge br-tun fail_mode: secure Port br-tun Interface br-tun type: internal Port patch-int Interface patch-int type: patch options: &#123;peer=patch-tun&#125; Port &quot;vxlan-0a0026df&quot; Interface &quot;vxlan-0a0026df&quot; type: vxlan options: &#123;df_default=&quot;true&quot;, in_key=flow, local_ip=&quot;10.0.38.218&quot;, out_key=flow, remote_ip=&quot;10.0.38.223&quot;&#125; Bridge br-int fail_mode: secure Port patch-tun Interface patch-tun type: patch options: &#123;peer=patch-int&#125; Port &quot;qvo0fc2bc51-8d&quot; tag: 3 Interface &quot;qvo0fc2bc51-8d&quot; Port br-int Interface br-int type: internal Bridge br-trans Port br-trans Interface br-trans type: internal Port &quot;eth2&quot; Interface &quot;eth2&quot; Port &quot;tra0fc2bc51-8d&quot; Interface &quot;tra0fc2bc51-8d&quot; ovs_version: &quot;2.5.0&quot; 我们查看br-tun的流表如下(开启了l2 population) ： ​ 当数据包由in_port = 1(也就是由br-int发出)到达table 0时候，会转给table 2；如果是arp广播请求，因为开启l2 population，也就是arp_responder之后，会提交给 table 21。此时table21有条规则会处理这个请求，这条规则专门由l2 population发来的 entry 来更新 。 ​ table 21 的更新过程并非网上所讲的那么简单，实际过程如下：假如我们创建了网络A和网络B ，有2个计算机点和1个网络节点。创建一台虚拟机aa加入网络A，同时落地在计算节点1时候，本计算节点的table21只有dhcp的arp的回应记录。再创建一虚拟机bb加入网络B，同时落地在计算节点2时候，本计算节点的table21只有dhcp的arp的回应记录，计算节点1的table21并没有bb的arp的回应记录。创建第三台虚拟机加入网络A,如果落地在计算节点1时候，两个计算节点的table21没有任何更新。当创建第四台虚拟机加入网络A，同时落地在计算机点2时候，计算机点2的table 21更新了所有在计算节点1的同一网络的虚拟机的arp信息，同时table 20记录了所有到达计算机点1同一网络的虚拟机的规则。计算节点1的table21也更新了计算节点2的同网络的虚拟机的arp回应，table20也记录了到达其的规则。 ​ br.add_flow(table=21, priority=1, proto=’arp’, dl_vlan=local_vid, nw_dst= ip, actions=actions) 其中action为： 12345678910111213141516171819202122232425262728actions = (‘move:NXM_OF_ETH_SRC[]-&gt;NXM_OF_ETH_DST[],’ – Place the source MAC address of the request (The requesting VM) as the new reply’s destination MAC address ‘mod_dl_src:%(mac)s,’ – Put the requested MAC address of the remote VM as this message’s source MAC address ‘load:0x2-&gt;NXM_OF_ARP_OP[],’ – Put an 0x2 code as the type of the ARP message. 0x2 is an ARP response. ‘move:NXM_NX_ARP_SHA[]-&gt;NXM_NX_ARP_THA[],’ – Place the ARP request’s source hardware address (MAC) as this new message’s ARP target / destination hardware address ‘move:NXM_OF_ARP_SPA[]-&gt;NXM_OF_ARP_TPA[],’ – Place the ARP request’s source protocol / IP address as the new message’s ARP destination IP address ‘load:%(mac)#x-&gt;NXM_NX_ARP_SHA[],’ – Place the requested VM’s MAC address as the source MAC address of the ARP reply ‘load:%(ip)#x-&gt;NXM_OF_ARP_SPA[],’ – Place the requested VM’s IP address as the source IP address of the ARP reply ‘in_port’ % &#123;‘mac’: mac, ‘ip’: ip&#125;) – Forward the message back to the port it came in onHere’s the match part: self.tun_br.add_flow(table=constants.ARP_RESPONDER, – Add this new flow to the ARP_RESPONDER table priority=1, – With a priority of 1 (Another, default flow with the lower priority of 0 is added elsewhere in the code) proto=‘arp’, – Match only on ARP messages dl_vlan=lvid, – Match only if the destination VLAN (The message has been locally VLAN tagged by now) matches the VLAN ID / network of the remote VM nw_dst=‘%s‘ % ip, – Match on the IP address of the remote VM in question actions=actions) ​ 如果table21还是无法解决arp的问题就发给table22 去 flood 到所有端口。如果不是arp请求就转到table 20 ，通过已知学习到的mac地址从相应的口发出，如果不能处理也是发给table 22去flood到所有的端口。 ​ 当数据包从in_port=4(也就是由发往br-int)到达table 0时候，会提交给table 4， 它根据tunel号修改为内部vlan号，然后提交给table 10 ,它进行学习更新table 20，然后从patch-int发出。 table 10使用了 openvswitch 的 learn 动作。该动作能根据处理的流来动态修改其它表中的规则。因为此时访问虚拟机的只有dhcp服务，我们看到table 20有一条到达dhcp的流表，这个流表就是这个learn动作生成的。 ​ table=20 说明是修改表 20 中的规则，后面是添加的规则内容； ​ NXM_OF_VLAN_TCI[0..11]，匹配跟当前流同样的 VLAN 头，其中 NXM 是 Nicira Extensible Match 的缩写 ，dl_vlan=3； ​ NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[]，将 mac source address 记录，所以结果中有 dl_dst= fa:16:3e:c0:0e:07； ​ load:0-&gt;NXM_OF_VLAN_TCI[]，在发送出去的时候，vlan tag设为0，所以结果中有 actions=strip_vlan； ​ load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[]，发出去的时候，设置 tunnul id，所以结果中有set_tunnel: 0x8； ​ output:NXM_OF_IN_PORT[]，指定发送给哪个port，由于是从 port 4进来的，因而结果中有output4。 123456789101112131415161718192021222324252627282930313233343536373839root@com2:~# ovs-ofctl show br-tunOFPT_FEATURES_REPLY (xid=0x2): dpid:00005e38cc7c8e43n_tables:254, n_buffers:256capabilities: FLOW_STATS TABLE_STATS PORT_STATS QUEUE_STATS ARP_MATCH_IPactions: output enqueue set_vlan_vid set_vlan_pcp strip_vlan mod_dl_src mod_dl_dst mod_nw_src mod_nw_dst mod_nw_tos mod_tp_src mod_tp_dst 1(patch-int): addr:ea:ff:57:bb:5f:2a config: 0 state: 0 speed: 0 Mbps now, 0 Mbps max 4(vxlan-0a0026df): addr:02:1c:31:dd:58:08 config: 0 state: 0 speed: 0 Mbps now, 0 Mbps max LOCAL(br-tun): addr:5e:38:cc:7c:8e:43 config: PORT_DOWN state: LINK_DOWN speed: 0 Mbps now, 0 Mbps maxOFPT_GET_CONFIG_REPLY (xid=0x4): frags=normal miss_send_len=0root@com2:~# ovs-ofctl dump-flows br-tunNXST_FLOW reply (xid=0x4): cookie=0xae4f2288fae3c173, duration=75532.472s, table=0, n_packets=14490, n_bytes=1290354, idle_age=0, hard_age=65534, priority=1,in_port=1 actions=resubmit(,2) cookie=0xae4f2288fae3c173, duration=84.773s, table=0, n_packets=2, n_bytes=732, idle_age=73, priority=1,in_port=4 actions=resubmit(,4) cookie=0xae4f2288fae3c173, duration=75532.472s, table=0, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0 actions=drop cookie=0xae4f2288fae3c173, duration=75532.471s, table=2, n_packets=846, n_bytes=50760, idle_age=0, hard_age=65534, priority=1,arp,dl_dst=ff:ff:ff:ff:ff:ff actions=resubmit(,21) cookie=0xae4f2288fae3c173, duration=75532.471s, table=2, n_packets=13547, n_bytes=1230482, idle_age=709, hard_age=65534, priority=0,dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,20) cookie=0xae4f2288fae3c173, duration=75532.471s, table=2, n_packets=97, n_bytes=9112, idle_age=31, hard_age=65534, priority=0,dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,22) cookie=0xae4f2288fae3c173, duration=75532.471s, table=3, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0 actions=drop cookie=0xae4f2288fae3c173, duration=85.471s, table=4, n_packets=2, n_bytes=732, idle_age=73, priority=1,tun_id=0x8 actions=mod_vlan_vid:3,resubmit(,10) cookie=0xae4f2288fae3c173, duration=75532.470s, table=4, n_packets=2, n_bytes=140, idle_age=2866, hard_age=65534, priority=0 actions=drop cookie=0xae4f2288fae3c173, duration=75532.470s, table=6, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0 actions=drop cookie=0xae4f2288fae3c173, duration=75532.470s, table=10, n_packets=12541, n_bytes=1237278, idle_age=73, hard_age=65534, priority=1 actions=learn(table=20,hard_timeout=300,priority=1,cookie=0xae4f2288fae3c173,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0-&gt;NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]-&gt;NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:1 cookie=0xae4f2288fae3c173, duration=84.772s, table=20, n_packets=0, n_bytes=0, idle_age=84, priority=2,dl_vlan=3,dl_dst=fa:16:3e:c0:0e:07 actions=strip_vlan,set_tunnel:0x8,output:4 cookie=0xae4f2288fae3c173, duration=73.586s, table=20, n_packets=0, n_bytes=0, hard_timeout=300, idle_age=73, priority=1,vlan_tci=0x0003/0x0fff,dl_dst=fa:16:3e:c0:0e:07 actions=load:0-&gt;NXM_OF_VLAN_TCI[],load:0x8-&gt;NXM_NX_TUN_ID[],output:4 cookie=0xae4f2288fae3c173, duration=75532.470s, table=20, n_packets=0, n_bytes=0, idle_age=65534, hard_age=65534, priority=0 actions=resubmit(,22) cookie=0xae4f2288fae3c173, duration=84.772s, table=21, n_packets=0, n_bytes=0, idle_age=84, priority=1,arp,dl_vlan=3,arp_tpa=7.7.7.2 actions=move:NXM_OF_ETH_SRC[]-&gt;NXM_OF_ETH_DST[],mod_dl_src:fa:16:3e:c0:0e:07,load:0x2-&gt;NXM_OF_ARP_OP[],move:NXM_NX_ARP_SHA[]-&gt;NXM_NX_ARP_THA[],move:NXM_OF_ARP_SPA[]-&gt;NXM_OF_ARP_TPA[],load:0xfa163ec00e07-&gt;NXM_NX_ARP_SHA[],load:0x7070702-&gt;NXM_OF_ARP_SPA[],IN_PORT cookie=0xae4f2288fae3c173, duration=75532.469s, table=21, n_packets=827, n_bytes=49620, idle_age=0, hard_age=65534, priority=0 actions=resubmit(,22) cookie=0xae4f2288fae3c173, duration=84.758s, table=22, n_packets=84, n_bytes=5614, idle_age=0, dl_vlan=3 actions=strip_vlan,set_tunnel:0x8,output:4 cookie=0xae4f2288fae3c173, duration=75532.462s, table=22, n_packets=31, n_bytes=2778, idle_age=84, hard_age=65534, priority=0 actions=drop 下图是没有开启l2popluation功能，从上述流表看出与开启l2popluation功能不同。 L2 Population​ L2 Population 是用来提高 VXLAN 网络 Scalability 的，减少广播风暴。 ​ 这是一个包含 5 个节点的 VXLAN 网络，每个节点上运行了若干 VM。现在假设 Host 1 上的 VM A 想与 Host 4 上的 VM G 通信，VM A 要做的第一步是获知 VM G 的 MAC 地址。 于是 VM A 需要在整个 VXLAN 网络中广播 APR 报文：“VM G 的 MAC 地址是多少？” 如果没有L2poluation,情况会如下： ​ L2 Population 的作用是在 VTEP 上提供 Porxy ARP 功能，使得 VTEP 能够预先获知 VXLAN 网络中，包括VM IP – MAC 对应关系和 VM – VTEP 的对应关系。当 Host 1 上的 同网段的VM A 想与 Host 4 上的同网段的 VM G 通信时，Host 1 上的 VTEP 直接响应 VM A 的 APR 请求即可（为什么HOST1 上会响应，参看上文），告诉VM G的MAC地址。当Host 1 上的VMA想与不同网段的VM G 通信时，首先Host 1 上的 VTEP 响应 VMA所在网络的网关的arp信息（当路由器创建并关联网络时候，L2 Population会使得该网络所跨的所有HOST的VTEP更新该路由器的arp回应信息和如何到达的该路由器的流表，说具体就是table21和table20的更新），数据包会发送给路由器，到达路由器之后，如果路由器同时关联着VM G 所在的网络，它就会发送arp广播请求VM G 的mac，此时网络节点的table21会响应（L2 Population的功能）VM G的信息，路由器知道了VM G的mac地址后，发送单播，由table0到table2,再由table20匹配相关流表，tunnel发出。数据包到达VM G所在的HOST之后，首先匹配table0,然后转给table4，table4去tunnel转给table10, table10 学习完存到table 20之后从patch-int口仍给br-int。br-int相当于一个普通的交换机，将数据包转发给VM G。 另外我还发现如果开启了l2population之后，table10的学习可以去掉。 1ovs-ofctl add-flow br-tun &quot;table=10, n_packets=0, n_bytes=0, idle_age=62653, priority=1 actions=output:1&quot; 参考：http://www.cnblogs.com/sammyliu/p/4622563.html http://blog.csdn.net/cloudman6/article/details/53167522]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[经济学的经典著作]]></title>
      <url>%2F2017%2F03%2F31%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%9A%84%E7%BB%8F%E5%85%B8%E8%91%97%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[1.色诺芬：《经济论》2.托马斯·孟：《英国得自对外贸易的财富》3.托马斯·莫尔：《乌托邦》4.弗朗索瓦·魁奈：《经济表》5.威廉·配弟：《赋税论》6.亚当·斯密：《国民财富的性质和原因的研究》7.让·萨伊：《政治经济学概论》8.托马斯·马尔萨斯：《人口原理》9.大卫·李嘉图：《政治经济学及赋税原理》 10.布阿吉尔贝尔：《法国的辩护书》11.西斯蒙第：《政治经济学新原理》12.约翰·穆勒：《政治经济学原理及其在社会哲学上的若干应用》13.杜阁：《关于财富的形成和分配的考察》14.洛克：《论降低利息和提高货币价值的后果》15.魏克赛尔：《利息与价格》16.马克思：《资本论》17.康芒斯：《制度经济学》18.凡勃伦：《有闲阶级论》19.古诺：《财富理论的数学原理的研究》20.卡尔·门格尔：《国民经济学原理》21.杰文斯：《政治经济学理论》22.瓦尔拉斯：《纯粹经济学要义》23.庞巴维克：《资本实证论》24.戈森：《人类交换规律与人类行为准则的发展》25.汤普逊：《最能促进人类幸福的财富分配原理的研究》26.马歇尔：《经济学原理》27.约翰·希克斯：《价值与资本》28.李斯特：《政治经济学的国民体系》29.熊彼特：《资本主义、社会主义与民主》30.熊彼特：《经济发展理论》31.熊彼特：《经济分析史》32.凯恩斯：《就业、利息和货币通论》33.琼·罗宾逊：《不完全竞争经济学》34.萨缪尔森：《经济分析基础》35.肯尼斯·阿罗：《社会选择与个人价值》36.加尔布雷思：《经济学与公共目标》37.布坎南：《民主财政论》38.舒尔茨：《论人力资本投资》39.西蒙·库兹涅茨：《各国的经济增长》40.加里·贝克尔：《人类行为的经济分析》41.弗里德曼：《自由选择》42.弗里德曼：《价格理论》43.保罗·斯威齐：《资本主义发展论：一种解说》44.里昂惕夫：《投入产出经济学》45.罗伯特·索洛：《经济增长理论》46.泰勒尔：《产业组织理论》47.冯·哈耶克：《通向奴役之路》48.冯·哈耶克：《个人主义与经济秩序》 49.冯·米瑟斯：《自由与繁荣的国度》 50.道格拉斯·诺斯：《西方世界的兴起》51.约翰·纳什：《纳什博弈论论文集》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[经济学的100个关键词]]></title>
      <url>%2F2017%2F03%2F31%2F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%9A%84100%E4%B8%AA%E5%85%B3%E9%94%AE%E8%AF%8D%2F</url>
      <content type="text"><![CDATA[1.经济学（economics）：研究一个社会如何利用稀缺的资源进行有价值的生产，并把生产成果在社会成员之间进行分配的科学。2.稀缺（scarcity）：相对于人类无穷的欲望，资源总是显得不足的状态。3.效率（efficiency）：社会对资源的利用达到最佳状态，没有再改进的余地，即如果不让某个社会成员的境况变差，就不能让任何其他成员的境况变得更好。4.生产什么，如何生产，为谁生产（what，how and whom）：一个经济社会面临的基本问题，也叫资源配置，社会必须就这三个问题做出选择，以实现社会福利的最大化。5.微观经济学（microeconomics）：研究单个消费者、单个厂商、单个市场的经济学分支，其核心是价格的决定。6.宏观经济学（macroeconomics）：研究一个经济总体运行的经济学分支。7.计划经济（planned economy）：由中央计划当局决定生产什么、如何生产、为谁生产的经济。8.市场经济（market economy）：由市场特别是价格决定生产什么、如何生产、为谁生产的经济。9.亚当·斯密（Adam Smith，1723～1790年）：英国古典经济学的伟大代表，1776年出版《国民财富的性质和原因的研究》，从而创立了近代经济学体系。提出了著名的“看不见的手”的学说。他的另一部著作是1759年出版的《道德情操论》。 10.边际（marginal）：某个变量的微小变动，引起的其他变量的改变量。11.总收益（total revenue）：企业出售产品得到的全部货币。12.边际收益（marginal benifit）：某种活动的微小增加所增加的总收益。13.机会成本（opportunity cost）：一件事情的机会成本是把做这件事的资源用于其他事情，所能产出的最大价值。14.均衡（equilibrium）：本来是物理学上的概念，指物体受到大小相等方向相反的两个力的作用，而保持一种暂时不动的状态。经济学界借用这个概念，分析消费者、厂商以及宏观经济达到的最佳状态及其实现条件。15.经济人假设（economic man’s hypothesis）：每个人都是在给定约束下，追求自己利益极大化的人，是经济学最基本的假设。16.看不见的手（invisible hand）：最早由亚当·斯密在《国民财富的性质和原因的研究》中提出。他认为社会中存在着一种不同于人为秩序的“自然秩序”。看不见的手，实际上就是价格机制，在价格机制的诱导下，经济可以有效地运行，达到最佳状态，不需要政府的干预。 我:17.博弈论（game theory）：研究在当事人之间的决策互相影响的条件下，人们如何行动的一种方法。18.纳什均衡（Nash equilibrium）：博弈当事人战略的组合，其中每个人的战略都是在假定其他人战略不变的情况下的最佳战略。19.静态博弈（static game）：博弈的参加者同时做决策，或者虽然不同时，但是后行动者不知道先行动者的决策的一种博弈。20.战略（strategy）：博弈的参加者在什么条件下选择什么样的行动，以保证自身利益最大化。21.动态博弈（dynamic game）：博弈参加者的行动有先后，后行动者可以观察到先行动者的行为的一种博弈。22.需求（demand）：在其他条件不变的情况下，在给定价格下，消费者愿意并且能够购买的某种商品的数量。23.供给（supply）：在其他条件不变的情况下，在给定价格下，生产者愿意并且能够提供给市场的商品的数量。24.价格（price）：每单位商品、劳务的货币度量。25.市场（market）：买者和卖者相互作用决定价格的机制或者制度安排。26.均衡价格（equilibrium price）：需求量和供给量相等时的价格。27.效用（utility）：人们从物品的消费中得到的快乐和满足，可以用效用单位表示。28.边际效用（marginal utility）：新增加的一单位商品所增加的总效用。29.边际效用递减规律（law of diminishing marginal utility）：不断地增加对某种商品的消费，所增加的总效用越来越少。30.生产函数（production function）：在技术不变的条件下，一定量的投入与最大产出量之间关系的函数。31.边际产量（marginal product）：保持其他投入不变，单独增加某一种投入的一单位所增加的总产量。32.边际收益递减规律（law of diminishing marginal returns）：在技术和其他投入不变的条件下，单独增加某一种投入的一单位，所增加的总产量越来越少。33.企业家才能（entrepreneurship）：协调生产经营活动以及创新的能力。34.经济利润（economic profit）：总收益与总成本的差。35.正常利润（normal profit）：企业家才能的报酬，是生产成本的一部分。36.会计利润（accounting profit）：总收益减去会计成本。37.固定成本（fixed cost）：与产量无关的成本，或者说产量为零时的总成本。38.可变成本（variable cost）：随着产量变动而变动的成本，产量为零时，总可变成本是零。39.平均可变成本（average variable cost）：总可变成本除以总产量。 40.完全竞争（perfect competition）：一种市场结构，在这个市场上，存在过多的厂商，每个厂商的产量与总产量相比都是微不足道的，每个厂商都是价格的接受者，而不能影响价格。 41.垄断（monopoly）：只有一个厂商的市场结构，厂商对于价格有决定权。42.价格歧视（price discrimination）：出售同样的商品，向不同类型的买者收取不同的价格。43.消费者剩余（consumer surplus）：消费者愿意支付的价格与其实际支付的价格之差。44.自然垄断（natural monopoly）：指一个企业能以低于两个或者更多的企业生产时的成本为整个市场服务。45.垄断竞争（monopolistic competition）：一种市场结构，在其中，每个厂商生产的产品都与其他厂商有所差别，因此对消费者构成垄断；同时，每家厂商的产品差别又非常小，它们之间又存在竞争的关系。46.寡头（oligopoly）：少数几家大的厂商占据了市场的绝大部分份额。47.国内生产总值（gross domestic product，GDP）：一个国家在给定时期内，所生产的全部最终产品和劳务的市场价格的和。48.最终产品（final goods）：用于消费，不再进入下一阶段生产过程的产品。49.附加值（value added）：某一个环节上的附加值指的是售价与购进价格的差额。50.总需求（aggregate demand）：在给定时期内，在给定的价格水平下，一个经济中所有部门愿意购买的总和。51.大萧条（Great Depression）：指1929～1933年席卷整个资本主义世界的严重经济危机。52.萨伊定律（Say’s Law）：法国经济学家让·巴蒂斯特·萨伊（1767～1832）认为，供给能够创造它自己的需求，生产能够创造自己的销路，因此，不会有卖不出去的商品。萨伊定律可以概括凯恩斯之前全部经济学的精髓，即市场供求的力量可以自动达到充分就业状态，政府干预是不必要的。53.约翰·梅纳德·凯恩斯（John Maynard Keynes，1833～1946年）：英国人，1905年毕业于剑桥大学，后在英国财政部工作，1919年参加巴黎和会，写作《合约的经济后果》，获得世界性声誉。任剑桥大学经济学讲师，是20世纪以及有史以来最伟大的经济学家之一，1936年发表《就业、利息和货币通论》，创立现代宏观经济学体系，推翻了萨伊定律，主张国家干预经济。 54.财政（public finance）：政府的收支活动。55.公共物品（public goods）：每个人不管是否付费都可以消费的物品。56.税收（taxation）：政府利用强制力，无偿从居民或者企业取得的收入。57.财政政策（fiscal policy）：政府改变购买支出和转移支付规模，以及改变税收，调节总需求的手段。58.乘数效应（multiplier effect）：某些支出的变化，引起总产量数倍的变化。59.挤出效应（crowding out effect）：如果财政支出过多，企业和个人获得资金就困难了，利率就将提高，企业和个人的投资支出、消费支出就会减少，政府的支出就“挤出”了民间支出。60.货币（money）：被人们普遍接受的交易媒介或者支付手段。61.银行（bank）：从储户手里获得资金，借给需要资金的人，从中获取收益的企业。62.货币供给量（money supply）：一个经济中的货币总量。63.M1：现金和活期存款（支票存款）。64.M2：现金、活期存款和储蓄存款的和。65.中央银行（central bank）：银行的银行。66.货币政策（monetary policy）：中央银行控制货币供给量的手段。67.准备金（reserve）：商业银行吸收的存款中，按法律规定交给中央银行的部分。68.公开市场操作（open-market operation）：中央银行买进和卖出政府债券以影响货币供给量的行为。69.贴现率（discount rate）：商业银行向中央银行借款的利率。70.失业（unemployment）：年龄在16岁以上，有工作能力并且愿意接受现行工资条件，却没有被雇佣而正在寻找工作的人。71.失业率（unemployment rate）：失业人口占全部劳动力人口的百分比。72.自然失业率（natural rate of unemployment）：摩擦性失业率及结构性失业率的和。73.通货膨胀（inflation）：一般价格水平的上升，通常用CPI的变动程度来衡量。74.消费者价格指数（consumer price index，CPI）：计算方法是选取固定的“一篮子”商品，加权计算购买它们所需要的花费。 55.需求拉动型通货膨胀（demand-pull inflation）：因为总需求过大造成的通货膨胀。76.成本推动型通货膨胀（cost-push inflation）：由于成本上升造成的通货膨胀。77.惯性通货膨胀（inertial inflation）：如果大家都认为价格要上涨，并且据此调整所有合同，通货膨胀就将真的发生，并且持续下去。78.经济增长（economic growth）：一个国家潜在产出的持续增加。79.潜在产出（potential product）：一个国家最大的生产能力，可以用充分就业时的总产量衡量。80.72规则（rule 72）：用72除以一个变量的年平均增长率，就得到这个变量要翻一番所需要的年数。81.马尔萨斯的人口理论（Theory of Population of Thomas Robert Malthus）：托马斯·马尔萨斯（1766～1834），英国人，著名经济学家，以人口理论闻名于世。他认为，因为人口以几何级数增长，而生活资料以算术级数增长，所以，到一定时候，人类将面临饥饿的威胁。因此他提出要控制人口，并认为可以采取诸如战争和瘟疫等极端手段。82.人力资本（human capital）：个人通过教育和自身经历形成的可以用于生产的知识和技能。83.技术进步（technological progress）：生产工艺、过程的改进，或者新产品开发，使得在投入不变的情况下，产出仍然可以增加。84.国际贸易（international trade）：国家之间交换商品和相互提供劳务的活动，也叫世界贸易。85.绝对优势（absolute advantage）：如果一个国家生产某种产品的直接成本即会计成本比别的国家低，就说这个国家在这个产品的生产上具有绝对优势。首先由亚当·斯密在《国民财富的性质和原因的研究》中提出。86.比较优势（comparative advantage）：如果一个国家生产某种产品的机会成本比别的国家低，就说这个国家在这个产品的生产上具有比较优势。最早由英国伟大的经济学家大卫·李嘉图（David Ricardo，1772～1823）在1817年出版的《政治经济学及赋税原理》中提出。87.关税（customs，tariff）：一个国家对进出口物品征收的税。是最古老的税种之一。88.世界贸易组织（World Trade Organization，WTO）：一个独立于联合国的永久性国际组织，其前身为关税与贸易总协定（GATT），1995年1月1日正式开始运作，总部设在日内瓦。该组织的基本宗旨是通过实施非歧视、关税减让以及透明公平的贸易政策，来达到推动世界贸易自由化的目标。89.自由贸易（free trade）：不使用关税和非关税手段限制国际贸易的主张和政策。90.贸易保护主义（trade protectionism）：主张通过关税和非关税壁垒阻止外国产品进入本国市场，以保护本国产业的主张和政策。 91.关税壁垒（tariff barriers）：通过对进口产品征税阻止外国产品进入本国市场，或者对出口产品征税阻止本国产品出口。一般是指进口税。92.非关税壁垒（non-tariff barriers，NTB）：关税以外的阻止自由贸易的措施。93.配额（quota）：规定进口商品数量的做法。94.倾销（dumping）：进口产品的销售价格低于出口国的国内市场价格或低于其生产成本。95.汇率（foreign exchange rate）：一种货币与另一种货币相互交换的比率。96.外汇市场（foreign exchange market）：不同货币相互交换的场所。97.固定汇率制度（fixed exchange rates）：一个国家的货币采取盯住某一汇率水平而不变的制度。98.浮动汇率制度（floating exchange rates）：汇率由外汇市场决定，政府不规定汇率水平的制度。99.金本位制（gold standard）：一国规定其货币单位与某一固定量的黄金等价的制度。100.购买力平价理论（theory of purchasing power parity）：汇率的作用应该使不同货币在各国的购买力相等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(13)]]></title>
      <url>%2F2017%2F03%2F31%2F%E4%BD%A0%E6%87%82python%E5%90%97-13%2F</url>
      <content type="text"><![CDATA[Python垃圾回收机制​ Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。简单来说就是以引用计数为主，标记-清除和分代收集两种机制为辅 引用计数机制引用计数是啥？python里每一个东西都是对象，它们的核心就是一个结构体：PyObject 1234typedef struct_object &#123; int ob_refcnt; struct_typeobject *ob_type;&#125; PyObject; PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少 123456#define Py_INCREF(op) ((op)-&gt;ob_refcnt++) //增加计数#define Py_DECREF(op) \ //减少计数 if (--(op)-&gt;ob_refcnt != 0) \ ; \ else \ __Py_Dealloc((PyObject *)(op)) 当引用计数为0时，该对象生命就结束了。 导致引用计数+1的情况 ​ 对象被创建，例如a=23​ 对象被引用，例如b=a​ 对象被作为参数，传入到一个函数中，例如func(a)​ 对象作为一个元素，存储在容器中，例如list1=[a,a] 导致引用计数-1的情况 ​ 对象的别名被显式销毁，例如del a ​ 对象的别名被赋予新的对象，例如a=24 ​ 一个对象离开它的作用域，例如f函数执行完毕时，func函数中的局部变量 ​ 对象所在的容器被销毁，或从容器中删除对象 1234567891011121314151617181920212223242526272829303132333435import sysdef func(c): print 'in func function', sys.getrefcount(c) - 1if __name__ == '__main__': print 'init', sys.getrefcount(11) - 1 # 11初始化的引用值 a = 11 # 11被a引用 print 'after a=11', sys.getrefcount(11) - 1 b = a print 'after b=a', sys.getrefcount(11) - 1 #a被b引用 func(11) print 'after func(a)', sys.getrefcount(11) - 1 list1 = [a, 12, 14] print 'after list1=[a,12,14]', sys.getrefcount(11) - 1 a=12 print 'after a=12', sys.getrefcount(11) - 1 del a print 'after del a', sys.getrefcount(11) - 1 del b print 'after del b', sys.getrefcount(11) - 1 list1.pop(0) print 'after pop list1',sys.getrefcount(11)-1 del list1 print 'after del list1', sys.getrefcount(11) - 1#outputinit 30after a=11 31after b=a 32in func function 34after func(a) 32after list1=[a,12,14] 33after a=12 32after del a 32after del b 31after pop list1 30after del list1 30 引用计数机制的优点： 1、简单 2、实时性：一旦没有引用，内存就直接释放了。不用像其他机制等到特定时机。实时性还带来一个好处：处理回收内存的时间分摊到了平时。 引用计数机制的缺点： 1、维护引用计数消耗资源 2、循环引用 循环引用如何内存泄漏？有 del() 函数的对象间的循环引用是导致内存泄漏的主凶。但没有del()函数的对象间的循环引用是可以被垃圾回收器回收掉的。 首先我们要看一下没有内存泄漏的例子： 123456789101112131415161718192021222324252627282930313233343536373839import gcimport sysclass cycleLeak(object): def __init__(self): self._text = '#' * 10 def __del__(self): passdef make_cycle_ref(): _cycleLeak = cycleLeak() print '_cycleLeak ref count0: %d' % (sys.getrefcount(_cycleLeak)) del _cycleLeak try: print '_cycleLeak ref count1: %d' % (sys.getrefcount(_cycleLeak)) except UnboundLocalError: print '_cycleLeak is invalid !'def test_gcLeak(): gc.enable() # gc.set_debug(gc.DEBUG_LEAK) gc.set_debug(gc.DEBUG_COLLECTABLE | gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_INSTANCES | gc.DEBUG_OBJECTS) print 'begin gcleak test ....' make_cycle_ref() print 'gc begin collecting ....' _unreachable = gc.collect() print 'unreachable object num : %d ' % (_unreachable) ''' gc.garbage是一个list对象，列表项是垃圾收集器发现的不可达（即垃圾对象）、但又不能释放(不可回收)的对 象，通常gc.garbage中的对象是引用对象还中的对象。因Python不知用什么顺序来调用对象的__del__函数，导 致对象始终存活在gc.garbage中，造成内存泄露 ''' print 'garbage object num : %d' % (len(gc.garbage))if __name__ == '__main__': test_gcLeak()#outputbegin gcleak test ...._cycleLeak ref count0: 2 #对象_gcleak的引用计数为2_cycleLeak is invalid ! #因为执行了del函数，_gcleak变为了不可达的对象gc begin collecting .... #开始垃圾回收unreachable object num : 0 #本次垃圾回收发现的不可达的对象个数为0garbage object num : 0 #整个解释器中垃圾对象的个数为0 我们通过自我引用引起内存泄露，在上述程序中将 make_cycle_ref()添加如下： 123456789101112131415161718def make_cycle_ref(): _cycleLeak = cycleLeak() _cycleLeak._self=_cycleLeak #自我引用 print '_cycleLeak ref count0: %d' % (sys.getrefcount(_cycleLeak)) del _cycleLeak try: print '_cycleLeak ref count1: %d' % (sys.getrefcount(_cycleLeak)) except UnboundLocalError: print '_cycleLeak is invalid !'#outputbegin gcleak test ...._cycleLeak ref count0: 3_cycleLeak is invalid !gc begin collecting ....gc: uncollectable &lt;cycleLeak 0x7f4f50779350&gt;gc: uncollectable &lt;dict 0x7f4f5077a6e0&gt;unreachable object num : 2 #本次回收不可达的对象个数为2garbage object num : 1 #整个解释器中垃圾个数为1 我们互相引用导致内存泄漏,代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import gcimport sysclass cycleLeakA(object): def __init__(self): self._text = '#' * 10 def __del__(self): passclass cycleLeakB(object): def __init__(self): self._text = '#' * 10 def __del__(self): passdef make_cycle_ref(): _cycleLeakA = cycleLeakA() _cycleLeakB = cycleLeakB() _cycleLeakA._ref=_cycleLeakB _cycleLeakB._ref = _cycleLeakA print '_cycleLeak ref count0: _cycleLeakA %d ,_cycleLeakB %d' % (sys.getrefcount(_cycleLeakA),sys.getrefcount(_cycleLeakB)) del _cycleLeakA del _cycleLeakB try: print '_cycleLeak ref count1: _cycleLeakA %d ,_cycleLeakB %d' % (sys.getrefcount(_cycleLeakA),sys.getrefcount(_cycleLeakB)) except UnboundLocalError: print '_cycleLeak is invalid !'def test_gcLeak(): gc.enable() gc.set_debug(gc.DEBUG_COLLECTABLE | gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_INSTANCES | gc.DEBUG_OBJECTS ) print 'begin gcleak test ....' make_cycle_ref() print 'gc begin collecting ....' _unreachable = gc.collect() print 'unreachable object num : %d ' % (_unreachable) print 'garbage object num : %d' % (len(gc.garbage))if __name__ == '__main__': test_gcLeak()#outputbegin gcleak test ...._cycleLeak ref count0: _cycleLeakA 3 ,_cycleLeakB 3_cycleLeak is invalid !gc begin collecting ....unreachable object num : 4 garbage object num : 2gc: uncollectable &lt;cycleLeakA 0x7f59f3a04710&gt;gc: uncollectable &lt;cycleLeakB 0x7f59f3a04750&gt;gc: uncollectable &lt;dict 0x7f59f3a05a28&gt;gc: uncollectable &lt;dict 0x7f59f3a056e0&gt; 注意：如果我们将class cycleLeak(object)的__del__属性删除，garbage object num将会是0，为什么呢？因为如果循环引用中，两个对象都定义了__del__方法，gc模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的__del__方法，所以为了安全起见，gc模块会把对象放到gc.garbage中，但是不会销毁对象。 上述的例子使用了gc模块，我们简单的介绍一下gc模块 常用函数： gc.set_debug(flags) 设置gc的debug日志，一般设置为gc.DEBUG_LEAK ，也可以是上述事例gc.collect([generation]) 显式进行垃圾回收，可以输入参数，0代表只检查第一代的对象，1代表检查一，二代的对象，2代表检查一，二，三代的对象，如果不传参数，执行一个full collection，也就是等于传2。返回不可达（unreachable objects）对象的数目gc.get_count() 获取当前自动执行垃圾回收的计数器，返回一个长度为3的列表 解释如下： 12345678910111213import gcclass A(object): passif __name__ == '__main__': print 'gc.get_count()' ,gc.get_count() a=A() print 'gc.get_count()', gc.get_count() del a print 'gc.get_count()', gc.get_count()#outputgc.get_count() (581, 8, 0)gc.get_count() (582, 8, 0)gc.get_count() (581, 8, 0) （581，8，0）其中 581指距离上一次一代垃圾检查Python分配内存的数目减去释放内存的数目 8指距离上一次二代垃圾检查，一代垃圾检查的次数 0是指距离上一次三代垃圾检查，二代垃圾检查的次数 gc.set_threshold(threshold0[, threshold1[, threshold2]) 设置自动执行垃圾回收的频率。 解释如下： gc模快有一个自动垃圾回收的阀值，即通过gc.get_threshold函数获取到的长度为3的元组，例如(700,10,10)每一次计数器的增加，gc模块就会检查增加后的计数是否达到阀值的数目，如果是，就会执行对应的代数的垃圾检查，然后重置计数器。 例如，假设阀值是(700,10,10)： 当计数器从(699,3,0)增加到(700,3,0)，gc模块就会执行gc.collect(0),即检查一代对象的垃圾，并重置计数器为(0,4,0) 当计数器从(699,9,0)增加到(700,9,0)，gc模块就会执行gc.collect(1),即检查一、二代对象的垃圾，并重置计数器为(0,0,1) 当计数器从(699,9,9)增加到(700,9,9)，gc模块就会执行gc.collect(2),即检查一、二、三代对象的垃圾，并重置计数器为(0,0,0) 使用方法： 必须要import gc模块，并且is_enable()=True才会启动自动垃圾回收。这个机制的主要作用就是发现并处理不可达的垃圾对象。垃圾回收=垃圾检查+垃圾回收在Python中，采用分代收集的方法。把对象分为三代，一开始，对象在创建的时候，放在一代中，如果在一次一代的垃圾检查中，改对象存活下来，就会被放到二代中，同理在一次二代的垃圾检查中，该对象存活下来，就会被放到三代中。 标记-清除？标记-清除机制，顾名思义，首先标记对象（垃圾检测），然后清除垃圾（垃圾回收）。基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。 首先初始所有对象标记为白色，并确定根节点对象（这些对象是不会被删除），标记它们为黑色（表示对象有效）。将有效对象引用的对象标记为灰色（表示对象可达，但它们所引用的对象还没检查），检查完灰色对象引用的对象后，将灰色标记为黑色。重复直到不存在灰色节点为止。最后白色结点都是需要清除的对象。 这里所采用的高级机制作为引用计数的辅助机制，用于解决产生的循环引用问题。而循环引用只会出现在“内部存在可以对其他对象引用的对象”，比如：list，class等。为了要将这些回收对象组织起来，需要建立一个链表。自然，每个被收集的对象内就需要多提供一些信息，下面代码是回收对象里必然出现的。 123456789/* GC information is stored BEFORE the object structure. */typedef union _gc_head &#123; struct &#123; union _gc_head *gc_next; union _gc_head *gc_prev; Py_ssize_t gc_refs; &#125; gc; long double dummy; /* force worst-case alignment */&#125; PyGC_Head; 一个对象的实际结构如图所示： 通过PyGC_Head的指针将每个回收对象连接起来，形成了一个链表，也就是在1里提到的初始化的所有对象。 分代收集？分代技术是一种典型的以空间换时间的技术，这也正是java里的关键技术。这种思想简单点说就是：对象存在时间越长，越可能不是垃圾，应该越少去收集。分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 举例： 当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 这样的思想，可以减少标记-清除机制所带来的额外操作。分代就是将回收对象分成数个代，每个代就是一个链表（集合），代进行标记-清除的时间与代内对象存活时间成正比例关系。 12345678910111213141516171819/*** Global GC state ***/ struct gc_generation &#123; PyGC_Head head; int threshold; /* collection threshold */ int count; /* count of allocations or collections of younger generations */ &#125;;//每个代的结构 #define NUM_GENERATIONS 3//代的个数#define GEN_HEAD(n) (&amp;generations[n].head) /* linked lists of container objects */static struct gc_generation generations[NUM_GENERATIONS] = &#123; /* PyGC_Head, threshold, count */ &#123;&#123;&#123;GEN_HEAD(0), GEN_HEAD(0), 0&#125;&#125;, 700, 0&#125;, &#123;&#123;&#123;GEN_HEAD(1), GEN_HEAD(1), 0&#125;&#125;, 10, 0&#125;, &#123;&#123;&#123;GEN_HEAD(2), GEN_HEAD(2), 0&#125;&#125;, 10, 0&#125;, &#125;; PyGC_Head *_PyGC_generation0 = GEN_HEAD(0); 从上面代码可以看出python里一共有三代，每个代的threshold值表示该代最多容纳对象的个数。默认情况下，当0代超过700,或1，2代超过10，垃圾回收机制将触发。0代触发将清理所有三代，1代触发会清理1,2代，2代触发后只会清理自己。 整个过程包括链表建立，确定根节点，垃圾标记，垃圾回收。 链表建立0代触发将清理所有三代，1代触发会清理1,2代，2代触发后只会清理自己。在清理0代时，会将三个链表（代）链接起来，清理1代的时，会链接1,2两代。在后面三步，都是针对的这个建立之后的链表。 确定根节点如下图的例子，ist1与list2循环引用，list3与list4循环引用，a是一个外部引用。 对于这样一个链表，我们如何得出根节点呢。python里是在引用计数的基础上又提出一个有效引用计数的概念。顾名思义，有效引用计数就是去除循环引用后的计数。下面是计算有效引用计数的相关代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* Set all gc_refs = ob_refcnt. After this, gc_refs is &gt; 0 for all objects * in containers, and is GC_REACHABLE for all tracked gc objects not in * containers. */static voidupdate_refs(PyGC_Head *containers)&#123; PyGC_Head *gc = containers-&gt;gc.gc_next; for (; gc != containers; gc = gc-&gt;gc.gc_next) &#123; assert(gc-&gt;gc.gc_refs == GC_REACHABLE); gc-&gt;gc.gc_refs = Py_REFCNT(FROM_GC(gc)); assert(gc-&gt;gc.gc_refs != 0); &#125;&#125;/* A traversal callback for subtract_refs. */static intvisit_decref(PyObject *op, void *data)&#123; assert(op != NULL); if (PyObject_IS_GC(op)) &#123; PyGC_Head *gc = AS_GC(op); /* We're only interested in gc_refs for objects in the * generation being collected, which can be recognized * because only they have positive gc_refs. */ assert(gc-&gt;gc.gc_refs != 0); /* else refcount was too small */ if (gc-&gt;gc.gc_refs &gt; 0) gc-&gt;gc.gc_refs--; &#125; return 0;&#125;/* Subtract internal references from gc_refs. After this, gc_refs is &gt;= 0 * for all objects in containers, and is GC_REACHABLE for all tracked gc * objects not in containers. The ones with gc_refs &gt; 0 are directly * reachable from outside containers, and so can't be collected. */static voidsubtract_refs(PyGC_Head *containers)&#123; traverseproc traverse; PyGC_Head *gc = containers-&gt;gc.gc_next; for (; gc != containers; gc=gc-&gt;gc.gc_next) &#123; traverse = Py_TYPE(FROM_GC(gc))-&gt;tp_traverse; (void) traverse(FROM_GC(gc), (visitproc)visit_decref, NULL); &#125;&#125; update_refs函数里建立了一个引用的副本。 visit_decref函数对引用的副本减1，subtract_refs函数里traverse的作用是遍历对象里的每一个引用，执行visit_decref操作。 最后，链表内引用计数副本非0的对象，就是根节点了。 垃圾标记 接下来，python建立两条链表，一条存放根节点，以及根节点的引用对象。另外一条存放unreachable对象。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/* A traversal callback for move_unreachable. */static intvisit_reachable(PyObject *op, PyGC_Head *reachable)&#123; if (PyObject_IS_GC(op)) &#123; PyGC_Head *gc = AS_GC(op); const Py_ssize_t gc_refs = gc-&gt;gc.gc_refs; if (gc_refs == 0) &#123; /* This is in move_unreachable's 'young' list, but * the traversal hasn't yet gotten to it. All * we need to do is tell move_unreachable that it's * reachable. */ gc-&gt;gc.gc_refs = 1; &#125; else if (gc_refs == GC_TENTATIVELY_UNREACHABLE) &#123; /* This had gc_refs = 0 when move_unreachable got * to it, but turns out it's reachable after all. * Move it back to move_unreachable's 'young' list, * and move_unreachable will eventually get to it * again. */ gc_list_move(gc, reachable); gc-&gt;gc.gc_refs = 1; &#125; /* Else there's nothing to do. * If gc_refs &gt; 0, it must be in move_unreachable's 'young' * list, and move_unreachable will eventually get to it. * If gc_refs == GC_REACHABLE, it's either in some other * generation so we don't care about it, or move_unreachable * already dealt with it. * If gc_refs == GC_UNTRACKED, it must be ignored. */ else &#123; assert(gc_refs &gt; 0 || gc_refs == GC_REACHABLE || gc_refs == GC_UNTRACKED); &#125; &#125; return 0;&#125;/* Move the unreachable objects from young to unreachable. After this, * all objects in young have gc_refs = GC_REACHABLE, and all objects in * unreachable have gc_refs = GC_TENTATIVELY_UNREACHABLE. All tracked * gc objects not in young or unreachable still have gc_refs = GC_REACHABLE. * All objects in young after this are directly or indirectly reachable * from outside the original young; and all objects in unreachable are * not. */static voidmove_unreachable(PyGC_Head *young, PyGC_Head *unreachable)&#123; PyGC_Head *gc = young-&gt;gc.gc_next; /* Invariants: all objects "to the left" of us in young have gc_refs * = GC_REACHABLE, and are indeed reachable (directly or indirectly) * from outside the young list as it was at entry. All other objects * from the original young "to the left" of us are in unreachable now, * and have gc_refs = GC_TENTATIVELY_UNREACHABLE. All objects to the * left of us in 'young' now have been scanned, and no objects here * or to the right have been scanned yet. */ while (gc != young) &#123; PyGC_Head *next; if (gc-&gt;gc.gc_refs) &#123; /* gc is definitely reachable from outside the * original 'young'. Mark it as such, and traverse * its pointers to find any other objects that may * be directly reachable from it. Note that the * call to tp_traverse may append objects to young, * so we have to wait until it returns to determine * the next object to visit. */ PyObject *op = FROM_GC(gc); traverseproc traverse = Py_TYPE(op)-&gt;tp_traverse; assert(gc-&gt;gc.gc_refs &gt; 0); gc-&gt;gc.gc_refs = GC_REACHABLE; (void) traverse(op, (visitproc)visit_reachable, (void *)young); next = gc-&gt;gc.gc_next; &#125; else &#123; /* This *may* be unreachable. To make progress, * assume it is. gc isn't directly reachable from * any object we've already traversed, but may be * reachable from an object we haven't gotten to yet. * visit_reachable will eventually move gc back into * young if that's so, and we'll see it again. */ next = gc-&gt;gc.gc_next; gc_list_move(gc, unreachable); gc-&gt;gc.gc_refs = GC_TENTATIVELY_UNREACHABLE; &#125; gc = next; &#125;&#125; 标记之后，链表如下图： 垃圾回收回收的过程，就是销毁不可达链表内对象。下面代码就是list的清除方法： 12345678910111213141516171819202122232425/* Methods */static voidlist_dealloc(PyListObject *op)&#123; Py_ssize_t i; PyObject_GC_UnTrack(op); Py_TRASHCAN_SAFE_BEGIN(op) if (op-&gt;ob_item != NULL) &#123; /* Do it backwards, for Christian Tismer. There's a simple test case where somehow this reduces thrashing when a *very* large list is created and immediately deleted. */ i = Py_SIZE(op); while (--i &gt;= 0) &#123; Py_XDECREF(op-&gt;ob_item[i]); &#125; PyMem_FREE(op-&gt;ob_item); &#125; if (numfree &lt; PyList_MAXFREELIST &amp;&amp; PyList_CheckExact(op)) free_list[numfree++] = op; else Py_TYPE(op)-&gt;tp_free((PyObject *)op); Py_TRASHCAN_SAFE_END(op)&#125; 参考：http://www.cnblogs.com/hackerl/p/5901553.html http://www.jianshu.com/p/1e375fb40506 http://www.cnblogs.com/Xjng/p/5128269.html http://www.cnblogs.com/kaituorensheng/p/4449457.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(12)]]></title>
      <url>%2F2017%2F03%2F31%2F%E4%BD%A0%E6%87%82python%E5%90%97-12%2F</url>
      <content type="text"><![CDATA[python的拷贝1234567891011121314151617import copyif __name__ == '__main__': a=[1,2,3,[4,5,6]] b=a c=copy.copy(a) #浅拷贝 d=copy.deepcopy(a) #深拷贝 a.append(7) a[3].append(8) print 'a', a print 'b', b print 'c', c print 'd', d#outputa [1, 2, 3, [4, 5, 6, 8], 7]b [1, 2, 3, [4, 5, 6, 8], 7]c [1, 2, 3, [4, 5, 6, 8]]d [1, 2, 3, [4, 5, 6]]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(11)]]></title>
      <url>%2F2017%2F03%2F30%2F%E4%BD%A0%E6%87%82python%E5%90%97-11%2F</url>
      <content type="text"><![CDATA[lambda函数lambda的使用大量简化了代码，使代码简练清晰; lambda函数也叫匿名函数，即，函数没有具体的名称,而用def创建的方法是有名称的; 1234567891011121314def add_action(x): return x+100if __name__ == '__main__': list=[1,2,3,4] print map(add_action,list)#output[101, 102, 103, 104]#等价于if __name__ == '__main__': print map(lambda x : x+100,[1,2,3,4])#output[101, 102, 103, 104] lambda高效操作列表filter(bool_func,seq)：此函数的功能相当于过滤器。调用一个布尔函数bool_func来迭代遍历每个seq中的元素；返回一个使bool_seq返回值为true的元素的序列。 12345678910filter(lambda x : x%2 == 0,[1,2,3,4,5])#output[2,4]#filter的实现如下：def filter(bool_func,seq): filtered_seq = [] for eachItem in seq: if bool_func(eachItem): filtered_seq.append(eachItem) return filtered_seq map(func,seq1[,seq2…])：将函数func作用于给定序列的每个元素，并用一个列表来提供返回值；如果func为None，func表现为身份函数，返回一个含有每个序列中元素集合的n个元组的列表。 123456789map(lambda x : x+100,[1,2,3,4])#output[101,102,103,104]#map的实现如下：def map(func,seq): mapped_seq = [] for eachItem in seq: mapped_seq.append(func(eachItem)) return mapped_seq reduce(func,seq[,init])：func为二元函数，将func作用于seq序列的元素，每次携带一对（先前的结果以及下一个序列的元素），连续的将现有的结果和下一个值作用在获得的随后的结果上，最后减少我们的序列为一个单一的返回值：如果初始值init给定，第一个比较会是init和第一个序列元素而不是序列的头两个元素。 1234567891011121314reduce(lambda x,y : x + y,[1,2,3,4],initial=10) reduce(lambda x,y : x + y,[1,2,3,4],10) #等价#output20#reduce的实现如下：def reduce(bin_func,seq,initial=None): lseq = list(seq) if initial is None: res = lseq.pop(0) else: res = initial for eachItem in lseq: res = bin_func(res,eachItem) return res 参考：http://blog.csdn.net/prince2270/article/details/4681299]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(10)]]></title>
      <url>%2F2017%2F03%2F30%2F%E4%BD%A0%E6%87%82python%E5%90%97-10%2F</url>
      <content type="text"><![CDATA[Python的闭包和装饰器“learning about descriptors creates a deeper understanding of how python works and an appreciation for the elegance of its design”。 ​ 在python中，一般存在以下几个变量类型，local：函数内部作用域；enclosing：函数内部与内嵌函数之间；global：全局作用域；build-in：内置作用域。解释器在遇到变量的时候，会按照如下的顺序进行查找：L &gt; E &gt; G &gt; B，简称LEGB。 LEGB的理解？我们看一下如下代码： 123456789101112131415161718192021222324252627global valpassline = 60def func(val): print "0x%x" % id(val) #val对于func函数是local变量，对于in_func是enclosing变量 passline = 90 #我们看到结果是fail，说明passline最终取值是90 if val &gt;= passline: print "pass" else: print "fail" def in_func(): print 'val',val return in_funcdef Max(val1, val2): # max is a built-in fun return max(val1, val2) if __name__ == '__main__': fff = func(89) fff() print fff.__closure__ print Max(90, 100)#output0x10d38a8failval 89(&lt;cell at 0x7fa84c2750f8: int object at 0x10d38a8&gt;,)100 ​ 在python中，函数是一个对象（可以通过type函数查看），在内存中占用空间；函数执行完成之后内部的变量会被解释器回收，但是如果某变量被返回，则不会回收，因为引用计数器的值不为0；既然函数也是一个对象，他也拥有自己的属性；对于python函数来说，返回的不一定是变量，也可以是函数。我们在func函数中又定义了一个函数in_func，它目的是打印输出变量val，可是在输出过程查找变量的时候发现本地没有，于是它就会去func函数里面找，并且找到了val，val就是我们所说的对于in_func是enclosing变量。 ​ 分析代码执行的过程，我们发现func函数返回了in_func函数给了fff，但是没有打印出val，也就是没有返回变量，意味着在调用func完成之后val变量应该已经被解释器回收，但是在执行了 fff() 函数之后却仍然输出了val的值89，为什么呢？其原因就是：如果引用了enclosing作用域变量的话，会将变量添加到函数属性中，当再次查找变量时，不是去代码中查找，而是去函数属性中查找。因为上述结果我们看到fff()函数的__closure__属性拥有一个变量，这个变量的ID和func函数中val变量的ID一样0x10d38a8。 上面的代码是用来判断学生的成绩是否及格，即在百分制中60分及格，如果现在需要添加新的功能，即150分制中90分作为及格线，如何完成代码呢？最简单的就是我们创建两个函数，分别为func_100和func_150来完成判断，判断逻辑完全一样，代码如下： 12345678910111213141516171819def func_150(val): passline = 90 if val &gt;= passline: print "pass" else: print "fail"def func_100(val): passline = 60 if val &gt;= passline: print "pass" else: print "fail"if __name__ == '__main__': func_100(89) func_150(89)#outputpassfail 使用闭包()实现如下,可见闭包就是内部函数中对enclosing作用域的变量进行引用。 12345678910111213141516171819202122232425262728def set_passline(passline): print '0x%x' % id(passline) def cmp(val): if val &gt;= passline: print "pass" else: print "fail" return cmpif __name__ == '__main__': f_100 = set_passline(60) print type(f_100) print f_100.__closure__ f_100(89) print "****************" f_150 = set_passline(90) print type(f_150) print f_150.__closure__ f_150(89)#output0x24a9398&lt;type 'function'&gt;(&lt;cell at 0x7fa5730a30f8: int object at 0x24a9398&gt;,)pass****************0x24a9890&lt;type 'function'&gt;(&lt;cell at 0x7fa5730a3130: int object at 0x24a9890&gt;,)fail 什么是装饰器？“装饰器的功能是将被装饰的函数当作参数传递给与装饰器对应的函数（名称相同的函数），并返回包装后的被装饰的函数” 简而言之：@a 就是将 b 传递给 a()，并返回新的 b = a(b) 装饰器是闭包的一种应用？​ 闭包：在计算机科学中，闭包（Closure）是词法闭包（Lexical Closure）的简称，是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 ​ 上面提到了两个关键的地方： 自由变量 和 函数。望文知意，可以形象的把它理解为一个封闭的包裹，这个包裹就是一个函数，当然还有函数内部对应的逻辑，包裹里面的东西就是自由变量，自由变量可以在随着包裹到处游荡。当然还得有个前提，这个包裹是被创建出来的。 ​ 在通过Python的语言介绍一下，一个闭包就是你调用了一个函数A，这个函数A返回了一个函数B给你。这个返回的函数B就叫做闭包。你在调用函数A的时候传递的参数就是自由变量。 我们再来看装饰器发现其本身就是闭包的一种应用。 1234567891011121314151617def make_bold(fn): def wrapped(): return '&lt;b&gt;' + fn() + '&lt;b&gt;' return wrappeddef make_italic(fn): def wrapped(): return '&lt;i&gt;' + fn() + '&lt;i&gt;' return wrapped@make_italic # hello=make_italic(make_bold(hello))@make_bold # hello=make_bold (hello)def hello(): return 'hello,python'if __name__ == '__main__': print hello()#output&lt;i&gt;&lt;b&gt;hello,python&lt;b&gt;&lt;i&gt; ​ 闭包的最大特点是可以将父函数的变量与内部函数绑定，并返回绑定变量后的函数（也即闭包），此时即便生成闭包的环境（父函数）已经释放，闭包仍然存在，这个过程很像类（父函数）生成实例（闭包），不同的是父函数只在调用时执行，执行完毕后其环境就会释放，而类则在文件执行时创建，一般程序执行完毕后作用域才释放，因此对一些需要重用的功能且不足以定义为类的行为，使用闭包会比使用类占用更少的资源，且更轻巧灵活，现举一例：假设我们仅仅想打印出各类动物的叫声，分别以类和闭包来实现： 123456789101112131415161718class Animal(): def __init__(self,animal): self.animal=animal def sound(self,voice): print self.animal , ':',voicedef Voice(animal): def sound(voice): print animal , ':' ,voice return soundif __name__ == '__main__': dog=Animal('dog') dog.sound('wangwang') cat=Voice('cat') cat('miaomiao')#outputdog : wangwangcat : miaomiao ​ 可以看到输出结果是完全一样的，但显然类的实现相对繁琐，且这里只是想输出一下动物的叫声，定义一个 Animal 类未免小题大做，而且 voice 函数在执行完毕后，其作用域就已经释放，但 Animal 类及其实例 dog 的相应属性却一直贮存在内存中。 参考：http://www.jb51.net/article/63331.htm http://www.cnblogs.com/cotyb/p/5243252.html https://segmentfault.com/a/1190000004461404]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(3)]]></title>
      <url>%2F2017%2F03%2F27%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-3%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： 网络的工作原理 实现 IP 编址方案和 IP 服务，以满足中型企业分支机构网络的网络需求 DoD 模型​ DoD 模型的进程/应用层包含大量的协议，以集成分布在 OSI 上三层(应用层、表示层和会话层)的各种活动和职责 。 ​ 主机到主机层的功能与 OSI 模型的传输层相同，定义了用于为应用程序提供传输服务的协议，它负责解决的问题包括进行可靠的端到端通信和确保正确地传输数据，还对分组进行排序，并确保数据的完整性。 ​ 因特网层对应 OSI 模型的网络层，指定了与通过整个网络对分组进行逻辑传输相关的协议。它负责对主机进行编址一一给它们分配 IP (因特网协议)地址，还在多个网络之间路由分组。 ​ DoD 模型的最底端是网络接入层，它在主机和网络之间交换数据。网络接入层对应 OSI 模型的数据链路层和物理层，它负责硬件编址，并定义了用于实际传输数据的协议。 DoD模型中的协议 进程/应用层协议包括如下协议和应用程序： Telnet ​ 它让远程客户端机器( Telnet 客户端)的用户能够访问另一台机器( Telnet 服务器)的资源。 要建立 Telnet会话，用户首先运行 Telnet 客户端软件，然后登录 Telnet 服务器 。 FTP （File Transfer Protocol ，文件传输协议 ） ​ 让你能够传输文件，这可在任何两台使用它的机器之间进行。然而， FTP 不仅仅是协议，还是程序。作为协议， FTP 供应用程序使用;作为程序， FTP 供用户手工执行与文件相关的任务。FTP 让你能够访问目录和文件以及执行某些类型的目录操作，如将其移到其他目录中。 TFTP （Trivial File Transfer Protocol ，简单文件传输协议 ） ​ 是 FTP 的简化版，但如果你知道自己要什么以及到哪里去寻找，也可使用它。另外，它使用起来非常简单，速度也很快。然而，它提供的功能没有 FTP 丰富。 TFTP 没有提供目录浏览功能，除发送和接收文件外什么也不能做。 NFS （NetworkFile System ，网络文件系统 ） ​ 是一种致力于文件共享的协议，让两种不同的文件系统能够互操作。其工作原理大致如下:假设 NFS 服务器端软件运行在 Windows 服务器上，而 NFS 客户端软件运行在 Unix 主机上， NFS让 Windows服务器的部分 RAM 看起来像存储的是 Unix 文件，可被 Unix 用户使用。虽然 Windows 文件系统和 Unix 文件系统不同一一它们在是否区分大小写、文件名长度、安全性等方面不同，但 Unix 用户和 Windows 用户可像通常那样访问相同的文件，就像文件位于他们通常使用的文件系统中一样。 SMTP （SimpleMail Transfer Protocol，简单邮件传输协议 ） ​ 解决了无处不在的邮件收发需求，它使用假脱机(排队)的方式传递邮件。邮件到达目的地后，将被存储到设备(通常是磁盘)中。目标端的服务器软件定期检查队列，看其中是否有邮件。发现邮件后，它将把它们投递给收件人。 SMTP用于发送电子邮件，而 POP3 或 IMAP 用于接收邮件。 POP （Post Office Protocol ，邮局协议 ） ​ 提供了一种对到来邮件进行存储的机制，其最新版本为POP3 。 这种协议的工作原理如下:客户端设备连接到POP3 服务器后，可下载发送给它的邮件。它不允许选择性地下载邮件，但邮件下载后，客户端/服务器交互就结束了，用户可在本地随意删除和操作邮件。 MAP4 （Internet Message Access Proωcol，因特网消息访问协议 ） ​ 让你能够控制邮件的下载方式，因此使用它可获得亟需的安全性。它让你能够查看邮件头或下载邮件的一部分一一你可以咬住鱼饵，而不是将其整个吞下，进而被藏在鱼饵中的鱼钩钩住。使用 IMAP 时，你可选择将邮件以层次方式存储在电子邮件服务器中，并链接到文档和用户组。lMAP 甚至提供了搜索命令，让你能够根据主题、邮件头或内容搜索邮件。可以想见，它提供了一些身份验证功能一一实际上它支持 MIT 开发的 Kerberos 身份验证方案。 lMAP4 是最新的版本。 TLS （Transport Layer Security，传输层安全 ） ​ 及其前身 SSL ( Secure Sockets Layer，安全套接字层)都是加密协议，非常适合用于确保在线数据传输的安全，如 Web 浏览、即时通信、因特阿传真等。 SIP （VoIP，Session lnitiation Protocol，会话发起协议 ） ​ 是一种非常流行的信令胁议，用于建立和拆除多媒体通信会话，其应用非常广泛，可用于因特网上的语音和视频呼叫、视频会议、流媒体分发、即时通信、状态信息( presence information )、在线游戏等。 RTP （Real-time Transport，实时传输协议） ​ 是一种分组格式标准，用于通过因特网传输 语音和视频。 虽然它最初被设计为一种组播协议，但现在也被用于单播应用程序中。它常被用于流式媒体、视频会议和一键通( push to talk )系统，这使其成了 VoIP (Voice over IP，四语音)行业的事实标准。 LDP（Line Printer Daemon ，行式打印机守护进程） ​ 协议设计用于共享打印机。 LPD 和 LPR (Line Printer ，行式打印机)程序相互协作，使得能够将打印作业排队并使用 TCPIIP 将其发送给网络打印机 。 XWindow ​ XWindow 是为客户端/服务器操作设计的 ， 是一种编写基于 GUI (Graphical User Interface ，图形用户界面)的客户端/服务器应用程序的协议。其基本思想是，让运行在一台计算机上的客户端程序能够通过窗口服务器显示另一台计算机的内容。 SNMP ​ SNMP (Simple Network Management Protocol ，简单网络管理协议)收集并操作有价值的网络信息。它运行在管理工作站上，定期或随机地轮询网络中的设备，要求它们暴露特定的信息，以收集数据。在一切正常的情况下， SNMP将收到基线 (baseline) 信息 ， 即描述健康网络运行特征的报告。该协议还可充当网络的看门狗，将任何突发事件迅速告知管理员 。 SSH ​ 安全外壳 (SSH) 协议通过标准 TCPIIP 连接建立安全的 Telnet会话，用于执行如下操作:登录系统、在远程系统中运行程序以及在系统间传输文件等。它在执行这些操作时都使用健壮的加密连接。你可将其视为用于替代 rsh 、 rlogin 甚至 Telnet 的新一代协议。 HTTP​ 所有出色的网站都会包含图像、文本、链接等，这一切都是拜 HTTP ( Hypertext Transfer Protocol ,超文本传输协议)所赐。 它用于管理 Web 浏览器和 Web 服务器之间的通信，在你单击链接时打开相应的资源，而不管该资源实际位于何地。 HTTPS​ HTTPS(Hyp巳rtext Transfer Protoco1 Secure ，安全超文本传输协议)使用 SSL ( Secure Socket Layer ,安全套接字层)，有时也称为 SHTTP 或 S-HTTP( 这是一个 HTTP 扩展，不使用 SSL )，但这无关紧要。顾名思义，它是安全版盯TP ，提供了一系列安全工具，可确保 Web 浏览器和 Web 服务器之间的通信安全。当你在网上预订或购物时，浏览器需要使用它来填写表格、签名、验证和加密 HTTP 消息。 NTP​ NTP (Network Time Protoco1 ，网络时间协议)用于将计算机时钟与标准时间源(通常是原子钟)同步，由特拉华大学的 DavidMills 教授开发 。 NTP 将设备同步，确保给定网络中所有计算机的时间一致。这虽然听起来非常简单，但却非常重要，因为当今的很多交易都需要指出时间和日期。想想你的数据库吧，如果服务器不与相连的计算机同步，哪怕只相差几秒，也会带来严重的混乱(甚至崩溃)。如果某台机器在凌晨 1:50 发起交易，而服务器将交易时间记录为 1:45 ，交易将无法完成。 NNTP​ NNTP (Network News TransferProtoco1 ，网络新闻传输协议)用于访问 Usenet新闻服务器，这种服务器存储了大量称为新闻组的留言板。你可能知道，这些新闻组可以是任何有特定兴趣的人群。例如，如果你是某款经典车型的发烧友或 WWII 飞机爱好者很可能有大量基于这些兴趣爱好的新闻组供你加入。 NNTP 是在RFC977 中定义的。鉴于新闻阅读器程序的配置非常复杂，我们通常依靠很多网站(甚至搜索引擎)来访问各种资源。 SCP​ FTP 很好，它易于使用，是一种用户友好型文件传输方式一一前提是你不需要安全地传输这些文件。这是因为使用 FTP 传输数据时，将随文件请求以明文方式发送用户名和密码，根本没有加密，任何人都能看到。这就像绝境中的孤注一掷，你只是将信息发送出去，并析祷信息不要被坏人拦截。在这样的场合， SCP ( Secure Copy Protoco1 ，安全复制协议)可提供帮助，它通过 SSH 保护你金贵的文件。它首先在发送主机和接收主机之间建立一条安全的加密连接，并一直保持这种状态，直到文件传输完毕。有了 SCP ，你孤注一掷抛出的球将只能被目标接收方获得!然而，在当今的网络中，更健壮的 SFTP 比 SCP 更常用。 LDAP​ 如果管理的网络规模适当，你很可能会在某个地方存储目录，记录所有的网络资源，如设备和用户。但如何访问这些目录呢?通过 LDAP (Lightweight Directory Access Protocol ，轻量级目录访问协议)。该协议对如何访问目录进行了标准化，其第 l 版和第 2 版分别是在RFC 1487 和RFC 1777 中定义的。这两个版本存在一些缺陷，为解决这些问题，人们开发了第 3 版 LDAP (当前最常用的版本)，这是在RFC3377 中定义的。 IGMP （Internet Group Management Protocol ，因特网组管理协议）​ IGMP是一种用于管理 IP 组播会话的TCPIIP 协议，它这样完成其职责:通过网络发送唯一的 IGMP 消息，以揭示组播组信息，并找出主机所属的组播组。 IP 网络中的主机也使用 IGMP 消息来加入和退出组播组。 IGMP 消息非常方便用于跟踪组成员关系以及激活组播流。 LPR​ 在纯粹的 TCP/IP 环境中打印时，人们通常结合使用 LPR (行式打印机)和 LPD (Line Printer Daemon ，行式打印机守护进程)来完成打印作业。 LPD 安装在所有打印设备上，负责处理打印机和打印作业。 LPR 运行于客户端(发送主机)，用于将数据从主机发送到网络打印资掘，让你能够得到打印输出。 DNS （ Domain Name Service，域名服务） ​ 解析主机名，DNS 用于解析 FQDN (Fully Qualified Domain Name ，全限定域名)，FQDN 是一种层次结构，可根据域名标识符查找系统。 DHCP/BootP （Dynamic Host Configuration Protocol，动态主机配置协议 ） ​ 给主机分配 IP 地址，让管理工作更轻松，非常适合用于各种规模的网络。 DHCP 与 BootP (Bootstrap Protocol ，自举协议)的差别在于， BootP 给主机分配地址，但必须手工将主机的硬件地址输入到 BootP表中。你可将 DHCP 视为动态的 BootP。但别忘了， BootP也可用于发送操作系统，让主机使用它启动，而 DHCP 没有这样的功能。DHCP 是无连接的，这意味着它在传输层使用 UDP 。DHCP 服务器和客户端之间的交互如下： DHCP 客户端广播一条 DHCP 发现消息，旨在寻找 DHCP 服务器(端口 67 )； 收到 DHCP 发现消息的 DHCP 服务器向主机发回一条单播 DHCP 提议消息； 客户端向服务器广播一条 DHCP 请求消息，请求提议的 IP 地址和其他信息； 服务器以单播方式发回一条 DHCP 确认消息，完成交互。 APIPA （Automatic Private IP Addressing ，自动私有 IP编址 ） ​ 客户端可在 DHCP 服务器不可用时自动给自己配置 IP 地址和子网掩码(主机用来通信的基本 IP 信息 )。APIPA 使用的Ip 地址范围为169.254.0.1-169.254.255.254 ，客户端还会给自己配置默认的 B 类子网掩码一255.255.0.0 。 DHCP , SNMP 和 TFTP 使用 UDP ，而 SMTP ， FTP 和 HTTP 使用 TCP . 主机到主机层协议TCP （Transmission Control Protocol，传输控制协议 ） ​ 接收来自应用程序的大型数据块，并将其划分成数据段。它给每个数据段编号，让接收主机的 TCP 技能够按应用程序希望的顺序排列数据段。发送数据段后，发送主机的 TCP 等待来自接收端 TCP 的确认，并重传未得到确认的数据段。 TCP 数据段的格式 TCP 报头长 20B (在包含选项时为 24B)，你必须理解 TCP 数据段中的每个字段。 源端口 发送主机的应用程序的端口号 目标端口 目标主机的应用程序的端口号 序列号 一个编号， TCP 用来将数据按正确的顺序重新排列(称为排序)、 重传丢失或受损的数据。 确认号 TCP 期待接下来收到的数据段。 报头长度 TCP 报头的长度，以 32 位字为单位。它指出了数据的开始位置， TCP 报头的长度为 32 位的整数倍，即使包含选项时亦如此。 保留 总是设置为零。 编码位/标志 用于建立和终止会话的控制功能。 窗口大小 发送方愿意接受的窗口大 。 校验和 CRC (Cyclic Redundancy Check ，循环冗余校验) 由于 TCP 不信任低层，因此检查所有数据。 CRC 检查报头和数据字段。 紧急 仅当设置了编码位中的紧急指针字段时，该字段才有效。如果设置了紧急指针，该字段表示非紧急数据的开头位置相对于当前序列号的偏移量，单位为字节。 选项 长度为 0 或 32 位的整数倍 也就是说，没有选项时，长度为 0。然而，如果包含选项时导致该字段的长度不是 32 位的整数倍，必须填充零，以确保该字段的长度为 32 位的整数倍。 数据 传递给传输层的 TCP 协议的信息，包括上层报头。 UDP ​ 在有些情况下，开发人员选择 UDP 而不是 TCP 是绝对明智的，例如当进程/应用层已确保了可靠性时。 NFS (Network File System，网络文件系统)处理了自己的可靠性问题，这使得使用 TCP 既不现实也多余。但归根结底，使用 UDP 还是 TCP 取决于应用程序开发人员，而不是想更快地传输数据的用户。 ​ UDP 不对数据段排序，也不关心数据段到达目的地的顺序。 ​ UDP 不建立虚电路，也不在发送信息前与接收方联系。 UDP 数据段的格式 : 源端口号 发送主机的应用程序的端口号。 目标端口号 目标主机上被请求的应用程序的端口号。 长度 UDP 报头和 UDP 数据的总长度。 校验和 UDP 报头和 UDP 数据的校验和。 数据 上层数据。 对比总结： 端口 源主机从范围 1024-65535 中选择一个源端口 ，目的主机的端口一般是知名端口。 数据链路层和网络层协议分别使用硬件地址和逻辑地址标识发送主机，但 TCP 和上层协议不这样做，它们使用端口号。 因特网层协议​ 在 DoD 模型中，因特网层的作用有两个:路由选择以及提供单个到上层的网络接口。在网络中，并非条条道路通罗马，而是条条道路通 IP ，因特网层以及上层的所有协议都使用 IP 。接下来将介绍因特网层协议: 因特网协议 (IP) 因特网控制消息协议 (ICMP ) 地址解析协议 (ARP) 逆向地址解析协议 (RARP) 代理 ARP 免费 ARP IP ( Internet Protocol ，因特网协议 ) ​ 该层的其他协议都只是为它提供支持。IP 掌控全局，可以说”一切尽收它眼底”，从这种意义上说，它了解所有互联的网络。它之所以能够这样，是因为网络中的所有机器都有一个软件(逻辑)地址，这种地址称为 IP地址。 ​ IP 查看每个分组的地址，然后使用路由选择表判断接下来应将分组发送到哪里，从而选择最佳路径。在 DoD 模型底部的网络接入层协议不像 IP 那样胸怀整个网络，它们只处理物理链路(本地网络)。 ​ 要标识网络中的设备，需要回答两个问题:设备位于哪个网络中?它在该网络中的 ID 是多少?对于第一个问题，答案是软件(逻辑)地址(正确的街道); 对于第二个问题，答案是硬件地址(正确的邮箱)。网络中的所有主机都有一个逻辑 ID，称为 IP 地址，它属于软件(逻辑)地址，包含宝贵的编码信息，极大地简化了路由选择这种复杂的任务。 ​ 网络中的所有主机都有一个逻辑 ID，称为 IP 地址，它属于软件(逻辑)地址，包含宝贵的编码信息，极大地简化了路由选择这种复杂的任务。IP 接收来自主机到主机层的数据段，并在必要时将其划分成数据报(分组)。在接收端， IP 将数据报重组成数据段。每个数据报都包含发送方和接收方的 IP 地址，路由器(第 3 层设备)收到数据报后，将根据分组的目标 IP 地址做出路由选择决策。 IP 报头 如下： 版本 IP 版本号。 报头长度报头的长度 单位为 32 位字。 优先级和服务类型 服务类型指出应如何处理数据报，前 3 位为优先级位，当前称为区分服务位。总长度整个分组的长度 包括报头和数据。 标识 唯一的 IP分组值，用于区分不同的数据报。 标志 指出是否进行了分段。 分段偏移 在分组太大，无法放入一个帧中时，提供了分段和重组功能。它还使得因特网上可有不同的 MTU (Maximum Transmission Unit，最大传输单元)。 存活时间 生成分组时给它指定的存活时间。如果分组到达目的地之前 TTL就已到期，分组将被丢弃。这可避免 IP 分组因寻找目的地不断在网络中传输。 协议 上层协议的端口 (TCP 为端口 6 ， UDP 为端口 7)。还支持网络层协议，如 ARP和ICMP (在有些分析器中，该字段称为类型字段)。稍后我们将更详细地讨论该字段。 报头 校验和对报头执行 CRC 的结果。 源IP 地址 发送方的 32 位 IP 地址。 目标 IP 地址 接收方的 32 位 IP 地址。 选顶用于网络测试、调试、安全等。 数据位于选项字段后，为上层数据。 可能在IP报头的协议字段中指定的协议号 ICMP ( Internet Control Message Protocol ，因特网控制消息协议) ​ 运行在网络层， IP 使用它来获得众多服务。 ICMP 是一种管理协议，为IP提供消息收发服务，其消息是以 IP 数据报的形式传输的。 ICMP 分组具有如下特征: 可向主机提供有关网络故障的信息。 封装在IP数据报中。 与 ICMP相关的常见事件和消息: 目标不可达 如果路由器不能再向前转发 IP 数据报，它将使用 ICMP 向发送方发送一条消息，以通告这种情况。 缓冲区已满 如果用于接收数据报的路由器内存缓冲区已满，路由器将使用 ICMP 发送这种消息，直到拥塞解除。 超过跳数/时间 对于每个 IP 数据报，都指定了它可穿越的最大路由器数量(跳数)。如果数据报还未达到目的地就达到了该上限，最后一台收到该数据报的路由器将把它删除。然后，该路由器将使用 ICMP 发送一条协告，让发送方知道其数据报已被删除。 Ping Packet Internet Groper (Ping , 分组因特网探测器) 使用 ICMP 回应请求和应答消息，以检查互联网络中机器的物理连接性和逻辑连接性。 Traceroute 使用 ICMP 超时来发现分组在互联网络中传输时经过的路径。 虽然 ICMP 运行在因特网(网络)层，它仍使用 IP 来发出Ping 请求，你注意到这一点了吗?在 P 报头中，类型字段的值为 OxOl ，这表明数据报中的数据属于ICMP 协议。别忘了，条条道路通罗马，同样，所有数据段或数据都必须通过 IP 传送。 ARP (Address Resolution Protocol ，地址解析协议) ​ 根据已知的 IP 地址查找主机的硬件地址 ， 其工作原理如下: IP需要发送数据报时，它必须将目标端的硬件地址告知网络接入层协议，如以太网或无线。(上层协议已经将目标端的 IP 地址告诉它)如果 IP 在 ARP 援存中没有找到目标主机的硬件地址，它将使用 ARP 获悉这种信息。 RARP 如果 IP 主机为无盘计算机，一开始它不知道自己的 IP 地址，但知道自己的 MAC 地址。无盘机器可使用RARP (Reverse Address Resolution Protocol，逆向地址解析协议)来获悉其IP 地址，这是通过发送一个分组实现的，该分组包含元盘计算机的 MAC 地址和一个请求( 请求提供分配给该 MAC 地址的 IP 地址 )。名叫 RARP 服务器的专用机器将对此作出响应，从而解决身份危机。RARP 使用它知道的信息(即机器的 MAC 地址)来获悉机器的 IP 地址，从而完成身份标识。 RARP 将以太网 (MAC) 地址解析为IP 地址。 代理 ARP 在网络中，我们不能给主机配置多个默认网关。请想一想，如果默认网关(路由器)发生故障，结果将如何呢?主机不能自动将数据发送给另一台路由器，而你必须重新配置主机。但代理 ARP 可帮助主机前往远程子网，而无需配置路由选择甚至默认网关。 使用代理 ARP 的优点之一是，我们可在网络中的一台路由器上启用它，而不影响网络中其他路由器的路由选择表。然而，使用代理 ARP 也存在一个严重的缺陆:使用代理 ARP 将增加网段中的流量，而为处理所有的 IP 地址到 MAC 地址的映射，主机的 ARP 表比通常情况下大。 代理 ARP 并非一种独立的协议，而是路由器代表其他设备(通常是 PC) 运行的一种服务，路由器禁止这些设备查询远程设备，虽然在这些设备看来，它们与远程设备位于同一个子网中。这让路由器能够在响应 ARP查询时提供自己的 MAC地址，从而将远程 IP地址解析为有效的 MAC地址。 IP 编址IP 地址是分配给 IP 网络中每台机器的数字标识符，它指出了设备在网络中的具体位置。 基本术语 比特 一个比特相当于一位，其取值为 1 或 0 。 字节 1 B 为 7 或 8 位，这取决于是否使用奇偶校验。 我们都假定是8位。 八位组 (Octet) 由 8 位组成，是普通的 8 位二进制数 ，术语字节和八位组可互换使用。 网络地址 在路由选择中，使用它将分组发送到远程网络 。 广播地址 应用程序和主机用于将信息发送给网络中所有节点的地址。 A 类地址 在 A 类地址中，第一个字节为网络地址，余下的 3B 为节点地址，A 类网络地址的第一个字节的第一位必须为 0 ，A 类地址第一个字节的取值为 0-127（2的7次方） A 类地址的网路地址数目126个 A 类地址用3B表示节点地址，主机数目为2的24次方-2（全为0和全为1）=16 777 214 个 B类地址 在 B 类地址中，前 2B 为网络地址，余下的 2B 为节点地址 ，B 类网络地址的第一个字节的第一位必须为 1 ，且第二位必须为 0， B 类网络地址第一个字节的取值为 128 -191 B类地址的网路地址要以二进制10开头，因此有2的14次方=16 384 B类地址用 2B 表示节点地址 ，主机数目为2的16次方-2（全为0和全为1）=65534 个 C 类地址 C 类地址的前 3 个字节为网络部分，余下的一个字节表示节点地址，C 类网络地址的第一个字节的前两位必须为 1 ，而第三位必须为 0 ， C 类网络地址第一个字节的取值为 192-223 C类地址的网路地址要以二进制110开头，因此有2的21次方-2（全为0和全为1）=2097 152 个 C 类网络用1B 用作节点地址，主机数目为 2的8次方 - 2 (全为 1 和全为 0 )，即 254 个节点地址 私有IP地址 D 类和 E 类网络地址范围 第一个字节为 224-255 的地址被保留用于 D 类和 E 类网络。 D 类 (224 - 239 )用作组播地址，而 E 类( 240 - 255 )用于科学用途。 IPv4 地址类型第 2 层广播地址 表示 LAN 中的所有节点 ，即FF:FF:FF:FF:FF:FF 。 广播（第 3 层） 地址表示网络中的所有节点 其目标地址的主机位都为 1 。 单播地址 这是特定接口的地址，用于将分组发送给单个目标主机 。 组播地址 用于将分组传输到不同网络中的众多设备，常用一对多来形容 。组播确实支持点到多点通信，这类似于广播，但工作原理不同。组播的关键点在于，它让多个接收方能够接收消息，却不会将消息传递给广播域中的所有主机。然而，这并非默认行为，而是在配置正确的情况下，使用组播达到的。组播地址的范围为 244.0.0.0 - 239.255.255.255]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的stevedore模块]]></title>
      <url>%2F2017%2F03%2F27%2Fpython%E7%9A%84stevedore%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之stevedore模块 stevedore是用来实现动态加载代码的开源模块。它是在OpenStack中用来加载插件的公共模块，可以独立于OpenStack而安装使用。 https://pypi.Python.org/pypi/stevedore/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(9)]]></title>
      <url>%2F2017%2F03%2F27%2F%E4%BD%A0%E6%87%82python%E5%90%97-9%2F</url>
      <content type="text"><![CDATA[python的单例模式1.使用__new__方法​ 实现__new__方法 并在将一个类的实例绑定到类变量_instance上, 如果cls._instance为None说明该类还没有实例化过,实例化该类,并返回;如果cls._instance不为None,直接返回cls._instance 。 123456789101112131415161718192021class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, 'instance'): cls.instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls.instanceclass Person(Singleton): def __init__(self, name, age): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',24) person2=Person('lau',26) print id(person1) print id(person2)#output140057479545680140057479545680 2.使用修饰符方法​ 使用装饰器(decorator), 这是一种更pythonic,更elegant的方法,单例类本身根本不知道自己是单例的,因为他本身(自己的代码)并不是单例的。 12345678910111213141516171819202122232425def singleton(cls): instances = &#123;&#125; def _singleton(*args, **kw): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return _singleton@singletonclass Person(object): def __init__(self, name=None, age=None): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',24) person2=Person('lau',26) person3=Person() print id(person1) print id(person2) print id(person3) #output140059880903312140059880903312140059880903312 3.使用metaclass方法​ Person=Singleton(),Person其实为元类Singleton创建的一个实例类。创建Person的实例person1时，Person(‘lucky’,23)=Singleton.__call__(cls,args, *kwargs)，这样就将Person的所有实例都指向了Person的属性_instance上，这种方法与使用__new__方法其实是相同的。 12345678910111213141516171819202122232425262728class Singleton(type): def __call__(cls,*args, **kwargs): if not hasattr(cls, '_instance'): cls._instance = super(Singleton, cls).__call__(*args, **kwargs) return cls._instanceclass Person(object): __metaclass__ = Singleton def __init__(self, name=None, age=None): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',23) print person1.name print person1.age person2=Person() person3=Person() print id(person1) print id(person2) print id(person3)#outputlucky23139786319061776139786319061776139786319061776 4.共享属性​ 所谓单例就是所有引用(实例、对象)拥有相同的状态(属性)和行为(方法) 同一个类的所有实例天然拥有相同的行为(方法),只需要保证同一个类的所有实例具有相同的状态(属性)即可。所有实例共享属性的最简单最直接的方法就是__dict__属性指向(引用)同一个字典(dict)。 创建实例时把所有实例的__dict__指向同一个字典,这样它们具有相同的属性和方法。 123456789101112131415161718192021222324252627class Singleton(object): _state = &#123;&#125; def __new__(cls, *args, **kw): ob = super(Singleton, cls).__new__(cls, *args, **kw) ob.__dict__ = cls._state return obclass Person(Singleton): def __init__(self, name=None, age=None): self.name = name self.age = ageif __name__ == '__main__': person1=Person('lucky',23) person2=Person('lau',24) person3=Person() print id(person1) print id(person2) print id(person3) print id(person1.__dict__) print id(person2.__dict__)#output139890509018064139890509018128139890509018192139890509022944139890509022944 5.import方法作为python的模块是天然的单例模式 12345678910111213141516# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonif __name__ == '__main__': print id(my_singleton) print id(my_singleton)#output140353398006352140353398006352]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(8)]]></title>
      <url>%2F2017%2F03%2F24%2F%E4%BD%A0%E6%87%82python%E5%90%97-8%2F</url>
      <content type="text"><![CDATA[__init__与__new__的区别__init__与__new__的主要区别如下： __new__是一个静态方法,而__init__是一个实例方法. __new__方法会返回一个创建的实例,而__init__什么都不返回. 只有在__new__返回一个cls的实例时后面的__init__才能被调用. 当创建一个新实例时调用__new__,初始化一个实例时用__init__ __new__的使用我们先看一下普通例子： 123456789101112class Person(object): def __init__(self,name,age): self.name=name self.age=age def __str__(self): return "&lt;Person &lt;%s %s&gt;" %(self.name,self.age)if __name__ == '__main__': person=Person("luckylau",23) print person# output&lt;Person &lt;luckylau 23&gt; 这是__init__最普通的用法了。但__init__其实不是实例化一个类的时候第一个被调用 的方法。当使用 Persion(name, age) 这样的表达式来实例化一个类时，最先被调用的方法 其实是 __new__ 方法,等价于以下过程： 123456789101112131415class Person(object): def __new__(cls, name,age): print " __new__ called " return super(Person,cls).__new__(cls,name,age) def __init__(self,name,age): print " __init__ called " self.name=name self.age=age def __str__(self): return "&lt;Person &lt;%s %s&gt;" %(self.name,self.age)if __name__ == '__main__': person=Person("luckylau",23) print person 1.person = Person(name, age)2.首先执行使用name和age参数来执行Person类的__new__方法，这个__new__方法会 返回Person类的一个实例（通常情况下是使用 super(Persion, cls).__new__(cls, … …) 这样的方式），3.然后利用这个类实例来调用类的__init__方法，上一步里面__new__产生的实例也就是 __init__里面的 self。所以，__init__ 和 __new__ 最主要的区别在于：1.__init__ 通常用于初始化一个新实例，控制这个初始化的过程，比如添加一些属性， 做一些额外的操作，发生在类实例被创建完以后。它是实例级别的方法。2.__new__ 通常用于控制生成一个新实例的过程。它是类级别的方法。 因此一个应用就是__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。 12345678910class PositiveInteger(int): def __new__(cls, value): print " __new__ called " return super(PositiveInteger,cls).__new__(cls,abs(value))if __name__ == '__main__': num=PositiveInteger(-123) print num#output123 12345678910class PositiveInteger(int): def __init__(cls, value): print " __new__ called " return super(PositiveInteger,cls).__init__(cls,abs(value))if __name__ == '__main__': num=PositiveInteger(-123) print num#output-123 还有一个应用便是__new__来实现单例 123456789101112131415161718class Person(object): def __new__(cls,*args,**kwargs): if not hasattr(cls,'instance'): cls.instance=super(Person,cls).__new__(cls,*args,**kwargs) return cls.instance def __init__(self,name,age): self.name=name self.age=ageif __name__ == '__main__': person=Person("lucky",23) person2=Person("lau",24) print id(person) print id(person2)#output140094508307088140094508307088]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(2)]]></title>
      <url>%2F2017%2F03%2F23%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： 以太网 以太网数据封装 以太网回顾？包括以下内容： 冲突域，广播域，CSMNCD，半双工，全双工，以太网编址 ,以太网帧，以太网物理层，以太网布线 。 ​ 广播域指的是网段中的一组设备，它们侦听在该网段上发送的所有广播。广播域的边界通常为诸如交换机和路由器等物理介质，但广播域也可能是一个逻辑网段，其中每台主机都可通过数据链路层（硬件地址）广播访问其他所有主机。 ​ 冲突域是一个以太网术语，指的是这样一种网络情形，即网段上的一台设备发送分组时，该物理网段上的其他所有设备都必须侦听它。这很糟糕，因为如果同一个物理网段中的两台设备同时传输数据，将发生冲突（即两台设备的数字信号将在线路上相互干扰），导致设备必须在以后重传数据。冲突对网络性能有严重的负面影响，因此绝对要避免冲突。 ​ CSMNCD (Carrier Sense Multiple Access with Collision Detection ，载波侦听多路访问/冲突检测) 这是一种帮助设备均衡地共享带宽的协议，可避免两台设备同时在网络介质上传输数据。 帮助最大限度地减少冲突，从而提高数据传输效率。主机想通过网络传输数据时，它首先检查线路上是否有数字信号。如果没有其他主机传输数据，该主机将开始传输数据。但到这里并非万事大吉，传输主机将持续地监视线路，确保没有其他主机开始传输。如果该主机在线路上检测到其他信号，它将发送一个扩展的拥堵信号 （jam signal），使网段上的所有节点都不再发送数据（想想电话忙音吧）。检测到拥堵信号后，其他节点将等待一段时间再尝试传输。后退算法决定了发生冲突的工作站多长时间后可重新传输，如果连续 15 次尝试都导致冲突，尝试传输的节点将超时。 以太网 LAN 中发生冲突后，将出现如下情况： 拥堵信号告诉所有设备发生了冲突； 冲突激活随机后退算法； 以太网网段中的每台设备都暂停传输，直到其后退定时器到期； 定时器到期后，所有主机的传输优先级都相同。 CSMAlCD 网络持续发生严重冲突时，将导致如下结果： 延迟； 低吞吐量； 拥塞； 半双工以太网使用 CSMA/CD 协议，以帮助防范冲突，并在发生冲突时支持重传。如果集线器与交换机相连，它必须运行在半双工模式下，因为终端必须能够检测冲突。半双工以太网的效率只有30%-40% ，因为在大型 100BaseT 网络中，通常最大传输速度只有 30 - 40 Mbit/s。 全双工以太网同时使用两对导线,与半双工以太网只使用一对导线不同 。在传输设备的发射器和接收设备的接收器之间，全双工使用一条点到点连接，这意味着使用全双工时，数据传输速度比半双工时快。你无需担心冲突，因为全双工提供了一条”多车道高速公路”，而不像半双工那样提供一条”单车道公路”。全双工以太网在两个方向的效率都为 100% 。全双工以太网可用于下面 6 种情形：交换机到主机的连接；交换机到交换机的连接；主机到主机的连接(使用交叉电缆)；交换机到路由器的连接(使用交叉电缆)；路由器到路由器的连接(使用交叉电缆)；路由器到主机的连接(使用交叉电缆) 。基本上除集线器外，其他所有设备都可在全双工模式下运行。 以太网编址 MAC (硬件)地址长 48 位 (6 B)，采用十六进制格式。 I/G (Individual/Group) 位： 值为 0 ，我们就可认为相应的地址为某台设备的 MAC 地址，很可能出现在 MAC 报头的源地址部分；值为 1 ，我们就可认为相应的地址为以太网中的广播地址或组播地址或者令牌环和FDDI 中的广播地址或功能地址 。 G/L位(全局/本地位，也称为 U/L位)： 值为 0 ，则表示相应的地址为全局管理地址，由 IEEE 分配； 值为 1， 则表示相应的地址为本地管理地址 ； OUI ( Organizationally Unique Identifier，组织唯一标识符)： 由 IEEE 分配给组织的，它包含 24位 (3 B)，而组织给其生产的每个网卡都分配一个唯一的( 据说如此，但不保证 ) 全局管理地址，该地址长 24 位 (3 B)。 右边 24 位为本地管理(制造商分配)的编码，特定制造商生产第一个网卡时，通常将这部分设置为 24 个 0 ，然后依次递增，直到将其生产的第 1677 216 个网卡设置为 24 个 1 。 数据链路层负责将比特合并成字节，再将字节封装成帧。在数据链路层，我们使用帧封装来自网络层的分组，以便通过特定类型的介质进行传输。 以太网帧 数据链路层负责将比特合并成字节，再将字节封装成帧。在数据链路层，我们使用帧封装来自网络层的分组，以便通过特定类型的介质进行传输。下图是以太网帧和802.3帧。 前导码交替的 0 和 1 ，在每个分组的开头提供 5 MHz 的时钟信号，让接收设备能够跟踪到来的比特流。 帧起始位置分隔符 (SFD) I同步前导码为 7B，而 SFD (同步)为 lBo SFD 的值为 10101011 ,其中最后两个 l 让接收方能够识别中间的 0 和 1 交替模式，进而同步并检测到数据开头。 目标地址 (DA) 包含一个 48 位的值，且 LSB (Least Significant Bit，最低有效位)优先。接收方根据 DA 判断到来的分组是否是发送给特定节点的。 目标地址可以是单播地址、广播地址或组播 MAC 地址。 别忘了， 广播地址全为 1 (在十六进制格式下全为 F) ， 广播发送给所有设备，而组播只发送给网络中一组类似的节点。 源地址 (SA) SA 是一个 48 位的 MAC 地址 ， 用于标识传输设备，也使用 LSB 优先格式。在 SA 字段中，不能包含广播地址或组播地址。 长度或类型 802.3 帧使用长度字段，而 Etbemet_II 帧使用类型字段标识网络层协议。 802.3不能标识上层协议，只能用于专用 LAN，如 IPX。 数据这是网络层传递给数据链路层的帧，其长度为 46-1500 B。 帧校验序列 (FCS) FCS 字段位子，用于存储 CRC (Cyclic Redundancy Check ，循环冗余校验 ) 结果的帧的帧尾 。 CRC 是一种数学算法，创建每个帧时都将运行它 。 作为接收方的主机收到帧并运行 CRC 时，其结果必须相同，否则，接收方将认为发生了错误，进而将帧丢弃。 以太网物理层 ，IEEE 对 802.3进行了扩展，制定了两个新标准: 802.3u ( 快速以太网)和 802 .3ab (使用 5 类电缆的吉比特以太网)，然后又制定了标准 802.3ae (使用光纤和同轴电缆，速度为 10 Gbitls )。 IEEE 802.3 标准： 以太网布线 有三种，直通电缆 交叉电缆 反转电缆。 (1)主机到主机。交叉电缆(2) 主机到交换机或集线器。直通电缆(3) 路由器到主机。交叉电缆(4) 交换机到交换机。交叉电缆(5) 路由器到交换机或集线器。直通电缆(6) 集线器到集线器。交叉电缆(7) 集线器到交换机。交叉电缆(8) 主机到路由器的控制台串行通信 (COM) 端口。 反转电缆 二进制和十进制和十六进制转换？ 半字节（4位） 字节（8位） 8 4 2 1 128 64 32 16 8 4 2 1 二进制转十进制 10010110: 128+16+4+2=150 十六进制转二进制 0x6A : 6 =0110 A=1010 即为01101010 二进制转十六进制 11001101 : 1100=12 1101=13 即为0xCD 数据封装？​ 为通信和交换信息，每层都使用 PDU ( Protocol Data Unit，协议数据单元 )0 PDU包含在模型每一层给数据添加的控制信息。这些控制信息通常被添加在数据字段前面的报头中，但也可能被添加在报尾中。 ​ OSI 模型每一层都对数据进行封装来形成 PDU ， PDU 的名称随报头提供的信息而异。这些 PDU信息仅在接收设备的对等层被读取，然后被剥离，然后数据被交给下一层。 封装过程如下： (1) 用户信息被转换为数据，以便通过网络传输；(2) 数据被转换为数据段，并在发送主机和接收主机之间建立一条可靠的连接；(3) 数据段被转换为分组或数据报，并在报头中加入逻辑地址，使得能够在互联网络中路由分组；(4) 分组或数据报被转换为帧，以便在本地网络中传输。使用硬件(以太网)地址来唯一地标识本地网络中的主机；(5) 帧被转换为比特，并使用数字编码和时钟同步方案 ； 解释上述过程如下： ​ 事实上由上层将数据流交给传输层。作为技术人员，我们并不关心数据流来自何方。我们的职责是，在接收设备处可靠地重建数据流，并将其交给上层。 使用面向连接的协议(即 TCP) 时，传输层将数据流转换为数据段，并创建一条虚电路以建立可靠的会话。 接下来，它对每个数据段进行编号，并使用确认和流量控制。如果你使用的是 TCP，虚电路将由源端口号和目标端口号以及源 IP 地址和目标 P 地址(称为套接字)标识。别忘了，主机只能使用不小于 1024 的端口号( 0-1023 为知名端口号)。目标端口号标识了上层进程(应用程序)，在接收主机可靠地重建数据流后，数据流将被交给该进程(应用程序)。 问与答？以太网帧包含哪些字段？ 源 MAC 地址、目标 MAC 地址、标识网络层协议的以太类型( Ether-Type )、数据以及存储 CRC 结果的 FCS]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(7)]]></title>
      <url>%2F2017%2F03%2F21%2F%E4%BD%A0%E6%87%82python%E5%90%97-7%2F</url>
      <content type="text"><![CDATA[python的新式类和旧式类​ python的新式类是2.2版本引进来的，我们可以将之前的类叫做经典类或者旧式类。为什么要在2.2中引进new style class呢？官方给的解释是：为了统一类(class)和类型(type)。 使用环境是python 2.7 新式类与旧式类的区别 12345678910111213141516171819202122class C(object): passclass B: passif __name__ == '__main__': c = C() b = B() print type(c) print c.__class__ print type(b) print b.__class__ print "**********************" print dir(C) print dir(B)#output&lt;class '__main__.C'&gt;&lt;class '__main__.C'&gt;&lt;type 'instance'&gt;__main__.B**********************['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']['__doc__', '__module__'] ​ 如上所示b是旧式类的一个实例，c是新式类的一个实例。c的__class__与type返回的结果是一样的，得到统一。而b的__class__与type返回的结果并不相同。同时我们还发现新式类有更多的属性和方法，旧式类只有区区的2个方法。 ​ 我们也发现为了向前兼容，默认情况下用户定义的类为经典类，新类需要继承自所有类的基类 object 或者继承自object的新类。那么为了确保自己使用的是新式类，有两种以下方法： 元类，在类模块代码的最前面加入如下代码 __metaclass__ = classname(自定义的某个新式类)。 类都从内建类object直接或者间接地继承。 新式类的属性和方法内置的object对象是所有内置，object对象定义了一系列特殊的方法实现所有对象的默认行为。 1.__new__，__init__方法这两个方法是用来创建object的子类对象，静态方法__new__()用来创建类的实例，然后再调用__init__()来初始化实例。 123456789101112class C(object): passclass B: passif __name__ == '__main__': c = C("ooo") b = B("ooo")#outputTypeError: object() takes no parameters #新式类TypeError: this constructor takes no arguments #旧式类 新式类都有一个__new__的静态方法，它的原型是object.__new__(cls[, …])cls是一个类对象，如上面代码，当你调用C(args, **kargs)来创建一个类C的实例时，python的内部调用是C.__new__(C, args, kargs)，然后返回值是类C的实例c，在确认c是C的实例后，python再调用C.__init__(c, *args, kargs)来初始化实例c。所以调用一个实例c = C(”ooo“)，实际执行的代码为： 123c = C.__new__(C, "ooo")if isinstance(c, C): C.__init__(c, "ooo") 可以使用__new__来实现Singleton单例模式： 12345678910111213141516171819202122class Singleton(object): _singleton=&#123;&#125; def __new__(cls, *args, **kwargs): if not cls._singleton.has_key(cls): cls._singleton[cls]=object.__new__(cls) return cls._singleton[cls]class B(object): #做对比 passif __name__ == '__main__': a=Singleton() print id(a) b=Singleton() print id(b) c=B() print id(c) d=B() print id(d)#output140573118190288140573118190288140573118190352140573118190416 使用id()操作，可以看到两个实例指向同一个内存地址。Singleton的所有子类也有这一特性，只有一个实例对象，如果它的子类定义了__init__()方法，那么必须保证它的__init__方法能够安全的同一个实例进行多次调用。 2.__delattr__, __getattribute__, __setattr__方法对象使用这些方法来处理属性的访问 __getattribute__ 对新式类的实例来说，所有属性和方法的访问操作都是通过getattribute完成，这是由object基类实现的。如果有特殊的要求，可以重载getattribute方法，下面实现一个不能使用append方法的list： 12345678910111213141516class listNoappend(list): def __getattribute__(self, item): if item == 'append': raise AttributeError(item) return list.__getattribute__(self, item)if __name__ == '__main__': a = listNoappend() print type(a) print dir(a) a.append("abc")#output&lt;class '__main__.listNoappend'&gt;['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__dict__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']a.append("abc")raise AttributeError(item)AttributeError: append 3.__hash__, __repr__, __str__方法print(someobj)会调用someobj.__str__()， 如果__str__没有定义，则会调用someobj.__repr__()， __str__()和__repr__()的区别： 默认的实现是没有任何作用的，__repr__的目标是对象信息唯一性，__str__的目标是对象信息的可读性 容器对象的__str__一般使用的是对象元素的__repr__，如果重新定义了__repr__，而没有定义__str__，则默认调用__str__时，调用的是__repr__，也就是说好的编程习惯是每一个类都需要重写一个__repr__方法，用于提供对象的可读信息，而重写__str__方法是可选的。实现__str__方法，一般是需要更加好看的打印效果，比如你要制作一个报表的时候等。可以允许object的子类重载这些方法，或者添加新的方法。 4.__slots__属性​ 通常每一个实例x都会有一个__dict__属性，用来记录实例中所有的属性和方法，也是通过这个字典，可以让实例绑定任意的属性。而__slots__属性作用就是，当类C有比较少的变量，而且拥有__slots__属性时，类C的实例 就没有__dict__属性，而是把变量的值存在一个固定的地方。如果试图访问一个__slots__中没有的属性，实例就会报错。这样操作有什么好处呢？__slots__属性虽然令实例失去了绑定任意属性的便利，但是因为每一个实例没有__dict__属性，却能有效节省每一个实例的内存消耗，有利于生成小而精干的实例。 ​ 在一个实际的企业级应用中，当一个类生成上百万个实例时，即使一个实例节省几十个字节都可以节省一大笔内存，这种情况就值得使用__slots__属性。 __slots__是一个类变量，__slots__属性可以赋值一个包含类属性名的字符串元组，或者是可迭代变量，或者是一个字符串。 只有在新式类中生效，如下对比： 1234567891011121314151617181920212223242526272829class A: #做对比 def __init__(self,x,y): self.x=x self.y=y __slots__='x','y'class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__='x','y'if __name__ == '__main__': a=A(3,6) print a.x print a.y a.z=7 print a.z b = B(3, 6) print b.x print b.y b.z=6 print b.z#output36736AttributeError: 'B' object has no attribute 'z' 需要注意的几点： 当一个类的父类没有定义__slots__属性，父类中的__dict__属性总是可以访问到的，所以只在子类中定义__slots__属性，而不在父类中定义是没有意义的。 如果定义了__slots__属性，还是想在之后添加新的变量，就需要把__dict__字符串添加到__slots__的元组里。 12345class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__=('x','y',"__dict__") 定义了__slots__属性，还会消失的一个属性是__weakref__，这样就不支持实例的weak reference，如果还是想用这个功能，同样，可以把’__weakref__‘字符串添加到元组里。 __slots__功能是通过descriptor实现的，会为每一个变量创建一个descriptor。 __slots__的功能只影响定义它的类，因此，子类需要重新定义__slots__才能有它的功能。 12345678910111213141516171819class B(object): def __init__(self,x,y): self.x=x self.y=y __slots__=('x','y')class C(B): passif __name__ == '__main__': b = B(3, 6) c=C(3,6) c.z=9 print c.z b.z=9 print b.z# output9'B' object has no attribute 'z' 5.__getitem__方法​ 在python中，隐式调用实例的私有特殊方法时，新的对象模型和经典对象模型表现上不太一样。在经典对象模型中，无论是显示调用还是隐式调用特殊方法，都会调用实例中后绑定的特殊方法。而在新的对象模型中，除非显式地调用实例的特殊方法，否则python总是会去调用类中定义的特殊方法，如果没有定义的话，就报错。 123456789101112131415161718def getItem(index): return index + 1class OldStyle: passclass NewStyle(object): passif __name__ == '__main__': old = OldStyle() old.__getitem__=getItem print old[2] new =NewStyle() new.__getitem__=getItem print new.__getitem__(2) #显示调用 print new[2]# output33TypeError: 'NewStyle' object does not support indexing 调用old[1]，将产生一个隐式的getitem方法的调用，在新式类中，因为类中没有定义这个方法，也不是object基类有的方法，所以报错。需要显示地调用才可以运行。 新式类的继承​ 新式类同样支持多继承，但是如果新式类想要从多个内置类型中继承生成一个新类的话，则这些内置类必须是经过精心设计，能够互相兼容的。显然，python也没会让你随意的从多个内置类中进行多继承，想创建一个超级类不是那么容易的。。。通常情况下，至多可以继承一个内置类，比如list, set, dict等。 下图是MRO(Method Resolution Order ,方法解析顺序)，分别是旧式类和新式类的方法顺序。旧式类深度优先的方式进行查找，新式类广度优先的方式查找 1234567891011121314151617class D: def __init__(self): self.x = "d"class B(D): passclass C(D): def __init__(self): self.x = "c"class A(B,C): passif __name__ == '__main__': a=A() print a.x print A.__mro__#output dAttributeError: class A has no attribute '__mro__' 1234567891011121314151617class D(object): def __init__(self): self.x = "d"class B(D): passclass C(D): def __init__(self): self.x = "c"class A(B,C): #当B,C变成C，B时候 A.__mro__的输出顺序也会变 passif __name__ == '__main__': a=A() print a.x print A.__mro__#outputc(&lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;type 'object'&gt;) 另一个注意的是协作式调用父类方法使用： 1234567891011121314151617181920212223242526272829303132class A(object): def foo(self): print "AAAAA"class B(A): def foo(self): print "BBBBB" A.foo(self)class C(A): def foo(self): print "CCCCC" A.foo(self)class D(B,C): def foo(self): print "DDDDD" B.foo(self) C.foo(self)if __name__ == '__main__': d=D() print d.foo() print D.__mro__#outputDDDDDBBBBBAAAAACCCCCAAAAANone(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;) ​ 可以看到，基类A的方法重复运行了两次。怎样才能确保父类中的方法只被顺序的调用一次呢？在新的对象系统中，有一种特殊的方法super(aclass, obj)，可以返回obj实例的一个特殊类型superobject(超对象， 不是简单的父类的对象)，当我们使用超对象调用父类的方法时，就能保证只被运行一次： 12345678910111213141516171819202122232425262728class A(object): def foo(self): print "AAAAA"class B(A): def foo(self): print "BBBBB" super(B,self).foo()class C(A): def foo(self): print "CCCCC" super(C, self).foo()class D(B,C): def foo(self): print "DDDDD" super(D, self).foo()if __name__ == '__main__': d=D() print d.foo()#outputDDDDDBBBBBCCCCCAAAAANone ​ 可以看到，D的父类中所有的foo方法都得到执行，并且基类A的foo方法只执行了一次。如果养成了使用super去调用父类方法的习惯，那么你的类就可以适应无论多么复杂的继承调用结构。super()可以看成是更加安全调用父类方法的一种新方式。 新式类的Descriptor​ descriptor可以说是一个绑定了特定访问方法的类属性，这些访问方法是重写了descriptor protocol中的三个方法，分别是__get__, __set__, __del__方法。如果三个中任一一个方法在对象中定义了，就说这个对象是一个descriptor对象，可以把这个对象赋值给其它属性。descriptor protocol可以看成是一个有三个方法的接口。 ​ 通常对一个实例的属性的访问操作，如get, set, delete是通过实例的__dict__字典属性进行的，例如下面代码: 123456789class Person(object): name="lucky"if __name__ == '__main__': person=Person() person.name="Lau" print person.name#outputLau ​ 对于操作person.name，会一个查找链，首先通过实例对象的__dict__属性访问，即person.dict[‘x’]（实例的字典），再通过类型对象的__dict__属性访问，即type(person).dict[‘x’]，等价于Person.dict[‘name’]（类的字典），再通过父类对象的__dict__属性访问，person.class.base.dict[‘name’],等价于Parent.dict[‘name’]，type(a)的父类的字典。 ​ 如果这个需要被查找的属性是一个定义了descriptor协议方法的对象，那么python就不会按照默认的查找方式，而是调用descriptor协议中定义的方法__get__方法获取，同样的道理，给name赋值的时候是通过调用__set__方法实现而不是通过__dict__属性。 12345678910111213141516171819class DescriptorName(object): def __init__(self,name): self.name=name def __get__(self, instance, owner): print '__get__' , instance,owner return self.name def __set__(self, instance, value): print '__set__',instance,value self.name=valueclass Person(object): name=DescriptorName("Lucky")if __name__ == '__main__': person=Person() person.name="Lau" print person.name#output__set__ &lt;__main__.Person object at 0x7f9b2458c490&gt; Lau__get__ &lt;__main__.Person object at 0x7f9b2458c490&gt; &lt;class '__main__.Person'&gt;Lau 上面的例子是基于类的方式来创建描述符，你还可以通过property()函数来创建描述符 123456789101112131415161718192021222324252627282930class Person(object): def __init__(self, name): self.name = name self._email=None def get_email(self): print ' get_email is invoked' return self._email def set_email(self, value): print ' set_email is invoked' self._email = value def del_email(self): print 'del_email is invoked' del self._email email = property(get_email, set_email, del_email, 'this is email property')if __name__ == '__main__': person = Person("Luckylau") person.email="laujunbupt0913@163.com" # set_email is invoked print person.email # get_email is invoked del person.email # del_email is invoked#outputset_email is invokedget_email is invokedlaujunbupt0913@163.comdel_email is invoked property()函数返回的是一个描述符对象，它可接收四个参数property(fget=None, fset=None, fdel=None, doc=None) fget：属性获取方法 fset：属性设置方法 fdel：属性删除方法 doc： docstring 使用纯python的方式来实现property函数如下： 1234567891011121314151617181920212223242526272829303132333435363738class Property(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, instance, owner): if instance is None: return self if self.fget is None: raise AttributeError("unreadable attribute") return self.fget(instance) def __set__(self, instance, value): if self.fset is None: raise AttributeError("can't set attribute") self.fset(instance, value) def __delete__(self, instance): if self.fdel is None: raise AttributeError("can't del attribute") self.fdel(instance) def getter(self, fget): print "Property getter is invoked " return type(self)(fget, self.fset, self.fdel, self.__doc__) def setter(self, fset): print "Property setter is invoked " return type(self)(self.fget, fset, self.fdel, self.__doc__) def deleter(self, fdel): print "Property deleter is invoked " return type(self)(self.fget, self.fset, fdel, self.__doc__) 同时你还可以用property装饰器创建描述符 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Property(object): def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset = fset self.fdel = fdel if doc is None and fget is not None: doc = fget.__doc__ self.__doc__ = doc def __get__(self, instance, owner): if instance is None: return self if self.fget is None: raise AttributeError("unreadable attribute") return self.fget(instance) def __set__(self, instance, value): if self.fset is None: raise AttributeError("can't set attribute") self.fset(instance, value) def __delete__(self, instance): if self.fdel is None: raise AttributeError("can't del attribute") self.fdel(instance) def getter(self, fget): print "Property getter is invoked " return type(self)(fget, self.fset, self.fdel, self.__doc__) def setter(self, fset): print "Property setter is invoked " return type(self)(self.fget, fset, self.fdel, self.__doc__) def deleter(self, fdel): print "Property deleter is invoked " return type(self)(self.fget, self.fset, fdel, self.__doc__)class Person(object): def __init__(self,name): self.name=name self._email = None @Property def email(self): pass @email.getter def email(self): print " get_email is invoked " return self._email @email.setter def email(self, value): print " set_email is invoked " self._email = value @email.deleter def email(self): print " del_email is invoked " del self._emailif __name__ == '__main__': p = Person("Luckylau") print "**************" p.email = "laujunbupt0913@163.com" print "**************" print p.email#outputProperty getter is invoked Property setter is invoked Property deleter is invoked ********** set_email is invoked ********** get_email is invoked laujunbupt0913@163.com 参考：http://www.pythontab.com/html/2015/pythonjichu_1113/982.html http://www.cnblogs.com/btchenguang/archive/2012/09/17/2689146.html http://blog.csdn.net/imzoer/article/details/8737642]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(6)]]></title>
      <url>%2F2017%2F03%2F20%2F%E4%BD%A0%E6%87%82python%E5%90%97-6%2F</url>
      <content type="text"><![CDATA[*args和 **kwargs用args和*kwargs只是为了方便并没有强制使用它们。 当你不确定你的函数里将要传递多少参数时你可以用*args.例如,它可以传递任意数量的参数: 123456789def print_everything(*args): for count, thing in enumerate(args): print '&#123;0&#125;. &#123;1&#125;'.format(count, thing)if __name__ == '__main__': print_everything('apple', 'banana', 'cabbage')#output0. apple1. banana2. cabbage 相似的,**kwargs允许你使用没有事先定义的参数名: 12345678def table_things(**kwargs): for name, value in kwargs.items(): print '&#123;0&#125; = &#123;1&#125;'.format(name, value)if __name__ == '__main__': table_things(apple='fruit', cabbage='vegetable')#outputcabbage = vegetableapple = fruit 你也可以混着用.命名参数首先获得参数值然后所有的其他参数都传递给*args和**kwargs.命名参数在列表的最前端.*args和**kwargs可以同时在函数的定义中,但是*args必须在**kwargs前面. 当调用函数时你也可以用*和**语法.例如: 12345678def print_three_things(a, b, c): print 'a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;'.format(a,b,c)if __name__ == '__main__': mylist = ['aardvark', 'baboon', 'cat'] print_three_things(*mylist)#outputa = aardvark, b = baboon, c = cat 就像你看到的一样,它可以传递列表(或者元组)的每一项并把它们解包.注意必须与它们在函数里的参数相吻合.当然,你也可以在函数定义或者函数调用时用* 参考：http://stackoverflow.com/questions/3394835/args-and-kwargs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂网络吗(1)]]></title>
      <url>%2F2017%2F03%2F17%2F%E4%BD%A0%E6%87%82%E7%BD%91%E7%BB%9C%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[本文主要是基于学习《CCNA学习指南》总结网络必备的知识。 本篇章涉及以下内容： OSI模型 OSI模型：​ OSI 模型包含 7 层，它们分为两组：上 3 层指定了终端中的应用程序如何彼此通信以及如何与用户交流；下 4 层指定了如何进行端到端的数据传输。 请记住，这3 层都对联网和网络地址一无所知，那是下 4 层的职责 。 ISO的功能如下： ​ 应用层是实际应用程序之间的接口。这意味着诸如 MicrosoftWord 等应用程序并不位于应用层中，而是与应用层协议交互。 ​ 表示层向应用层提供数据，并负责数据转换和代码格式化。 ​ 会话层负责在表示层实体之间建立、管理和终止会话，还有设备或节点之间的对话进行控制。 为此提供了 3 种不同的模式：单工、半双工和全双工。 ​ 传输层将数据进行分段并重组为数据流。位于传输层的服务将来自上层应用的数据进行分段和重组，并将它们合并到同一个数据流中。它们提供了端到端的数据传输服务，并可在互联网络上的发送主机和目标主机之间建立逻辑连接。另外，对上层应用程序进行多路复用、建立会话以及拆除虚电路，并提供透明的数据传输，从而对高层隐藏随网络而异的信息。 ​ 网络层管理设备编址、跟踪设备在网络中的位置并确定最佳的数据传输路径，这意味着网络层必须在位于不同网络中的设备之间传输数据流。 ​ 数据链路层将报文封装成数据帧，并添加定制的报头，其中包含目标硬件地址和源硬件地址 。路由器运行在网络层，根本不关心主机位于什么地方，而只关心网络(包括远程网络)位于什么地方以及前往这些网络(包括远程网络)的最佳路径。路由器只关心网络，这是好事！对本地网络中每台设备进行唯一标识的工作由数据链路层负责。数据链路层使用硬件地址，让主机能够给本地网络中的其他主机发送分组以及穿越路由器发送分组。每当在路由器之间传输分组时，分组都将被使用数据链路层控制信息封装成帧，但接收路由器会将这些信息剥离，只保留完整的原始分组。在每一跳都将重复这种将分组封装成帧的过程，直到分组最终到达正确的接收主机。在整个传输过程中，分组本身从未被修改过，而只是被必要的控制信息封装，以便能够通过不同的介质进行传输，明白这一点至关重要。 IEEE 以太网数据链路层包含两个子层，如下：介质访问控制 (MAC) 子层 (802.3)和逻辑链路控制 (LLC) 子层 (802.2) 。介质访问控制 (MAC) 子层 (802.3)，它采用”先到先服务”的访问方式，带宽由大家共享，因此称为竟用介质访问( contention media access )。 逻辑链路控制 (LLC) 子层 (802.2)负责识别网络层协议并对其进行封装。 ​ 物理层有两项功能:发送和接收比特。比特的取值只能为 0 或 1一一使用数字值的摩尔斯码。物理层直接与各种通信介质交流。 总结: 应用层、表示层和会话层属于上层，负责用户界面和应用程序之间的通信。传输层提供分段、排序和虚电路。网络层提供逻辑网络编址以及在互联网络中路由的功能。数据链路层提供了将数据封装成帧并将其放到网络介质上的功能。物理层负责将收到的 0 和 1 编码成数字信号，以便在网段中传输。 问与答：1.对数据流进行分段发生在 OSI模型的哪一层? 传输层 解释：传输层从上层接收大型数据，将其分割成较小的片段，这些片段称为数据段。 2.下面哪 4 项描述了路由器的主要功能?A. 分组交换 B. 冲突防范 C. 分组过滤D. 增大广播域 E. 互联网络通信 F. 广播转发G. 路径选择 A 、 C 、 E 、 G。路由器提供分组交换、分组过滤、互联网络通信以及路径选择功能。虽然路由器确实分割或终止冲突域，但这不是路由器的主要功能，因此选项 B 不正确。 3.路由器运行在第？层；LAN 交换机运行在第？层；以太网集线器运行在第？层；字处理程序运行在第？层。A. 3，3 ，1 ，7 B. 3 ， 2 ，1 ，无C. 3，2 ，1 ，7 D. 2 ， 3 ， 1 ，7E. 3 ， 3， 2 ，无 路由器运行在第 3 层， LAN 交换机运行在第 2 层，以太网集线器运行在第 1 层。字处理程序与应用层接口通信，但并非运行在第 7 层，因此答案为”无”。 4.下面哪 3 种有关全双工以太网运行方式的说法是正确的?A.在全双工模式下不会发生冲突B. 每个全双工节点都必须有一个专用的交换机端口C. 以太网集线器端口被预先配置为全双工模式D. 在全双工环境中，在传输数据前，主机的网卡必须检查网络介质是否可用E 主机的网卡和交换机端口必须能够以全双工模式运行 A 、 B 、 E。全双工意味着可使用两对导线同时发送和接收数据。每个节点都必须有专用的交换机端口，这意味着不会发送冲突。主机的网卡和交换机端口都必须支持全双工模式，并设置为这种模式。 5. (1) 哪一层选择通信伙伴并判断其可用性、判断建立连接所需资掘的可用性、协调参与通信的应用程序，并就控制数据完整性和错误恢复的流程达成一致?(2) 哪一层负责将来自数据链路层的数据分组转换为电信号?(3) 哪一层实现路由选择，在终端系统之间建立连接并选择路径?(4) 哪一层定义了如何对数据进行格式化、表示、编码和转换，以便在网络中使用?(5) 哪一层负责在应用程序之间建立、管理和终止会话?(6) 哪一层确保通过物理链路可靠地传输数据，且主要与物理地址、线路管理、网络拓扑、错误通知、按顺序传输帧以及流量控制有关?(7) 哪一层用于让终端节点能够通过网络进行可靠的通信，提供建立、维护、拆除虚电路的机制，提供传输错误检测和恢复的机制，并提供流量控制机制?(8) 哪一层提供逻辑地址，供路由器用来决定传输路径?(9) 哪一层指定了电平、线路速度和电缆针脚，并在设备之间传输比特?(10) 哪一层将比特合并成字节，再将字节封装成帧，使用 MAC 地址，并提供错误检测功能?(11) 哪一层负责在网络中将来自不同应用程序的数据分开。(12) 哪一层的数据表示为帧?(13) 哪一层的数据表示为数据段?(14) 哪一层的数据表示为分组?(15) 哪一层的数据表示为比特?(16) 按封装顺序排列下列各项:分组帧比特数据段(17) 哪一层对数据进行分段和重组?(1 8) 哪一层实际传输数据，并处理错误通知、网络拓扑和流量控制?(19) 哪一层管理设备编址、跟踪设备在网络中的位置并决定传输数据的最佳路径?(20) MAC 地址长多少位?以什么方式表示? (1) 应用层负责寻找服务器提供的网络资源，并提供流量控制和错误控制功能(如果应用程序开发人员选择这样做)(2) 物理层接收来自数据链路层的帧，将 0 和 1 编码成数字信号，以便在网络介质上传输(3) 网络层提供了在互联网络中进行路由选择的功能，还提供了逻辑地址(4) 表示层确保数据为应用层能够理解的格式(5) 会话层在应用程序之间建立、维护并终止会话 (6) 数据链路层的 PDU 称为帧，该层还提供物理编址以及将分组放到网络介质上的其他选项(7) 传输层使用虚电路在主机之间建立可靠的连接(8)网络层提供了逻辑地址(这通常是 IP 地址)和路由选择功能(9) 物理层负责在设备之间建立电气和机械连接(10) 数据链路层负责将数据分组封装成帧(11) 会话层在不同主机的应用程序之间建立会话(12) 数据链路层将从网络层收到的分组封装成帧(13) 传输层将用户数据分段(14) 网络层将来自传输层的数据段封装成分组(15) 物理层负责以数字信号的形式传输 l 和 o (比特)(16) 数据段、分组、帧、比特(17) 传输层(18) 数据链路层(19) 网络层(20) 长 48 位 (6B) 表示为一个十六进制数 6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(5)]]></title>
      <url>%2F2017%2F03%2F17%2F%E4%BD%A0%E6%87%82python%E5%90%97-5%2F</url>
      <content type="text"><![CDATA[python的format函数使用语法 它通过{}和:来代替%。 用法 ^、&lt;、&gt;分别是居中、左对齐、右对齐，后面带宽度:号后面带填充的字符，只能是一个字符，不指定的话默认是用空格填充 精度常跟类型f一起使用 b、d、o、x分别是二进制、十进制、八进制、十六进制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Person(): def __init__(self, name, age): self.name = name self.age = age def __str__(self): return 'This guy is &#123;self.name&#125;,&#123;self.age&#125; old'.format(self=self)if __name__ == '__main__': # 元组表达 info = ("luckylau", 23) print "info : %s" % (info,) #对于元组，后面的逗号不能少，会报错 print '&#123;1&#125;,&#123;0&#125;'.format(*info) #对于元组，星号不能少，会报错 # 通过位置映射 print '&#123;0&#125;,&#123;1&#125;'.format('test', '123') print '&#123;0&#125;,&#123;1&#125;,&#123;0&#125;'.format('test', '123') # 通过关键字映射 print "&#123;name&#125;,&#123;age&#125;".format(name="luckylau", age=23) # 通过对象属性 print str(Person("luckylau",23)) # 数组表达 info=["luckylau",23] print "info : %s" % (info,) print 'info :&#123;1&#125;,&#123;0&#125;'.format(*info) #星号不能少 print "info : %s" % (info) print 'info :&#123;0[1]&#125;,&#123;0[0]&#125;'.format(info) # 字典的表达 info=&#123;"name":"luckylau","age":23&#125; print "info : %s " %(info) print "info : %s" % (info,) print 'info : &#123;name&#125;,&#123;age&#125;'.format(**info) #两个星号一个不能少 # 对齐 print '&#123;:&gt;8&#125;'.format('189') print '&#123;:0&gt;8&#125;'.format('189') # 精度 print '&#123;:.2f&#125;'.format(321.33345) # 转二进制 print '&#123;:b&#125;'.format(17)#outputinfo : ('luckylau', 23)23,luckylautest,123test,123,testluckylau,23This guy is luckylau,23 oldinfo : ['luckylau', 23]info :23,luckylauinfo : ['luckylau', 23]info :23,luckylauinfo : &#123;'age': 23, 'name': 'luckylau'&#125; info : &#123;'age': 23, 'name': 'luckylau'&#125;info : luckylau,23 18900000189321.3310001]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(4)]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BD%A0%E6%87%82python%E5%90%97-4%2F</url>
      <content type="text"><![CDATA[Python 的类的下划线命名_xxx 单下划线开头的变量，标明是一个受保护(protected)的变量，原则上不允许直接访问，但外部类还是可以访问到这个变量，这只是程序员之间的一个约定，用于警告说明这是一个私有变量，外部类不要去访问它。 1234567891011121314class Person(object): def __init__(self, name): self._name = nameclass Student(Person): def __init__(self, age): super(Student,self).__init__("luckylau") self._age = ageif __name__ == '__main__': stu = Student(20) print stu._age print stu._name # 约定不能出现这样的代码来访问name属性,但实际是可以访问的。#output20luckylau __xxx 双下划线开头的，表示的是私有类型(private)的变量。只能是允许这个类本身进行访问了, 连子类也不可以,用于命名一个类属性（类变量），调用时名字被改变，双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。 12345678910111213141516class Person(object): def __init__(self, name): self.__name = nameclass Student(Person): def __init__(self, age): super(Student,self).__init__("luckylau") self._age = ageif __name__ == '__main__': stu = Student(20) print stu.__name #AttributeError: 'Student' object has no attribute '__name' 子类不能访问 print stu._Person__name #这样可以访问 person=Person("luckylau") #AttributeError: 'Person' object has no attribute '__name' 实例不能访问 print person.__name #AttributeError: 'Person' object has no attribute '__name' 实例不能访问 print person._Person__name #这样可以访问 print person.__dict__ #&#123;'_Person__name': 'luckylau'&#125; __xxx__ 以双下划线开头，并且以双下划线结尾的，是内置变量，内置变量是可以直接访问的，不是 private 变量，所以，不要自己定义这类变量。 123456__init____file____dirt__...]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(3)]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BD%A0%E6%87%82python%E5%90%97-3%2F</url>
      <content type="text"><![CDATA[@staticmethod和@classmethod的区别什么是python的修饰符Decorators？​ 装饰器模式可以在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责，也能够处理那些可以撤销的职责。经常用于日志记录、性能测试等场合。 ​ 想象一下这个很常见的场景，你写了一个方法： 1234567891011121314151617181920def A(n): if n &gt; 2: print n print "aaaaaa" else: print A.__name__def B(n): if n &gt;2: print n print "bbbbbb" else: print B.__name__if __name__ == '__main__': A(3) B(3)#ouptput3aaaaaa3bbbbbb 用修饰符优美的表达式 12345678910111213141516171819202122def decorator(fn): def inner(n): if n&gt;2: print n else: print fn.__name__ return inner@decoratordef A(n): print "aaaaaa"@decoratordef B(n): print "bbbbbb"if __name__ == '__main__': A(3) B(3)# output3aaaaaa3bbbbbb 当有多个修饰符时候，由远及近影响，如下： 123456789101112131415def tag_wrap(tag): def decorator(fn): def inner(s): return '&lt;%s&gt;%s&lt;%s&gt;' % (tag, fn(s), tag) return inner return decorator@tag_wrap('a')@tag_wrap('b')@tag_wrap('c')def greet(name): return 'Hello, %s!' % nameif __name__ == '__main__': print(greet('world'))#output&lt;a&gt;&lt;b&gt;&lt;c&gt;Hello, world!&lt;c&gt;&lt;b&gt;&lt;a&gt; 我们再举一个日志的例子 12345678910111213141516171819202122232425262728293031323334def log_calls(fn): def inner(*args, **kwargs): out = apply(fn, args, kwargs) with open('logfile.log', 'a') as logfile: logfile.write('%s called with args %s and kwargs %s, returning %s\n' % (fn.__name__, args, kwargs, out)) return out return inner@log_callsdef fizz_buzz_or_number(i): if i % 15 == 0: return 'fizzbuzz' elif i % 3 == 0: return 'fizz' elif i % 5 == 0: return 'buzz' else: return iif __name__ == '__main__': for i in range(1, 31): print(fizz_buzz_or_number(i))#outputfizz_buzz_or_number called with args (1,) and kwargs &#123;&#125;, returning 1fizz_buzz_or_number called with args (2,) and kwargs &#123;&#125;, returning 2fizz_buzz_or_number called with args (3,) and kwargs &#123;&#125;, returning fizzfizz_buzz_or_number called with args (4,) and kwargs &#123;&#125;, returning 4fizz_buzz_or_number called with args (5,) and kwargs &#123;&#125;, returning buzzfizz_buzz_or_number called with args (6,) and kwargs &#123;&#125;, returning fizzfizz_buzz_or_number called with args (7,) and kwargs &#123;&#125;, returning 7... @staticmethod和@classmethodPython其实有3个方法,即静态方法(staticmethod),类方法(classmethod)和实例方法 @staticmethod和@classmethod本身也是装饰器的一种特例。先看下面的例子： 12345678910111213141516171819202122232425262728293031def foo(x): print "executing foo(%s)"%(x)class A(object): def foo(self,x): print "executing foo(%s,%s)"%(self,x) @classmethod def class_foo(cls,x): #不需要self参数，但第一个参数需要是表示自身类的cls参数 print "executing class_foo(%s,%s)"%(cls,x) @staticmethod def static_foo(x): #不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样 print "executing static_foo(%s)"%xif __name__ == '__main__': a=A() a.class_foo(3) a.foo(3) a.static_foo(3) A.class_foo(3) A.static_foo(3) A.foo(3) #outputexecuting class_foo(&lt;class '__main__.A'&gt;,3)executing foo(&lt;__main__.A object at 0x7f79857c9350&gt;,3)executing static_foo(3)executing class_foo(&lt;class '__main__.A'&gt;,3)executing static_foo(3)A.foo(3)TypeError: unbound method foo() must be called with A instance as first argument (got int instance instead) \ 实例方法 类方法 静态方法 a = A() a.foo(x) a.class_foo(x) a.static_foo(x) A 不可用 A.class_foo(x) A.static_foo(x 参考：http://pythoncentral.io/difference-between-staticmethod-and-classmethod-in-python/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[云计算中的IAAS，PASS，SAAS的区别]]></title>
      <url>%2F2017%2F03%2F16%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84IAAS%EF%BC%8CSAAS-PASS%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[什么是云计算？​ “云”其实是互联网的一个隐喻，“云计算”其实就是使用互联网来接入存储或者运行在远程服务器端的应用，数据，或者服务。任何一个使用基于互联网的方法来计算，存储和开发的公司，都可以从技术上叫做从事云的公司。 IAAS,SAAS,PASS的通俗解释？ IAAS,SAAS,PASS的概念？Iaas（基础设施即服务Infrastructure as a Service） ​ IaaS就是专门提供基础设施服务，IaaS公司会提供场外服务器，存储和网络硬件，你可以租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。一些大的IaaS公司包括Amazon, Microsoft, VMWare, Rackspace和Red Hat.不过这些公司又都有自己的专长，比如Amazon和微软给你提供的不只是IaaS，他们还会将其计算能力出租给你来host你的网站。 Paas（平台即服务Platform-as-a-Service） ​ 第二层就是所谓的PaaS，某些时候也叫做中间件。你公司所有的开发都可以在这一层进行，节省了时间和资源。PaaS公司在网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统。这节省了你在硬件上的费用，也让分散的工作室之间的合作变得更加容易。网页应用管理，应用设计，应用虚拟主机，存储，安全以及应用开发协作工具等。一些大的PaaS提供者有Google App Engine,Microsoft Azure，Force.com,Heroku，Engine Yard。最近兴起的公司有AppFog,Mendix和Standing Cloud. Saas（软件即服务Software-as-a-Service） ​ 第三层也就是所谓SaaS。这一层是和你的生活每天接触的一层，大多是通过网页浏览器来接入。任何一个远程服务器上的应用都可以通过网络来运行，就是SaaS了。你消费的服务完全是从网页如Netflix,MOG,Google Apps,Box.net,Dropbox或者苹果的iCloud那里进入这些分类。尽管这些网页服务是用作商务和娱乐或者两者都有，但这也算是云技术的一部分。一些用作商务的SaaS应用包括Citrix的Go To Meeting，Cisco的WebEx，Salesforce的CRM，ADP，Workday和SuccessFactors。 参考:https://www.zhihu.com/question/21641778]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java基础之Enum的用法]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82java%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[Enum的用法 首先从整体来看，我们可以把enum 看成是一个普通的 class，并定义一些属性和方法，不同之处是：enum 不能使用 extends 关键字继承其他类，因为 enum 已经继承了 java.lang.Enum（java是单一继承）。 常用方法包括： 123456789101112int compareTo(E o) 比较此枚举与指定对象的顺序。Class&lt;E&gt; getDeclaringClass() 返回与此枚举常量的枚举类型相对应的 Class 对象。String name() 返回此枚举常量的名称，在其枚举声明中对其进行声明。int ordinal() 返回枚举常量的序数（它在枚举声明中的位置，其中初始常量序数为零）。String toString() 返回枚举常量的名称，它包含在声明中。static &lt;T extends Enum&lt;T&gt;&gt; T valueOf(Class&lt;T&gt; enumType, String name) 返回带指定名称的指定枚举类型的枚举常量。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package test;public class enumdemo &#123; public enum weekSchedule &#123; Mon(7,"语文"), Tus(6,"数学"), Wed(5,"英语"), Thu(4,"物理"), Fri(3,"化学"), Sat(2,"生物"), Sun(1,"体育"); private int num ; private String value; private weekSchedule(int num ,String value)&#123; this.num = num; this.value = value; &#125; public int getNum() &#123; return num; &#125; public String getValue() &#123; return value; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub System.out.println(weekSchedule.Fri.getValue()); weekSchedule test = weekSchedule.Thu; switch (test.compareTo(weekSchedule.Sat)) &#123; case -2: System.out.println("TUE 在 Sat 之前"); break; case 1: System.out.println("TUE 在 Sat 之后"); break; default: System.out.println("处于同一位置"); break; &#125; System.out.println(test.toString()); System.out.println(test.ordinal()); System.out.println(test.name()); System.out.println(test.getDeclaringClass()); &#125;&#125;#outputTUE 在 Sat 之前Thu3Thuclass test.enumdemo$weekSchedule 枚举实现单例模式123456789101112131415public enum Singleton &#123; INSTANCE; private Resource resource; private Singleton() &#123; resource = new Resource(); &#125; public Resource getInstance()&#123; return resource; &#125;&#125;class Resource&#123; public void dosomething()&#123; System.out.println("do something"); &#125;&#125; 123456public class test &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Singleton3.INSTANCE.getInstance().dosomething();; &#125;&#125; 枚举类型的遍历12345678910111213141516171819202122232425262728293031public enum WeekSchedule &#123; Mon(7,"语文"), Tus(6,"数学"), Wed(5,"英语"), Thu(4,"物理"), Fri(3,"化学"), Sat(2,"生物"), Sun(1,"体育"); private int num ; private String value; private WeekSchedule(int num ,String value)&#123; this.num = num; this.value = value; &#125; public int getNum() &#123; return num; &#125; public String getValue() &#123; return value; &#125; public WeekSchedule getWeekSchedule(String value)&#123; for(WeekSchedule item: WeekSchedule.values())&#123; String itemValue = item.getValue(); if(itemValue != null &amp;&amp; itemValue.equals(value))&#123; return item; &#125; &#125; return null; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(2)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82python%E5%90%97-2%2F</url>
      <content type="text"><![CDATA[深刻理解Python中的元类(metaclass)问题 ：什么是metaclass？在哪些情况会使用？ 类也是对象​ 在理解元类之前，你需要先掌握Python中的类。Python中类的概念借鉴于Smalltalk，这显得有些奇特。在大多数编程语言中，类就是一组用来描述如何生成一个对象的代码段。在Python中这一点仍然成立： 1234567class ObjectCreator(object): passif __name__ == '__main__': my_object=ObjectCreator() print my_object#output&lt;__main__.ObjectCreator object at 0x7f8fd686d450&gt; ​ 但是，Python中的类还远不止如此。类同样也是一种对象。是的，没错，就是对象。只要你使用关键字class，Python解释器在执行的时候就会创建一个对象。将在内存中创建一个对象，名字就是ObjectCreator。这个对象（类）自身拥有创建对象（类实例）的能力，而这就是为什么它是一个类的原因。但是，它的本质仍然是一个对象，于是乎你可以对它做如下的操作： 1) 你可以将它赋值给一个变量 2) 你可以拷贝它 3) 你可以为它增加属性 4) 你可以将它作为函数参数进行传递 下面的代码段： 1234567891011121314151617181920class ObjectCreator(object): passdef echo(o): print oif __name__ == '__main__': echo(ObjectCreator) #作为函数参数进行传递 echo(ObjectCreator()) print hasattr(ObjectCreator, 'new_attribute') ObjectCreator.new_attribute = 'foo' #增加属性 print hasattr(ObjectCreator, 'new_attribute') print ObjectCreator.new_attribute ObjectCreatorMirror = ObjectCreator #赋值给一个变量 print ObjectCreatorMirror()#output&lt;class '__main__.ObjectCreator'&gt;&lt;__main__.ObjectCreator object at 0x7f94fa648450&gt;FalseTruefoo&lt;__main__.ObjectCreator object at 0x7f94fa558e10&gt; 动态地创建类​ 因为类也是对象，你可以在运行时动态的创建它们，就像其他任何对象一样。首先，你可以在函数中创建类，使用class关键字即可。 1234567891011121314151617def choose_class(name): if name == 'foo': class Foo(object): pass return Foo # 返回的是类，不是类的实例 else: class Bar(object): pass return Barif __name__ == '__main__': MyClass = choose_class('foo') print MyClass # 函数返回的是类，不是类的实例 print MyClass() # 你可以通过这个类创建类实例，也就是对象#output&lt;class '__main__.Foo'&gt;&lt;__main__.Foo object at 0x7f401385a450&gt; ​ 但这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是通过什么东西来生成的才对。当你使用class关键字时，Python解释器自动创建这个对象。但就和Python中的大多数事情一样，Python仍然提供给你手动处理的方法。还记得内建函数type吗？这个古老但强大的函数能够让你知道一个对象的类型是什么，就像这样： 12345678910111213class ObjectCreator(object): passif __name__ == '__main__': print type(1) print type("1") print type(ObjectCreator) print type(ObjectCreator()) # output&lt;type 'int'&gt;&lt;type 'str'&gt;&lt;type 'type'&gt;&lt;class '__main__.ObjectCreator'&gt; 这里，type有一种完全不同的能力，它也能动态的创建类。type可以接受一个类的描述作为参数，然后返回一个类。（我知道，根据传入参数的不同，同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后兼容性） type可以像这样工作： 1type(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）) 可以手动像这样创建： 1234567891011if __name__ == '__main__': MyShinyClass = type('MyShinyClass', (), &#123;&#125;) # 返回一个类对象 等价于 # class MyShinyClass(object): # pass # print MyShinyClass print MyShinyClass() # 创建一个该类的实例#output&lt;class '__main__.MyShinyClass'&gt;&lt;__main__.MyShinyClass object at 0x7fc8bb86a450&gt; ​ 你会发现我们使用“MyShinyClass”作为类名，并且也可以把它当做一个变量来作为类的引用。类和变量是不同的，这里没有任何理由把事情弄的复杂。 1234567891011121314if __name__ == '__main__': foo = type('Foo', (), &#123;'bar': False&#125;) #等价于class Foo(object): # bar = False print foo print foo.bar f = foo() #将foo当成一个普通的类一样使用 print f print f.bar #output &lt;class '__main__.Foo'&gt; False &lt;__main__.Foo object at 0x7f9868844450&gt; False type 接受一个字典来为类定义属性，并且可以将foo当成一个普通的类一样使用 12345678910if __name__ == '__main__': foo = type('Foo', (), &#123;'bar': False&#125;) class foochild(foo): pass FooChild = type('foochild', (foo,), &#123;&#125;) print FooChild print FooChild.bar # bar属性是由foo继承而来#output &lt;class '__main__.foochild'&gt; False 你可以看到，在Python中，类也是对象，你可以动态的创建类。这就是当你使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的。 到底什么是元类​ 元类就是用来创建类的“东西”。你创建类就是为了创建类的实例对象，不是吗？但是我们已经学习到了Python中的类也是对象。好吧，元类就是用来创建这些类（对象）的，元类就是类的类。 你已经看到了type可以让你像这样做： 1MyClass = type('MyClass', (), &#123;&#125;) ​ 这是因为函数type实际上是一个元类。type就是Python在背后用来创建所有类的元类。现在你想知道那为什么type会全部采用小写形式而不是Type呢？好吧，我猜这是为了和str保持一致性，str是用来创建字符串对象的类，而int是用来创建整数对象的类。type就是创建类对象的类。你可以通过检查class属性来看到这一点。Python中所有的东西，注意，我是指所有的东西——都是对象。这包括整数、字符串、函数以及类。它们全部都是对象，而且它们都是从一个类创建而来。 1234567891011121314151617181920212223242526def foo(): passclass Bar(object): passif __name__ == '__main__': age=35 name="lucky" b = Bar() print age.__class__ print name.__class__ print foo.__class__ print b.__class__ print Bar.__class__ print age.__class__.__class__ print name.__class__.__class__ print b.__class__.__class__# output&lt;type 'int'&gt;&lt;type 'str'&gt;&lt;type 'function'&gt;&lt;class '__main__.Bar'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt;&lt;type 'type'&gt; 因此，元类就是创建类这种对象的东西。如果你喜欢的话，可以把元类称为“类工厂”（不要和工厂类搞混了:D） type就是Python的内建元类，当然了，你也可以创建自己的元类。 创建自己的元类首先了解metaclass**属性** 12class Foo(object): __metaclass__ = something 你可以在写一个类的时候为其添加metaclass属性,如果你这么做了，Python就会用元类来创建类Foo。小心点，这里面有些技巧。你首先写下class Foo(object)，但是类对象Foo还没有在内存中创建。Python会在类的定义中寻找metaclass属性，如果找到了，Python就会用它来创建类Foo，如果没有找到，就会用内建的type来创建这个类。把下面这段话反复读几次。当你写如下代码时 : 12class Foo(Bar): pass Python做了如下的操作： Foo中有metaclass这个属性吗？如果是，Python会在内存中通过metaclass创建一个名字为Foo的类对象（我说的是类对象，请紧跟我的思路）。如果Python没有找到metaclass，它会继续在Bar（父类）中寻找metaclass属性，并尝试做和前面同样的操作。如果Python在任何父类中都找不到metaclass，它就会在模块层次中去寻找metaclass，并尝试做同样的操作。如果还是找不到metaclass,Python就会用内置的type来创建这个类对象。 现在的问题就是，你可以在metaclass中放置些什么代码呢？答案就是：可以创建一个类的东西。那么什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东东都可以。 ​ 元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。假想一个很傻的例子，你决定在你的模块里所有的类的属性都应该是大写形式。有好几种方法可以办到，但其中一种就是通过在模块级别设定metaclass。采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改成大写形式就万事大吉了。 ​ 幸运的是，metaclass实际上可以被任意调用，它并不需要是一个正式的类（我知道，某些名字里带有‘class’的东西并不需要是一个class，画画图理解下，这很有帮助）。所以，我们这里就先以一个简单的函数作为例子开始。 123456789101112131415161718192021222324252627282930313233343536373839404142import six# 元类会自动将你通常传给‘type’的参数作为自己的参数传入def upper_attr(future_class_name, future_class_parents, future_class_attr): ''' 返回一个类对象，将属性都转为大写形式 :param future_class_name: :param future_class_parents: :param future_class_attr: :return: ''' # 选择所有不以'__'开头的属性 attrs = ((name, value)for name, value in future_class_attr.items() if not name.startswith('__')) # 将它们转为大写形式 uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 通过'type'来做类对象的创建 return type(future_class_name, future_class_parents, uppercase_attr)#__metaclass__ = upper_attr #这会作用到这个模块中的所有类class Foo(object): # 我们也可以只在这里定义__metaclass__，这样就只会作用于这个类中 __metaclass__ = upper_attr bar = 'bar'@six.add_metaclass(upper_attr) #还可以这么设置metaclassclass Doo(object): doo = "doo" if __name__ == '__main__': print hasattr(Foo, 'bar') print hasattr(Foo, 'BAR') if hasattr(Foo, 'BAR'): f = Foo() print f.BAR print hasattr(Doo, 'DOO')#outputFalseTruebarTrue 现在让我们再做一次，这一次用一个真正的class来当做元类: 1234567891011121314# 请记住，'type'实际上是一个类，就像'str'和'int'一样# 所以，你可以从type继承class UpperAttrMetaClass(type): # __new__ 是在__init__之前被调用的特殊方法 # __new__是用来创建对象并返回之的方法 # 而__init__只是用来将传入的参数初始化给对象 # 你很少用到__new__，除非你希望能够控制对象的创建 # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情 # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用 def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type(future_class_name, future_class_parents, uppercase_attr) 但是，这种方式其实不是OOP。我们直接调用了type，而且我们没有改写父类的new方法。现在让我们这样去处理: 12345678class UpperAttrMetaclass(type): def __new__(upperattr_metaclass, future_class_name, future_class_parents, future_class_attr): attrs = ((name, value) for name, value in future_class_attr.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) # 复用type.__new__方法 # 这就是基本的OOP编程，没什么魔法 return type.__new__(upperattr_metaclass, future_class_name, future_class_parents, uppercase_attr) 你可能已经注意到了有个额外的参数upperattr_metaclass，这并没有什么特别的。类方法的第一个参数总是表示当前的实例，就像在普通的类方法中的self参数一样。当然了，为了清晰起见，这里的名字我起的比较长。但是就像self一样，所有的参数都有它们的传统名称。因此，在真实的产品代码中一个元类应该是像这样的： 12345class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__') uppercase_attr = dict((name.upper(), value) for name, value in attrs) return type.__new__(cls, name, bases, uppercase_attr) 如果使用super方法的话，我们还可以使它变得更清晰一些，这会缓解继承（是的，你可以拥有元类，从元类继承，从type继承） 123456789101112131415class UpperAttrMetaclass(type): def __new__(cls, name, bases, dct): attrs = ((name, value) for name, value in dct.items() if not name.startswith('__')) uppercase_attr = dict((name.upper(), value) for name, value in attrs) return super(UpperAttrMetaclass, cls).__new__(cls, name, bases, uppercase_attr)class doo(): __metaclass__ = UpperAttrMetaclass doo="doo"if __name__ == '__main__': foo=UpperAttrMetaclass("Foo",(),&#123;'bar' :"foo"&#125;) print hasattr(foo, 'bar') print hasattr(doo, 'DOO')#outputFalseTrue 就是这样，除此之外，关于元类真的没有别的可说的了。使用到元类的代码比较复杂，这背后的原因倒并不是因为元类本身，而是因为你通常会使用元类去做一些晦涩的事情，依赖于自省，控制继承等等。确实，用元类来搞些“黑暗魔法”是特别有用的，因而会搞出些复杂的东西来。但就元类本身而言，它们其实是很简单的： 1) 拦截类的创建 2) 修改类 3) 返回修改之后的类 为什么要用metaclass类而不是函数?由于metaclass可以接受任何可调用的对象，那为何还要使用类呢，因为很显然使用类会更加复杂啊？这里有好几个原因： 1） 意图会更加清晰。当你读到UpperAttrMetaclass(type)时，你知道接下来要发生什么。 2） 你可以使用OOP编程。元类可以从元类中继承而来，改写父类的方法。元类甚至还可以使用元类。 3） 你可以把代码组织的更好。当你使用元类的时候肯定不会是像我上面举的这种简单场景，通常都是针对比较复杂的问题。将多个方法归总到一个类中会很有帮助，也会使得代码更容易阅读。 4） 你可以使用new, init以及call这样的特殊方法。它们能帮你处理不同的任务。就算通常你可以把所有的东西都在new里处理掉，有些人还是觉得用init更舒服些。 5） 哇哦，这东西的名字是metaclass，肯定非善类，我要小心！ 现在回到我们的大主题上来，究竟是为什么你会去使用这样一种容易出错且晦涩的特性？好吧，一般来说，你根本就用不上它： 12Metaclasses are deeper magic that 99% of users should never worry about. If you wonder whether you need them, you don&apos;t (the people who actually need them know with certainty that they need them, and don&apos;t need an explanation about why).Python Guru Tim Peters “元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类。” —— Python界的领袖 Tim Peters 元类的主要用途是创建API。一个典型的例子是Django ORM。它允许你像这样定义： 123class Person(models.Model): name = models.CharField(max_length=30) age = models.IntegerField() 但是如果你像这样做的话： 12guy = Person(name='bob', age='35')print guy.age 这并不会返回一个IntegerField对象，而是会返回一个int，甚至可以直接从数据库中取出数据。这是有可能的，因为models.Model定义了metaclass， 并且使用了一些魔法能够将你刚刚定义的简单的Person类转变成对数据库的一个复杂hook。Django框架将这些看起来很复杂的东西通过暴露出一个简单的使用元类的API将其化简，通过这个API重新创建代码，在背后完成真正的工作。 结语：首先，你知道了类其实是能够创建出类实例的对象。好吧，事实上，类本身也是实例，当然，它们是元类的实例。Python中的一切都是对象，它们要么是类的实例，要么是元类的实例，除了type。type实际上是它自己的元类，在纯Python环境中这可不是你能够做到的，这是通过在实现层面耍一些小手段做到的。其次，元类是很复杂的。对于非常简单的类，你可能不希望通过使用元类来对类做修改。你可以通过其他两种技术来修改类： 1） Monkey patching 2) class decorators 当你需要动态修改类时，99%的时间里你最好使用上面这两种技术。当然了，其实在99%的时间里你根本就不需要动态修改类 :D 参考：http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python http://blog.jobbole.com/21351/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你懂python吗(1)]]></title>
      <url>%2F2017%2F03%2F14%2F%E4%BD%A0%E6%87%82python%E5%90%97-1%2F</url>
      <content type="text"><![CDATA[Python的函数参数传递示例一： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c=2 print "test after" print id(c) return cif __name__ == '__main__': a=1 print "main before" print id(a) test(a) print "main after" print id(a) print a# outputmain before12460376test before12460376test after12460352main after124603761 示例二： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c.append(1) print "test after" print id(c) return cif __name__ == '__main__': a=[] print "main before" print id(a) test(a) print "main after" print id(a) print a #output main before139625132046312test before139625132046312test after139625132046312main after139625132046312[1] 示例三： 12345678910111213141516171819202122232425def test(c): print "test before" print id(c) c=[2,3] print "test after" print id(c) return cif __name__ == '__main__': a=[1] print "main before" print id(a) test(a) print "main after" print id(a) print a# outputmain before139900695660520test before139900695660520test after139900695661672main after139900695660520[1] 总结： ​ 对象有两种,“可更改”（mutable）与“不可更改”（immutable）对象。在python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。对于不可更改对象而言一定是“值传递”引用，如示例一；对于可更改对象也可以“值传递”，如示例三；对于示例二，传入的是可变对象，并且函数对其进行操作，属于“引用传递”。 函数参数的定义有四种形式： F(arg1,arg2,…) F(arg2=,arg3=…) F(*arg1) F(**arg1) 12345678910111213141516171819202122232425262728293031323334def test(x,y=5,*a,**b): print x,y,a,bif __name__ == '__main__': test(1) test(1, 2) test(1, 2, 3) test(1, 2, 3, 4) test(1, 2, (3, 4),5) test(1, 2, 3, 4, 5,a=2) test(x=1) test(x=1,y=2) test(x=1,y=2,a=3) test(x=1,y=2,a=3,b=4) test(x=1, y=2, a=3, b=4,c=5) test(1, 2, z=1) test(1, 2, 3, a=1) test(1, 2, 3, 4, a=1) test(1, 2, 3, 4, a=1, b=2, c=3) #output 1 5 () &#123;&#125; 1 2 () &#123;&#125; 1 2 (3,) &#123;&#125; 1 2 (3, 4) &#123;&#125; 1 2 ((3, 4), 5) &#123;&#125; 1 2 (3, 4, 5) &#123;'a': 2&#125; 1 5 () &#123;&#125; 1 2 () &#123;&#125; 1 2 () &#123;'a': 3&#125; 1 2 () &#123;'a': 3, 'b': 4&#125; 1 2 () &#123;'a': 3, 'c': 5, 'b': 4&#125; 1 2 () &#123;'z': 1&#125; 1 2 (3,) &#123;'a': 1&#125; 1 2 (3, 4) &#123;'a': 1&#125; 1 2 (3, 4) &#123;'a': 1, 'c': 3, 'b': 2&#125; 首先按顺序把“arg”这种形式的实参给对应的形参； 第二，把“arg=”这种形式的实参赋值给形参； 第三，把多出来的“arg”这种形式的实参组成一个tuple给带一个星号的形参； 第四，把多出来的“key=value”这种形式的实参转为一个dictionary给带两个星号的形参。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LoadBalancerv2的原理分析]]></title>
      <url>%2F2017%2F03%2F10%2FLoadBalancerv2%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[​ OpenStack 是直接采用各种开源可用的负载均衡项目来完成负载均衡的任务，默认使用 HAProxy。LBaaSv2 本质来说，其实也是根据用户提出的负载均衡要求，生成符合的HAProxy配置文件并启动 HAProxy，然后由 HAProxy 进行负载均衡。 更新时间 更新内容 2017-03-10 初始版本 2017-04-24 添加HAProxy详细说明链接 High Availability Proxy（HAProxy）？​ HAProxy 是个著名的开源的软件 TCP（四层）/HTTP（七层） 负载均衡器和代理（proxy）软件，可以运行在 Linux，Solaris 和 FreeBSD 等系统上。目前，它已经被许多大公司采用，包括GitHub, Imgur, Instagram, and Twitter 等。它类似 Nginx 的，采用了单进程和事件驱动模型；它使用的内存量低而且稳定，能够处理大量并发请求。 在这里我简单罗列HAProxy配置。详细内容查看： Neutron中的LoadBalancerv2的Haproxy haproxy 配置中分成五部分内容，分别如下：​ global：参数是进程级的，通常是和操作系统相关。这些参数一般只设置一次，如果配置无误，就不需要再次进行修改。​ defaults：配置默认参数，这些参数可以被用到frontend，backend，Listen组件。​ frontend：接收请求的前端虚拟节点，Frontend可以更加规则直接指定具体使用后端的backend。​ backend：后端服务集群的配置，是真实服务器，一个Backend对应一个或者多个实体服务器。​ Listen Fronted和backend的组合体。 neutron的LoadBalancerv2配置文件在 /etc/haproxy/haproxy.cfg中 12345678910111213141516171819202122232425262728293031323334353637###########全局配置######### global log /dev/log local0 #[日志输出配置，所有日志都记录在本机，通过local0输出] log /dev/log local1 notice #定义haproxy 日志级别[error warringinfo debug] chroot /var/lib/haproxy stats socket /run/haproxy/admin.sock mode 660 level admin stats timeout 30s user haproxy group haproxy #可以由配置项 user_group 指定，默认为 nogroup daemon #以后台形式运行harpoxy # Default SSL material locations ca-base /etc/ssl/certs crt-base /etc/ssl/private # Default ciphers to use on SSL-enabled listening sockets. # For more information, see ciphers(1SSL). This list is from: # https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS ssl-default-bind-options no-sslv3 ########默认配置############ defaults log global mode http option httplog option dontlognull timeout connect 5000 timeout client 50000 timeout server 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.http 我们事先创建了qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2，我们看看它的配置文件 12root@netagent:~# ip netns listqlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 该负载均衡是1个LoadBalance对应1个listener,1个pool。 在/var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy.conf 中 12345678910111213141516171819202122232425262728293031323334# Configuration for loadbalance1global daemon user nobody group haproxy log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy_stats.sock mode 0666 level userdefaults log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 62ac018e-f6fc-4d60-80df-13b1e4cdc6f6 option tcplog maxconn 100 option forwardfor bind 2.2.2.20:80 mode http default_backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 mode http balance roundrobin timeout check 1 option httpchk GET /index.html http-check expect rstatus 201|200|202 server d56fc582-33cd-4fc7-b95f-16534c8a4860 2.2.2.5:80 weight 1 check inter 1s fall 5 server cc2230bf-f3b8-4beb-8584-71b0f3a0ba5c 2.2.2.4:80 weight 1 check inter 1s fall 5 server b490cadb-cff1-4e7a-92c7-a134c0f8b321 2.2.2.6:80 weight 1 check inter 1s fall 5 LBaasv2 可以看做 OpenStack Neutron 对各种物理负载均衡器的虚拟化。它的概念可以和 HAProxy 中的概念进行类比： HAProxy 的概念 LBaasv2 的概念 说明 Driver LBaas v2也是采取 driver 模型来支持多种物理的负载均衡器。LBaasv2 默认实现了 HAProxy driver，同时，它也支持多个其他 Vendor driver。 Frontend Listener LBaasv2采用Listener方式将流量转移到不同的pool中的member。 Backend Pool 代表Listener所监听的负载后端的虚拟机池。 Backend server Member Member 对应的是 pool 里面处理网络请求的一个 OpenStack Nova 虚机 Health check Health monitor 它用来监测 pool 里面 member 的状态，支持 HTTP, TCP, 和 ping 等多种检测方法。在 Nuetron 中这是可选的，如果没有 Health monitor，pool 会一直认为所有的 member 都是 ACTIVE 状态，这样所有的 member 会一直出现在 VIP 的分发列表中，哪怕 member 对应的实例不能响应网络请求。这在实际应用中会造成负载均衡的响应异常。 LoadBalancerv2的使用场景？ ​ 由上图可知道，一个LoadBalancerv2可以对应多个Pool,我们另外又建立一个pool如下所示： 在/var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy.conf 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# Configuration for loadbalance1global daemon user nobody group haproxy #可以由配置项 user_group 指定，默认为 nogroup log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/0f66315f-0ccf-43cb-abca-2bb6f51e8fb2/haproxy_stats.sock mode 0666 level user defaults #不用管 log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 62ac018e-f6fc-4d60-80df-13b1e4cdc6f6 option tcplog maxconn 100 option forwardfor # 当 mode 为 ”http“时，设置 forwardfor，使得通过 X-Forward-For 头来保存原始的源 IP 地址 bind 2.2.2.20:80 #监听Listener的vip:port mode http #监听Protocol default_backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 #对应的监听池frontend bf144f31-cdbb-4426-b90b-4bdbc67501f1 option tcplog maxconn 100 option forwardfor bind 2.2.2.20:100 mode http default_backend 8b50ed30-5290-421c-9d31-fb3751a26be2backend 8b50ed30-5290-421c-9d31-fb3751a26be2 mode http balance roundrobin server bef852d0-9164-46ee-ace5-92462e8d89ef 2.2.2.14:100 weight 1 server 8aeb5cc2-7301-4931-ac3b-e0d0ca891e88 2.2.2.15:100 weight 1 server 250a919f-dfc1-41b6-8378-2b4015f1acd0 2.2.2.16:100 weight 1backend 8d28b2c3-9c44-46e5-b2eb-7bd9b8d5faf6 mode http balance roundrobin timeout check 1 option httpchk GET /index.html http-check expect rstatus 201|200|202 server cc2230bf-f3b8-4beb-8584-71b0f3a0ba5c 2.2.2.4:80 weight 1 check inter 1s fall 5 #member1 的配置，包括 ip，port（member 提供服务的端口，此时没有指定check port，因此也是健康检查的 TCP端口），weight；check 指定做健康检查；inter 指定两次连续检查之间的间隔，默认2s (1s）；fall 指定 Max Retries 或者连续几次检查失败即认为member 是 DOWN 的次数 （5） server d56fc582-33cd-4fc7-b95f-16534c8a4860 2.2.2.5:80 weight 1 check inter 1s fall 5 server b490cadb-cff1-4e7a-92c7-a134c0f8b321 2.2.2.6:80 weight 1 check inter 1s fall 5 访问wget -O - http://2.2.2.2:80 和wget -O - http://2.2.2.2:100都成功。 以上是vip与pool的members同在一个subnet下，下面我们验证一下vip与pool的members不在同一个subnet。 我们创建一个新的Loadbalance和一个listener,vip地址为7.7.7.7,然后创建一个pool,注意一个虚拟机可以加入多个pool,所以我们还把上面的虚拟机加入这个新建的pool中。然后通过路由器subnet7.7.7.0/24和subnet2.2.2.0/24连通。也就是说vip7.7.7.7能与member2.2.2.4,2.2.2.5,2.2.2.6是联通的。 配置如下/var/lib/neutron/lbaas/v2/5081116f-8928-40d7-8aaa-e30c336ca713/haproxy.conf 12345678910111213141516171819202122232425262728293031# Configuration for loadbalance3global daemon user nobody group haproxy log /dev/log local0 log /dev/log local1 notice stats socket /var/lib/neutron/lbaas/v2/5081116f-8928-40d7-8aaa-e30c336ca713/haproxy_stats.sock mode 0666 level userdefaults log global retries 3 option redispatch timeout connect 5000 timeout client 50000 timeout server 50000frontend 84800dd3-0507-4628-b54b-a23226bec4f8 option tcplog maxconn 100 option forwardfor bind 7.7.7.7:80 mode http default_backend 3583deda-e9ca-40bb-ba23-0fec204c099fbackend 3583deda-e9ca-40bb-ba23-0fec204c099f mode http balance roundrobin server 48b36860-8e4d-476e-9196-ad052c317f44 2.2.2.5:80 weight 1 server f8732b2a-bfaa-4e5f-b8bb-f88c9fed899b 2.2.2.4:80 weight 1 server 004f7950-4031-4de3-98b2-ca30e39c4e4e 2.2.2.6:80 weight 1 也就是说只要vip与member可通信即可，不一定要在同一个subnet中。 另外，如果要从外网访问的话，则还需要创建一个 floating ip 并且把它关联到 lb 的vip 上。 haproxy 所在的namespace 其实只有一个IP地址，分别接收外部连接以及和成员之间的连接。 LoadBalancerv2的多agent模式？​ LoadBalancerv2服务可以独立部署在服务器上，包括2个服务，neutron-openvswitch-agent 和neutron-lbassv2-agent。假设有2个节点都部署了LoadBalancerv2服务，当neutron-server发出创建请求时，会在这两个节点选择一个创建对应得namespace空间。 LoadBalancerv2的流程分析？​ 我们以qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2为例子来分析这个过程。 12345678910111213ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever9: tap83f82fcf-d1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether fa:16:3e:d1:c8:b1 brd ff:ff:ff:ff:ff:ff inet 2.2.2.20/24 brd 2.2.2.255 scope global tap83f82fcf-d1 #vip的地址 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fed1:c8b1/64 scope link valid_lft forever preferred_lft forever ​ 该接口tap83f82fcf-d1挂在ovs上，并被打上它所在network的vlan_id的: 12345678910111213Bridge br-int fail_mode: secure Port patch-tun Interface patch-tun type: patch options: &#123;peer=patch-int&#125; Port br-int Interface br-int type: internal Port &quot;tap83f82fcf-d1&quot; tag: 1 Interface &quot;tap83f82fcf-d1&quot; type: internal ​ 对于LoadBalancerv2创建过程（在v2中指Create a load balancer和Create listener完成，我们发现当只是完成Create a load balancer时候，并没有出现namespace，当Create listener完成时才会有namespace出现）我们对等如下操作： 12345678910111213141516171819202122232425ovs-vsctl --if-exists del-port tap83f82fcf-d1 --add-port br-int tap83f82fcf-d1 --set Interface tap83f82fcf-d1 type=internal --set Interface tap83f82fcf-d1 external-ids:iface-id=83f82fcf-d141-4774-87a0-ace79196bc88 --set Interface tap83f82fcf-d1 external-ids:iface-status=active --set Interface tap83f82fcf-d1 external-ids:attached-mac=fa:16:3e:d1:c8:b1#iface-id 和 attached-mac可以在数据库中查到ip link set tap83f82fcf-d1 address fa:16:3e:d1:c8:b1ip netns add qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 sysctl -w net.ipv4.conf.all.promote_secondaries=1ip link set tap83f82fcf-d1 netns qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip link set lo upip link set tap83f82fcf-d1 netns qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip link set tap83f82fcf-d1 upip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip addr show tap83f82fcf-d1 permanent scope globalip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip -4 addr add 2.2.2.20/24 brd 255.255.255.0 scope global dev tap83f82fcf-d1ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 ip route list dev tap83f82fcf-d1 scope linkip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 route add default gw 2.2.2.1ip netns exec qlbaas-0f66315f-0ccf-43cb-abca-2bb6f51e8fb2 arping -U -I tap83f82fcf-d1 -c 3 2.2.2.20 LoadBalancerv2的源码解读？​ LoadBalancerv2的代码结构如下： 1.Create a load balancer 2.Create a listener 3.Create a pool 4.Add member 5.Create a health monitor 参考：http://blog.csdn.net/zhu_tianwei/article/details/41117323]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IO的同步与异步，阻塞与非阻塞]]></title>
      <url>%2F2017%2F03%2F08%2FIO%E7%9A%84%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5%EF%BC%8C%E9%98%BB%E5%A1%9E%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
      <content type="text"><![CDATA[​ 同步（synchronous） IO和异步（asynchronous） IO，阻塞（blocking） IO和非阻塞（non-blocking）IO分别是什么，到底有什么区别？我们以Linux环境下的network IO来讨论。 ​ 对于一个network IO (以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 1 等待数据准备 (Waiting for the data to be ready) 2 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I/O Models ”有以下5种： blocking IO； nonblocking IO； IO multiplexing； signal driven IO； asynchronous IO。其中signal driven IO不常见，以下分析4中模型。然后再区分IO的同步与异步，阻塞与非阻塞。 I/O Models1.阻塞式I/O模型 blocking IO 在linux中，默认情况下所有的socket都是blocking ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据；对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。这时在用户进程这边，整个进程挂起，被阻塞。kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。​ 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 2.非阻塞I/O模型 non-blocking IO linux下，可以通过设置socket使其变为non-blocking。 ​ 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据；对于network io来说，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程没有被挂起，可以干些别的，但是需要不断的主动询问kernel数据好了没有，直到准备好，发起一个系统调用。但是在第二个阶段仍然是block的。 3.I/O复用模型 IO multiplexing ​ I/O复用最常见的就是select和epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 ​ 当用户进程调用了select，那么整个进程会被block，不能干别的，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。这个和阻塞式I/O模型 blocking IO的区别在于这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 4.异步I/O模型 Asynchronous I/O ​ 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 四者的区别：blocking vs non-blocking：调用blocking IO会一直block住对应的进程直到操作完成，准备阶段和拷贝阶段都被blocking，而non-blocking IO在kernel还准备数据的情况下会立刻返回，只是在拷贝阶段blocking。 synchronous IO和asynchronous IO： 首先看定义：（简单来说：同步I/O：导致请求进程阻塞，直到I/O操作完成；异步I/O: 不导致请求进程阻塞。） A synchronous I/O operation causes the requesting process to be blocked until that I/O operationcompletes; An asynchronous I/O operation does not cause the requesting process to be blocked; blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 ​ 有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 通俗的例子： 3个人排队去买包子，甲买肉馅馒头，乙买素馅馒头，丙买白馒头。 如果是阻塞式I/O模型，按照先后到来顺序处理甲乙丙，甲到来时候，店铺老板说我在做啊，你就在这等着我做完，哪里也不要去，肉馅馒头做好后给甲，甲可以走了，接着处理乙，乙处理完，再处理丙。 如果是非阻塞式I/O模型，假设还是甲乙丙顺序来，甲询问说我要肉馅馒头，老板说还没有做好，这时侯甲就离开搞其他的事情了，乙到了，询问说我要素馅馒头，老板说还没有做好，这时侯乙就离开搞其他的事情了，丙到了，询问说我要白馒头，老板说还没有做好，这时侯丙就离开搞其他的事情了。只不过甲乙丙还会时不时来询问我要的好了没有，假设白馒头非常好做，某个时刻老板做好了，正巧碰到丙又来询问，老板此刻说你的好了，此时丙哪里也不要去了，什么也不要做了，等着老板把白馒头返回给他。此后甲和乙时不时还来询问我要的好了没有。。可见这时候甲乙丙并不需要一直等待，可以做其他事情，同时并不一定是甲先来一定会被先处理。 如果是I/O复用模型，假设还是甲乙丙顺序来，然后甲乙丙会把自己的需求告诉店小二，然后店小二负责去询问老板肉馅馒头，素馅馒头，白馒头做好了没有。如果在I/O复用模型中，socket没有non-blocking时候，甲乙丙不能走，其他事情也不能做，干等着。店小二通知说素馅馒头好了，这时候乙去见老板拿自己所需要的。我们看到这时候并不是按甲乙丙顺序处理的，虽然甲乙丙被店小二阻塞了，但给人感觉是“并发”，哪个先准备好，先处理哪个。 如果是异步I/O模型，假设还是甲乙丙顺序来，店老板立即给甲乙丙返回一个纸条“好的”，甲乙丙各自散去了，该干嘛就干嘛，这时候店老板做馒头，无论是先做好了甲还是乙丙，就通知他们并把相应的馒头交给他们。甲乙丙也不需要时不时的来询问，更不需要去等待啦。 参考：http://blog.csdn.net/historyasamirror/article/details/5778378 https://www.zhihu.com/question/19732473]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Openstack 负载均衡 LoadBalancerv2]]></title>
      <url>%2F2017%2F03%2F07%2FOpenstack%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1LoadBalancerv2%2F</url>
      <content type="text"><![CDATA[​ 最近研究了一下Openstack负载均衡，yum源和源码级别的安装都尝试成功了。网上有很多文章都是LoadBalancerv1，这个已经被放弃了。所以写一下自己是如何使用LoadBalancerv2。当然在介绍之前还是从负载均衡基础知识开始吧。（Mitaka版本的LoadBalancerv2） 负载均衡的概念和分类？​ 负载均衡（Load Balancing）是将来访的网络流量在运行相同应用的多个服务器之间进行分发的一种核心网络服务。它的功能由负载均衡器（load balancer）提供。负载均衡器可以是一个硬件设备，也可以由软件实现。它充当反向代理，在多个服务器之间分发网络或者应用流量。它常用来增加应用的访问容量（并发用户数）和可靠性，它也会通过降低服务器的负载来提高应用的总体性能。 负载均衡器的分类 负载均衡器一般可以分为两类：第4层负载均衡器和第7层负载均衡器。 第 4 层负载平衡器：基于网络和传输层协议（IP，TCP，FTP，UDP等）来均衡负载。 第7层的负载均衡器：基于应用层协议比如 HTTP, SMTP, SNMP, FTP, Telnet 等均衡负载。比如对 HTTP 来说，第七层的负载均衡器能根据应用的特定数据比如 HTTP 头，cookies 或者应用消息中的数据来做进一步的请求分发。 负载分发算法 ​ 两种类型的负载均衡器都能接收请求，然后根据特定的算法将请求分发到特定的服务器。一些行业标准的算法是： ​ 轮询 (Round robin)：轮流分发到各个（活动）服务器​ 加权轮循 (Weighted round robin)：每个服务器有一定的加权（weight），轮询时考虑加权。​ 最少连接 (Least connections)：转发到有最少连接数的服务器​ 最少响应时间 (Least response time)：转发到响应时间最短的服务器 可靠性和可用性 ​ 负载均衡器通过监控应用的健康状态来确保可靠性和可用性，并且只转发请求到能及时做出响应的服务和应用。 Session persistence （会话保持） ​ 用户(浏览器)在和服务端交互的时候，通常会在本地保存一些信息，而整个过程叫做一个会话(Session)并用唯一的Session ID进行标识。会话的概念不仅用于购物车这种常见情况，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制，此外HTTP客户端也会额外缓存一些数据在本地，这样就可以减少请求提高性能了。如果负载均衡可能将这个会话的请求分配到不同的后台服务端上，这肯定是不合适的，必须通过多个backend共享这些数据，效率肯定会很低下，最简单的情况是保证会话一致性——相同的会话每次请求都会被分配到同一个backend上去。 ​ 会话保持表示在一个会话期间，转发一个用户的请求到同一个后端服务器。这对购物车或者付款类的请求非常重要。 常用的方法包括： ​ Source IP：相同来源的请求转发到同一个服务器​ HTTP Cookie：该模式下，loadbalancer 为客户端的第一次连接生成 cookie，后续携带该 cookie 的请求会被某个 member 处理​ APP Cookie：该模式下，依靠后端应用服务器生成的 cookie 决定被某个 member 处理 负载均衡的实现方式？http重定向 ​ 当http代理（比如浏览器）向web服务器请求某个URL后，web服务器可以通过http响应头信息中的Location标记来返回一个新的URL。这意味着HTTP代理需要继续请求这个新的URL，完成自动跳转。 缺陷：1、吞吐率限制​ 主站点服务器的吞吐率平均分配到了被转移的服务器。现假设使用RR（Round Robin）调度策略，子服务器的最大吞吐率为1000reqs/s，那么主服务器的吞吐率要达到3000reqs/s才能完全发挥三台子服务器的作用，那么如果有100台子服务器，那么主服务器的吞吐率可想而知得有大？相反，如果主服务的最大吞吐率为6000reqs/s，那么平均分配到子服务器的吞吐率为2000reqs/s，而现子服务器的最大吞吐率为1000reqs/s，因此就得增加子服务器的数量，增加到6个才能满足。 2、重定向访问深度不同​ 有的重定向一个静态页面，有的重定向相比复杂的动态页面，那么实际服务器的负载差异是不可预料的，而主站服务器却一无所知。因此整站使用重定向方法做负载均衡不太好。 ​ 我们需要权衡转移请求的开销和处理实际请求的开销，前者相对于后者越小，那么重定向的意义就越大，例如下载。你可以去很多镜像下载网站试下，会发现基本下载都使用了Location做了重定向。 DNS负载均衡 ​ DNS负责提供域名解析服务，当访问某个站点时，实际上首先需要通过该站点域名的DNS服务器来获取域名指向的IP地址，在这一过程中，DNS服务器完成了域名到IP地址的映射，同样，这样映射也可以是一对多的，这时候，DNS服务器便充当了负载均衡调度器，它就像http重定向转换策略一样，将用户的请求分散到多台服务器上，但是它的实现机制完全不同。 ​ 相比http重定向，基于DNS的负载均衡完全节省了所谓的主站点，或者说DNS服务器已经充当了主站点的职能。但不同的是，作为调度器，DNS服务器本身的性能几乎不用担心。因为DNS记录可以被用户浏览器或者互联网接入服务商的各级DNS服务器缓存，只有当缓存过期后才会重新向域名的DNS服务器请求解析。也说是DNS不存在http的吞吐率限制，理论上可以无限增加实际服务器的数量。 缺陷：1、没有用户能直接看到DNS解析到了哪一台实际服务器，加服务器运维人员的调试带来了不便。2、策略的局限性。例如你无法将HTTP请求的上下文引入到调度策略中，而在前面介绍的基于HTTP重定向的负载均衡系统中，调度器工作在HTTP层面，它可以充分理解HTTP请求后根据站点的应用逻辑来设计调度策略，比如根据请求不同的URL来进行合理的过滤和转移。3、如果要根据实际服务器的实时负载差异来调整调度策略，这需要DNS服务器在每次解析操作时分析各服务器的健康状态，对于DNS服务器来说，这种自定义开发存在较高的门槛，更何况大多数站点只是使用第三方DNS服务。4、DNS记录缓存，各级节点的DNS服务器不同程序的缓存会让你晕头转向。5、基于以上几点，DNS服务器并不能很好地完成工作量均衡分配，最后，是否选择基于DNS的负载均衡方式完全取决于你的需要。 反向代理负载均衡 ​ 几乎所有主流的Web服务器都热衷于支持基于反向代理的负载均衡。它的核心工作就是转发HTTP请求。相比前面的HTTP重定向和DNS解析，反向代理的调度器扮演的是用户和实际服务器中间人的角色：1、任何对于实际服务器的HTTP请求都必须经过调度器2、调度器必须等待实际服务器的HTTP响应，并将它反馈给用户（前两种方式不需要经过调度反馈，是实际服务器直接发送给用户） 特性：1、调度策略丰富。例如可以为不同的实际服务器设置不同的权重，以达到能者多劳的效果。2、对反向代理服务器的并发处理能力要求高，因为它工作在HTTP层面。3、反向代理服务器进行转发操作本身是需要一定开销的，比如创建线程、与后端服务器建立TCP连接、接收后端服务器返回的处理结果、分析HTTP头部信息、用户空间和内核空间的频繁切换等，虽然这部分时间并不长，但是当后端服务器处理请求的时间非常短时，转发的开销就显得尤为突出。例如请求静态文件，更适合使用前面介绍的基于DNS的负载均衡方式。4、反向代理服务器可以监控后端服务器，比如系统负载、响应时间、是否可用、TCP连接数、流量等，从而根据这些数据调整负载均衡的策略。5、反射代理服务器可以让用户在一次会话周期内的所有请求始终转发到一台特定的后端服务器上（粘滞会话），这样的好处一是保持session的本地访问，二是防止后端服务器的动态内存缓存的资源浪费。 IP层负载均衡LVS-NAT ​ 我们需要在HTTP层面以下实现负载均衡，这些负载均衡调度器的工作必须由Linux内核来完成，因为我们希望网络数据包在从内核缓冲区进入进程用户地址空间之前，尽早地被转发到其他实际服务器上。而且正因为可以将调度器工作在应用层之下，这些负载均衡系统可以支持更多的网络服务协议，比如ftp，smtp，dns，以及流媒体和VoIP等应用。 ​ DNAT： 反向NAT，将实际服务器放置在内部网络，而作为网关的NAT服务器将来自用户端的数据包转发给内部网络的实际服务器(需要修改的是数据包的目标地址和端口)。比较著名的例子是LVS。NAT调度器的吞吐率很高是因为其在内核中进行请求转发的较低开销。 但是NAT服务器的带宽却成为了瓶颈。幸运的是，LVS提供了另一种负载均衡的方式，那就是直接路由。 直接路由LVS-DR ​ 不同于NAT机制，直接路由的负载均衡调度器工作在数据链路层上，简单地说，它通过修改数据包的目标mac地址，将数据包转发到实际服务器上，并且重要的是，实际服务器的响应数据包将直接发送给客户端，不经过调度器。适用于视频网站（响应的数据包远远超过请求的数据包）。对于LVS-DR，一旦调度器失效，你可以马上将LVS-DR切换到DNS-RR模式 常见的开源软件负载均衡器？​ 负载均衡器 目前有2种，一种是通过硬件来进行进行，常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；另外一种就是类似于LVS/HAProxy、Nginx的基于Linux的开源免费的负载均衡软件策略,这些都是通过软件级别来实现，所以费用非常低廉。 Nginx、LVS及HAProxy是目前最常用的开源软件负载均衡器。 LVS LVS：使用集群技术和Linux操作系统实现一个高性能、高可用的服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。 LVS的特点是： 1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的； 2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； 3、工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived； 4、无流量，保证了均衡器IO的性能不会收到大流量的影响； 5、应用范围比较广，可以对所有应用做负载均衡； 6、软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了；其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。 7、如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。 Nginx Nginx的特点是： 1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是许多朋友喜欢它的原因之一； 2、Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在； 3、Nginx安装和配置比较简单，测试起来比较方便； 4、也可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； 5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测； 6、Nginx仅能支持http和Email，这样就在适用范围上面小很多，这个它的弱势； 7、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web架构，大有和以前最流行的LAMP架构分庭抗争之势，在高流量的环境中也有很好的效果。 8、Nginx现在作为Web反向加速缓存越来越成熟了，很多朋友都已在生产环境下投入生产了，而且反映效果不错，速度比传统的Squid服务器更快，有兴趣的朋友可以考虑用其作为反向代理加速器。 HAProxy HAProxy的特点是： 1、HAProxy是支持虚拟主机的，以前有朋友说这个不支持虚拟主机，我这里特此更正一下。 2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作 3、支持url检测后端的服务器出问题的检测会有很好的帮助。 4、它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。 5、HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。 6、HAProxy的算法现在也越来越多了，具体有如下8种： roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的； static-rr，表示根据权重，建议关注； leastconn，表示最少连接者先处理，建议关注； source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注； ri，表示根据请求的URI； rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name； hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求； rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 负载均衡部署模式？基本的负载均衡场景有3种： Two-Arm (or sometimes called In-Line)（双臂）模式One-Arm（单臂）模式Direct Server Response模式 Two-Arm (or sometimes called In-Line)（双臂）模式 双臂模式有 switched mode（“bridge mode” or “transparent mode”） 和routed mode两种，routed mode要优于switched mode，实际生产环境也没有switched mode方式。 ​ 对于routed mode模式来说，As you can agree, the Load-Balancer is also a router between the “Front End” and “Back End” networks. As such, he can simply do destination IP NAT in client request coming to the load-balanced virtual IP and forward the packet to one of the servers in server farm. During this proces, the destination physical server is chosen by the load-balancing algorithm.Return traffic is going back via the Load-Balancer and the source IP is again changed to the virtual load-balanced IP in the response to the Client. One-Arm（单臂）模式 ​ the Load-Balancer is using only one interface and this interface is on the same L2 network with all the servers. ​ The traffic that the client initializes will get to the Load-Balancer that has the virtual load-balanced IP. The load-sharing algorithm will pick a physical server to which the Load-Balancer will forward the traffic with destination IP NATed to the physical IP of the server and forward it out the same interface towards the physical server.BUT the Load-balancer also needs to do source IP nat so that the server reply will go back from the server to the Load-Balancer and not directly back to the Client, who is not expecting a reply directly from physical server IP. From the physical servers perspective, all the traffic is coming from Load-Balancer Direct Server Response (or sometimes called Direct Server Return) ​ As we hopefully all know, switches learn about MAC addresses as they see frames coming on ports with source MACs. Also imagine that we have a router that has to know the MAC address of the Load-Balanced IP on the last L3 hop. With the picture below, you can already spot the “trick” this scenario tries to present here once you notice the disabled ARP on physical servers ​ In this scenario, Load-balancer only sees the incoming part of client-server traffic and all the returning traffic from physical servers is coming directly back to the client IP. The biggest advantages of this solution is that there is no NAT and the Load-Balancer throughput is only used in one way, so less performance impact for the Load-Balancer system. Disabling ARP on a physical server is not a difficult task. ​ Disadvantages however are that you have to manually configure the Load-Balancer with all the server MAC addresses and might be more difficult to troubleshoot with only one way traffic seen by the Load-Balancer on the whole L2 segment. LoadBalancerv2初体验？1.部署 我们假设LoadBalancerv2服务在网络节点启动，以yum源的方式安装。源码是： https://github.com/openstack/neutron-lbaas/tree/stable/mitaka 在控制节点(neutron-server)操作如下: 12345678910111213141516171819202122232425262728293031yum install openstack-neutron-lbaascd /etc/neutron/#1.3编辑neutron.conf文件service_plugins =router, neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2#1.4 编辑lbaas_agent.ini 文件[DEFAULT]interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverovs_use_veth = Truedevice_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver[haproxy]user_group =haproxy#1.5 编辑neutron_lbaas.conf文件service_provider =LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default#然后执行neutron-db-manage --subproject neutron-lbaas upgrade headsystemctl restart neutron-server 在网络节点操作如下： 12345678910111213141516171819202122232425262728293031yum install haproxyyum install openstack-neutron-lbaascd /etc/neutron/#1.4 编辑neutron.conf文件service_plugins =router, neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2#1.5 编辑lbaas_agent.ini 文件[DEFAULT]interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverovs_use_veth = Truedevice_driver = neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver[haproxy]user_group =haproxy#1.6 编辑neutron_lbaas.conf文件service_provider =LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default#1.7启动服务systemctl start neutron-lbaasv2-agent.service 另外可以安装前端界面 1.8安装neutron-lbaas-dashboard这个是在openstack_dashboard安装的节点，一般是controller节点 123456789git clone https://git.openstack.org/openstack/neutron-lbaas-dashboardcd neutron-lbaas-dashboardpython setup.py installcp neutron_lbaas_dashboard/enabled/1480project_loadbalancersv2_panel.py /usr/share/openstack-dashboard/openstack_dashboard/local/enabled/systemctl restart httpd.service memcached.service 2.创建负载均衡 Load balancerThe load balancer occupies a neutron network port and has an IP address assigned from a subnet.ListenerLoad balancers can listen for requests on multiple ports. Each one of those ports is specified by a listener.PoolA pool holds a list of members that serve content through the load balancer.MemberMembers are servers that serve traffic behind a load balancer. Each member is specified by the IP address and port that it uses to serve traffic.Health monitorMembers may go offline from time to time and health monitors divert traffic away from members that are not responding properly. Health monitors are associated with pools.由于lbaas dashboard有些问题，所以在后台用命令行创建， dashboard可显示，但不能任何操作 [root@controller ~]# source admin-openrc.sh [root@controller ~]# neutron subnet-list 创建loadbalancer[root@controller ~]# neutron lbaas-loadbalancer-create –name lb1 96f0db98-45fb-48ef-afae-808425fbb2bc添加lbaas-listener[root@controller ~]# neutron lbaas-listener-create –loadbalancer lb1 –protocol HTTP –protocol-port 80 –name listener1创建pool[root@controller ~]# neutron lbaas-pool-create –lb-algorithm ROUND_ROBIN –listener listener1 –protocol HTTP –name pool1添加member[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.4 –protocol-port 80 pool1[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.5 –protocol-port 80 pool1[root@controller ~]# neutron lbaas-member-create –subnet 96f0db98-45fb-48ef-afae-808425fbb2bc –address 172.16.1.6 –protocol-port 80 pool1添加监控[root@controller ~]# neutron lbaas-healthmonitor-create –delay 3 –type HTTP –max-retries 3 –timeout 3 –pool pool1 [root@controller ~]# neutron lbaas-loadbalancer-show lb1 3.简单验证： 我们对member成员进行模拟http服务，即172.16.1.4,172.16.1.5,172.16.1.6分别运行 172.16.1.4while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver1’ | sudo nc -l -p 80 ; done172.16.1.5while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver2’ | sudo nc -l -p 80 ; done172.16.1.6while true; do echo -e ‘HTTP/1.0 200 OK\r\nContent-Length: 8\r\n\r\nserver3’ | sudo nc -l -p 80 ; done 然后创建一个客户端访问负载均衡的vip 172.16.1.9 ,多次执行,如下图wget -O - http:// 172.16.1.9 （第一次）wget -O - http:// 172.16.1.9 （第二次）wget -O - http:// 172.16.1.9 （第三次）wget -O - http:// 172.16.1.9（第四次） 我们发现第一次是server1响应 第二次是server2响应 第三次是server3响应 第四次是server1响应 参考：http://networkgeekstuff.com/networking/basic-load-balancer-scenarios-explained/ https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html http://www.cnblogs.com/sammyliu/p/4656176.html http://blog.csdn.net/u013628152/article/details/51318414]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python yield 使用浅析]]></title>
      <url>%2F2017%2F03%2F06%2FPython-yield-%E4%BD%BF%E7%94%A8%E6%B5%85%E6%9E%90%2F</url>
      <content type="text"><![CDATA[yield的概念？1.简单的斐波那契數列第一版： 12345678def fab(max): n, a, b = 0, 0, 1 while n &lt; max: print b a, b = b, a + b n = n + 1if __name__ == '__main__': fab(5) 缺点：直接在 fab 函数中用 print 打印数字会导致该函数可复用性较差，因为 fab 函数返回 None，其他函数无法获得该函数生成的数列。 2.简单的斐波那契數列第二版： 1234567891011def fab(max): n, a, b = 0, 0, 1 L = [] while n &lt; max: L.append(b) a, b = b, a + b n = n + 1 return Lif __name__ == '__main__': for n in fab(5): print n 缺点：该函数在运行中占用的内存会随着参数 max 的增大而增大，如果要控制内存占用，最好不要用 List。 3.简单的斐波那契數列第三版： 根据range与xrange的思想设计： 123456789101112131415161718class Fab(object): def __init__(self,max): self.max=max self.n,self.a,self.b=0,0,1 def __iter__(self): return self def next(self): if self.n&lt;self.max: r=self.b self.a, self.b = self.b, self.a + self.b self.n=self.n+1 return r raise StopIterationif __name__ == '__main__': for n in Fab(5): print n 缺点：代码远远没有第一版的 fab 函数来得简洁。 如果我们想要保持第一版 fab 函数的简洁性，同时又要获得 iterable 的效果，yield 就派上用场了。 123456789def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': for n in fab(5): print n ​ yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator，调用 fab(5) 不会执行 fab 函数，而是返回一个 iterable 对象！在 for 循环执行时，每次循环都会执行 fab 函数内部的代码，执行到 yield b 时，fab 函数就返回一个迭代值，下次迭代时，代码从 yield b 的下一条语句继续执行，而函数的本地变量看起来和上次中断执行前是完全一样的，于是函数继续执行，直到再次遇到 yield。 12345678910111213def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1if __name__ == '__main__': f=fab(5) print (f.next()) print (f.next()) print (f.next()) print (f.next()) print (f.next()) 一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。比如在读取文件时候很好使用的。 123456789def read_file(fpath): BLOCK_SIZE = 1024 with open(fpath, 'rb') as f: while True: block = f.read(BLOCK_SIZE) if block: yield block else: return Iterables，Generators，Yield？​ 当你创建了一个列表,你可以一个一个的读取它的每一项,这叫做iteration。所有你可以用在for...in...语句中的都是可迭代的:比如lists,strings,files…因为这些可迭代的对象你可以随意的读取所以非常方便易用,但是你必须把它们的值放到内存里,当它们有很多值时就会消耗太多的内存. 1234if __name__ == '__main__': mylist = [x * x for x in range(3)] for i in mylist: print i ​ 生成器也是迭代器的一种,但是你只能迭代它们一次.原因很简单,因为它们不是全部存在内存里,它们只在要调用的时候在内存里生成。 1234if __name__ == '__main__': mygenerator = (x * x for x in range(3)) for i in mygenerator: print i ​ 生成器和迭代器的区别就是用()代替[],还有你不能用for i in mygenerator第二次调用生成器:首先计算0,然后会在内存里丢掉0去计算1,直到计算完4. 1234567891011121314def createGenerator(): mylist = range(3) for i in mylist: yield i * iif __name__ == '__main__': mygenerator = createGenerator() print(mygenerator) for i in mygenerator: print i#output&lt;generator object createGenerator at 0x7f5930639730&gt;014 ​ 在这里这个例子好像没什么用,不过当你的函数要返回一个非常大的集合并且你希望只读一次的话,那么它就非常的方便了.要理解Yield你必须先理解当你调用函数的时候,函数里的代码并没有运行.函数仅仅返回生成器对象,这就是它最微妙的地方:-)然后呢,每当for语句迭代生成器的时候你的代码才会运转.一旦函数运行并没有碰到yeild语句就认为生成器已经为空了.原因有可能是循环结束或者没有满足if/else之类的. 1234567891011121314151617181920212223242526272829303132class Bank(): # 让我们建个银行,生产许多ATM crisis = False def create_atm(self): while not self.crisis: yield "$100"if __name__ == '__main__': hsbc = Bank() # 当一切就绪了你想要多少ATM就给你多少 corner_street_atm = hsbc.create_atm() print(corner_street_atm.next()) print(corner_street_atm.next()) print([corner_street_atm.next() for cash in range(5)]) hsbc.crisis = True # cao,经济危机来了没有钱了! print(corner_street_atm.next()) wall_street_atm = hsbc.create_atm() # 对于其他ATM,它还是True print(wall_street_atm.next()) hsbc.crisis = False # 麻烦的是,尽管危机过去了,ATM还是空的 print(corner_street_atm.next()) brand_new_atm = hsbc.create_atm() # 只能重新新建一个atm了 for cash in brand_new_atm: print cash#output$100$100['$100', '$100', '$100', '$100', '$100']&lt;type 'exceptions.StopIteration'&gt;&lt;type 'exceptions.StopIteration'&gt;&lt;type 'exceptions.StopIteration'&gt;$100$100... yield的源码分析？在解释生成器之前，需要讲解一下Python虚拟机的调用原理。 1234567891011121314151617181920212223242526272829303132333435typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* code segment */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* points after the last local */ /* Next free slot in f_valuestack. Frame creation sets to f_valuestack. Frame evaluation usually NULLs it, but a frame that yields sets it to the current stack top. */ PyObject **f_stacktop; PyObject *f_trace; /* Trace function */ /* If an exception is raised in this frame, the next there are used to * record the exception info (if any) originally in the thread state. See * comments before set_exc_info() -- it's not obvious. * Invariant: if _type is NULL, then so are _value and _traceback. * Desired invariant: all three are NULL, or all three are non-NULL. That * one isn't currently true, but "should be". */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; PyThreadState *f_tstate; int f_lasti; /* Last instruction if called */ /* Call PyFrame_GetLineNumber() instead of reading this field directly. As of 2.3 f_lineno is only valid when tracing is active (i.e. when f_trace is set). At other times we use PyCode_Addr2Line to calculate the line from the current bytecode index. */ int f_lineno; /* Current line number */ int f_iblock; /* index in f_blockstack */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */&#125; PyFrameObject; 生成器的源码在Objects/genobject.c 12345678910111213141516PyObject *PyGen_New(PyFrameObject *f)&#123; PyGenObject *gen = PyObject_GC_New(PyGenObject, &amp;PyGen_Type); # 创建生成器对象 if (gen == NULL) &#123; Py_DECREF(f); return NULL; &#125; gen-&gt;gi_frame = f; # 赋予代码块 Py_INCREF(f-&gt;f_code); # 引用计数+1 gen-&gt;gi_code = (PyObject *)(f-&gt;f_code); gen-&gt;gi_running = 0; # 0表示为执行，也就是生成器的初始状态 gen-&gt;gi_weakreflist = NULL; _PyObject_GC_TRACK(gen); # GC跟踪 return (PyObject *)gen;&#125; send与next 123456789101112static PyObject *gen_iternext(PyGenObject *gen)&#123; return gen_send_ex(gen, NULL, 0);&#125;static PyObject *gen_send(PyGenObject *gen, PyObject *arg)&#123; return gen_send_ex(gen, arg, 0);&#125; 从上面的代码中可以看到，send和next都是调用的同一函数gen_send_ex，区别在于是否带有参数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970static PyObject *gen_send_ex(PyGenObject *gen, PyObject *arg, int exc)&#123; PyThreadState *tstate = PyThreadState_GET(); PyFrameObject *f = gen-&gt;gi_frame; PyObject *result; if (gen-&gt;gi_running) &#123; # 判断生成器是否已经运行 PyErr_SetString(PyExc_ValueError, "generator already executing"); return NULL; &#125; if (f==NULL || f-&gt;f_stacktop == NULL) &#123; # 如果代码块为空或调用栈为空，则抛出StopIteration异常 /* Only set exception if called from send() */ if (arg &amp;&amp; !exc) PyErr_SetNone(PyExc_StopIteration); return NULL; &#125; if (f-&gt;f_lasti == -1) &#123; # f_lasti=1 代表首次执行 if (arg &amp;&amp; arg != Py_None) &#123; # 首次执行不允许带有参数 PyErr_SetString(PyExc_TypeError, "can't send non-None value to a " "just-started generator"); return NULL; &#125; &#125; else &#123; /* Push arg onto the frame's value stack */ result = arg ? arg : Py_None; Py_INCREF(result); # 该参数引用计数+1 *(f-&gt;f_stacktop++) = result; # 参数压栈 &#125; /* Generators always return to their most recent caller, not * necessarily their creator. */ f-&gt;f_tstate = tstate; Py_XINCREF(tstate-&gt;frame); assert(f-&gt;f_back == NULL); f-&gt;f_back = tstate-&gt;frame; gen-&gt;gi_running = 1; # 修改生成器执行状态 result = PyEval_EvalFrameEx(f, exc); # 执行字节码 gen-&gt;gi_running = 0; # 恢复为未执行状态 /* Don't keep the reference to f_back any longer than necessary. It * may keep a chain of frames alive or it could create a reference * cycle. */ assert(f-&gt;f_back == tstate-&gt;frame); Py_CLEAR(f-&gt;f_back); /* Clear the borrowed reference to the thread state */ f-&gt;f_tstate = NULL; /* If the generator just returned (as opposed to yielding), signal * that the generator is exhausted. */ if (result == Py_None &amp;&amp; f-&gt;f_stacktop == NULL) &#123; Py_DECREF(result); result = NULL; /* Set exception if not called by gen_iternext() */ if (arg) PyErr_SetNone(PyExc_StopIteration); &#125; if (!result || f-&gt;f_stacktop == NULL) &#123; /* generator can't be rerun, so release the frame */ Py_DECREF(f); gen-&gt;gi_frame = NULL; &#125; return result;&#125; 参考：http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/ http://www.cnblogs.com/coder2012/p/4990834.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的eventlet使用与理解]]></title>
      <url>%2F2017%2F03%2F06%2FPython%E7%9A%84eventlet%E4%BD%BF%E7%94%A8%E4%B8%8E%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Eventlet eventlet在openstack，还有ryu控制器中使用频率很高，有必要总结一下用法。 什么是协程？​ 说到Coroutine，我们必须提到两个更远的东西。在操作系统（os）级别，有进程（process）和线程（thread）两个（仅从我们常见的讲）实际的“东西”（不说概念是因为这两个家伙的确不仅仅是概念，而是实际存在的，os的代码管理的资源）。这两个东西都是用来模拟“并行”的，写操作系统的程序员通过用一定的策略给不同的进程和线程分配CPU计算资源，来让用户“以为”几个不同的事情在“同时”进行“。在单CPU上，是os代码强制把一个进程或者线程挂起，换成另外一个来计算，所以，实际上是串行的，只是“概念上的并行”。在现在的多核的cpu上，线程可能是“真正并行的”。 ​ Coroutine，翻译成”协程“，初始碰到的人马上就会跟上面两个概念联系起来。直接先说区别，Coroutine是编译器级的，Process和Thread是操作系统级的。Coroutine的实现，通常是对某个语言做相应的提议，然后通过后成编译器标准，然后编译器厂商来实现该机制。Process和Thread看起来也在语言层次，但是内生原理却是操作系统先有这个东西，然后通过一定的API暴露给用户使用，两者在这里有不同。Process和Thread是os通过调度算法，保存当前的上下文，然后从上次暂停的地方再次开始计算，重新开始的地方不可预期，每次CPU计算的指令数量和代码跑过的CPU时间是相关的，跑到os分配的cpu时间到达后就会被os强制挂起。Coroutine是编译器的魔术，通过插入相关的代码使得代码段能够实现分段式的执行，重新开始的地方是yield关键字指定的，一次一定会跑到一个yield对应的地方。 总之，对于Coroutine，是编译器帮助做了很多的事情，来让代码不是一次性的跑到底，而不是操作系统强制的挂起。代码每次跑多少，是可预期的。但是，Process和Thread，在这个层面上完全不同，这两个东西是操作系统管理的。 python-eventlet又是什么?官方网站对eventlet的描述是： ​ Eventlet is built around the concept of green threads (i.e. coroutines, we use the terms interchangeably) that are launched to do network-related work. Green threads differ from normal threads in two main ways: ​ Green threads are so cheap they are nearly free. You do not have to conserve green threads like you would normal threads. In general, there will be at least one green thread per network connection.Green threads cooperatively yield to each other instead of preemptively being scheduled. The major advantage from this behavior is that shared data structures don’t need locks, because only if a yield is explicitly called can​ another green thread have access to the data structure. It is also possible to inspect primitives such as queues to see if they have any pending data. ​ 大概意思是Eventlet是以绿色线程（协同线程）的概念建立起来的网络库，绿色线程和普通线程的区别是：1.绿色线程的开销小 2.绿色线程共享数据，无需锁，同一时刻只有一个线程能访问数据，通过类似队列的去查找等待的数据。 ​ eventlet是一个用来处理和网络相关的python库函数，而且可以通过协程来实现并发，在eventlet里，把“协程”叫做 greenthread(绿色线程)。所谓并发，就是开启了多个greenthread，并且对这些greenthread进行管理，以实现非阻塞式的 I/O。比如说用eventlet可以很方便的写一个性能很好的web服务器，或者是一个效率很高的网页爬虫，这都归功于eventlet的“绿色线程”，以及对“绿色线程”的管理机制。更让人不可思议的是，eventlet为了实现“绿色线程”，竟然对python的和网络相关的几个标准库函数进行了改写，并且可以以补丁（patch）的方式导入到程序中，因为python的库函数只支持普通的线程，而不支持协程，eventlet称之为“绿化”。​ 它通过greenlet提供的协程功能，让开发者可以不用将以往的多线程等并发程序的开发方式转变成异步状态机模型，就能直接使用select/epoll/kqueue等操作系统提供的支持高并发IO接口，并且能尽可能地发挥它们在并发上的优势。 eventlet的结构如下图所示,eventlet实现的”并发” 更准确的讲, 是 IO多路复用。 python-eventlet API?Greenthread Spawn (spawn，孵化的意思，即如何产生greenthread) 主要有3个函数可以创建绿色线程： 1)eventlet.spawn(func, args, *kwargs)： ​ 创建一个绿色线程去运行func这个函数，后面的参数是传递给这个函数的参数。返回值是一个eventlet.GreenThread对象，这个对象可以用来接受func函数运行的返回值。在绿色线程池还没有满的情况下，这个绿色线程一被创建就立刻被执行。其实，用这种方法去创建线程也是可以理解的，线程被创建出来，肯定是有一定的任务要去执行，这里直接把函数当作参数传递进去，去执行一定的任务，就好像标准库中的线程用run()方法去执行任务一样。 2)eventlet.spawn_n(func, args, *kwargs)： 这个函数和spawn()类似，不同的就是它没有返回值，因而更加高效，这种特性，使它也有存在的价值。 3)eventlet.spawn_after(seconds, func, args, *kwargs)： 这个函数和spawn()基本上一样，都有一样的返回值，不同的是它可以限定在什么时候执行这个绿色线程，即在seconds秒之后，启动这个绿色线程。 Greenthread Control 1）eventlet.sleep(seconds=0) 悬挂当前的绿色线程，以允许其它的绿色线程执行 2）class eventlet.GreenPool ​ 这是一个类，在这个类中用set集合来容纳所创建的绿色线程，并且可以指定容纳线程的最大数量（默认是1000个），它的内部是用Semaphore和Event这两个类来对池进行控制的，这样就构成了线程池。其中，有几个比较重要的方法： ​ free() ​ imap(function, *iterables) ​ resize(new_size) ​ running() ​ spawn(function, args, *kwargs) ​ spawn_n(function, args, *kwargs) ​ starmap(function, iterable) ​ waitall() ​ waiting() 3）class eventlet.GreenPile 这也是一个类，而且是一个很有用的类，在它内部维护了一个GreenPool对象和一个Queue对象。这个GreenPool对象可以是从外部传递进来的，也可以是在类内部创建的，GreenPool对象主要是用来创建绿色线程的，即在GreenPile内部调用了GreenPool.spawn()方法。而Queue对象则是用来保存spawn()方法的返回值的，即Queue中保存的是GreenThread对象。并且它还实现了next()方法，也就意味着GreenPile对象具有了迭代器的性质。所以如果我们要对绿色线程的返回值进行操作的话，用这个类是再好不过的了。 next()Wait for the next result, suspending the current greenthread until it is available. Raises StopIteration when there are no more results. spawn(func, args, *kw)Runs func in its own green thread, with the result available by iterating over the GreenPile object 4）class eventlet.Queue ​ 基类是LightQueue，它实现了大部分的队列的常用方法。它是用collections做为实现队列的基本数据结构的。而且这个LightQueue的实现，不单单实现了存取操作，在本质上它实现了一个生产者和消费者问题，定义了两个set()类型的成员变量putters和getters，前者用来存放在队列满时，被阻塞的绿色线程，后者用来存放当队列空时，被阻塞的绿色线程。类中的putting()和getting()方法就是分别得到被阻塞的绿色线程的数量。Queue继承了LightQueue，并且又增加了它自己的两个方法：task_done()和join()。task_done()是被消费者的绿色线程所调用的，表示在这个项上的所有工作都做完了，join()是阻塞，直到队列中所有的任务都完成。LifoQueue和PriorityQueue是存放数据的两种不同的方式。 5）class eventlet.Timeout This class is a way to add timeouts to anything. It raises exception in the current greenthread after timeout seconds. When exception is omitted or None, the Timeout instance itself is raised. Patching Functions 这里就是之前所说的“绿化”，经过eventlet“绿化”过的模块都在eventlet.green中，导入他们主要有两种方法： 1) eventlet.import_patched(modulename, additional_modules, *kw_additional_modules) 1234567from eventlet.green import socketfrom eventlet.green import SocketServerBaseHTTPServer = eventlet.import_patched('BaseHTTPServer', ('socket', socket), ('SocketServer', SocketServer))BaseHTTPServer = eventlet.import_patched('BaseHTTPServer', socket=socket, SocketServer=SocketServer) 2）eventlet.monkey_patch(all=True, os=False, select=False, socket=False, thread=False, time=False) 12import eventleteventlet.monkey_patch(socket=True, select=True) Network Convenience Functions（和网络相关的函数） eventlet.connect(addr, family=, bind=None) 主要执行了以下几个步骤：新建了一个TCP类型的socket，绑定本地的ip和端口，和远程的地址进行连接 123456def connect(addr, family=socket.AF_INET, bind=None): sock = socket.socket(family, socket.SOCK_STREAM) if bind is not None: sock.bind(bind) sock.connect(addr) return sock eventlet.listen(addr, family=, backlog=50) 和connect()类似，只是把connect()换成了listen()，backlog指定了最大的连接数量 1234567def listen(addr, family=socket.AF_INET, backlog=50): sock = socket.socket(family, socket.SOCK_STREAM) if sys.platform[:3]=="win": sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #这段不知道具体是做什么的 sock.bind(addr) sock.listen(backlog) return sock eventlet.wrap_ssl(sock, a, *kw) 给socket加上ssl(安全套接层)，对数据进行加密 eventlet.serve(sock, handle, concurrency=1000) 这个函数直接创建了一个socket服务器，在它内部创建了一个GreenPool对象，默认的最大绿色线程数是1000，然后是一个循环来接受连接 123456789101112def serve(sock, handle, concurrency=1000): pool = greenpool.GreenPool(concurrency) server_gt = greenthread.getcurrent() while True: try: conn, addr = sock.accept() gt = pool.spawn(handle, conn, addr) gt.link(_stop_checker, server_gt, conn) conn, addr, gt = None, None, None except StopServe: return eventlet 中的wsgi？流程描述： 服务器开一个socket等待客户端连接；请求来了，服务器会读出传来的数据，然后根据HTTP协议做一些初步的封装，接着就可以调用事先注册的应用程序了，并将请求的数据塞进去；等响应处理完毕了再把数据通过socket发出去。 123456789101112131415161718192021222324server参数介绍：def server(sock, # Server socket, must be already bound to a port and listening(IP和端口并开启监听). site, # WSGI application function(事件处理函数，发送start_response响应头然后返回响应内容) log=None, # File-like object that logs should be written to.If not specified, sys.stderr is used.(日志处理，默认为sys.stderr用来重定向标准错误信息的) environ=None, # Additional parameters that go into the environ dictionary of every request(每次请求的参数，写入一个字典中) max_size=None, #Maximum number of client connections opened at any time by this server.(默认为1024) max_http_version=DEFAULT_MAX_HTTP_VERSION, # Set to "HTTP/1.0" to make the server pretend it only supports HTTP 1.0. # This can help with applications or clients that don't behave properly using HTTP 1.1.(HTTP协议版本,默认为HTTP/1.1) protocol=HttpProtocol, # Protocol class.（协议类，默认为HttpProtocol） server_event=None, # Used to collect the Server object(搜集服务器对象信息) minimum_chunk_size=None, # Minimum size in bytes for http chunks. This can be used to improve performance of applications which yield many small strings, though # using it technically violates the WSGI spec. This can be overridden on a per request basis by setting environ['eventlet.minimum_write_chunk_size']. # 设置最小的Chunk大小，可以通过设置environ['eventlet.minimum_write_chunk_size']来覆盖.Chunk表示服务器发送给客户端的分块传输编码（Chunked transfer encoding） log_x_forwarded_for=True, # If True (the default), logs the contents of the x-forwarded-for header in addition to the actual client ip address in the 'client_ip' field of the log line. # 默认为True,记录客户端IP日志,X-Forwarded-For(XFF)是用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段。 custom_pool=None, # A custom GreenPool instance which is used to spawn client green threads.If this is supplied, max_size is ignored.(协程池，如果启用则可以忽略前面的max_size参数) keepalive=True, # If set to False, disables keepalives on the server; all connections will be closed after serving one request.（控制客户端连接数是否保持alive） log_output=True, # A Boolean indicating if the server will log data or not.(确定服务端是否输出日志) log_format=DEFAULT_LOG_FORMAT, # A python format string that is used as the template to generate log lines.(日志输出格式) url_length_limit=MAX_REQUEST_LINE, # A maximum allowed length of the request url. If exceeded, 414 error is returned.（最大的url长度限制，默认为8192） debug=True, # True if the server should send exception tracebacks to the clients on 500 errors.If False, the server will respond with empty bodies.(是否发送调式信息给客户端) socket_timeout=None, # Timeout for client connections' socket operations. Default None means wait forever.(Socket超时时间设置，单位是秒) capitalize_response_headers=True) # Normalize response headers' names to Foo-Bar(是否标准化相应头) Client端： 12345678#客户端代码：import eventletc=eventlet.connect(('127.0.0.1', 6000))while True: data=raw_input('Enter data:') c.sendall(data) rc=c.recv(1024) print rc Server端： 123456789101112#服务端代码：import eventletdef handle(client): while True: c = client.recv(1024) print c client.sendall(c)server = eventlet.listen(('127.0.0.1', 6000))pool = eventlet.GreenPool(10000)while True: new_sock, address = server.accept() pool.spawn_n(handle, new_sock) python-eventlet 的Demo?官方上引以为傲的“网页爬虫”，用到了绿色线程池和imap()函数 123456789101112131415urls = [ "http://www.google.com/intl/en_ALL/images/logo.gif", "http://python.org/images/python-logo.gif", "http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif",]import eventletfrom eventlet.green import urllib2def fetch(url): return urllib2.urlopen(url).read()pool = eventlet.GreenPool()for body in pool.imap(fetch, urls): print("got body", len(body)) 源码级别的分析？eventlet主要依赖另外2个python package: greenletpython-epoll (或其他类似的异步IO库, 如poll/select等) 主要做了3个工作: 封装greenlet封装epoll改写python标准库中相关的module, 以便支持epoll 什么是epoll？ epoll是linux实现的一个基于事件的异步IO库, 在之前类似的异步IO库poll上改进而来。 下面两个例子会演示如何用epoll将阻塞的IO操作用epoll改写为异步非阻塞： blocking IO import socket 12345678910111213141516171819202122EOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)try: while True: connectiontoclient, address = serversocket.accept() request = b'' while EOL1 not in request and EOL2 not in request: request += connectiontoclient.recv(1024) print('-'*40 + '\n' + request.decode()[:-2]) connectiontoclient.send(response) connectiontoclient.close()finally: serversocket.close() ​ 需要注意的是程序会在connectiontoclient, address = serversocket.accept()这一行block住, 直到获取到新的连接, 程序才会继续往下运行.同时, 这个程序同一个时间内只能处理一个连接, 如果有很多用户同时访问8080端口, 必须要按先后 顺序依次处理这些连接, 前面一个连接成功返回后, 才会处理后面的连接. non-blocking IO by using epoll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import socket, selectEOL1 = b'\n\n'EOL2 = b'\n\r\n'response = b'HTTP/1.0 200 OK\r\nDate: Mon, 1 Jan 1996 01:01:01 GMT\r\n'response += b'Content-Type: text/plain\r\nContent-Length: 13\r\n\r\n'response += b'Hello, world!'serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)serversocket.bind(('0.0.0.0', 8080))serversocket.listen(1)serversocket.setblocking(0)epoll = select.epoll()epoll.register(serversocket.fileno(), select.EPOLLIN)try: connections = &#123;&#125;; requests = &#123;&#125;; responses = &#123;&#125; while True: events = epoll.poll(1) for fileno, event in events: if fileno == serversocket.fileno(): connection, address = serversocket.accept() connection.setblocking(0) epoll.register(connection.fileno(), select.EPOLLIN) connections[connection.fileno()] = connection requests[connection.fileno()] = b'' responses[connection.fileno()] = response elif event &amp; select.EPOLLIN: requests[fileno] += connections[fileno].recv(1024) if EOL1 in requests[fileno] or EOL2 in requests[fileno]: epoll.modify(fileno, select.EPOLLOUT) print('-'*40 + '\n' + requests[fileno].decode()[:-2]) elif event &amp; select.EPOLLOUT: byteswritten = connections[fileno].send(responses[fileno]) responses[fileno] = responses[fileno][byteswritten:] if len(responses[fileno]) == 0: epoll.modify(fileno, 0) connections[fileno].shutdown(socket.SHUT_RDWR) elif event &amp; select.EPOLLHUP: epoll.unregister(fileno) connections[fileno].close() del connections[fileno]finally: epoll.unregister(serversocket.fileno()) epoll.close() serversocket.close() 可以看到, 例子中首先使用serversocket.setblocking(0)将socket设为异步的模式,然后 用select.epoll()新建了一个epoll, 接着用epoll.register(serversocket.fileno(),select.EPOLLIN)将该socket上的IO输入事件(select.EPOLLIN)注册到epoll里.这样做了以后, 就可以将 上面例子中会在socket.accept()这步阻塞的MainLoop改写为基于异步IO事件的epoll循环了.events = epoll.poll(1) ​ 简单的说, 如果有很多用户同时连接到8080端口, 这个程序会同时accept()所有的socket连接, 然后通过这行代码将发生IO事件socket放到events中, 并在后面循环中处理. 没有发生IO事件的 socket不会在loop中做处理. 这样使用epoll就实现了一个简单的并发web服务器. 注意, 这里提到的并发, 和我们通常所理解线程/进程的并发并不太一样, 更准确的说, 是 IO多路复用 . 什么是greenlet？ greentlet是python中实现我们所谓的”Coroutine(协程)”的一个基础库. 12345678910111213141516from greenlet import greenletdef test1(): print 12 gr2.switch() print 34def test2(): print 56 gr1.switch() print 78 gr1 = greenlet(test1) gr2 = greenlet(test2) gr1.switch()#输出125634 ​ 程序先分别为两个函数定义了2个greenlet: gr1和gr2.gr1.switch()显式切换到gr1上执行, gr1中输出”12”后gr2.switch()显式切换到gr2上执行输出56, 又gr1.switch()显式切换到gr1上, 输出34. test1()执行结束,gr1 die. 于是 test2()里的78不会输出.可以发现greenlet仅仅是实现了一个最简单的”coroutine”, 而eventlet中的greenthread是在 greenlet的基础上封装了一些更high-level的功能, 比如greenlet的调度等. 什么是eventlet.green？ 从epoll的运行机制可以看出, 要使用异步IO, 必须要将相关IO操作改写成non-blocking的方式. 但是我们用eventlet.spawn()的函数,并没有针对epoll做任何改写, 那eventlet是怎么实现 异步IO的呢?这也是eventlet这个package最凶残的地方, 它自己重写了python标准库中IO相关的操作, 将它们 改写成支持epoll的模式, 放在eventlet.green中.比如说, socket.accept()被改成了这样 123456789101112def accept(self): if self.act_non_blocking: return self.fd.accept() fd = self.fd while True: res = socket_accept(fd) if res is not None: client, addr = res set_nonblocking(client) return type(self)(client), addr trampoline(fd, read=True, timeout=self.gettimeout(), timeout_exc=socket.timeout("timed out")) ​ 然后在eventlet.spawn()的时候, 通过 一些高阶魔法和”huge hack”, 将这些改写过得模块”patch”到spawn出的greenthread上, 从而 实现epoll的IO多路复用, 相当凶残.其中的hub和greenthread分别对应eventlet.hubs.hub和eventlet.greenthread, 本质都是 一个greenlet的实例.hub中封装前面提到的epoll, epoll的事件循环是由hub.run()这个方法里实现.每当用户调用 eventlet.spawn(), 就会在当前python线程的pool里产生一个新的greenthread. 由于greenthread 里的IO相关的python标准库被改写成non-blocking的模式(参考上面的socket.accept()).每当greenthread里做IO相关的操作时, 最终都会返回到hub中的epoll循环, 然后根据epoll中的 IO事件, 调用响应的函数. 具体如下面所示.greenthread.sleep(), 实际上也是将CPU控制权交给hub,然后由hub调度下一个需要运行的 greenthread. 123456789101112131415161718192021222324252627282930313233def wait(self, seconds=None): readers = self.listeners[READ] writers = self.listeners[WRITE] if not readers and not writers: if seconds: sleep(seconds) return try: presult = self.poll.poll(int(seconds * self.WAIT_MULTIPLIER)) except select.error, e: if get_errno(e) == errno.EINTR: return raise SYSTEM_EXCEPTIONS = self.SYSTEM_EXCEPTIONS for fileno, event in presult: try: if event &amp; READ_MASK: readers.get(fileno, noop).cb(fileno) if event &amp; WRITE_MASK: writers.get(fileno, noop).cb(fileno) if event &amp; select.POLLNVAL: self.remove_descriptor(fileno) continue if event &amp; EXC_MASK: readers.get(fileno, noop).cb(fileno) writers.get(fileno, noop).cb(fileno) except SYSTEM_EXCEPTIONS: raise except: self.squelch_exception(fileno, sys.exc_info()) clear_sys_exc_info() 参考:http://blog.csdn.net/xiangmin2587/article/details/8182775 http://blog.csdn.net/qq910894904/article/details/41699541 http://www.cnblogs.com/wonderKK/p/4062591.html http://eventlet.net/doc/ http://eventlet.net/doc/modules/wsgi.html http://www.xuebuyuan.com/1379840.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java框架之SpringBoot]]></title>
      <url>%2F2017%2F03%2F03%2Fjava%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBoot%2F</url>
      <content type="text"><![CDATA[SpringBoot非常受欢迎，在github我也用SpringBoot封装neutron-api，地址为： https://github.com/Luckylau/SpringBoot-NeutronApi 总觉得应该普及一下基本知识。 什么是SpringBoot？​ Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式，Boot致力于在蓬勃发展的快速应用开发领域（rapid application development）成为领导者。 ​ Boot的目标不在于为已解决的问题域提供新的解决方案，而是为平台带来另一种开发体验，从而简化对这些已有技术的使用。对于已经熟悉Spring生态系统的开发人员来说，Boot是一个很理想的选择，不过对于采用Spring技术的新人来说，Boot提供一种更简洁的方式来使用这些技术。 ​ Boot提供了许多的“starter”模块，它们定义了一组依赖，这些依赖能够添加到构建系统之中，从而解析框架及其父平台所需的特定类库。例如，spring-boot-starter-actuator依赖会引入一组基本的Spring项目，从而实现应用的快速配置和即时可用。关于这种依赖，值得强调的一点就是当开发Web应用，尤其是RESTful Web服务的时候，如果包含了spring-boot-starter-web依赖，它就会为你提供启动嵌入式Tomcat容器的自动化配置，并且提供对微服务应用有价值的端点信息，如服务器信息、应用指标（metrics）以及环境详情。除此之外，如果引入spring-boot-starter-security模块的话，actuator会自动配置Spring Security，从而为应用提供基本的认证以及其他高级的安全特性。它还会为应用结构引入一个内部的审计框架，这个框架可以用来生成报告或其他的用途，比如开发认证失败的锁定策略。 ​ Boot对Spring应用的开发进行了简化，提供了模块化方式导入依赖的能力，强调了开发RESTful Web服务的功能并提供了生成可运行jar的能力，这一切都清晰地表明在开发可部署的微服务方面Boot框架是一个强大的工具。正如前面的例子所示，借助于Boot，让一个RESTful Web工程运行起来是一件很容易的事情；在企业级基础设施领域，微服务是一种越来越流行的应用架构，因为它能够实现快速开发、更小的代码库、企业级集成以及模块化部署。 总结： 为Spring开发提供更加简单的使用和快速开发的技巧。具有开箱即用的默认配置功能，能根据项目依赖自动配置。具有功能更加强大的服务体系，包括嵌入式服务、安全、性能指标、健康检查等。绝对没有代码生成，可以不再需要XML配置，即可让应用更加轻巧和灵活。 实战Domo?用Spring Tool Suite创建sprinboot项目还可以右键springstarterproject项目，在第二个下一步勾选web列表中的web即可。 以SpringBoot-neutron-api项目为例，这也是一个RESTFUL项目。 1.创建一个Maven项目 我们在eclipse下创建两个maven项目，一个选择maven-archtype-quickstart，一个选择maven-archtype-webapp。将maven-archtype-webapp下的webapp目录拷贝到基于maven-archtype-quickstart创建的maven项目，然后将其删除。 如果没有src/main/resources可以按照如下方式创建 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 其余根据开发需要补充即可。下面是一些配置数据库的，主要别人的一些操作，我也看了一下公司产品的代码，大同小异，简单的贴出来。 12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!--数据库操作--&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在src/main/resources这个文件夹下面新建一个application.properties 123456789101112131415#DB Configuration:spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = jdbc:mysql://localhost:3306/testdbspring.datasource.username = rootspring.datasource.password = 123456#JPA Configuration: spring.jpa.database=MySQLspring.jpa.show-sql=true spring.jpa.generate-ddl=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernate.dialect.MySQL5Dialect spring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy #spring.jpa.database=org.hibernate.dialect.MySQL5InnoDBDialect #spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MYSQL5Dialect 后面将有SpringBoot专题学习。 参考：http://www.infoq.com/cn/articles/microframeworks1-spring-boot http://blog.csdn.net/cool__wang/article/details/49466609 http://www.cnblogs.com/dreamroute/p/5173896.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的sqlalchemy库使用]]></title>
      <url>%2F2017%2F03%2F02%2FPython%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Sqlalchemy库 本文主要参考官方文档和一些网上资料，并结合之前python-web-frame项目使用来详细说明Sqlalchemy的使用，版本号为SQLAlchemy 1.1。 Sqlalchemy的架构？ Object Relational Mapper &amp;&amp; SQL Expression Language ?下面是截取python-web-frame项目代码 12345678910111213141516171819202122232425262728293031323334#api.pydef get_engine(): global _ENGINE if _ENGINE is not None: return _ENGINE _ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) db_models.int_dbs(_ENGINE) return _ENGINE# db_models.pyBase = declarative.declarative_base()def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE)class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) def __init__(self, user_id, name, gender, age, email): self.user_id = user_id self.name = name self.gender = gender self.age = age self.email = email Connecting 123_ENGINE = create_engine( "mysql+mysqldb://root:root123@10.0.38.237:3306/test?charset=utf8", echo=True) echo flag is a shortcut to setting up SQLAlchemy logging, which is accomplished via Python’s standard logging module. With it enabled, we’ll see all the generated SQL produced. echo意思说开启日志，你可以看到整个SQL是如何产生的，方便调试。 _ENGINE is an instance of Engine, and it represents the core interface to the database, adapted through a dialect that handles the details of the database and DBAPI in use. _ENGINE 意思说与数据库打交道的核心接口 Declare a Mapping 123456789101112131415Base = declarative.declarative_base()class db_User(Base): __tablename__ = 'user' __table_args__ = ( Index('ix_user_user_id', 'user_id'), ) id = Column(Integer, primary_key=True) user_id = Column(String(255), nullable=False) name = Column(String(64), nullable=False, unique=True) gender = Column(String(64), nullable=False) age = Column(Integer, nullable=False) email = Column(String(255)) def __repr__(self): return "&lt;User(user_id='%s', name='%s', gender='%s',age='%s',email='%s')&gt;" % ( self.user_id, self.name, self.gender, self.age, self.email) 生成一个映射使用的Base. Create a Schema 12def int_dbs(_ENGINE): Base.metadata.create_all(_ENGINE) db_User类继承了Base类，它具有metadata属性，通过create_all()方法，注入与数据库打交道的核心接口_ENGINE，我们发现有一系列的命令完成数据库中user表是否存在的检测和生成。 Creating a Session 1234567891011def get_session_maker(engine): global _SESSION_MAKER if _SESSION_MAKER is not None: return _SESSION_MAKER _SESSION_MAKER = sqlalchemy.orm.sessionmaker(bind=engine) return _SESSION_MAKERdef get_session(): engine = get_engine() maker = get_session_maker(engine) session = maker() return session This custom-made Session class will create new Session objects which are bound to our database. Querying http://docs.sqlalchemy.org/en/rel_1_1/orm/query.html#sqlalchemy.orm.query.Query query()和 aliased() Common Filter Operators filter() 12345678910111213141516171819202122232425262728293031equals:query.filter(User.name == 'ed')not equals:query.filter(User.name != 'ed')LIKE:query.filter(User.name.like('%ed%'))IN:query.filter(User.name.in_(['ed', 'wendy', 'jack']))# works with query objects too:query.filter(User.name.in_( session.query(User.name).filter(User.name.like('%ed%'))))NOT IN:query.filter(~User.name.in_(['ed', 'wendy', 'jack']))IS NULL:query.filter(User.name == None)# alternatively, if pep8/linters are a concernquery.filter(User.name.is_(None))AND:# use and_()from sqlalchemy import and_query.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))# or send multiple expressions to .filter()query.filter(User.name == 'ed', User.fullname == 'Ed Jones')# or chain multiple filter()/filter_by() callsquery.filter(User.name == 'ed').filter(User.fullname == 'Ed Jones'OR:from sqlalchemy import or_query.filter(or_(User.name == 'ed', User.name == 'wendy'))MATCH:query.filter(User.name.match('wendy') Returning Lists and Scalars all() returns a list first() applies a limit of one and returns the first result as a scalar one() fully fetches all rows, and if not exactly one object identity or composite row is present in the result, raises an error 注意：The one() method is great for systems that expect to handle “no items found” versus “multiple items found” differently; such as a RESTful web service, which may want to raise a “404 not found” when no results are found, but raise an application error when multiple results are found. one_or_none() is like one(), except that if no results are found, it doesn’t raise an error; it just returns None. Like one(), however, it does raise an error if multiple results are found scalar() invokes the one() method, and upon success returns the first column of the row Using Textual SQL text() Counting count() Building a Relationship 一对多 12345678class db_User(Base): .... telephone = relationship("db_Telephone",order_by="db_Telephone.id",back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 即：一个db_user对应多个db_Telephone 一对一 12345678class db_User(Base): .... telephone = relationship("db_Telephone",uselist=False,back_populates="user") ....class db_Telephone(Base): .... user_id = Column(Integer, ForeignKey('user.id')) user = relationship("db_User", back_populates="telephone") 多对多 Many to Many adds an association table between two classes.多对多关系会在两个类之间增加一个关联的表。The association table is indicated by the secondary argument to relationship().这个关联的表在 relationship() 方法中通过 secondary 参数来表示。Usually, the Table uses the MetaData object associated with the declarative base class,通常的，这个表会通过 MetaData 对象来与声明基类关联，so that the ForeignKey directives can locate the remote tables with which to link:所以这个 ForeignKey 指令会使用链接来定位到远程的表： 123456789101112131415161718192021#多对多关系中的两个表之间的一个关联表post_keywords = Table('post_keywords', Base.metadata, Column('post_id', ForeignKey('posts.id'), primary_key=True), Column('keyword_id', ForeignKey('keywords.id'), primary_key=True) class Parent(Base): __tablename__ = 'left' id = Column(Integer, primary_key=True) children = relationship( "Child", secondary=association_table, back_populates="parents")class Child(Base): __tablename__ = 'right' id = Column(Integer, primary_key=True) parents = relationship( "Parent", secondary=association_table, back_populates="children") Querying with Joins Using Aliases Using EXISTS Common Relationship Operators eq() (many-to-one “equals” comparison) ne() (many-to-one “not equals” comparison) IS NULL (many-to-one comparison, also uses eq()) contains() (used for one-to-many collections) any() (used for collections) has() (used for scalar references) Query.with_parent() (used for any relationship) Eager Loading Query.options() subqueryload()第一种 Joined Load()第二种 contains_eager()第三种 Deleting db_user与db_Telephone是一对多关系，下面操作解决了删除db_user，会自动删除关联的表数据 12345678910111213141516171819202122def delete_user(self, user_id): logger.info("user.user_id: %s" % (user_id)) try: session = get_session() user=session.query( db_models.db_User).filter_by( user_id=user_id).first() session.delete(user) session.flush() session.commit() except exc.NoResultFound: logger.error("delete user occur error ...")class db_User(Base): ... telephone = relationship( "db_Telephone", order_by="db_Telephone.id", back_populates="user" , cascade="save-update, merge, delete")class db_Telephone(Base): ... user = relationship("db_User", back_populates="telephone") 参考：http://docs.sqlalchemy.org/en/rel_1_0/orm/tutorial.html http://docs.sqlalchemy.org/en/rel_1_0/core/tutorial.html http://blog.csdn.net/zd0303/article/details/50261347 http://blog.csdn.net/Jmilk/article/details/52445093#one-to-many]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python的pecan框架使用]]></title>
      <url>%2F2017%2F03%2F01%2Fpython%E7%9A%84pecan%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之Pecan web框架 什么是Pecan?​ 创造Pecan是为了填补Python web框架世界的一个空缺——一个提供object-dispatch（对象分发）方式路由的超轻量级的框架。Pecan的目标并不是要成为一个“全栈”框架，因此没有支持一些额外的功能，比如session或是数据库 。相反，Pecan专注于HTTP本身。 功能包括： Object-dispatch for easy routingFull support for REST-style controllersExtensible security frameworkExtensible template language supportExtensible JSON supportEasy Python-based configuration 所以对于OpenStack来说，Pecan是一个很好的选择，因为OpenStack项目中统一使用sqlalchemy来实现ORM，API的实现也不需要模板功能，安全控制则基于Keystone体系。使用Pecan来开发REST服务，代码量很少，代码结构也清晰。 创建简单的Pecan应用？首先在linux新建一个virtualenv环境（本文是在ubantu16.04），我们首先看一下自动生成的工程目录结构。 12345678910111213141516171819202122232425262728293031323334353637383940luckylau@luckylau-Ubuntu:~$virtualenv pecan-envluckylau@luckylau-Ubuntu:~$cd pecan-env/luckylau@luckylau-Ubuntu:~/pecan-env$ source bin/activate(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pip install pecan(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ pecan create test_project(pecan-env) luckylau@luckylau-Ubuntu:~/pecan-env$ tree test_project/test_project/├── config.py├── MANIFEST.in├── public #一些静态文件包括CSS,JS,images,为你的开发服务│ ├── css│ │ └── style.css│ └── images│ └── logo.png├── setup.cfg├── setup.py└── test_project #基于MVC模型生成的结构 ├── app.py #决定应用是如何创造的，这个文件必须包含set_app()并返回WSGI应用对象，一般情况下就用原生的，除非不能满足你定制的应用。 ├── controllers #控制层实现 │ ├── __init__.py │ ├── __init__.pyc │ ├── root.py │ └── root.pyc ├── __init__.py ├── __init__.pyc ├── model #模型实现 │ ├── __init__.py #在这里可以加入与database交互，定义表和ORM等 │ └── __init__.pyc ├── templates #模板实现 │ ├── error.html │ ├── index.html │ └── layout.html └── tests #单元测试 ├── config.py ├── __init__.py ├── test_functional.py ├── test_units.py └── test_units.pyc8 directories, 23 files 实战Demo?我们通过实际操作中补充pecan相关知识点。项目托管到github: https://github.com/Luckylau/python-web-frame 该项目用到pecan和wsme(Web Services Made Easy),首先解释一下WSME吧 WSME的全称是Web Service Made Easy，是专门用于实现REST服务的typing库，让你不需要直接操作请求和响应，而且刚好和Pecan结合得非常好，所以，OpenStack的很多项目都使用了Pecan + WSME的组合来实现API。 WSME的理念是：在大部分情况下，Web服务的输入和输出对数据类型的要求都是严格的。所以它就专门解决了这个事情，然后把其他事情都交给其他框架去实现。 WSME会自动帮你检查HTTP请求和响应中的数据是否符合预先设定好的要求。WSME的主要方式是通过装饰器来控制controller方法的输入和输出。WSME中主要使用两个控制器： ● @signature: 这个装饰器用来描述一个函数的输入和输出。 ● @wsexpose: 这个装饰器包含@signature的功能，同时会把函数的路由信息暴露给Web框架，效果就像Pecan的expose装饰器。 123456789101112131415luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── config.py│ ├── controllers│ │ ├── __init__.py│ │ └── root.py│ ├── expose.py│ ├── hooks.py│ └── __init__.py├── cmd│ ├── api.py│ └── __init__.py└── __init__.py 首先参考openstack我们人工的建立如上目录。首先我们实现config.py 代码 https://pecan.readthedocs.io/en/latest/configuration.html#application-configuration 该链接解释配置的含义。 config.py 123456789101112131415161718192021222324app = &#123; 'root': 'webdemo.api.controllers.root.RootController', 'modules': ['webdemo.api'], 'debug': True,&#125;logging = &#123; 'root': &#123;'level': 'INFO', 'handlers': ['console']&#125;, 'loggers': &#123; 'webdemo': &#123;'level': 'INFO', 'handlers': ['console']&#125; &#125;, 'handlers': &#123; 'console': &#123; 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'simple' &#125; &#125;, 'formatters': &#123; 'simple': &#123; 'format': ('%(asctime)s %(levelname)-5.5s [%(name)s]' '[%(threadName)s] %(message)s') &#125; &#125;&#125; modules At least one of the listed modules must contain an app.setup_app function which is called to create the WSGI app. In other words, this package should be where your app.py file is located, and this file should contain a setup_app function. 简单来说，modules是app.py(同时包含setup_pp功能)所在的包，pecan会扫描的。 root The root controller of your application. Remember to provide a string representing a Python path to some callable (e.g.”yourapp.controllers.root.RootController”). 简单来说，RootController所在路径 debugEnables the ability to display tracebacks in the browser and interactively debug during development. 简单来说，是否开启debug模式 app.py 123456789101112import pecanfrom webdemo.api import config as api_configdef get_pecan_config(): filename=api_config.__file__.replace('.pyc','.py') return pecan.configuration.conf_from_file(filename)def setup_app(): config=get_pecan_config() app_conf=dict(config.app) app=pecan.make_app(app_conf.pop('root'), logging=getattr(config,'logging',&#123;&#125;), **app_conf) return app expose.py 123456#让API返回JSON格式的数据import wsmeext.pecan as wsme_pecandef expose(*args, **kwargs): if 'rest_content_types' not in kwargs: kwargs['rest_content_types'] = ('json',) return wsme_pecan.wsexpose(*args, **kwargs) root.py 12345678910from pecan import restfrom wsme import types as wtypesfrom webdemo.api import exposeimport logginglogger = logging.getLogger(__name__)class RootController(rest.RestController): @expose.expose(wtypes.text) def get(self): logger.info("Method is called ...") return "python-web-frame: pecan &amp; wsme " api.py 123456789from wsgiref import simple_serverfrom webdemo.api import appdef main(): application = app.setup_app() httpd = simple_server.make_server('', 8080, application) print ("Server on port 8080 ,listening ...") httpd.serve_forever()if __name__ == '__main__': main() 我们进一步扩展该Demo，源码更新看日志： https://github.com/Luckylau/python-web-frame/commits/master 需求：设计一个管理用户的API，实现如下 GET /v1/users 获取所有用户的列表。POST /v1/users 创建一个用户。GET /v1/users/ 获取一个特定用户的详细信息。PUT /v1/users/ 修改一个用户的详细信息。DELETE /v1/users/ 删除一个用户。 1234567891011121314151617181920212223242526luckylau@luckylau-Ubuntu:~/github/python-web-frame$ tree webdemo/webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── __init__.py│ │ ├── controller.py #用户管理控制器│ │ └── users.py #用户模型│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── __init__.py└── __init__.pyc 然后我们在加入sqlalchemy库来实现数据库操作 我们可以看一个脚本预热一下 https://github.com/Luckylau/oslo.modules.sample/blob/lucky-branch/sqlalchemy.orm/db_query_ports.py 然后开始我们这个Demo的扩展 由于OpenStack项目在单元测试中使用的是sqlite的内存数据库，这样开发者运行单元测试的时候不需要安装和配置复杂的MySQL数据库，只要安装好sqlite3就可以了。而且，数据库是保存在内存中的，会提高单元测试的速度，我们的Demo也是用sqlite，sqlalchemy库的使用参考： https://luckylau.github.io/2017/03/02/Python%E7%9A%84sqlalchemy%E5%BA%93%E7%90%86%E8%A7%A3/ 12345678910111213141516171819202122232425262728293031323334webdemo/├── api│ ├── app.py│ ├── app.pyc│ ├── config.py│ ├── config.pyc│ ├── controllers│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── root.py│ │ ├── root.pyc│ │ └── v1│ │ ├── controller.py│ │ ├── controller.pyc│ │ ├── __init__.py│ │ ├── __init__.pyc│ │ ├── users.py│ │ └── users.pyc│ ├── expose.py│ ├── expose.pyc│ ├── hooks.py│ ├── __init__.py│ └── __init__.pyc├── cmd│ ├── api.py│ └── __init__.py├── db│ ├── api.py #sqlalchemy 增删改查功能│ ├── __init__.py #│ └── models.py # sqlalchemy ORM的定义├── __init__.py└── __init__.pyc5 directories, 26 files 具体的分析在源码有标注。 参考：https://pecan.readthedocs.io/en/latest/ http://www.infoq.com/cn/articles/OpenStack-demo-API3 https://pythonhosted.org/WSME/ http://www.sqlalchemy.org/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python的wsgi理解]]></title>
      <url>%2F2017%2F02%2F28%2Fpython%E7%9A%84wsgi%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[neutron源码学习基础知识储备之WSGI ​ WSGI的全称是Web Server Gateway Interface，翻译过来就是Web服务器网关接口。具体的来说，WSGI是一个规范，定义了Web服务器如何与Python应用程序进行交互，使得使用Python写的Web应用程序可以和Web服务器对接起来。WSGI一开始是在PEP-0333中定义的，最新版本是在Python的PEP-3333定义的。 为什么需要WSGI规范？在Web部署的方案上，有一个方案是目前应用最广泛的： ​ 首先，部署一个Web服务器专门用来处理HTTP协议层面相关的事情，比如如何在一个物理机上提供多个不同的Web服务（单IP多域名，单IP多端口等）这种事情。 ​ 然后，部署一个用各种语言编写（Java, PHP, Python, Ruby等）的应用程序，这个应用程序会从Web服务器上接收客户端的请求，处理完成后，再返回响应给Web服务器，最后由Web服务器返回给客户端。 ​ 要采用这种方案，Web服务器和应用程序之间就要知道如何进行交互。为了定义Web服务器和应用程序之间的交互过程，就形成了很多不同的规范。比如改进CGI性能的FasgCGI，Java专用的Servlet规范，还有Python专用的WSGI规范等。提出这些规范的目的就是为了定义统一的标准，提升程序的可移植性。在WSGI规范的最开始的PEP-333中一开始就描述了为什么需要WSGI规范。 ​ WSGI存在的目的有两个： 让Web服务器知道如何调用Python应用程序，并且把用户的请求告诉应用程序。 让Python应用程序知道用户的具体请求是什么，以及如何返回结果给Web服务器。 WSGI中的角色？​ 在WSGI中定义了两个角色，Web服务器端称为server或者gateway，应用程序端称为application或者framework（因为WSGI的应用程序端的规范一般都是由具体的框架来实现的）。我们下面统一使用server和application这两个术语。 ​ server端会先收到用户的请求，然后会根据规范的要求调用application端，如下图所示： 调用的结果会被封装成HTTP响应后再发送给客户端。 WSGI中间件 ?​ WSGI Middleware（中间件）也是WSGI规范的一部分。上一章我们已经说明了WSGI的两个角色：server和application。那么middleware是一种运行在server和application中间的应用（一般都是Python应用）。middleware同时具备server和application角色，对于server来说，它是一个application；对于application来说，它是一个server。middleware并不修改server端和application端的规范，只是同时实现了这两个角色的功能而已。 1.Server收到客户端的HTTP请求后，生成了environ_s，并且已经定义了start_response_s。 2.Server调用Middleware的application对象，传递的参数是environ_s和start_response_s。 3.Middleware会根据environ执行业务逻辑，生成environ_m，并且已经定义了start_response_m。 4.Middleware决定调用Application的application对象，传递参数是environ_m和start_response_m。Application的application对象处理完成后，会调用start_response_m并且返回结果给Middleware，存放在result_m中。 5.Middleware处理result_m，然后生成result_s，接着调用start_response_s，并返回结果result_s给Server端。Server端获取到result_s后就可以发送结果给客户端了。 从上面的流程可以看出middleware应用的几个特点： Server认为middleware是一个application。 Application认为middleware是一个server。 Middleware可以有多层。 WSGi示例代码？​ 在给出示例代码前我们需要了解wsgiref，它是官方给出的一个实现了WSGI标准用于演示用的简单Python内置库，实现了一个简单的WSGI Server和WSGI Application（在simple_server模块中），主要分为五个模块：simple_server， util， headers， handlers， validate。 注意：simple_server只支持单线程，做测试 WSGI对于应用程序有以下标准规定： 应用程序必须是一个可调用的对象，因此，应用程序可以是一个函数，一个类，或者一个重载了call的类的实例。 应用程序必须接受两个参数并且要按照位置顺序，分别是environ（环境变量），以及start_response函数（负责将响应的status code，headers写进缓冲区但不返回给客户端）。 应用程序返回的结果必须是一个可迭代的对象 由简入繁 123456789from wsgiref.simple_server import make_serverdef simple_app(environ,start_response): status="200 OK" response_headers=[('Content-type', 'text/plain')] start_response(status,response_headers) return [u"This is simple app demo".encode('utf-8')]http=make_server('',8080,simple_app)print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011from wsgiref.simple_server import make_serverclass App(): def __call__(self, environ, start_response): status = "200 OK" response_headers = [('Content-type', 'text/plain')] start_response(status, response_headers) return [u"This is App".encode('utf-8')]simple_app = App()http = make_server('', 8080, simple_app) #只要是实现了__call__方法的实例也可以的print ("Server on port 8080 ,listening ...")http.serve_forever() 1234567891011121314from wsgiref.simple_server import make_serverclass class_app: def __init__(self, environ, start_response): self.env = environ self.start = start_response def __iter__(self): status = "200 OK" response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield "Class : My Own Hello World!"app = class_apphttpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 1234567891011121314151617181920212223242526272829303132from wsgiref.simple_server import make_serverURL_PATTERNS = ( ('tags', 'tag_app'), ('about', 'about_app'))class Dispatcher(object): def _match(self, path): path = path.split("/")[1] for url, app in URL_PATTERNS: print("path:%s url:%s" % (path, url)) if path == url: return app def __call__(self, environ, start_response): path = environ.get('PATH_INFO') app = self._match(path) if app: app = globals()[app] return app(environ, start_response) else: start_response("404 not found ", [('Content-type', 'text/plain')]) return ["Page dose not exists!"]def tag_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is tag page!"]def about_app(environ, start_response): start_response("200 OK", [('Content-type', 'text/html')]) return ["This is about me page!"]app = Dispatcher()httpd = make_server('', 8000, app)print "Serving on port 8000..."httpd.serve_forever() 源码wsgiref解析?wsgiref.simple_server 中make_server函数 12345678# wsgiref/simple_server.pydef make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): """Create a new WSGI server listening on `host` and `port` for `app`""" server = server_class((host, port), handler_class) server.set_app(app) return server make_server函数默认使用的服务器类为WSGI Server，调用了构造函数（但是它的构造函数到底藏在哪一层服务器上呢？），相对应的使用WSGIRequestHandler 类作为请求的处理类（这两个类都定义在wsgiref.simple_server模块中），在实例化一个WSGI Server后设置它的application后返回该实例。 server_class=WSGIServer WSGI Server作为一个服务器，自然免不了要调用socket来建立TCP连接，因此这里的WSGI Server是基于Python的内置网络库BaseHTTPServer.py以及SocketServer.py实现的。 WSGI Server继承了HTTPServer,HTTPServer继承了TCPServer,TCPServer继承了BaseServer，在 BaseServerr中有handle_request函数 12345678910111213141516171819#SocketServer.pydef handle_request(self): """Handle one request, possibly blocking. Respects self.timeout. """ # Support people who used socket.settimeout() to escape # handle_request before self.timeout was available. timeout = self.socket.gettimeout() if timeout is None: timeout = self.timeout #self.timeout是BaseServer类的属性，默认是None elif self.timeout is not None: timeout = min(timeout, self.timeout) fd_sets = _eintr_retry(select.select, [self], [], [], timeout) #处理EINTR，当捕获到某个信号且相应信号处理函数返回时，这个系统调用被中断，调用返回错误，设置errno为EINTR。 if not fd_sets[0]: self.handle_timeout() return self._handle_request_noblock() 12345678def _eintr_retry(func, *args): """restart a system call interrupted by EINTR""" while True: try: return func(*args) except (OSError, select.error) as e: if e.args[0] != errno.EINTR: rais 1234567891011121314151617181920#SocketServer.pydef _handle_request_noblock(self): """Handle one request, without blocking. I assume that select.select has returned that the socket is readable before this function was called, so there should be no risk of blocking in get_request(). """ try: request, client_address = self.get_request() except socket.error: return if self.verify_request(request, client_address): try: self.process_request(request, client_address) except: self.handle_error(request, client_address) self.shutdown_request(request) else: self.shutdown_request(request) 关于使用select解决EINTR错误请参考这里：PEP 475 – Retry system calls failing with EINTR 因为我们把timeout设置为None，导致select.select永远不会超时，因此如果一直没有客户端连接服务器，服务器就会阻塞在select函数。当一个EINTR错误提出时，select可以重复调用。 通过select函数当我们确认已经收到了来自客户端的请求连接，此时调用accept函数不会阻塞时，于是调用handle_request_noblock函数,在函数中再依次调用了verify_request, process_request, finish_request。 1234567891011121314151617181920212223242526#SocketServer.py def get_request(self): """Get the request and client address from the socket. May be overridden. """ return self.socket.accept() #定义在TCPServerdef verify_request(self, request, client_address): """Verify the request. May be overridden. Return True if we should proceed with this request. """ return Truedef process_request(self, request, client_address): """Call finish_request. Overridden by ForkingMixIn and ThreadingMixIn. """ self.finish_request(request, client_address) self.shutdown_request(request)def finish_request(self, request, client_address): """Finish one request by instantiating RequestHandlerClass.""" self.RequestHandlerClass(request, client_address, self)def shutdown_request(self, request): """Called to shutdown and close an individual request.""" self.close_request(request)def close_request(self, request): """Called to clean up an individual request.""" pass handle_request——-&gt;handle_request_noblock——–&gt;get_request——–&gt;verify_request——-&gt; process_request———&gt;finish_request———&gt;RequestHandlerClass RequestHandlerClass在simple_server 传入的是WSGIRequestHandler handler_class=WSGIRequestHandler RequestHandlerClass主要用于处理请求，生成一些必要的环境参数之后才传给负责发送响应请求的ServerHandler WSGIRequestHandler的handle()继承如下，最后追踪到wsgiref/handles.py:BaseHandler 123456789101112131415161718192021222324252627282930313233def run(self, application): """Invoke the application""" # Note to self: don't move the close()! Asynchronous servers shouldn't # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you'll break asynchronous servers by # prematurely closing. Async servers must return from 'run()' without # closing if there might still be output to iterate over. try: self.setup_environ() self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out. def finish_response(self): """Send any iterable data, then close self and the iterable Subclasses intended for use in asynchronous servers will want to redefine this method, such that it sets up callbacks in the event loop to iterate over the data, and to call 'self.close()' once the response is finished. """ try: if not self.result_is_file() or not self.sendfile(): for data in self.result: self.write(data) self.finish_content() finally: self.close() ServerHandler函数主要功能集中在run函数上，同时start_response函数也定义在同一文件中，start_response函数（在application中调用）也必须要按照PEP-333标准定义 最终所有的数据都在finish_response()中写回给客户端。finish_response函数调用了write函数，write函数每次调用时都会检查headers是否已发送，否则先发送headers在发送data。 start_response函数源码 12345678910111213141516171819202122232425def start_response(self, status, headers,exc_info=None): """'start_response()' callable as specified by PEP 333""" if exc_info: try: if self.headers_sent: # Re-raise original exception if headers sent raise exc_info[0], exc_info[1], exc_info[2] finally: exc_info = None # avoid dangling circular ref elif self.headers is not None: raise AssertionError("Headers already set!") assert type(status) is StringType,"Status must be a string" assert len(status)&gt;=4,"Status must be at least 4 characters" assert int(status[:3]),"Status message must begin w/3-digit code" assert status[3]==" ", "Status message must have a space after code" if __debug__: for name,val in headers: assert type(name) is StringType,"Header names must be strings" assert type(val) is StringType,"Header values must be strings" assert not is_hop_by_hop(name),"Hop-by-hop headers not allowed" self.status = status self.headers = self.headers_class(headers) return self.write start_response函数主要用于检测headers是不是已经发送了，如果发送了必须提出异常，同时检测headers是否有不规范的地方，最后返回一个write函数（用于向套接字相关文件写入数据，PEP要求）。 参考：https://segmentfault.com/a/1190000003069785 http://blog.csdn.net/laughing2333/article/details/51288660 http://blog.csdn.net/sraing/article/details/8455242 https://www.python.org/dev/peps/pep-3333/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Neutron架构]]></title>
      <url>%2F2017%2F02%2F27%2Fneutron%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之线程同步工具]]></title>
      <url>%2F2017%2F02%2F25%2F%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7CountDownLatch%EF%BC%8CCyclicBarrier%E5%92%8CSemaphore%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
      <content type="text"><![CDATA[CountDownLatch​ CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 伪代码为： ​ Main thread start​ Create CountDownLatch for N threads​ Create and start N threads​ Main thread wait on latch​ N threads completes there tasks are returns​ Main thread resume execution 主要方法： public CountDownLatch(int count); public void countDown(); public void await() throws InterruptedException CountDownLatch实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package Demo;import java.util.concurrent.CountDownLatch;public abstract class BaseHealthChecker implements Runnable&#123; private CountDownLatch latch; private String name; private boolean isServiceUp; public BaseHealthChecker(CountDownLatch latch, String name) &#123; super(); this.latch = latch; this.name = name; this.isServiceUp=false; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public boolean isServiceUp() &#123; return isServiceUp; &#125; public void setServiceUp(boolean isServiceUp) &#123; this.isServiceUp = isServiceUp; &#125; public abstract void checkService(); @Override public void run() &#123; // TODO Auto-generated method stub try &#123; checkService(); isServiceUp=true; &#125; catch (Throwable t) &#123; // TODO: handle exception t.printStackTrace(System.err); isServiceUp=false; &#125; finally&#123; if(latch!=null)&#123; latch.countDown(); &#125; &#125; &#125; &#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class CacheHealthChecker extends BaseHealthChecker &#123; public CacheHealthChecker(CountDownLatch latch) &#123; super(latch, "Cache Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class DatabaseHealthChecker extends BaseHealthChecker &#123; public DatabaseHealthChecker(CountDownLatch latch) &#123; super(latch, "Database Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+"is Up"); &#125;&#125; 1234567891011121314151617181920212223242526package Demo;import java.util.concurrent.CountDownLatch;public class NetworkHealthChecker extends BaseHealthChecker &#123; public NetworkHealthChecker(CountDownLatch latch) &#123; super(latch, "Network Service"); // TODO Auto-generated constructor stub &#125; @Override public void checkService() &#123; // TODO Auto-generated method stub System.out.println("Checking "+this.getName()); try &#123; Thread.sleep(7000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(this.getName()+" is Up"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package Demo;import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ApplicationStartupUtil &#123; private static List&lt;BaseHealthChecker&gt; services; private static CountDownLatch latch; private final static ApplicationStartupUtil app=new ApplicationStartupUtil(); public ApplicationStartupUtil()&#123; &#125; public static ApplicationStartupUtil getInstance()&#123; return app; &#125; public static boolean checkExternalService()&#123; boolean re=true; latch=new CountDownLatch(3); services=new ArrayList&lt;BaseHealthChecker&gt;(); services.add(new NetworkHealthChecker(latch)); services.add(new CacheHealthChecker(latch)); services.add(new DatabaseHealthChecker(latch)); ExecutorService executors=Executors.newFixedThreadPool(services.size()); for(final BaseHealthChecker v: services)&#123; executors.execute(v); &#125; executors.shutdown(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for(final BaseHealthChecker v:services)&#123; if(! v.isServiceUp())&#123; re=false; System.out.println("All services checked ,result is "+re); &#125; &#125; System.out.println("All services checked ,result is "+re); return re; &#125;&#125; 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; boolean re=false; ApplicationStartupUtil.checkExternalService(); &#125;&#125;//输出：Checking Network ServiceChecking Cache ServiceChecking Database ServiceNetwork Service is UpCache Serviceis UpDatabase Serviceis UpAll services checked ,result is true 1234567891011121314151617public class Participant implements Runnable &#123; private Videoconference videoconference; private String name; public Participant(Videoconference videoconference, String name) &#123; // TODO Auto-generated constructor stub this.videoconference = videoconference; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub long duration = (long)(Math.random()*10); videoconference.arrive(name,duration); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;public class Videoconference implements Runnable&#123; private final CountDownLatch controller; private int counter; public Videoconference(int number)&#123; this.controller =new CountDownLatch(number); this.counter = number; &#125; public synchronized void arrive(String name,long duration)&#123; try &#123; TimeUnit.SECONDS.sleep(duration); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(name+" has arrived."); System.out.println("VideoConference:Waiting for "+(--counter)); controller.countDown(); &#125; @Override public void run() &#123; System.out.println("VideoConference:Initialization:"+controller.getCount()); // TODO Auto-generated method stub try &#123; controller.await(); System.out.printf("VideoConference: All the participants have come\n"); System.out.printf("VideoConference: Let's start...\n"); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 123456789101112public class Main &#123; public static void main(String[] args) &#123; Videoconference conference = new Videoconference(10); Thread threadConference = new Thread(conference); threadConference.start(); for(int i=0;i&lt;10;i++)&#123; Participant p = new Participant(conference, "Participant"+i); Thread t = new Thread(p); t.start(); &#125; &#125; &#125; CyclicBarrier​ CyclicBarrier 类有一个整数初始值，此值表示将在同一点同步的线程数量。当其中一个线程到达确定点，它会调用await() 方法来等待其他线程。此时CyclicBarrier阻塞该线程进入休眠等待其他线程的到达。当最后一个线程调用CyclicBarrier 类的await() 方法，它唤醒所有等待的线程并继续执行它们的任务。 ​ CountDownLatch和CyclicBarrier的区别在于：CountDownLatch 适用于一组线程和另一个主线程之间的工作协作。一个主线程等待一组工作线程的任务完毕才继续它的执行是使用 CountDownLatch 的主要场景；CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例如同时开始一个工作。CyclicBarrier 的循环特性和构造函数所接受的 Runnable 参数也是 CountDownLatch 所不具备的； CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 CyclicBarrier实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.Random;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class DemoCyclicBarrier &#123; public static void main(String[] args) &#123; int thread_num=5; CyclicBarrier cyclicBarrier=new CyclicBarrier(thread_num, new Runnable() &#123; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("Internal Barrier"); &#125; &#125;); ExecutorService executor=Executors.newFixedThreadPool(thread_num); for (int i=0;i&lt;5;i++)&#123; executor.execute(new worker("worker "+i, cyclicBarrier)); &#125; executor.shutdown(); &#125;&#125;class worker implements Runnable&#123; private String name; private CyclicBarrier cyclicbarrier; public worker(String name, CyclicBarrier cyclicBarrier)&#123; this.name=name; this.cyclicbarrier=cyclicBarrier; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; Thread.sleep(1000 * (new Random()).nextInt(8)); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker "+this.getName()+" is waiting"); try &#123; cyclicbarrier.await(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println("worker"+this.getName()+" is working"); &#125; &#125; Semaphore​ Semaphore 直译是信号量，可能称它是许可量更容易理解。当然，因为在计算机科学中这个名字由来已久，所以不能乱改。它的功能比较好理解，就是通过构造函数设定一个数量的许可，然后通过 acquire 方法获得许可，release 方法释放许可。它还有 tryAcquire 和 acquireUninterruptibly 方法，可以根据自己的需要选择。当一个线程想要访问某个共享资源，首先，它必须获得semaphore。如果semaphore的内部计数器的值大于0，那么semaphore减少计数器的值并允许访问共享的资源。计数器的值大于0表示，有可以自由使用的资源，所以线程可以访问并使用它们。在默认的情况下信号量的进入是不公平的。如果在初始化的第二个参数设定为true时，则会选择时间等待最久的一个进入。 Semaphore实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); Semaphore semp=new Semaphore(5); for(int i=0;i&lt;10;i++)&#123; exec.execute(new workerThread(i,semp)); &#125; exec.shutdown(); &#125;&#125;class workerThread implements Runnable&#123; private int id ; private Semaphore semp; public workerThread(int id, Semaphore semp) &#123; super(); this.id = id; this.semp = semp; &#125; public int getId() &#123; return id; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; semp.acquire(); System.out.println("workerThread id "+this.getId()+" get Access"); Thread.sleep((long) (Math.random() * 10000)); System.out.println("workerThread id "+this.getId()+" finish the work"); semp.release();//注销该语句后，只会执行5个线程，其他处在阻塞中 &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;//输出(未注销semp.release())workerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 4 get AccessworkerThread id 1 get AccessworkerThread id 1 finish the workworkerThread id 5 get AccessworkerThread id 2 finish the workworkerThread id 6 get AccessworkerThread id 4 finish the workworkerThread id 7 get AccessworkerThread id 6 finish the workworkerThread id 8 get AccessworkerThread id 7 finish the workworkerThread id 9 get AccessworkerThread id 8 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 9 finish the workworkerThread id 5 finish the work//输出(注销semp.release())workerThread id 1 get AccessworkerThread id 4 get AccessworkerThread id 0 get AccessworkerThread id 2 get AccessworkerThread id 3 get AccessworkerThread id 2 finish the workworkerThread id 0 finish the workworkerThread id 3 finish the workworkerThread id 4 finish the workworkerThread id 1 finish the work 1234567891011121314151617public class Job implements Runnable &#123; private PrintQueue printQueue; public Job(PrintQueue printQueue)&#123; this.printQueue = printQueue; &#125; @Override public void run() &#123; // TODO Auto-generated method stub System.out.printf("%s:Going to print a document\n", Thread.currentThread().getName()); printQueue.printJob(new Object()); System.out.printf("%s:The document has been printed\n",Thread.currentThread().getName()); &#125;&#125; 123456789101112131415161718192021222324import java.util.concurrent.Semaphore;public class PrintQueue &#123; private final Semaphore semaphore; public PrintQueue()&#123; semaphore = new Semaphore(1, true); &#125; public void printJob(Object document)&#123; try &#123; semaphore.acquire(); Long duration = (long)(Math.random()*10000); System.out.println(Thread.currentThread().getName() +" PrintQueue:Printing a Job during " +(duration/1000)+" seconds"); Thread.sleep(duration); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally&#123; semaphore.release(); &#125; &#125; &#125; 12345678910111213public class Main &#123; public static void main(String[] args) &#123; PrintQueue printQueue = new PrintQueue(); Thread thread[] = new Thread[10]; for(int i=0;i&lt;10;i++)&#123; thread[i] = new Thread(new Job(printQueue),"Thread"+i); &#125; for(int i=0;i&lt;10;i++)&#123; thread[i].start(); &#125; &#125; &#125; Phaser​ JDK 1.7 添加了一个新的工具Phaser，Phaser在功能上与CountDownLatch有部分重合。下面使用Phaser类来同步3个并发任务。这3个任务会在3个不同的文件夹和它们的子文件夹中搜索扩展名是.log的文件。这个任务被分成3个步骤：1.在指定的文件夹和子文件夹中获得文件扩展名为.log的文件列表。2.在操控台打印结果。3.在步骤1和步骤2的结尾我们要检查列表是否为空。如果为空，那么线程直接结束运行并从phaser类中淘汰。 Phaser实例12345678910111213141516171819202122232425262728293031import java.util.concurrent.Phaser;public class Main &#123; public static void main(String[] args) &#123; Object object = new Object(); Phaser phaser = new Phaser(3); FileSearch system = new FileSearch("C:\\Windows",".log",phaser,object); FileSearch apps = new FileSearch("c:\\Program Files",".log",phaser,object); FileSearch documents = new FileSearch("c:\\Documents And Settings",".log",phaser,object); Thread systemThread = new Thread(system,"Windows"); systemThread.start(); Thread appsThread = new Thread(apps,"Program Files"); appsThread.start(); Thread documentsThread = new Thread(documents,"Documents And Settings"); documentsThread.start(); try &#123; systemThread.join(); appsThread.join(); documentsThread.join(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println("Terminated: " + phaser.isTerminated()); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import java.io.File;import java.util.ArrayList;import java.util.List;import java.util.concurrent.Phaser;public class FileSearch implements Runnable &#123; private String initPath; private String suffix; private Phaser phaser; private List&lt;String&gt; results; private final Object controller; public FileSearch(String initPath, String suffix,Phaser phaser,Object object) &#123; this.initPath = initPath; this.suffix = suffix; this.phaser = phaser; results=new ArrayList&lt;String&gt;(); controller=object; &#125; @Override public void run() &#123; // TODO Auto-generated method stub phaser.arriveAndAwaitAdvance(); System.out.printf("%s: Starting.\n", Thread.currentThread().getName()); File file = new File(initPath); if (file.isDirectory()) &#123; try &#123; directoryProcess(file); &#125; catch (InterruptedException e) &#123; System.out.printf("%s: The search has been interrupted",Thread.currentThread().getName()); &#125; &#125; if(resultsisEmpty())&#123; return; &#125; showInfo(); &#125; private boolean resultsisEmpty()&#123; if(results.isEmpty())&#123; System.out.printf("%s :0 results\n",Thread.currentThread().getName()); phaser.arriveAndDeregister(); return true; &#125;else&#123; System.out.printf("%s :%d results\n",Thread.currentThread().getName(), results.size()); phaser.arriveAndAwaitAdvance(); return false; &#125; &#125; private void showInfo()&#123; synchronized (controller) &#123; for(int i =0 ;i &lt; results.size();i++)&#123; File file = new File(results.get(i)); System.out.printf("%s: %s\n", Thread.currentThread().getName(), file.getAbsolutePath()); &#125; System.out.printf("%s: Work completed.\n", Thread.currentThread().getName()); phaser.arriveAndDeregister(); &#125; &#125; private void directoryProcess(File file) throws InterruptedException &#123; File list[] = file.listFiles(); if (list != null) &#123; for (int i = 0; i &lt; list.length; i++) &#123; if (list[i].isDirectory()) &#123; directoryProcess(list[i]); &#125; else &#123; fileProcess(list[i]); &#125; &#125; &#125; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; &#125; private void fileProcess(File file) throws InterruptedException &#123; if (file.getName().endsWith(suffix)) &#123; results.add(file.getAbsolutePath()); &#125; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; &#125; &#125; 参考：1.http://www.importnew.com/15731.html 2.http://blog.csdn.net/junshuaizhang/article/details/39580751 3.http://blog.csdn.net/junshuaizhang/article/details/39667289 4.http://developer.51cto.com/art/201403/432095.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java并发之Executor框架]]></title>
      <url>%2F2017%2F02%2F23%2FJava%E5%B9%B6%E5%8F%91%E4%B9%8BExecutor%E6%A1%86%E6%9E%B6%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[基础简介​ 在Java中，使用线程来异步执行任务 。Java线程的创建与销毁需要一定的开销，如果我们为每一个任务创建一个新线程来执行，这些线程的创建与销毁将消耗大量的计算资源。同时，为每一个任务创建一个新线程来执行，这种策略可能会使处于高负荷状态的应用最终崩溃。Java的线程既是工作单元，也是执行机制。从JDK 5开始，把工作单元与执行机制分离开来。工作单元包括Runnable和Callable，而执行机制由Executor框架提供，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。 Executors框架Executors框架结构​ 在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上。 Executor框架主要由3大部分组成如下： 任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。 任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。 异步计算的结果。包括接口Future和实现Future接口的FutureTask类。 主线程首先要创建实现Runnable或者Callable接口的任务对象。工具类Executors可以把一个Runnable对象封装为一个Callable对象（Executors.callable（Runnable task）或Executors.callable（Runnable task，Object resule））。 然后可以把Runnable对象直接交给ExecutorService执行（ExecutorService.execute（Runnable command））；或者也可以把Runnable对象或Callable对象提交给ExecutorService执行（ExecutorService.submit（Runnable task）或ExecutorService.submit（Callabletask））。 如果执行ExecutorService.submit（…），ExecutorService将返回一个实现Future接口的对象（到目前为止的JDK中，返回的是FutureTask对象）。由于FutureTask实现了Runnable，程序员也可以创建FutureTask，然后直接交给ExecutorService执行。 最后，主线程可以执行FutureTask.get()方法来等待任务执行完成。主线程也可以FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。 ExecuteService排队策略​ 直接提交。缓冲队列采用 SynchronousQueue，它将任务直接交给线程处理而不保持它们。如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中。直接提交通常要求无界 maximumPoolSizes （Integer .MAX_VALUE） 以避免拒绝新提交的任务。newCachedThreadPool采用的便是这种策略。 ​ 无界队列。使用无界队列（典型的便是采用预定义容量的 LinkedBlockingQueue，理论上是该缓冲队列可以对无限多的任务排队）将导致在所有 corePoolSize 线程都工作的情况下将新任务加入到缓冲队列中。这样，创建的线程就不会超过 corePoolSize，也因此，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列。newFixedThreadPool采用的便是这种策略。 ​ 有界队列。当使用有限的 maximumPoolSizes 时，有界队列（一般缓冲队列使用ArrayBlockingQueue，并制定队列的最大长度）有助于防止资源耗尽，但是可能较难调整和控制，队列大小和最大池大小需要相互折衷，需要设定合理的参数。 submit和executesubmit有返回值，接受的是Callable任务而execute没有返回值，接受的是Runnable任务。 ​ 在Java 5之后，任务分两类：一类是实现了Runnable接口的类，一类是实现了Callable接口的类。两者都可以被ExecutorService执行，但是Runnable任务没有返回值，而Callable任务有返回值。并且Callable的call()方法只能通过ExecutorService的submit(Callable task) 方法来执行，并且返回一个 Future，是表示任务等待完成的 Future。 ​ Callable接口类似于Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常而Callable又返回结果，而且当获取返回结果时可能会抛出异常。Callable中的call()方法类似Runnable的run()方法，区别同样是有返回值，后者没有。 ​ 当将一个Callable的对象传递给ExecutorService的submit方法，则该call方法自动在一个线程上执行，并且会返回执行结果Future对象。同样，将Runnable的对象传递给ExecutorService的submit方法，则该run方法自动在一个线程上执行，并且会返回执行结果Future对象，但是在该Future对象上调用get方法，将返回null。 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TestCachedThreadPool&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); //ExecutorService executorService = Executors.newFixedThreadPool(3); //ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 5; i++)&#123; executorService.execute(new TestRunnable(i)); &#125; executorService.shutdown(); &#125; &#125; class TestRunnable implements Runnable&#123; private int count ; public TestRunnable(int count)&#123; this.count=count; System.out.println("Create Thread-"+count); &#125; public void run()&#123; System.out.println("线程池中的"+Thread.currentThread().getName() + "被调用来处理Thread-"+count); &#125; &#125; //输出：Create Thread-0Create Thread-1Create Thread-2线程池中的pool-1-thread-1被调用来处理Thread-0Create Thread-3线程池中的pool-1-thread-2被调用来处理Thread-1Create Thread-4线程池中的pool-1-thread-2被调用来处理Thread-4线程池中的pool-1-thread-3被调用来处理Thread-2线程池中的pool-1-thread-4被调用来处理Thread-3 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import java.util.ArrayList; import java.util.List; import java.util.concurrent.*; public class CallableDemo&#123; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;(); //创建10个任务并执行 for (int i = 0; i &lt; 10; i++)&#123; //使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中 Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i)); //将任务执行结果存储到List中 resultList.add(future); &#125; //遍历任务的结果 for (Future&lt;String&gt; fs : resultList)&#123; try&#123; while(!fs.isDone());//Future返回如果没有完成，则一直循环等待，直到Future返回完成 System.out.println(fs.get()); //打印各个线程（任务）执行的结果 &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125;catch(ExecutionException e)&#123; e.printStackTrace(); &#125;finally&#123; //启动一次顺序关闭，执行以前提交的任务，但不接受新任务 executorService.shutdown(); &#125; &#125; &#125; &#125; class TaskWithResult implements Callable&lt;String&gt;&#123; private int id; public TaskWithResult(int id)&#123; this.id = id; &#125; /** * 任务的具体过程，一旦任务传给ExecutorService的submit方法， * 则该方法自动在一个线程上执行 */ public String call() throws Exception &#123; System.out.println("Task id="+id+" 的call()方法被" + Thread.currentThread().getName()+"自动调用！！"); //该返回结果将被Future的get方法得到 return "Task id="+id+" 的call()方法被自动调用，任务返回的结果是：" + id + ""; &#125; &#125; //输出：Task id=0 的call()方法被pool-1-thread-1自动调用！！Task id=2 的call()方法被pool-1-thread-3自动调用！！Task id=1 的call()方法被pool-1-thread-2自动调用！！Task id=3 的call()方法被pool-1-thread-4自动调用！！Task id=4 的call()方法被pool-1-thread-5自动调用！！Task id=0 的call()方法被自动调用，任务返回的结果是：0Task id=9 的call()方法被pool-1-thread-1自动调用！！Task id=6 的call()方法被pool-1-thread-7自动调用！！Task id=5 的call()方法被pool-1-thread-6自动调用！！Task id=7 的call()方法被pool-1-thread-8自动调用！！Task id=1 的call()方法被自动调用，任务返回的结果是：1Task id=2 的call()方法被自动调用，任务返回的结果是：2Task id=8 的call()方法被pool-1-thread-9自动调用！！Task id=3 的call()方法被自动调用，任务返回的结果是：3Task id=4 的call()方法被自动调用，任务返回的结果是：4Task id=5 的call()方法被自动调用，任务返回的结果是：5Task id=6 的call()方法被自动调用，任务返回的结果是：6Task id=7 的call()方法被自动调用，任务返回的结果是：7Task id=8 的call()方法被自动调用，任务返回的结果是：8Task id=9 的call()方法被自动调用，任务返回的结果是：9 ​ 从结果中可以同样可以看出，pool-1-thread-1被调用2次处理id=0和id=9的任务，submit也是首先选择空闲线程来执行任务，如果没有，才会创建新的线程来执行任务。另外，需要注意：如果Future的返回尚未完成，则get（）方法会阻塞等待，直到Future完成返回，可以通过调用isDone（）方法判断Future是否完成了返回。 服务的关闭​ shutdown()方法在终止前允许执行以前提交的任务，而 shutdownNow() 方法阻止等待任务的启动并试图停止当前正在执行的任务。在终止后，执行程序没有任务在执行，也没有任务在等待执行，并且无法提交新任务。应该关闭未使用的 ExecutorService以允许回收其资源。 Executor框架成员Executor框架的主要成员：ThreadPoolExecutor、ScheduledThreadPoolExecutor、Future接口、Runnable接口、Callable接口和Executors。 ThreadPoolExecutor详解Executors提供了一系列工厂方法用于创建线程池，返回的线程池都实现了ExecutorService接口。在了解常用的静态线程池之前，我们先看一下ThreadPoolExecutor。 123456789101112131415public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123;..&#125; corePoolSize：corePoolSize定义了线程池的基本大小，也就是线程池的目标大小，即在没有任务执行时线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。 maximumPoolSize：池中允许的最大线程数，表示线程池可同时活动线程数量上限。 keepAliveTime：线程池中的空闲线程所能持续的最长时间。 unit：持续时间的单位。 workQueue：包含Runnable的阻塞队列，当线程池达到基本大小时，新提交的任务将放入这个阻塞队列中，阻塞队列的实现包含三种：无界队列、有界队列以及同步移交队列。 threadFactory参数用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字，方便定位问题。 handler参数定义了线程池饱和策略。当有界队列被填满后，并且线程池活动线程达到最大线程数，饱和策略开始生效。JDK提供了几种不同的RejectedExecutionHandler实现，分别是AbortPolicy、DiscardPolicy、DiscardOldestPolicy以及CallerRunsPolicy。AbortPolicy是默认的饱和策略，该策略将抛出未检查的RejectedExecutionException。DiscardPolicy策略会把新提交的任务直接抛弃，而DiscardOldestPolicy策略会抛弃队列首部最老的任务。CallerRunsPolicy策略实现了一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量，它不会在线程池中的某个线程中执行新提交的任务，而是在一个调用了execute的线程中执行该任务。 按照如下规则运行： 1、如果线程池中的线程数量少于corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务； 2、如果线程池中的线程数量大于等于corePoolSize，但缓冲队列workQueue未满，则将新添加的任务放到workQueue中，按照FIFO的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）； 3、如果线程池中的线程数量大于等于corePoolSize，且缓冲队列workQueue已满，但线程池中的线程数量小于maximumPoolSize，则会创建新的线程来处理被添加的任务； 4、如果线程池中的线程数量等于了maximumPoolSize，有4种才处理方式（该构造方法调用了含有5个参数的构造方法，并将最后一个构造方法为RejectedExecutionHandler类型，它在处理线程溢出时有4种方式）。 另外，当线程池中的线程数量大于corePoolSize时，如果里面有线程的空闲时间超过了keepAliveTime，就将其移除线程池，这样，可以动态地调整线程池中线程的数量。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class ThreadPoolTest&#123; public static void main(String[] args)&#123; //创建等待队列 BlockingQueue&lt;Runnable&gt; bqueue = new ArrayBlockingQueue&lt;Runnable&gt;(20); //创建线程池，池中保存的线程数为3，允许的最大线程数为5 ThreadPoolExecutor pool = new ThreadPoolExecutor(3,5,50,TimeUnit.MILLISECONDS,bqueue); //创建七个任务 Runnable t1 = new MyThreads("t1"); Runnable t2 = new MyThreads("t2"); Runnable t3 = new MyThreads("t3"); Runnable t4 = new MyThreads("t4"); Runnable t5 = new MyThreads("t5"); Runnable t6 = new MyThreads("t6"); Runnable t7 = new MyThreads("t7"); //每个任务会在一个线程上执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); pool.execute(t6); pool.execute(t7); //关闭线程池 pool.shutdown(); &#125; &#125; class MyThreads implements Runnable&#123; private String name; public String getName() &#123; return name; &#125; public MyThreads(String name) &#123; // TODO Auto-generated constructor stub this.name=name; &#125; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + "正在执行 "+this.getName()); try&#123; Thread.sleep(100); &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; //输出pool-1-thread-2正在执行 t2pool-1-thread-3正在执行 t3pool-1-thread-1正在执行 t1pool-1-thread-1正在执行 t4pool-1-thread-3正在执行 t6pool-1-thread-2正在执行 t5pool-1-thread-3正在执行 t7 CachedThreadPool详解public static ExecutorService newCachedThreadPool() ​ CachedThreadPool的corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置Integer .MAX_VALUE，即maximumPool是无界的。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。 CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。缓存型池子通常用于执行一些生存期很短的异步型任务 ，因此在一些面向连接的daemon型SERVER中用得不多。 1234567891011public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125;public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory); &#125; 首先执行SynchronousQueue.offer（Runnable task）。如果当前maximumPool中有空闲线程正在执行SynchronousQueue.poll（keepAliveTime，TimeUnit.NANOSECONDS），那么主线程执行offer操作与空闲线程执行的poll操作配对成功，主线程把任务交给空闲线程执行，execute()方法执行完成；否则执行下面的步骤。 当初始maximumPool为空，或者maximumPool中当前没有空闲线程时，将没有线程执行SynchronousQueue. poll（keepAliveTime，TimeUnit.NANOSECONDS）。这种情况下，步骤1）将失败。此时CachedThreadPool会创建一个新线程执行任务，execute()方法执行完成。 在步骤2）中新创建的线程将任务执行完后，会执行SynchronousQueue.poll（keepAliveTime，TimeUnit .NANOSECONDS）。这个poll操作会让空闲线程最多在SynchronousQueue中等待60秒钟。如果60秒钟内主线程提交了一个新任务（主线程执行步骤1）），那么这个空闲线程将执行主线程提交的新任务；否则，这个空闲线程将终止。由于空闲60秒的空闲线程会被终止，因此长时间保持空闲的CachedThreadPool不会使用任何资源。 ​ SynchronousQueue是一个没有容量的阻塞队列。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。CachedThreadPool使用SynchronousQueue，把主线程提交的任务传递给空闲线程执行。 FixedThreadPool详解 public static ExecutorService newFixedThreadPool(int nThreads) 1234567891011public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); &#125; ​ FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads 。当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间 ，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。在任意点，大多数 nThreads 线程会处于处理任务的活动状态，如果在所有线程处于活动状态时提交附加任务 ， 则在有可用线程之前，附加任务将在队列中等待。如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 如果当前运行的线程数少于corePoolSize，则创建新线程来执行任务。 在线程池完成预热之后（当前运行的线程数等于corePoolSize），将任务加入LinkedBlockingQueue。 线程执行完1中的任务后，会在循环中反复从LinkedBlockingQueue获取任务来执行。 FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer .MAX_VALUE）。使用无界队列作为工作队列会对线程池带来如下影响： 当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。 由于1，使用无界队列时maximumPoolSize将是一个无效参数。 由于1和2，使用无界队列时keepAliveTime将是一个无效参数。 由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。 SingleThreadExecutor详解SingleThreadExecutor是使用单个worker线程的Executor。 public static ExecutorService newSingleThreadExecutor() 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; ​ 创建一个单线程化的Executor。 单例线程，任意时间池中只能有一个线程，用的是和cache池和fixed池相同的底层池，但线程数目是1-1,0秒IDLE（无IDLE）。 ScheduledThreadPoolExecutor详解ScheduledThreadPoolExecutor运行机制​ ScheduledThreadPoolExecutor继承自ThreadPoolExecutor。它主要用来在给定的延迟之后运行任务，或者定期执行任务。 DelayQueue是一个无界队列，所以ThreadPoolExecutor的maximumPoolSize在ScheduledThread Pool Executors中没有什么意义。 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) 123456789101112131415public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); &#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; ScheduledThreadPoolExecutor的执行主要分为两大部分：当调用ScheduledThreadPoolExecutor的scheduleAtFixedRate()方法或者scheduleWithFixedDelay()方法时，会向ScheduledThreadPoolExecutor的DelayQueue添加一个实现了RunnableScheduledFutur接口的ScheduledFutureTask；线程池中的线程从DelayQueue中获取ScheduledFutureTask，然后执行任务。其中ScheduleAtFixedRate为每次执行时间为上一次任务开始起向后推一个时间间隔；ScheduleWithFixedDelay为每次执行时间为上一次任务结束起向后推一个时间间隔。由此可见，ScheduleAtFixedRate是基于固定时间间隔进行任务调度，ScheduleWithFixedDelay 取决于每次任务执行的时间长短，是基于不固定时间间隔进行任务调度。 ​ 对于Timer类而言， 它实现任务调度的核心类是Timer 和 TimerTask。其中 Timer 负责设定 TimerTask 的起始与间隔执行时间。使用者只需要创建一个 TimerTask的继承类，实现自己的 run 方法，然后将其丢给 Timer 去执行即可。Timer 的设计核心是一个 TaskList和一个 TaskThread。Timer 将接收到的任务丢到自己的 TaskList 中，TaskList 按照 Task的最初执行时间进行排序。TimerThread 在创建 Timer时会启动成为一个守护线程。这个线程会轮询所有任务，找到一个最近要执行的任务，然后休眠，当到达最近要执行任务的开始时间点，TimerThread被唤醒并执行该任务。之后 TimerThread 更新最近一个要执行的任务，继续休眠。Timer的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。 12345678910111213141516171819202122232425262728import java.util.Timer;import java.util.TimerTask;public class TimerTest extends TimerTask&#123; private String jobName = ""; private int num; public TimerTest(String jobName , int num) &#123; this.jobName = jobName; this.num = num; &#125; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("execute " + jobName); try &#123; int i = 7/num; System.out.println(i); num--; &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println(e.getMessage()); &#125; &#125; public static void main(String[] args) &#123; Timer timer = new Timer(); timer.schedule(new TimerTest("job1",2), 1000, 1000); &#125;&#125; 12345678910111213141516171819202122232425262728public class TimerTest implements Runnable&#123; private String jobName = ""; private int num; public TimerTest(String jobName , int num) &#123; this.jobName = jobName; this.num = num; &#125; @Override public void run() &#123; // TODO Auto-generated method stub System.out.println("execute " + jobName); try &#123; int i = 7/num; System.out.println(i); num--; &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println(e.getMessage()); &#125; &#125; public static void main(String[] args) &#123; ScheduledExecutorService service = Executors.newScheduledThreadPool(10); service.scheduleAtFixedRate(new TimerTest("job1",2), 1000, 1000, TimeUnit.MILLISECONDS); service.scheduleWithFixedDelay(new TimerTest("job2",2), 1000, 1000, TimeUnit.MILLISECONDS); &#125;&#125; ScheduledThreadPoolExecutor的实现ScheduledThreadPoolExecutor会把待调度的任务（ScheduledFutureTask）放到一个DelayQueue中。ScheduledFutureTask主要包含3个成员变量，如下。 long型成员变量time，表示这个任务将要被执行的具体时间。 long型成员变量sequenceNumber，表示这个任务被添加到ScheduledThreadPoolExecutor中的序号。 long型成员变量period，表示任务执行的间隔周期。 DelayQueue封装了一个PriorityQueue，这个PriorityQueue会对队列中的ScheduledFutureTask进行排序。排序时，time小的排在前面（时间早的任务将被先执行）。如果两个ScheduledFutureTask的time相同，就比较sequenceNumber，sequenceNumber小的排在前面（也就是说，如果两个任务的执行时间相同，那么先提交的任务将被先执行）。 线程1从DelayQueue中获取已到期的ScheduledFutureTask（DelayQueue.take()）。到期任务是指Scheduled FutureTask的time大于等于当前时间。 线程1执行这个ScheduledFutureTask。 线程1修改ScheduledFutureTask的time变量为下次将要被执行的时间。 线程1把这个修改time之后的ScheduledFutureTask放回DelayQueue中（DelayQueue.add()）。 参考文献http://blog.csdn.net/ns_code/article/details/17465497 http://blog.csdn.net/linghu_java/article/details/17123057 http://blog.csdn.net/bairrfhoinn/article/details/16848785 http://zhangjunhd.blog.51cto.com/113473/70068/ http://www.cnblogs.com/wanqieddy/p/3853863.html http://blog.csdn.net/defonds/article/details/9715455 《java并发编程艺术》 修订 时间 初始化章节 2017-02-23 丰富内容，梳理章节 2017-09-11]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HttpClient工具类]]></title>
      <url>%2F2017%2F02%2F15%2FHttpClient%E5%B7%A5%E5%85%B7%E7%B1%BB%E7%9A%84%E5%B0%81%E8%A3%85%2F</url>
      <content type="text"><![CDATA[一.HttpClient 介绍：​ HttpClient相比传统JDK自带的URLConnection，增加了易用性和灵活性，它不仅是客户端发送Http请求变得容易，而且也方便了开发人员测试接口（基于Http协议的），即提高了开发的效率，也方便提高代码的健壮性。它支持在HTTP/1.1规范中定义的所有的HTTP方法：GET, HEAD, POST, PUT, DELETE, TRACE 和 OPTIONS。每有一个方法都有一个对应的类：HttpGet，HttpHead，HttpPost，HttpPut，HttpDelete，HttpTrace和HttpOptions。所有的这些类均实现了HttpUriRequest接口，故可以作为execute的执行参数使用。 HTTP请求的URI包含一个协议计划protocol scheme，主机名host name,，可选的端口optional port，资源的路径resource path，可选的查询optional query和可选的片段optional fragment。 二. 特性：​ 基于标准、纯净的Java语言。实现了Http1.0和Http1.1 ​ 以可扩展的面向对象的结构实现了Http全部的方法（GET, POST, PUT, DELETE, HEAD, OPTIONS, and TRACE）。 ​ 支持HTTPS协议。 ​ 通过Http代理建立透明的连接。 ​ 利用CONNECT方法通过Http代理建立隧道的https连接。 ​ Basic, Digest, NTLMv1, NTLMv2, NTLM2 Session, SNPNEGO/Kerberos认证方案。 ​ 插件式的自定义认证方案。 ​ 便携可靠的套接字工厂使它更容易的使用第三方解决方案。 ​ 连接管理器支持多线程应用。支持设置最大连接数，同时支持设置每个主机的最大连接数，发现并关闭过期的连接。 ​ 自动处理Set-Cookie中的Cookie。 ​ 插件式的自定义Cookie策略。 ​ Request的输出流可以避免流中内容直接缓冲到socket服务器。 ​ Response的输入流可以有效的从socket服务器直接读取相应内容。 ​ 在http1.0和http1.1中利用KeepAlive保持持久连接。 ​ 直接获取服务器发送的response code和 headers。 ​ 设置连接超时的能力。 ​ 实验性的支持http1.1 response caching。 ​ 源代码基于Apache License 可免费获取。 三. 使用方法​ 创建HttpClient对象。 ​ 创建请求方法的实例，并指定请求URL。如果需要发送GET请求，创建HttpGet对象；如果需要发送POST请求，创建HttpPost对象。 ​ 如果需要发送请求参数，可调用HttpGet、HttpPost共同的setParams(HetpParams params)方法来添加请求参数；对于HttpPost对象而言，也可调用setEntity(HttpEntity entity)方法来设置请求参数。 ​ 调用HttpClient对象的execute(HttpUriRequest request)发送请求，该方法返回一个HttpResponse。 ​ 调用HttpResponse的getAllHeaders()、getHeaders(String name)等方法可获取服务器的响应头；调用HttpResponse的getEntity()方法可获取HttpEntity对象，该对象包装了服务器的响应内容。程序可通过该对象获取服务器的响应内容。 ​ 释放连接。无论执行方法是否成功，都必须释放连接 四.封装工具类 ​ 我的相关实现链接：https://github.com/Luckylau/UsefulTools 五.参考资料http://blog.csdn.net/xiaoxian8023/article/category/5968067 http://blog.csdn.net/wangpeng047/article/details/19624529]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BeanUtils.copyProperties 与 PropertyUtils.copyProperties]]></title>
      <url>%2F2017%2F02%2F06%2FBeanUtils-copyProperties-%E4%B8%8E-PropertyUtils-copyProperties%2F</url>
      <content type="text"><![CDATA[首先明确一点是BeanUtils.copyProperties 存在于spring和apache commons-beanutils，PropertyUtils.copyProperties存在于apache commons-PropertyUtils。 org.springframework.beans.BeanUtils; org.apache.commons.beanutils.BeanUtils; org.apache.commons.beanutils.PropertyUtils; 1.org.springframework.beans.BeanUtils使用：首先看一下源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void copyProperties(Object source, Object target) throws BeansException &#123; copyProperties(source, target, (Class)null, (String[])null); &#125; public static void copyProperties(Object source, Object target, Class&lt;?&gt; editable) throws BeansException &#123; copyProperties(source, target, editable, (String[])null); &#125; public static void copyProperties(Object source, Object target, String... ignoreProperties) throws BeansException &#123; copyProperties(source, target, (Class)null, ignoreProperties); &#125; private static void copyProperties(Object source, Object target, Class&lt;?&gt; editable, String... ignoreProperties) throws BeansException &#123; Assert.notNull(source, "Source must not be null"); Assert.notNull(target, "Target must not be null"); Class actualEditable = target.getClass(); if(editable != null) &#123; if(!editable.isInstance(target)) &#123; throw new IllegalArgumentException("Target class [" + target.getClass().getName() + "] not assignable to Editable class [" + editable.getName() + "]"); &#125; actualEditable = editable; &#125; PropertyDescriptor[] targetPds = getPropertyDescriptors(actualEditable); List ignoreList = ignoreProperties != null?Arrays.asList(ignoreProperties):null; PropertyDescriptor[] var7 = targetPds; int var8 = targetPds.length; for(int var9 = 0; var9 &lt; var8; ++var9) &#123; PropertyDescriptor targetPd = var7[var9]; Method writeMethod = targetPd.getWriteMethod(); if(writeMethod != null &amp;&amp; (ignoreList == null || !ignoreList.contains(targetPd.getName()))) &#123; PropertyDescriptor sourcePd = getPropertyDescriptor(source.getClass(), targetPd.getName()); if(sourcePd != null) &#123; Method readMethod = sourcePd.getReadMethod(); if(readMethod != null &amp;&amp; ClassUtils.isAssignable(writeMethod.getParameterTypes()[0], readMethod.getReturnType())) &#123; try &#123; if(!Modifier.isPublic(readMethod.getDeclaringClass().getModifiers())) &#123; readMethod.setAccessible(true); &#125; Object ex = readMethod.invoke(source, new Object[0]); if(!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers())) &#123; writeMethod.setAccessible(true); &#125; writeMethod.invoke(target, new Object[]&#123;ex&#125;); &#125; catch (Throwable var15) &#123; throw new FatalBeanException("Could not copy property \'" + targetPd.getName() + "\' from source to target", var15); &#125; &#125; &#125; &#125; &#125; &#125; 成员变量赋值是基于目标对象的成员列表, 并且会跳过ignore的以及在源对象中不存在的属性, 所以这个方法是安全的, 不会因为两个对象之间的结构差异导致错误, 但是必须保证同名的两个成员变量类型相同. 1BeanUtils.copyProperties(source, target); 2.org.apache.commons.beanutils.BeanUtils使用：2.1 对于类型为Boolean/Short/Integer/Float/Double的属性，它会转换为0: 1234567891011121314151617181920212223242526public class User &#123; private Integer intVal; private Double doubleVal; private Short shortVal; private Long longVal; private Float floatVal; private Byte byteVal; private Boolean booleanVal; &#125; User src = new User(); User dest = new User(); BeanUtils.copyProperties(dest, src); System.out.println(src); System.out.println(dest); //输出 User [intVal=null, doubleVal=null, shortVal=null, longVal=null, floatVal=null, byteVal=null, booleanVal=null] User [intVal=0, doubleVal=0.0, shortVal=0, longVal=0, floatVal=0.0, byteVal=0, booleanVal=false] 在stackoverflow上有人解释说是因为这几个类型都有对应的基本类型，在进行类型转换时，有可能遇到类似Integer -&gt; int的转换，此时显然不能对int类型的属性赋值为null，因此统一转换为0。 如何让它不要转为0呢？可以这样： 1234import org.apache.commons.beanutils.converters.IntegerConverter; IntegerConverter converter = new IntegerConverter(null); //默认为null，而不是0 BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); beanUtilsBean.getConvertUtils().register(converter, Integer.class); 2.2 对于java.util.Date/BigDecimal/java.sql.Date/java.sql.Timestamp/java.sql.Time这几个类，如果值为null，则在copy时会抛异常，需要使用对应的Conveter： 12345678910111213141516171819202122232425262728293031public class User2 &#123; private java.util.Date javaUtilDateVal; private java.sql.Date javaSqlDateVal; private java.sql.Timestamp javaSqlTimeStampVal; private BigDecimal bigDecimalVal; private java.sql.Time javaSqlTime; &#125; User2 src = new User2(); User2 dest = new User2(); BeanUtilsBean beanUtilsBean = new BeanUtilsBean(); //如果没有下面几行，则在转换null时会抛异常，例如：org.apache.commons.beanutils.ConversionException: No value specified for 'BigDecimal' //在org.apache.commons.beanutils.converters这个包下面有很多的Converter，可以按需要使用 beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.BigDecimalConverter(null), BigDecimal.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.DateConverter(null), java.util.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimestampConverter(null), java.sql.Timestamp.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlDateConverter(null), java.sql.Date.class); beanUtilsBean.getConvertUtils().register(new org.apache.commons.beanutils.converters.SqlTimeConverter(null), java.sql.Time.class); beanUtilsBean.copyProperties(dest, src); System.out.println(src); System.out.println(dest); 2.3使用BeanUtils还会经常碰到这样变态的需求： 假设是从A复制到B：需求1：如果B中某字段有值（不为null），则该字段不复制；也就是B中该字段没值时，才进行复制，适合于对B进行补充值的情况。需求2：如果A中某字段没值（为null），则该字段不复制，也就是不要把null复制到B当中。 对于需求1，可以这样： 12345678910111213141516171819import org.apache.commons.beanutils.BeanUtilsBean; import org.apache.commons.beanutils.PropertyUtils; public class CopyWhenNullBeanUtilsBean extends BeanUtilsBean&#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; try &#123; Object destValue = PropertyUtils.getSimpleProperty(bean, name); if (destValue == null) &#123; super.copyProperty(bean, name, value); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; 对于需求2，可以这样： 123456789101112import org.apache.commons.beanutils.BeanUtilsBean; public class CopyFromNotNullBeanUtilsBean extends BeanUtilsBean &#123; @Override public void copyProperty(Object bean, String name, Object value) throws IllegalAccessException, InvocationTargetException &#123; if (value == null) &#123; return; &#125; super.copyProperty(bean, name, value); &#125; &#125; 2.4 使用BeanUtils时，遇到日期类型的空值时会抛错的解决办法 新建一个转换器类，该类实现Converter接口，在convert方法中实现日期类型值的转换逻辑，然后注册。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class DateConverter implements Converter&#123; public Object convert(Class type, Object value)&#123; if(value == null)&#123; return null; &#125;else if(type == Timestamp.class)&#123; return convertToDate(type, value, "yyyy-MM-dd HH:mm:ss"); &#125;else if(type == Date.class)&#123; return convertToDate(type, value, "yyyy-MM-dd"); &#125;else if(type == String.class)&#123; return convertToString(type, value); &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToDate(Class type, Object value, String pattern) &#123; SimpleDateFormat sdf = new SimpleDateFormat(pattern); if(value instanceof String)&#123; try&#123; if(CommonUtils.isEmpty(value.toString()))&#123; return null; &#125; Date date = sdf.parse((String) value); if(type.equals(Timestamp.class))&#123; return new Timestamp(date.getTime()); &#125; return date; &#125;catch(Exception pe)&#123; return null; &#125; &#125;else if(value instanceof Date)&#123; return value; &#125; throw new ConversionException("不能转换 " + value.getClass().getName() + " 为 " + type.getName()); &#125; protected Object convertToString(Class type, Object value) &#123; if(value instanceof Date)&#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); if (value instanceof Timestamp) &#123; sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); &#125; try&#123; return sdf.format(value); &#125;catch(Exception e)&#123; throw new ConversionException("日期转换为字符串时出错！"); &#125; &#125;else&#123; return value.toString(); &#125; &#125; &#125; 1ConvertUtils.register(new DateConverter(), java.util.Date.class); 使用： 1BeanUtils.copyProperties(target, source); 3.org.apache.commons.beanutils.PropertyUtils使用：​ 使用PropertyUtils.copyProperties()拷贝一个bean中的属性到另一个bean中,第一个参数是目标bean,第二个参数是源bean，只是拷贝具有相同的 1PropertyUtils.copyProperties(target, source); 4.三者之间的区别：4.1 org.apache.commons.beanutils.BeanUtils 与org.apache.commons.beanutils.PropertyUtils ​ 从大范围讲，两个工具类都是对两个bean之前存在name相同的属性进行处理，无论是源bean或者目标bean多出的属性均不处理。具体到BeanUtils是相同name并且类型之间支持转换的属性可以处理，而PropertyUtils不支持类型转换必须是类型和name一样才处理。 ​ 对null的处理：PropertyUtils支持为null的场景；BeanUtils对部分属性不支持null的情况，具体为：date类型不支持，异常 date为org.apache.commons.beanutils.ConversionException: No value；specified for ‘Date’；Ineger、Boolean、Long等不支持， 转为0；string支持，保持null； ​ 源bean有属性：private Long dateVal;目标bean有属性：private Date dateVal;​ 使用 PropertyUtils，会报错：Caused by: java.lang.IllegalArgumentException: argument type mismatch​ 使用BeanUtils，则相当于new date（dateVal） ​ BeanUtils的高级功能org.apache.commons.beanutils.Converter接口可以自定义类型之间的转化，PropertyUtils没有 4.2 org.apache.commons.beanutils.BeanUtils与org.springframework.beans.BeanUtils org.springframework.beans.BeanUtils中实现的方式很简单，就是对两个对象中相同名字的属性进行简单get/set，仅检查属性的可访问性。 而org.springframework.beans.BeanUtils则施加了很多的检验，包括类型的转换，甚至于还会检验对象所属的类的可访问性。 5.参考：http://www.cnblogs.com/milton/p/5830942.html http://bylijinnan.iteye.com/blog/2224808 http://caoyaojun1988-163-com.iteye.com/blog/1871316 http://chenjumin.iteye.com/blog/701190 http://www.cnblogs.com/gaojing/archive/2011/08/23/2413616.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[历史金融危机一览表]]></title>
      <url>%2F2017%2F01%2F27%2F%E5%8E%86%E5%8F%B2%E9%87%91%E8%9E%8D%E5%8D%B1%E6%9C%BA%E4%B8%80%E8%A7%88%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[历史金融危机一览表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是vxlan网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFvxlan%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[前言：​ 处在年末工作的最后一天，其实也没有心情学习了，要不就总结和整理一下之前看的vxlan网络，大部分的内容还是复制拷贝的，只是按照自己的分明别类梳理梳理。vxlan网络是云计算网络的基础，openstack本身也是一种基础性简单使用，但还是有必要从理论上来学习vxlan网络。 云计算虚拟化对传统网络带来的挑战​ 云计算、虚拟化相关技术的发展，传统的网络无法满足于规模大、灵活性要求高的云数据中心的要求，于是便有了overlay网络的概念。overlay网络中被广泛应用的就是vxlan技术。首先我们了解一下随着云计算的发展，传统网络面临哪些挑战。 1.虚拟机迁移范围受到网络架构限制 ​ 虚拟机迁移，顾名思义，就是将虚拟机从一个物理机迁移到另一个物理机，但是要求在迁移过程中业务不能中断。要做到这一点，需要保证虚拟机迁移前后，其IP地址、MAC地址等参数维持不变。这就决定了，虚拟机迁移必须发生在一个二层域中。对于传统网络就要求网络本身具备多路径多链路的冗余和可靠性。传统的网络生成树(STPSpaning Tree Protocol)技术不仅部署繁琐荣，且协议复杂，网络规模不宜过大，限制了虚拟化的网络扩展性。基于各厂家私有的的IRF/vPC等设备级的(网络N:1)虚拟化技术，虽然可以简化拓扑简化、具备高可靠性的能力，但是对于网络有强制的拓扑形状限制，在网络的规模和灵活性上有所欠缺，只适合小规模网络构建，且一般适用于数据中心内部网络。而为了大规模网络扩展的TRILL/SPB/FabricPath/VPLS等技术，虽然解决了上述技术的不足，但对网络有特殊要求，即网络中的设备均要软硬件升级而支持此类新技术，带来部署成本的上升。 2.虚拟机规模受网络设备表项规格的限制 ​ 在大二层网络环境下，数据流均需要通过明确的网络寻址以保证准确到达目的地，因此网络设备的二层地址表项大小(即MAC地址表)，成为决定了云计算环境下虚拟机的规模的上限，并且因为表项并非百分之百的有效性，使得可用的虚机数量进一步降低，特别是对于低成本的接入设备而言，因其表项一般规格较小，限制了整个云计算数据中心的虚拟机数量，但如果其地址表项设计为与核心或网关设备在同一档次，则会提升网络建设成本。虽然核心或网关设备的MAC与ARP规格会随着虚拟机增长也面临挑战，但对于此层次设备能力而言，大规格是不可避免的业务支撑要求。减小接入设备规格压力的做法可以是分离网关能力，如采用多个网关来分担虚机的终结和承载，但如此也会带来成本的上升。 3.网络隔离/分离能力限制 ​ VLAN作为当前主流的网络隔离技术，在标准定义中只有12比特，也就是说可用的VLAN数量只有4000个左右。对于公有云或其它大型虚拟化云计算服务这种动辄上万甚至更多租户的场景而言，VLAN的隔离能力显然已经力不从心。 VLAXN网络的初相识1.VXLAN网络模型 从上图可以看到，VXLAN网络中出现了以下传统数据中心网络中没有的新元素： VTEP（VXLAN Tunnel Endpoints，VXLAN隧道端点）VXLAN网络的边缘设备，是VXLAN隧道的起点和终点，VXLAN报文的相关处理均在这上面进行。总之，它是VXLAN网络中绝对的主角。VTEP既可以是独立的网络设备（比如华为的CE系列交换机），也可以是虚拟机所在的服务器。那它究竟是如何发挥作用的呢？答案稍候揭晓。 VNI（VXLAN Network Identifier，VXLAN 网络标识符）前文提到，以太网数据帧中VLAN只占了12比特的空间，这使得VLAN的隔离能力在数据中心网络中力不从心。而VNI的出现，就是专门解决这个问题的。VNI是一种类似于VLAN ID的用户标示，一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VXLAN报文封装时，给VNI分配了足够的空间使其可以支持海量租户的隔离。详细的实现，我们将在后文中介绍。 VXLAN隧道“隧道”是一个逻辑上的概念，它并不新鲜，比如大家熟悉的GRE。说白了就是将原始报文“变身”下，加以“包装”，好让它可以在承载网络（比如IP网络）上传输。从主机的角度看，就好像原始报文的起点和终点之间，有一条直通的链路一样。而这个看起来直通的链路，就是“隧道”。顾名思义，“VXLAN隧道”便是用来传输经过VXLAN封装的报文的，它是建立在两个VTEP之间的一条虚拟通道。 2.VXLAN是如何解决以上挑战 2.1解决虚拟机迁移范围受到网络架构限制问题 ​ overlay网络的本质是在三层网络中实现二层网络的扩展。三层网络可以通过路由的方式在网络中分发，而路由网络本身并无特殊网络结构限制，具备良性大规模扩展能力，并且对设备本身无特殊要求，以高性能路由转发为佳，且路由网络本身具备很强的的故障自愈能力、负载均衡能力。前面提到，为了保证业务不中断，VM的迁移就必须发生在同一个二层域内。有了VTEP的封装机制和VXLAN隧道后，所谓的 “二层域”就可以轻而易举的突破物理上的界限？也就是说，在IP网络中， “明”里传输的是跨越三层网络的UDP报文，“暗”里却已经悄悄将源VM的原始报文送达目的VM。就好像在三层的网络之上，构建出了一个虚拟的二层网络，而且只要IP网络路由可达，这个虚拟的二层网络想做多大就做多大。 2.2解决虚拟机规模受网络设备表项规格的限制问题 ​ 既然无法提升设备表项规格，那就只能限制设备上的MAC表项，将大量VM的MAC地址“隐形”。VTEP会将VM发出的原始报文封装成一个新的UDP报文，并使用物理网络的IP和MAC地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就是说，网络中的其他设备看不到VM发送的原始报文。 ​ 如果服务器作为VTEP，那从服务器发送到接入设备的报文便是经过封装后的报文，这样，接入设备就不需要学习VM的MAC地址了，它只需要根据外层封装的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表项规格的限制了。 ​ 当然，如果网络设备作为VTEP，它还是需要学习VM的MAC地址。但是，从对报文进行封装的角度来说，网络设备的性能还是要比服务器强很多。 2.3解决网络隔离/分离能力限制 ​ 一个VNI代表了一个租户，属于不同VNI的虚拟机之间不能直接进行二层通信。VTEP在对报文进行VXLAN封装时，给VNI分配了24比特的空间，这就意味着VXLAN网络理论上支持多达16M（即：2^24-1）的租户隔离。相比VLAN，VNI的隔离能力得到了巨大的提升，有效得解决了云计算中海量租户隔离的问题。 3.VXLAN报文格式 VTEP对VM发送的原始以太帧（Original L2 Frame）进行了以下“包装”： VXLAN Header: ​ 增加VXLAN头（8字节），其中包含24比特的VNI字段，用来定义VXLAN网络中不同的租户。此外，还包含VXLAN Flags（8比特，取值为00001000）和两个保留字段（分别为24比特和8比特）。 UDP Header: ​ VXLAN头和原始以太帧一起作为UDP的数据。UDP头中，目的端口号（VXLAN Port）固定为4789，源端口号（UDP Src. Port）是原始以太帧通过哈希算法计算后的值。 Outer IP Header: ​ 封装外层IP头。其中，源IP地址（Outer Src. IP）为源VM所属VTEP的IP地址，目的IP地址（Outer Dst. IP）为目的VM所属VTEP的IP地址。 Outer MAC Header: ​ 封装外层以太头。其中，源MAC地址（Src. MAC Addr.）为源VM所属VTEP的MAC地址，目的MAC地址（Dst. MAC Addr.）为到达目的VTEP的路径上下一跳设备的MAC地址。 VXLAN报文转发机制以CE系列交换机的实现为例 1.建立VXLAN隧道 前面提到的“同一大二层域”，就类似于传统网络中VLAN（虚拟局域网）的概念，只不过在VXLAN网络中，它有另外一个名字，叫做Bridge-Domain，简称BD。 ​ 我们知道，不同的VLAN是通过VLAN ID来进行区分的，那不同的BD是如何进行区分的呢？其实前面已经提到了，就是通过VNI来区分的。对于CE系列交换机而言，BD与VNI是1：1的映射关系，这种映射关系是通过在VTEP上配置命令行建立起来的。配置如下： 12bridge-domain 10 //表示创建一个“大二层广播域”BD，其编号为10 vxlan vni 5000 //表示在BD 10下，指定与之关联的VNI为5000 VTEP会根据以上配置生成BD与VNI的映射关系表，该映射表可以通过命令行查看，如下所示： 12345&lt;HUAWEI&gt; display vxlan vniNumber of vxlan vni : 1VNI BD-ID State ----------------------------------5000 10 up 有了映射表后，进入VTEP的报文就可以根据自己所属的BD来确定报文封装时该添加哪个VNI。那么，报文根据什么来确定自己属于哪个BD呢？ 在回答“如何确定报文属于哪个BD”之前，必须先要回答“哪些报文要进入VXLAN隧道”。 ​ 在VXLAN网络中，VTEP上有一个叫做“二层子接口”的逻辑接口，主要做两件事：一是根据配置来检查哪些报文需要进入VXLAN隧道；二是判断对检查通过的报文做怎样的处理。在二层子接口上，可以根据需要定义不同的流封装类型（类似于传统网络中不同的接口类型）。CE系列交换机目前支持三种不同的流封装类型，分别是dot1q、untag和default，它们各自对报文的处理方式如表3-1所示。有了这张表，你就能明白哪些报文要进VXLAN隧道了。 流封装类型 允许进入VXLAN隧道的报文类型 报文进行封装前的处理 收到VXLAN报文并解封装后的处理 dot1q 只允许携带指定VLAN Tag的报文进入VXLAN隧道。（这里的“指定VLAN Tag”是通过命令进行配置的） 进行VXLAN封装前，先剥掉原始报文的外层VLAN Tag 进行VXLAN解封装后：若内层原始报文带有VLAN Tag，则先将该VLAN Tag替换为指定的VLAN Tag，再转发；若内层原始报文不带VLAN Tag，则先将其添加指定的VLAN Tag，再转发。 untag 只允许不携带VLAN Tag的报文进入VXLAN隧道。 进行VXLAN封装前，不对原始报文做处理，即不添加任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 default 允许所有报文进入VXLAN隧道，不论报文是否携带VLAN Tag。 进行VXLAN封装前，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 进行VXLAN解封装后，不对原始报文做处理，即不添加/不替换/不剥掉任何VLAN Tag。 说明：VXLAN隧道两端二层子接口的配置并不一定是完全对等的。正因为这样，才可能实现属于同一网段但是不同VLAN的两个VM通过VXLAN隧道进行通信。 看了上面的描述，再来回答“如何确定报文属于哪个BD”就非常简单了。其实，只要将二层子接口加入指定的BD，然后根据二层子接口上的配置，就可以确定报文属于哪个BD啦！ 比如下图所示的组网，我们可以分别在VTEP的两个物理接口10GE 1/0/1和10GE 1/0/2上配置不同流封装类型的二层子接口并将其分别加入不同的BD。 基于二层物理接口10GE 1/0/1，分别创建二层子接口10GE 1/0/1.1和10GE 1/0/1.2，且分别配置其流封装类型为dot1q和untag。配置如下： 123interface 10GE1/0/1.1 mode l2 //创建二层子接口10GE1/0/1.1 encapsulation dot1q vid 10 //只允许携带VLAN Tag 10的报文进入VXLAN隧道 bridge-domain 10 //报文进入的是BD 10 123interface 10GE1/0/1.2 mode l2 //创建二层子接口10GE1/0/1.2 encapsulation untag //只允许不携带VLAN Tag的报文进入VXLAN隧道 bridge-domain 20 //报文进入的是BD 20 基于二层物理接口10GE 1/0/2，创建二层子接口10GE 1/0/2.1，且流封装类型为default。配置如下： 123interface 10GE1/0/2.1 mode l2 //创建二层子接口10GE1/0/2.1 encapsulation default //允许所有报文进入VXLAN隧道 bridge-domain 30 //报文进入的是BD 30 此时你可能会有这样的疑问，为什么要在10GE 1/0/1上创建两个不同类型的子接口？是否还可以继续在10GE 1/0/1上创建一个default类型的二层子接口？换句话说，用户应该如何选择配置哪种类型的二层子接口？三种类型的二层子接口之间，是否存在配置约束关系？ 答案是不可以。其实根据上表的描述，这一点很容易理解。因为default类型的二层子接口允许所有报文进入VXLAN隧道，而dot1q和untag类型的二层子接口只允许某一类报文进入VXLAN隧道。这就决定了，default类型的二层子接口跟其他两种类型的二层子接口是不可以在同一物理接口上共存的。否则，报文到了接口之后如何判断要进入哪个二层子接口呢。所以，default类型的子接口，一般应用在经过此接口的报文均需要走同一条VXLAN隧道的场景，即下挂的VM全部属于同一BD。例如，图3-3中VM3和VM4均属于BD 30，则10GE 1/0/2上就可以创建default类型的二层子接口。 再来看下为什么可以在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。如图上所示，VM1和VM2分别属于VLAN 10和VLAN 20，且分别属于不同的大二层域BD 10和BD 20，显然他们发出的报文要进入不同的VXLAN隧道。如果VM1和VM2发出的报文在到达VTEP的10GE 1/0/1接口时，一个是携带VLAN 10的Tag的，一个是不携带VLAN Tag的（比如二层交换机上行连接VTEP的接口上配置的接口类型是Trunk，允许通过的VLAN为10和20，PVID为VLAN 20），则为了区分两种报文，就必须要在10GE 1/0/1上分别创建dot1q和untag类型的二层子接口。所以，当经过同一物理接口的报文既有带VLAN Tag的，又有不带VLAN Tag的，并且他们各自要进入不同的VXLAN隧道，则可以在该物理接口上同时创建dot1q和untag类型的二层子接口。 现在，我们可以来看下VXLAN隧道是怎么建立起来的了。一般而言，隧道的建立不外乎手工方式和自动方式两种。 手工方式这种方式需要用户手动指定VXLAN隧道的源和目的IP地址分别为本端和对端VTEP的IP地址，也就是人为的在本端VTEP和对端VTEP之间建立静态VXLAN隧道。对于CE系列交换机，以上配置是在NVE（Network Virtualization Edge）接口下完成的。配置过程如下： 1234interface Nve1 //创建逻辑接口NVE 1 source 1.1.1.1 //配置源VTEP的IP地址（推荐使用Loopback接口的IP地址） vni 5000 head-end peer-list 2.2.2.2 vni 5000 head-end peer-list 2.2.2.3 其中，vni 5000 head-end peer-list 2.2.2.2和vni 5000 head-end peer-list 2.2.2.3的配置，表示属于VNI 5000的对端VTEP有两个，IP地址分别为2.2.2.2和2.2.2.3。根据这两条配置，VTEP上会生成如下所示的一张表： 123456789&lt;HUAWEI&gt; display vxlan vni 5000 verbose BD ID : 10 State : up NVE : 288 Source : 1.1.1.1 UDP Port : 4789 BUM Mode : head-end Group Address : - Peer List : 2.2.2.2 2.2.2.3 根据上表中的Peer List，本端VTEP就可以知道属于同一BD（或同一VNI）的对端VTEP都有哪些，这也就决定了同一大二层广播域的范围。当VTEP收到BUM（Broadcast&amp;Unknown-unicast&amp;Multicast，广播&amp;未知单播&amp;组播）报文时，会将报文复制并发送给Peer List中所列的所有对端VTEP（这就好比广播报文在VLAN内广播）。因此，这张表也被称为“头端复制列表”。当VTEP收到已知单播报文时，会根据VTEP上的MAC表来确定报文要从哪条VXLAN隧道走。而此时Peer List中所列的对端，则充当了MAC表中“出接口”的角色。在后面的报文转发流程中，你将会看到头端复制列表是如何在VXLAN网络中指导报文进行转发的。 自动方式自动方式下VXLAN隧道的建立需要借助于其他的协议，例如BGP。CE系列交换机中，自动方式建立VXLAN隧道主要应用在EVN（Ethernet Virtual Network）和VXLAN的分布式网关场景中。本文不对该方式进行详细讲述，具体实现可参考EVN的相关资料。 从前面的描述我们知道，属于同一BD的VXLAN隧道可能不止一条，比如前面的头端复制列表中，同一个源端VTEP（1.1.1.1）对应了两个对端VTEP（2.2.2.2和2.2.2.3）。那就带来了另一个问题，报文到底应该走哪一条隧道呢？我们知道，基本的二三层转发中，二层转发依赖的是MAC表，如果没有对应的MAC表，则主机发送ARP广播报文请求对端的MAC地址；三层转发依赖的是FIB表。在VXLAN中，其实也是同样的道理。下面就让我们来看下，VXLAN网络中报文的转发流程。相信看完下面的内容，关于“如何确定报文要进哪条隧道”的疑惑也就迎刃而解了。 2.VXLAN网络中报文的转发流程 同子网互通 VM_A、VM_B和VM_C同属于10.1.1.0/24网段，且同属于VNI 5000。此时，VM_A想与VM_C进行通信。 ​ 由于是首次进行通信，VM_A上没有VM_C的MAC地址，所以会发送ARP广播报文请求VM_C的MAC地址。下面就让我们根据ARP请求报文及ARP应答报文的转发流程，来看下MAC地址是如何进行学习的。 ARP请求报文转发流程 ARP请求报文的转发流程如下： VM_A发送源MAC为MAC_A、目的MAC为全F、源IP为IP_A、目的IP为IP_C的ARP广播报文，请求VM_C的MAC地址。 VTEP_1收到ARP请求后，根据二层子接口上的配置判断报文需要进入VXLAN隧道。确定了报文所属BD后，也就确定了报文所属的VNI。同时，VTEP_1学习MAC_A、VNI和报文入接口（Port_1，即二层子接口对应的物理接口）的对应关系，并记录在本地MAC表中。之后，VTEP_1会根据头端复制列表对报文进行复制，并分别进行封装。 可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_1）的IP地址，外层目的IP地址为对端VTEP（VTEP_2和VTEP_3）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2和VTEP_3后，VTEP对报文进行解封装，得到VM_A发送的原始报文。同时，VTEP_2和VTEP_3学习VM_A的MAC地址、VNI和远端VTEP的IP地址（IP_1）的对应关系，并记录在本地MAC表中。之后，VTEP_2和VTEP_3根据二层子接口上的配置对报文进行相应的处理并在对应的二层域内广播。VM_B和VM_C接收到ARP请求后，比较报文中的目的IP地址是否为本机的IP地址。VM_B发现目的IP不是本机IP，故将报文丢弃；VM_C发现目的IP是本机IP，则对ARP请求做出应答。下面，让我们看下ARP应答报文是如何进行转发的。 ARP应答报文转发流程 ARP应答报文的转发流程如下： 由于此时VM_C上已经学习到了VM_A的MAC地址，所以ARP应答报文为单播报文。报文源MAC为MAC_C，目的MAC为MAC_A，源IP为IP_C、目的IP为IP_A。 VTEP_3接收到VM_C发送的ARP应答报文后，识别报文所属的VNI（识别过程与步骤2类似）。同时，VTEP_3学习MAC_C、VNI和报文入接口（Port_3）的对应关系，并记录在本地MAC表中。之后，VTEP_3对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP（VTEP_3）的IP地址，外层目的IP地址为对端VTEP（VTEP_1）的IP地址；外层源MAC地址为本地VTEP的MAC地址，而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_1后，VTEP_1对报文进行解封装，得到VM_C发送的原始报文。同时，VTEP_1学习VM_C的MAC地址、VNI和远端VTEP的IP地址（IP_3）的对应关系，并记录在本地MAC表中。之后，VTEP_1将解封装后的报文发送给VM_A。至此，VM_A和VM_C均已学习到了对方的MAC地址。之后，VM_A和VM_C将采用单播方式进行通信。 不同子网互通 ​ VM_A和VM_B分别属于10.1.10.0/24网段和10.1.20.0/24网段，且分别属于VNI 5000和VNI 6000。VM_A和VM_B对应的三层网关分别是VTEP_3上BDIF 10和BDIF 20的IP地址。VTEP_3上存在到10.1.10.0/24网段和10.1.20.0/24网段的路由。此时，VM_A想与VM_B进行通信。 ​ BDIF接口的功能与VLANIF接口类似，是基于BD创建的三层逻辑接口，用以实现不同子网VM之间或VXLAN网络与非VXLAN网络之间的通信。 由于是首次进行通信，且VM_A和VM_B处于不同网段，VM_A需要先发送ARP广播报文请求网关（BDIF 10）的MAC，获得网关的MAC后，VM_A先将数据报文发送给网关；之后网关也将发送ARP广播报文请求VM_B的MAC，获得VM_B的MAC后，网关再将数据报文发送给VM_B。以上MAC地址学习的过程与同子网互通中MAC地址学习的流程一致，不再赘述。现在假设VM_A和VM_B均已学到网关的MAC、网关也已经学到VM_A和VM_B的MAC，下面就让我们看下数据报文是如何从VM_A发送到VM_B的。 不同子网VM互通报文转发流程 数据报文从VM_A发送到VM_B的流程如下： VM_A先将数据报文发送给网关。报文的源MAC为MAC_A，目的MAC为网关BDIF 10的MAC_10，源IP地址为IP_A，目的IP为IP_B。 VTEP_1收到数据报文后，识别此报文所属的VNI（VNI 5000），并根据MAC表项对报文进行封装。可以看到，这里封装的外层源IP地址为本地VTEP的IP地址（IP_1），外层目的IP地址为对端VTEP的IP地址（IP_3）；外层源MAC地址为本地VTEP的MAC地址（MAC_1），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文进入VTEP_3，VTEP_3对报文进行解封装，得到VM_A发送的原始报文。然后，VTEP_3会对报文做如下处理： VTEP_3发现该报文的目的MAC为本机BDIF 10接口的MAC，而目的IP地址为IP_B（10.1.20.1），所以会根据路由表查找到IP_B的下一跳。 发现下一跳为10.1.20.10，出接口为BDIF 20。此时VTEP_3查询ARP表项，并将原始报文的源MAC修改为BDIF 20接口的MAC（MAC_20），将目的MAC修改为VM_B的MAC（MAC_B）。 报文到BDIF 20接口时，识别到需要进入VXLAN隧道（VNI 6000），所以根据MAC表对报文进行封装。这里封装的外层源IP地址为本地VTEP的IP地址（IP_3），外层目的IP地址为对端VTEP的IP地址（IP_2）；外层源MAC地址为本地VTEP的MAC地址（MAC_3），而外层目的MAC地址为去往目的IP的网络中下一跳设备的MAC地址。封装后的报文，根据外层MAC和IP信息，在IP网络中进行传输，直至到达对端VTEP。 报文到达VTEP_2后，VTEP_2对报文进行解封装，得到内层的数据报文，并将其发送给VM_B。 说明：VXLAN网络与非VXLAN网络之间的互通，也需要借助于三层网关。 VXLAN应用部署方式我们以下图所示的典型的“Spine-Leaf”数据中心组网为例，给大家介绍一下CE系列交换机VXLAN的应用场景和部署方案。 ​ 在上图所示的数据中心里，企业用户拥有多个部门（部门1和部门2），每个部门中拥有多个VM（VM1和VM3，VM2和VM4）。同部门的VM属于同一个网段，不同部门的VM属于不同的网段。用户希望同一部门VM之间、不同部门VM之间，VM与Internet之间均可相互访问。 VXLAN网络的子网互通 相同子网互通 部署方案如图所示，Leaf1和Leaf2作为VXLAN网络的VTEP，两个Leaf之间搭建VXLAN隧道，并在每个Leaf上部署VXLAN二层网关，即可实现同一部门VM之间的相互通信。此时Spine只作为VXLAN报文的转发节点，不感知VXLAN隧道的存在，可以是任意的三层网络设备。 不同子网互通（集中式网关） 部署方案如图4-2所示，Leaf1、Leaf2和Spine作为VXLAN网络的VTEP，Leaf1和Spine之间、Leaf2和Spine之间分别搭建VXLAN隧道，并在Spine上部署VXLAN三层网关，即可实现不同部门VM之间的相互通信。 不同子网互通（分布式网关） 出现背景细心的读者可能已经发现，在不同子网互通（集中式网关）中，同一Leaf（Leaf1）下挂的不同网段VM（VM1和VM2）之间的通信，都需要在Spine上进行绕行，这样就导致Leaf与Spine之间的链路上，存在冗余的报文，额外占用了大量的带宽。同时，Spine作为VXLAN三层网关时，所有通过三层转发的终端租户的表项都需要在该设备上生成。但是，Spine的表项规格有限，当终端租户的数量越来越多时，容易成为网络瓶颈。分布式网关的出现，很好的解决了这两个问题。 部署方案 同Leaf节点下不同部门VM之间的通信如图4-3所示，Leaf1作为VXLAN网络的VTEP，在Leaf1上部署VXLAN三层网关，即可实现同Leaf下不同部门VM之间的相互通信。此时，VM1和VM2互访时，流量只需要在Leaf1节点进行转发，不再需要经过Spine节点，从而节约了大量的带宽资源。 跨Leaf节点不同部门VM之间的通信如图4-3所示，Leaf1和Leaf2作为VXLAN网络的VTEP，在Leaf1和Leaf2上部署VXLAN三层网关。两个VXLAN三层网关之间通过BGP动态建立VXLAN隧道，并通过BGP的remote-nexthop属性发布本网关下挂的主机路由信息给其他BGP邻居，从而实现跨Leaf节点不同部门VM之间的相互通信。 说明：Leaf作为VXLAN三层网关时，只学习其下挂终端租户的表项，而不必像集中式三层网关一样，需要学习网络中所有终端租户的表项，从而解决了集中式三层网关带来表项瓶颈问题。 VXLAN网络的可靠性 随着网络的快速普及和应用的日益深入，基础网络的可靠性日益成为用户关注的焦点，如何能够保证网络传输不中断对于终端用户而言非常重要。在VXLAN网络的子网互通中，VM与Leaf之间，Leaf与Spine之间都是通过单归方式接入的。这种组网接入方式，显然已经不能满足用户对VXLAN网络可靠性的需求。这时，可以按照如下图所示方式，提升VXLAN网络的可靠性。 接入层的可靠性 通常采用堆叠（CSS）方式提升接入层的可靠性。这是因为，接入层的设备数量繁多，堆叠方式可以将多台交换机设备组合在一起，虚拟化成一台交换设备，所有配置均在这一台虚拟交换机上进行，从而简化了接入层设备的运维复杂度。此外，堆叠系统内成员交换机之间在进行冗余备份的同时，能够利用跨设备的Eth-Trunk实现设备间链路的负载分担。 参考： http://support.huawei.com/huaweiconnect/enterprise/forum.php?mod=viewthread&amp;tid=334207&amp;extra=page%3D&amp;page=1 http://blog.csdn.net/sinat_31828101/article/details/50504656]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[什么是overlay网络]]></title>
      <url>%2F2017%2F01%2F23%2F%E4%BB%80%E4%B9%88%E6%98%AFoverllay%E7%BD%91%E7%BB%9C%2F</url>
      <content type="text"><![CDATA[​ Overlay在网络技术领域，指的是一种网络架构上叠加的虚拟化技术模式，其大体框架是对基础网络不进行大规模修改的条件下，实现应用在网络上的承载，并能与其它网络业务分离，并且以基于IP的基础网络技术为主。 ​ 随着云计算虚拟化的驱动，基于主机虚拟化的Overlay技术出现，在服务器的Hypervisor内vSwitch上支持了基于IP的二层Overlay技术，通过更靠近应用的边缘来提供网络虚拟化服务，其目的是使虚拟机的部署与业务活动脱离物理网络及其限制，使得云计算的网络形态不断完善。主机的vSwitch支持基于IP的Overlay之后，虚机的二层访问直接构建在Overlay之上，物理网不再感知虚机的诸多特性。 存在三种不同的构建模式: Network Overlay 方案: ​ 所有终端均采用物理交换机作为VTEP节点,所有的物理接入交换机支持VXLAN，物理服务器支持SR-IOV功能，使虚拟机通过SR-IOV技术直接与物理交换机相连，虚拟机的流量在接入交换机上进行VXLAN报文的封装和卸载，对于非虚拟化服务器，直接连接支持VXLAN的接入交换机，服务器流量在接入交换机上进行VXLAN报文封装和卸载；当VXLAN网络需要与VLAN网络通信时，采用物理交换机做VXLAN GW，实现VXLAN网络主机与VLAN网络主机的通信；采用高端交换机做VXLAN IP GW，实现VXLAN网络与WAN以及Internet的互连。 Host Overlay 方案: ​ 所有终端均采用虚拟交换机作为VTEP节点，VTEP、VXLAN GW、VXLAN IP GW均通过安装在服务器上的软件实现，vSwitch实现VTEP功能，完成VXLAN报文的封装解封装；vFW等实现VXLAN GW功能，实现VXLAN网络与VLAN网络、物理服务器的互通；vRouter作为VXLAN IP GW，实现VXLAN网络与Internet和WAN的互联。在本组网中，由于所有VXLAN报文的封装卸载都通过软件实现，会占用部分服务器资源，当访问量大时，vRouter会成为系统瓶颈。 Hybrid Overlay 方案: ​ 既有物理交换机接入，又有虚拟交换机接入，且软件VTEP和硬件VTEP之间可以基于标准协议互通。上述两种组网方案中，网络Overlay方案与虚拟机相连，需要通过一些特殊的要求或技术实现虚拟机与VTEP的对接，组网不够灵活，但是主机Overlay方案与传统网络互通时，连接也比较复杂，且通过软件实现VXLAN IP GW也会成为整个网络的瓶颈，所以最理想的组网方案应该是一个结合了网络Overlay与主机Overlay两种方案优势的混合Overlay方案。如上图所示它通过vSwitch实现虚拟机的VTEP，通过物理交换机实现物理服务器的VTEP，通过物理交换机实现VXALN GW和VXLAN IP GW；混合式Overlay组网方案对虚拟机和物理服务器都能够很好的兼容，同时通过专业的硬件交换机实现VXLAN IP GW从而承载超大规模的流量转发，是目前应用比较广泛的组网方案。 PS: OpenStack 采用的是第二种方案 ​ 另外IETF在Overlay技术领域有如下三大技术路线正在讨论，为简单起见，只讨论基于IPv4的Overlay相关内容。 1 . VXLAN。 VXLAN是将以太网报文封装在UDP传输层上的一种隧道转发模式，目的UDP端口号为4798；为了使VXLAN充分利用承载网络路由的均衡性，VXLAN通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为UDP的号；采用24比特标识二层网络分段，称为VNI(VXLAN Network Identifier)，类似于VLAN ID作用；未知目的、广播、组播等网络流量均被封装为组播转发，物理网络要求支持任意源组播(ASM)。 2. GRE/NVGRE（Generic Routing Encapsulation，通用路由协议封装）是一种 IP-over-IP 的隧道。 NVGRE是将以太网报文封装在GRE内的一种隧道转发模式；采用24比特标识二层网络分段，称为VSI(Virtual Subnet Identifier)，类似于VLAN ID作用；为了使NVGRE利用承载网络路由的均衡性，NVGRE在GRE扩展字段flow ID，这就要求物理网络能够识别到GRE隧道的扩展信息，并以flow ID进行流量分担；未知目的、广播、组播等网络流量均被封装为组播转发。 3.STT（Stateless Transport Tunneling）。 STT利用了TCP的数据封装形式，但改造了TCP的传输机制，数据传输不遵循TCP状态机，而是全新定义的无状态机制，将TCP各字段意义重新定义，无需三次握手建立TCP连接，因此称为无状态TCP；以太网数据封装在无状态TCP；采用64比特Context ID标识二层网络分段；为了使STT充分利用承载网络路由的均衡性，通过将原始以太网数据头(MAC、IP、四层端口号等)的HASH值作为无状态TCP的源端口号；未知目的、广播、组播等网络流量均被封装为组播转发。 参考: http://www.h3c.com.cn/About_H3C/Company_Publication/IP_Lh/2013/04/Home/Catalog/201309/796466_30008_0.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[pyinstaller使用技巧]]></title>
      <url>%2F2017%2F01%2F22%2Fpyinstaller%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[​ 不经意间发现了这个工具pyinstaller2.0。它的功能是把python脚本打包成windows的可执行文件，这样就可以方便使用程序了。为了玩一下，于是写了一个图片分类的脚本，按照jpg, gif, png后缀将图片分别存储在各自文件夹中。脚本放在github上了。https://github.com/Luckylau/Useful-Python-Sample/blob/master/useful-tools/classify_Pic.py pythoninstall2.0运行前需要安装pywin32，假如你使用的是python 2.7(64位)，需要在官网 https://sourceforge.net/projects/pywin32/files/pywin32找到对应的版本 我的环境：win 10 python 2.7 (64位) ,pywin32-220.win-amd64-py2.7 打开pyinstall-2.0文件夹 如下图，shift+右键鼠标打开cmd,注意的是文件的路径不能有中文，我之前用的路径是D:\日常资料\日常资料\图片\大雪，会出现编码问题 在cmd上执行,不用理会error报错。 pyinstaller参数有如下选项，我们用的是-F, 后面跟的是要打包的python脚本的位置。 可选的opts有： -F, –onefile 打包成一个exe文件。 -D, –onedir 创建一个目录，包含exe文件，但会依赖很多文件（默认选项）。 -c, –console, –nowindowed 使用控制台，无界面(默认) -w, –windowed, –noconsole 使用窗口，无控制台 完毕之后，会在下图所示位置生成exe文件。 我们在该目录下取得exe文件，执行效果和python脚本是一样的。大功告成~~~~]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo备份小技巧]]></title>
      <url>%2F2017%2F01%2F21%2Fhexo%E5%A4%87%E4%BB%BD%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[提交到github上备份: 12345678910111213cd blog/hexo# 初始化仓库git initgit add .git commit -m &quot;init&quot;# 建一个分支git checkout -b hexo# 删除本地的master分支git branch -d master# 添加远程git remote add origin https://github.com/用户名/用户名.github.io.git# 保存git push -u origin hexo 更换环境时: 12345678910111213141516#1.安装git(配置git),nodejs;其中nodejs会出现权限，需要管理员运行#2.克隆到本地git clone https://github.com/用户名/用户名.github.io.git hexocd hexo git checkout hexo#3.安装各种npm包npm config set registry https://registry.npm.taobao.orgnpm install -g hexo-clinpm installnpm install hexo-deployer-git --save#用于markdown插入图片,首先确认 _config.yml 中有 post_asset_folder:truenpm install https://github.com/CodeFalling/hexo-asset-image --save#4 部署hexo cleanhexo generatehexo deploy]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python中的struct模块]]></title>
      <url>%2F2017%2F01%2F19%2FPython%E4%B8%AD%E7%9A%84struct%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[​ python的struct模块，是在查看RYU控制器Openflow协议的实现源码接触到的。RYU控制器解包和封包就是用struct模块实现的。 ​ 在C语言中，struct结构体里面可以包含不同数据类型，比如int ,char,bool等。但是一旦涉及到网络通信时，传递的是二进制数据流（binary data）。对于二进制字符串，不必担心，但是对于如int，char等基本数据类型，需要有一种机制将这些特定的结构体类型打包成二进制流的字符串然后再在网络传输，同时接收端也需要通过某种机制进行解包还原出原始的结构体数据。 ​ python中的struct模块就提供了这样的机制，该模块的主要作用就是对python基本类型值与用python字符串格式表示的C struct类型间的转化，如下图: 1.简单演示 12345678910111213141516171819import structimport binasciivalues=(2017,'luckylau0',1.19)s=struct.Struct('I9sf')packed_data = s.pack(*values)#打包unpacked_data = s.unpack(packed_data)#解包print 'Original values:', valuesprint 'Format string :', s.formatprint 'Uses :', s.size, 'bytes'print struct.calcsize('I9sf')print 'Packed Value :', binascii.hexlify(packed_data)print 'Unpacked Type :', type(unpacked_data), ' Value:', unpacked_data#输出Original values: (2017, 'luckylau0', 1.19)Format string : I9sfUses : 20 bytes20Packed Value : e10700006c75636b796c617530000000ec51983fUnpacked Type : &lt;type 'tuple'&gt; Value: (2017, 'luckylau0', 1.190000057220459) ​ 代码中，首先定义了一个元组数据，包含int、string、float三种数据类型，然后定义了struct对象，并制定了format‘I8sf’，I 表示int ,8s表示八个字符长度的字符串，f 表示 float。最后通过struct的pack和unpack进行打包和解包。通过输出结果可以发现，value被pack之后，转化为了一段二进制字节串，而unpack可以把该字节串再转换回一个元组，但是值得注意的是对于float的精度发生了改变，这是由一些比如操作系统等客观因素所决定的。 2.字节顺序 ​ 打包的后的字节顺序默认上是由操作系统的决定的，当然struct模块也提供了自定义字节顺序的功能 ​ 例如采用小端存储 s = struct.Struct(‘&lt;I3sf’) 3.利用buffer，使用pack_into和unpack_from方法 12345678910111213141516171819202122import structimport binasciiimport ctypes values1 = (1, 'abc', 2.7)values2 = ('defg',101)s1 = struct.Struct('I3sf')s2 = struct.Struct('4sI') prebuffer = ctypes.create_string_buffer(s1.size+s2.size)print 'Before :',binascii.hexlify(prebuffer)s1.pack_into(prebuffer,0,*values1)s2.pack_into(prebuffer,s1.size,*values2)print 'After pack:',binascii.hexlify(prebuffer)print s1.unpack_from(prebuffer,0)print s2.unpack_from(prebuffer,s1.size)#输出Before : 0000000000000000000000000000000000000000After pack: 0100000061626300cdcc2c406465666765000000(1, 'abc', 2.700000047683716)('defg', 101) ​ 使用二进制打包数据的场景大部分都是对性能要求比较高的使用环境，所以上面提到的pack方法都是对输入数据进行操作后重新创建了一个内存空间用于返回，也就是说我们每次pack都会在内存中分配出相应的内存资源，这有时是一种很大的性能浪费。pack_into() 和 unpack_from()的方法就是对一个已经提前分配好的buffer进行字节的填充，而不会每次都产生一个新对象对字节进行存储。在RYU控制器中就是使用这两种方法。 4.总结： struct 模块 Python的struct库是一个简单的,高效的数据封装\解封装的库。主要包含5个函数: struct.pack(fmt, v1, v2, …): 将V1,V2等值按照对应的fmt(format)进行封装。 struct.unpack(fmt, string): 将string按照fmt的格式解封。 struct.pack_into(fmt, buffer, offset, v1, v2, …): 将V1,V2等值按照对应的fmt(format)封装到buffer中，从初始位置offset开始。 struct.unpack_from(fmt, buffer[offset=0，]): 按照fmt的格式，从offset开始将buffer解封。 struct.calcsize(fmt)： 计算对应的fmt的长度。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(3)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-3%2F</url>
      <content type="text"><![CDATA[2015年-2016年（35本书）2015年（4本书） 63.《黑客与画家》-Paul Graham 64.《文明之光》-吴军 65.《向死而生》-李开复 66.《大学之路（上）》-吴军 2016年（31本书） 67.《硅谷之谜》-吴军 68.《时间的针脚》-玛利亚杜埃尼亚斯 69.《动物庄园》-奥威尔 70.《绝望锻炼了我：朴槿惠自传》-朴槿惠 71.《解忧杂货店》-东野圭吾 72.《激荡三十年上》-吴晓波 73.《疑问集》-聂鲁达 74.《硅谷钢铁侠：埃隆·马斯克的冒险人生》-阿什利·范斯 75.《鱼羊野史第一卷》-高晓松 76.《你一定爱读的极简欧洲史》-约翰·赫斯特 77.《这么慢,那么美》-罗敷 78.《一个人的朝圣》-蕾秋·乔伊斯 79.《野火集：三十周年纪念版》-龙应台 80.《我们仨》-杨绛 81.《人间失格》-太宰治 82.《在绝望中寻找希望》-俞敏洪 83.《当尼采哭泣》-欧文 D.亚隆 84.《念完哈佛念阿弥陀佛》-陈宇廷 85.《你今天真好看》-莉兹克里莫 86.《我们生活在巨大差异里》-余华 87.《梦里花落知多少》-三毛 88.《纯真博物馆》-奥尔罕帕慕克 89.《岛上书店》-加布瑞埃拉泽文 90.《我与地坛》-史铁生 91.《史玉柱自述：我的营销心得》-史玉柱 92.《飞鸟集》-泰戈尔 93.《我可以咬你一口吗？》-利兹克利莫 94.《末日巨塔-基地组织与911之路》-劳伦斯赖特 95.《菊与刀:日本文化类型》-鲁思本尼迪克特 96.《小王子》-安托万德圣埃克苏佩里 97.《爱你就像爱生命》-王小波]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单(2)]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95-2%2F</url>
      <content type="text"><![CDATA[2012年-2014年（37本书）2012年（7本书） 26.《爱的艺术》-艾弗洛姆 27.《平凡的世界》-路遥 28.《人生课》-张岱年 29.《世间最美丽的情郎：仓央嘉措的情与诗》-王臣 30.《追风筝的人》-(美国）胡赛尼 31.《纳兰词》-纳兰性德 32.《阿德勒谈灵魂与情感》-阿尔弗雷德阿德勒 2013年（13本书） 33.《促销的本质》-山姆沃尔顿 34.《历史是个什么玩意》-袁腾飞 35.《世界如此险恶，你要内心强大2》-石勇 36.《少有人走的路1》-M·斯科特·派克 37.《世界如此险恶，你要内心强大1》-石勇 38.《明朝那些事儿》-当年明月 39.《天才在左疯子在右》-高铭 40.《哲学与人生I》-傅佩荣 41.《哲学与人生II》-傅佩荣 42.《乌合之众》（法译本）-[法]古斯塔夫·勒庞 43.《万历十五年（增订纪念本）》-[美]黄仁宇 44.《沉默的大多数》-王小波 45.《自控力》-凯利·麦格尼格尔 2014年（17本书） 46.《七里香》，《无怨的青春》，《时光九篇》，《边缘光影》，《迷途诗册》，《我折叠着我的爱》-席慕容 47.《蒙田随笔》-蒙田（上海书店出版社） 48.《读书与做人》-季羡林 49.《男人来自火星，女人来自金星1》-约翰格雷 50.《男人来自火星，女人来自金星2》-约翰格雷 51.《超越自卑》-阿尔弗雷德阿德勒 52.《苏菲的世界》-乔斯坦贾德 53.《德意志的另一行泪》-朱维毅 54.《浪潮之巅》-吴军 55.《如果在冬夜，一个旅人》-[意大利] 伊塔洛·卡尔维诺 56.《审美与人的自由》-刘晓波 57.《撒哈拉的故事》-三毛 58.《文明之光》-吴军 59.《悉达多》-[德]赫尔曼黑塞 60.《呼兰河传》-萧红 61.《月亮与六便士》-毛姆 62.《人类的群星闪耀时》-斯蒂芬茨威格]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阅读书单]]></title>
      <url>%2F2017%2F01%2F19%2F%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95%2F</url>
      <content type="text"><![CDATA[2009年-2011年（25本书）1.《谈美》-朱光潜 2.《安娜·卡列尼娜》（上下册）-（俄罗斯）托尔斯泰 3.《遇见未知的自己》- 张德芬 4.《人生若只如初见古典诗词的美丽与哀愁》- 安意如 5.《宋词三百首》- 上疆村民选编 6.《世界因你不同——李开复自传》- 李开复 范海涛 7.《思无邪：追绎前生的记忆》-安意如 8.《看张·爱玲画语》-安意如 9.《林肯传 》-戴尔·卡耐基 10.《富豪发家史》-子志编著 11.《水知道答案》-〔日〕江本胜 12.《彼得大帝》-帕甫连科 13.《活着就是为了改变世界》-杰弗里·扬,威廉西蒙 14.《我是沃兹：一段硅谷和苹果的悲情罗曼史》-斯蒂夫沃兹尼亚 15.《美国通史(上)》 16.《美国通史(下)》 17.《爱情诗集》- 文爱艺 18.《麦田里的守望者》-J.D塞林格 19.《批评官员的尺度：《纽约时报》诉警察局长沙利文案》-安东尼 20.《你是那人间的四月天》-林徽因 21.《汪国真经典诗文》-汪国真 22.《中国人的品格》-罗家伦 23.《蒙田随笔》-蒙田 24.《汪国真精选集》 25.《巨流河》-齐邦媛]]></content>
    </entry>

    
  
  
</search>
